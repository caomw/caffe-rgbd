Vendor:  Continuum Analytics, Inc.
Package: mkl
Message: trial mode expires in 10 days
Vendor:  Continuum Analytics, Inc.
Package: mkl
Message: trial mode expires in 10 days
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0302 01:27:40.205600 29253 solver.cpp:48] Initializing solver from parameters: 
base_lr: 0.01
display: 20
max_iter: 100000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 10000
snapshot: 5000
snapshot_prefix: "/nfs.yoda/xiaolonw/fast_rcnn/models_sunrgbd/pre_cls_1fc_scratch/model_"
solver_mode: GPU
net: "train.prototxt"
I0302 01:27:40.207401 29253 solver.cpp:91] Creating training net from net file: train.prototxt
I0302 01:27:40.208941 29253 net.cpp:49] Initializing net from parameters: 
name: "sungrbd"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: false
    crop_size: 128
    mean_value: 1
  }
  image_data_param {
    source: "/nfs/hn38/users/xiaolonw/sunrgbd/SUNRGBDtoolbox/trainlist2.txt"
    batch_size: 100
    shuffle: true
    new_height: 128
    new_width: 128
    root_folder: "/scratch/xiaolonw/sunrgbd/data/"
  }
}
layer {
  name: "da_conv1"
  type: "Convolution"
  bottom: "data"
  top: "da_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "da_conv1"
  top: "bn1"
}
layer {
  name: "da_relu1"
  type: "ReLU"
  bottom: "bn1"
  top: "bn1"
  relu_param {
    negative_slope: 0.2
  }
}
layer {
  name: "da_conv2"
  type: "Convolution"
  bottom: "bn1"
  top: "da_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 2
    kernel_size: 5
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "da_conv2"
  top: "bn2"
}
layer {
  name: "da_relu2"
  type: "ReLU"
  bottom: "bn2"
  top: "bn2"
  relu_param {
    negative_slope: 0.2
  }
}
layer {
  name: "da_conv3"
  type: "Convolution"
  bottom: "bn2"
  top: "da_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "da_conv3"
  top: "bn3"
}
layer {
  name: "da_relu3"
  type: "ReLU"
  bottom: "bn3"
  top: "bn3"
  relu_param {
    negative_slope: 0.2
  }
}
layer {
  name: "da_conv4"
  type: "Convolution"
  bottom: "bn3"
  top: "da_conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "da_conv4"
  top: "bn4"
}
layer {
  name: "da_relu4"
  type: "ReLU"
  bottom: "bn4"
  top: "bn4"
  relu_param {
    negative_slope: 0.2
  }
}
layer {
  name: "da_conv5"
  type: "Convolution"
  bottom: "bn4"
  top: "da_conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn5"
  type: "BatchNorm"
  bottom: "da_conv5"
  top: "bn5"
}
layer {
  name: "da_relu5"
  type: "ReLU"
  bottom: "bn5"
  top: "bn5"
  relu_param {
    negative_slope: 0.2
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "bn5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "cls_score"
  type: "InnerProduct"
  bottom: "pool5"
  top: "cls_score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 19
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss_cls"
  type: "SoftmaxWithLoss"
  bottom: "cls_score"
  bottom: "label"
  top: "loss_cls"
}
I0302 01:27:40.209038 29253 layer_factory.hpp:77] Creating layer data
I0302 01:27:40.209059 29253 net.cpp:106] Creating Layer data
I0302 01:27:40.209065 29253 net.cpp:411] data -> data
I0302 01:27:40.209081 29253 net.cpp:411] data -> label
I0302 01:27:40.209682 29253 image_data_layer.cpp:38] Opening file /nfs/hn38/users/xiaolonw/sunrgbd/SUNRGBDtoolbox/trainlist2.txt
I0302 01:27:40.281720 29253 image_data_layer.cpp:51] Shuffling data
I0302 01:27:40.282872 29253 image_data_layer.cpp:56] A total of 4845 images.
I0302 01:27:40.297765 29253 image_data_layer.cpp:84] output data size: 100,6,128,128
I0302 01:27:40.359657 29253 net.cpp:150] Setting up data
I0302 01:27:40.359699 29253 net.cpp:157] Top shape: 100 6 128 128 (9830400)
I0302 01:27:40.359707 29253 net.cpp:157] Top shape: 100 (100)
I0302 01:27:40.359710 29253 net.cpp:165] Memory required for data: 39322000
I0302 01:27:40.359719 29253 layer_factory.hpp:77] Creating layer da_conv1
I0302 01:27:40.359741 29253 net.cpp:106] Creating Layer da_conv1
I0302 01:27:40.359746 29253 net.cpp:454] da_conv1 <- data
I0302 01:27:40.359755 29253 net.cpp:411] da_conv1 -> da_conv1
I0302 01:27:40.361129 29253 net.cpp:150] Setting up da_conv1
I0302 01:27:40.361142 29253 net.cpp:157] Top shape: 100 64 64 64 (26214400)
I0302 01:27:40.361146 29253 net.cpp:165] Memory required for data: 144179600
I0302 01:27:40.361160 29253 layer_factory.hpp:77] Creating layer bn1
I0302 01:27:40.361169 29253 net.cpp:106] Creating Layer bn1
I0302 01:27:40.361174 29253 net.cpp:454] bn1 <- da_conv1
I0302 01:27:40.361181 29253 net.cpp:411] bn1 -> bn1
I0302 01:27:40.361408 29253 net.cpp:150] Setting up bn1
I0302 01:27:40.361418 29253 net.cpp:157] Top shape: 100 64 64 64 (26214400)
I0302 01:27:40.361420 29253 net.cpp:165] Memory required for data: 249037200
I0302 01:27:40.361435 29253 layer_factory.hpp:77] Creating layer da_relu1
I0302 01:27:40.361443 29253 net.cpp:106] Creating Layer da_relu1
I0302 01:27:40.361448 29253 net.cpp:454] da_relu1 <- bn1
I0302 01:27:40.361452 29253 net.cpp:397] da_relu1 -> bn1 (in-place)
I0302 01:27:40.361465 29253 net.cpp:150] Setting up da_relu1
I0302 01:27:40.361470 29253 net.cpp:157] Top shape: 100 64 64 64 (26214400)
I0302 01:27:40.361474 29253 net.cpp:165] Memory required for data: 353894800
I0302 01:27:40.361479 29253 layer_factory.hpp:77] Creating layer da_conv2
I0302 01:27:40.361488 29253 net.cpp:106] Creating Layer da_conv2
I0302 01:27:40.361492 29253 net.cpp:454] da_conv2 <- bn1
I0302 01:27:40.361498 29253 net.cpp:411] da_conv2 -> da_conv2
I0302 01:27:40.365769 29253 net.cpp:150] Setting up da_conv2
I0302 01:27:40.365783 29253 net.cpp:157] Top shape: 100 128 32 32 (13107200)
I0302 01:27:40.365787 29253 net.cpp:165] Memory required for data: 406323600
I0302 01:27:40.365793 29253 layer_factory.hpp:77] Creating layer bn2
I0302 01:27:40.365800 29253 net.cpp:106] Creating Layer bn2
I0302 01:27:40.365803 29253 net.cpp:454] bn2 <- da_conv2
I0302 01:27:40.365808 29253 net.cpp:411] bn2 -> bn2
I0302 01:27:40.365994 29253 net.cpp:150] Setting up bn2
I0302 01:27:40.366003 29253 net.cpp:157] Top shape: 100 128 32 32 (13107200)
I0302 01:27:40.366006 29253 net.cpp:165] Memory required for data: 458752400
I0302 01:27:40.366017 29253 layer_factory.hpp:77] Creating layer da_relu2
I0302 01:27:40.366025 29253 net.cpp:106] Creating Layer da_relu2
I0302 01:27:40.366030 29253 net.cpp:454] da_relu2 <- bn2
I0302 01:27:40.366034 29253 net.cpp:397] da_relu2 -> bn2 (in-place)
I0302 01:27:40.366042 29253 net.cpp:150] Setting up da_relu2
I0302 01:27:40.366046 29253 net.cpp:157] Top shape: 100 128 32 32 (13107200)
I0302 01:27:40.366050 29253 net.cpp:165] Memory required for data: 511181200
I0302 01:27:40.366053 29253 layer_factory.hpp:77] Creating layer da_conv3
I0302 01:27:40.366060 29253 net.cpp:106] Creating Layer da_conv3
I0302 01:27:40.366065 29253 net.cpp:454] da_conv3 <- bn2
I0302 01:27:40.366070 29253 net.cpp:411] da_conv3 -> da_conv3
I0302 01:27:40.372233 29253 net.cpp:150] Setting up da_conv3
I0302 01:27:40.372248 29253 net.cpp:157] Top shape: 100 256 16 16 (6553600)
I0302 01:27:40.372251 29253 net.cpp:165] Memory required for data: 537395600
I0302 01:27:40.372259 29253 layer_factory.hpp:77] Creating layer bn3
I0302 01:27:40.372267 29253 net.cpp:106] Creating Layer bn3
I0302 01:27:40.372272 29253 net.cpp:454] bn3 <- da_conv3
I0302 01:27:40.372277 29253 net.cpp:411] bn3 -> bn3
I0302 01:27:40.372454 29253 net.cpp:150] Setting up bn3
I0302 01:27:40.372462 29253 net.cpp:157] Top shape: 100 256 16 16 (6553600)
I0302 01:27:40.372467 29253 net.cpp:165] Memory required for data: 563610000
I0302 01:27:40.372474 29253 layer_factory.hpp:77] Creating layer da_relu3
I0302 01:27:40.372483 29253 net.cpp:106] Creating Layer da_relu3
I0302 01:27:40.372488 29253 net.cpp:454] da_relu3 <- bn3
I0302 01:27:40.372493 29253 net.cpp:397] da_relu3 -> bn3 (in-place)
I0302 01:27:40.372498 29253 net.cpp:150] Setting up da_relu3
I0302 01:27:40.372503 29253 net.cpp:157] Top shape: 100 256 16 16 (6553600)
I0302 01:27:40.372505 29253 net.cpp:165] Memory required for data: 589824400
I0302 01:27:40.372509 29253 layer_factory.hpp:77] Creating layer da_conv4
I0302 01:27:40.372515 29253 net.cpp:106] Creating Layer da_conv4
I0302 01:27:40.372519 29253 net.cpp:454] da_conv4 <- bn3
I0302 01:27:40.372524 29253 net.cpp:411] da_conv4 -> da_conv4
I0302 01:27:40.392678 29253 net.cpp:150] Setting up da_conv4
I0302 01:27:40.392695 29253 net.cpp:157] Top shape: 100 512 8 8 (3276800)
I0302 01:27:40.392699 29253 net.cpp:165] Memory required for data: 602931600
I0302 01:27:40.392710 29253 layer_factory.hpp:77] Creating layer bn4
I0302 01:27:40.392719 29253 net.cpp:106] Creating Layer bn4
I0302 01:27:40.392724 29253 net.cpp:454] bn4 <- da_conv4
I0302 01:27:40.392732 29253 net.cpp:411] bn4 -> bn4
I0302 01:27:40.392920 29253 net.cpp:150] Setting up bn4
I0302 01:27:40.392928 29253 net.cpp:157] Top shape: 100 512 8 8 (3276800)
I0302 01:27:40.392932 29253 net.cpp:165] Memory required for data: 616038800
I0302 01:27:40.392941 29253 layer_factory.hpp:77] Creating layer da_relu4
I0302 01:27:40.392948 29253 net.cpp:106] Creating Layer da_relu4
I0302 01:27:40.392953 29253 net.cpp:454] da_relu4 <- bn4
I0302 01:27:40.392957 29253 net.cpp:397] da_relu4 -> bn4 (in-place)
I0302 01:27:40.392966 29253 net.cpp:150] Setting up da_relu4
I0302 01:27:40.392971 29253 net.cpp:157] Top shape: 100 512 8 8 (3276800)
I0302 01:27:40.392973 29253 net.cpp:165] Memory required for data: 629146000
I0302 01:27:40.392976 29253 layer_factory.hpp:77] Creating layer da_conv5
I0302 01:27:40.392983 29253 net.cpp:106] Creating Layer da_conv5
I0302 01:27:40.392987 29253 net.cpp:454] da_conv5 <- bn4
I0302 01:27:40.392994 29253 net.cpp:411] da_conv5 -> da_conv5
I0302 01:27:40.403224 29253 net.cpp:150] Setting up da_conv5
I0302 01:27:40.403237 29253 net.cpp:157] Top shape: 100 128 8 8 (819200)
I0302 01:27:40.403240 29253 net.cpp:165] Memory required for data: 632422800
I0302 01:27:40.403247 29253 layer_factory.hpp:77] Creating layer bn5
I0302 01:27:40.403255 29253 net.cpp:106] Creating Layer bn5
I0302 01:27:40.403259 29253 net.cpp:454] bn5 <- da_conv5
I0302 01:27:40.403264 29253 net.cpp:411] bn5 -> bn5
I0302 01:27:40.403444 29253 net.cpp:150] Setting up bn5
I0302 01:27:40.403450 29253 net.cpp:157] Top shape: 100 128 8 8 (819200)
I0302 01:27:40.403455 29253 net.cpp:165] Memory required for data: 635699600
I0302 01:27:40.403463 29253 layer_factory.hpp:77] Creating layer da_relu5
I0302 01:27:40.403470 29253 net.cpp:106] Creating Layer da_relu5
I0302 01:27:40.403475 29253 net.cpp:454] da_relu5 <- bn5
I0302 01:27:40.403480 29253 net.cpp:397] da_relu5 -> bn5 (in-place)
I0302 01:27:40.403486 29253 net.cpp:150] Setting up da_relu5
I0302 01:27:40.403491 29253 net.cpp:157] Top shape: 100 128 8 8 (819200)
I0302 01:27:40.403493 29253 net.cpp:165] Memory required for data: 638976400
I0302 01:27:40.403496 29253 layer_factory.hpp:77] Creating layer pool5
I0302 01:27:40.403504 29253 net.cpp:106] Creating Layer pool5
I0302 01:27:40.403507 29253 net.cpp:454] pool5 <- bn5
I0302 01:27:40.403512 29253 net.cpp:411] pool5 -> pool5
I0302 01:27:40.403553 29253 net.cpp:150] Setting up pool5
I0302 01:27:40.403559 29253 net.cpp:157] Top shape: 100 128 4 4 (204800)
I0302 01:27:40.403563 29253 net.cpp:165] Memory required for data: 639795600
I0302 01:27:40.403565 29253 layer_factory.hpp:77] Creating layer cls_score
I0302 01:27:40.403578 29253 net.cpp:106] Creating Layer cls_score
I0302 01:27:40.403583 29253 net.cpp:454] cls_score <- pool5
I0302 01:27:40.403587 29253 net.cpp:411] cls_score -> cls_score
I0302 01:27:40.404788 29253 net.cpp:150] Setting up cls_score
I0302 01:27:40.404800 29253 net.cpp:157] Top shape: 100 19 (1900)
I0302 01:27:40.404803 29253 net.cpp:165] Memory required for data: 639803200
I0302 01:27:40.404811 29253 layer_factory.hpp:77] Creating layer loss_cls
I0302 01:27:40.404819 29253 net.cpp:106] Creating Layer loss_cls
I0302 01:27:40.404824 29253 net.cpp:454] loss_cls <- cls_score
I0302 01:27:40.404829 29253 net.cpp:454] loss_cls <- label
I0302 01:27:40.404834 29253 net.cpp:411] loss_cls -> loss_cls
I0302 01:27:40.404847 29253 layer_factory.hpp:77] Creating layer loss_cls
I0302 01:27:40.404937 29253 net.cpp:150] Setting up loss_cls
I0302 01:27:40.404943 29253 net.cpp:157] Top shape: (1)
I0302 01:27:40.404947 29253 net.cpp:160]     with loss weight 1
I0302 01:27:40.404955 29253 net.cpp:165] Memory required for data: 639803204
I0302 01:27:40.404959 29253 net.cpp:226] loss_cls needs backward computation.
I0302 01:27:40.404963 29253 net.cpp:226] cls_score needs backward computation.
I0302 01:27:40.404968 29253 net.cpp:226] pool5 needs backward computation.
I0302 01:27:40.404970 29253 net.cpp:226] da_relu5 needs backward computation.
I0302 01:27:40.404974 29253 net.cpp:226] bn5 needs backward computation.
I0302 01:27:40.404978 29253 net.cpp:226] da_conv5 needs backward computation.
I0302 01:27:40.404980 29253 net.cpp:226] da_relu4 needs backward computation.
I0302 01:27:40.404984 29253 net.cpp:226] bn4 needs backward computation.
I0302 01:27:40.404988 29253 net.cpp:226] da_conv4 needs backward computation.
I0302 01:27:40.404991 29253 net.cpp:226] da_relu3 needs backward computation.
I0302 01:27:40.404994 29253 net.cpp:226] bn3 needs backward computation.
I0302 01:27:40.404997 29253 net.cpp:226] da_conv3 needs backward computation.
I0302 01:27:40.405001 29253 net.cpp:226] da_relu2 needs backward computation.
I0302 01:27:40.405004 29253 net.cpp:226] bn2 needs backward computation.
I0302 01:27:40.405009 29253 net.cpp:226] da_conv2 needs backward computation.
I0302 01:27:40.405011 29253 net.cpp:226] da_relu1 needs backward computation.
I0302 01:27:40.405015 29253 net.cpp:226] bn1 needs backward computation.
I0302 01:27:40.405019 29253 net.cpp:226] da_conv1 needs backward computation.
I0302 01:27:40.405024 29253 net.cpp:228] data does not need backward computation.
I0302 01:27:40.405027 29253 net.cpp:270] This network produces output loss_cls
I0302 01:27:40.405045 29253 net.cpp:283] Network initialization done.
I0302 01:27:40.405107 29253 solver.cpp:60] Solver scaffolding done.
I0302 01:27:42.199970 29253 net.cpp:816] Ignoring source layer da_roi_pool5
I0302 01:27:42.199988 29253 net.cpp:816] Ignoring source layer da_fc6
I0302 01:27:42.199992 29253 net.cpp:816] Ignoring source layer bn6_2
I0302 01:27:42.199995 29253 net.cpp:816] Ignoring source layer da_relu6
I0302 01:27:42.199998 29253 net.cpp:816] Ignoring source layer da_drop6
I0302 01:27:42.200001 29253 net.cpp:816] Ignoring source layer da_fc7
I0302 01:27:42.200003 29253 net.cpp:816] Ignoring source layer bn7
I0302 01:27:42.200006 29253 net.cpp:816] Ignoring source layer da_relu7
I0302 01:27:42.200009 29253 net.cpp:816] Ignoring source layer da_drop7
I0302 01:27:42.200011 29253 net.cpp:816] Ignoring source layer bn7_da_drop7_0_split
I0302 01:27:42.200014 29253 net.cpp:816] Ignoring source layer da_cls_score
I0302 01:27:42.200016 29253 net.cpp:816] Ignoring source layer da_bbox_pred
I0302 01:27:42.200018 29253 net.cpp:816] Ignoring source layer da_loss_cls
I0302 01:27:42.200021 29253 net.cpp:816] Ignoring source layer da_loss_bbox
I0302 01:27:42.435448 29253 solver.cpp:237] Iteration 0, loss = 3.16784
I0302 01:27:42.435482 29253 solver.cpp:253]     Train net output #0: loss_cls = 3.16784 (* 1 = 3.16784 loss)
I0302 01:27:42.435492 29253 sgd_solver.cpp:106] Iteration 0, lr = 0.01
I0302 01:27:42.437265 29253 blocking_queue.cpp:50] Data layer prefetch queue empty
I0302 01:28:11.536866 29253 solver.cpp:237] Iteration 20, loss = 4.66288
I0302 01:28:11.536896 29253 solver.cpp:253]     Train net output #0: loss_cls = 4.66288 (* 1 = 4.66288 loss)
I0302 01:28:11.536905 29253 sgd_solver.cpp:106] Iteration 20, lr = 0.01
I0302 01:28:41.386526 29253 solver.cpp:237] Iteration 40, loss = 2.2039
I0302 01:28:41.386557 29253 solver.cpp:253]     Train net output #0: loss_cls = 2.2039 (* 1 = 2.2039 loss)
I0302 01:28:41.386565 29253 sgd_solver.cpp:106] Iteration 40, lr = 0.01
I0302 01:29:10.787991 29253 solver.cpp:237] Iteration 60, loss = 2.01626
I0302 01:29:10.788022 29253 solver.cpp:253]     Train net output #0: loss_cls = 2.01626 (* 1 = 2.01626 loss)
I0302 01:29:10.788029 29253 sgd_solver.cpp:106] Iteration 60, lr = 0.01
I0302 01:29:39.820272 29253 solver.cpp:237] Iteration 80, loss = 2.07329
I0302 01:29:39.820302 29253 solver.cpp:253]     Train net output #0: loss_cls = 2.07329 (* 1 = 2.07329 loss)
I0302 01:29:39.820312 29253 sgd_solver.cpp:106] Iteration 80, lr = 0.01
I0302 01:30:08.727838 29253 solver.cpp:237] Iteration 100, loss = 1.90712
I0302 01:30:08.727869 29253 solver.cpp:253]     Train net output #0: loss_cls = 1.90712 (* 1 = 1.90712 loss)
I0302 01:30:08.727877 29253 sgd_solver.cpp:106] Iteration 100, lr = 0.01
I0302 01:30:37.756769 29253 solver.cpp:237] Iteration 120, loss = 1.64091
I0302 01:30:37.756801 29253 solver.cpp:253]     Train net output #0: loss_cls = 1.64091 (* 1 = 1.64091 loss)
I0302 01:30:37.756809 29253 sgd_solver.cpp:106] Iteration 120, lr = 0.01
I0302 01:31:06.738243 29253 solver.cpp:237] Iteration 140, loss = 1.80336
I0302 01:31:06.738272 29253 solver.cpp:253]     Train net output #0: loss_cls = 1.80336 (* 1 = 1.80336 loss)
I0302 01:31:06.738281 29253 sgd_solver.cpp:106] Iteration 140, lr = 0.01
I0302 01:31:35.623497 29253 solver.cpp:237] Iteration 160, loss = 1.45966
I0302 01:31:35.623528 29253 solver.cpp:253]     Train net output #0: loss_cls = 1.45966 (* 1 = 1.45966 loss)
I0302 01:31:35.623536 29253 sgd_solver.cpp:106] Iteration 160, lr = 0.01
I0302 01:32:04.292593 29253 solver.cpp:237] Iteration 180, loss = 1.46739
I0302 01:32:04.292624 29253 solver.cpp:253]     Train net output #0: loss_cls = 1.46739 (* 1 = 1.46739 loss)
I0302 01:32:04.292636 29253 sgd_solver.cpp:106] Iteration 180, lr = 0.01
I0302 01:32:33.374837 29253 solver.cpp:237] Iteration 200, loss = 1.35356
I0302 01:32:33.374866 29253 solver.cpp:253]     Train net output #0: loss_cls = 1.35356 (* 1 = 1.35356 loss)
I0302 01:32:33.374876 29253 sgd_solver.cpp:106] Iteration 200, lr = 0.01
I0302 01:33:02.290057 29253 solver.cpp:237] Iteration 220, loss = 1.43655
I0302 01:33:02.290087 29253 solver.cpp:253]     Train net output #0: loss_cls = 1.43655 (* 1 = 1.43655 loss)
I0302 01:33:02.290096 29253 sgd_solver.cpp:106] Iteration 220, lr = 0.01
I0302 01:33:31.123045 29253 solver.cpp:237] Iteration 240, loss = 1.73474
I0302 01:33:31.123075 29253 solver.cpp:253]     Train net output #0: loss_cls = 1.73474 (* 1 = 1.73474 loss)
I0302 01:33:31.123085 29253 sgd_solver.cpp:106] Iteration 240, lr = 0.01
I0302 01:33:59.958238 29253 solver.cpp:237] Iteration 260, loss = 1.23256
I0302 01:33:59.958268 29253 solver.cpp:253]     Train net output #0: loss_cls = 1.23256 (* 1 = 1.23256 loss)
I0302 01:33:59.958277 29253 sgd_solver.cpp:106] Iteration 260, lr = 0.01
I0302 01:34:29.051833 29253 solver.cpp:237] Iteration 280, loss = 1.19891
I0302 01:34:29.051865 29253 solver.cpp:253]     Train net output #0: loss_cls = 1.19891 (* 1 = 1.19891 loss)
I0302 01:34:29.051873 29253 sgd_solver.cpp:106] Iteration 280, lr = 0.01
I0302 01:34:57.714675 29253 solver.cpp:237] Iteration 300, loss = 1.04689
I0302 01:34:57.714707 29253 solver.cpp:253]     Train net output #0: loss_cls = 1.04689 (* 1 = 1.04689 loss)
I0302 01:34:57.714717 29253 sgd_solver.cpp:106] Iteration 300, lr = 0.01
I0302 01:35:26.755158 29253 solver.cpp:237] Iteration 320, loss = 1.19219
I0302 01:35:26.755188 29253 solver.cpp:253]     Train net output #0: loss_cls = 1.19219 (* 1 = 1.19219 loss)
I0302 01:35:26.755197 29253 sgd_solver.cpp:106] Iteration 320, lr = 0.01
I0302 01:35:55.731731 29253 solver.cpp:237] Iteration 340, loss = 0.97967
I0302 01:35:55.731762 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.97967 (* 1 = 0.97967 loss)
I0302 01:35:55.731771 29253 sgd_solver.cpp:106] Iteration 340, lr = 0.01
I0302 01:36:24.663491 29253 solver.cpp:237] Iteration 360, loss = 0.868895
I0302 01:36:24.663521 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.868895 (* 1 = 0.868895 loss)
I0302 01:36:24.663528 29253 sgd_solver.cpp:106] Iteration 360, lr = 0.01
I0302 01:36:53.414307 29253 solver.cpp:237] Iteration 380, loss = 1.27038
I0302 01:36:53.414340 29253 solver.cpp:253]     Train net output #0: loss_cls = 1.27038 (* 1 = 1.27038 loss)
I0302 01:36:53.414348 29253 sgd_solver.cpp:106] Iteration 380, lr = 0.01
I0302 01:37:22.301221 29253 solver.cpp:237] Iteration 400, loss = 0.737602
I0302 01:37:22.301252 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.737602 (* 1 = 0.737602 loss)
I0302 01:37:22.301261 29253 sgd_solver.cpp:106] Iteration 400, lr = 0.01
I0302 01:37:51.314324 29253 solver.cpp:237] Iteration 420, loss = 0.833788
I0302 01:37:51.314357 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.833788 (* 1 = 0.833788 loss)
I0302 01:37:51.314365 29253 sgd_solver.cpp:106] Iteration 420, lr = 0.01
I0302 01:38:20.003123 29253 solver.cpp:237] Iteration 440, loss = 0.758669
I0302 01:38:20.003155 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.758669 (* 1 = 0.758669 loss)
I0302 01:38:20.003165 29253 sgd_solver.cpp:106] Iteration 440, lr = 0.01
I0302 01:38:49.025081 29253 solver.cpp:237] Iteration 460, loss = 0.536218
I0302 01:38:49.025112 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.536218 (* 1 = 0.536218 loss)
I0302 01:38:49.025121 29253 sgd_solver.cpp:106] Iteration 460, lr = 0.01
I0302 01:39:18.152137 29253 solver.cpp:237] Iteration 480, loss = 0.881449
I0302 01:39:18.152169 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.881449 (* 1 = 0.881449 loss)
I0302 01:39:18.152179 29253 sgd_solver.cpp:106] Iteration 480, lr = 0.01
I0302 01:39:47.084761 29253 solver.cpp:237] Iteration 500, loss = 0.396941
I0302 01:39:47.084794 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.396941 (* 1 = 0.396941 loss)
I0302 01:39:47.084802 29253 sgd_solver.cpp:106] Iteration 500, lr = 0.01
I0302 01:40:16.122215 29253 solver.cpp:237] Iteration 520, loss = 0.594515
I0302 01:40:16.122246 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.594515 (* 1 = 0.594515 loss)
I0302 01:40:16.122254 29253 sgd_solver.cpp:106] Iteration 520, lr = 0.01
I0302 01:40:44.978704 29253 solver.cpp:237] Iteration 540, loss = 0.403991
I0302 01:40:44.978739 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.403991 (* 1 = 0.403991 loss)
I0302 01:40:44.978746 29253 sgd_solver.cpp:106] Iteration 540, lr = 0.01
I0302 01:41:13.607704 29253 solver.cpp:237] Iteration 560, loss = 0.39287
I0302 01:41:13.607738 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.39287 (* 1 = 0.39287 loss)
I0302 01:41:13.607748 29253 sgd_solver.cpp:106] Iteration 560, lr = 0.01
I0302 01:41:42.861737 29253 solver.cpp:237] Iteration 580, loss = 0.504868
I0302 01:41:42.861768 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.504868 (* 1 = 0.504868 loss)
I0302 01:41:42.861776 29253 sgd_solver.cpp:106] Iteration 580, lr = 0.01
I0302 01:42:11.750022 29253 solver.cpp:237] Iteration 600, loss = 0.303206
I0302 01:42:11.750053 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.303206 (* 1 = 0.303206 loss)
I0302 01:42:11.750062 29253 sgd_solver.cpp:106] Iteration 600, lr = 0.01
I0302 01:42:40.744731 29253 solver.cpp:237] Iteration 620, loss = 0.344103
I0302 01:42:40.744762 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.344103 (* 1 = 0.344103 loss)
I0302 01:42:40.744771 29253 sgd_solver.cpp:106] Iteration 620, lr = 0.01
I0302 01:43:09.571292 29253 solver.cpp:237] Iteration 640, loss = 0.196338
I0302 01:43:09.571322 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.196338 (* 1 = 0.196338 loss)
I0302 01:43:09.571331 29253 sgd_solver.cpp:106] Iteration 640, lr = 0.01
I0302 01:43:38.405042 29253 solver.cpp:237] Iteration 660, loss = 0.214922
I0302 01:43:38.405073 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.214922 (* 1 = 0.214922 loss)
I0302 01:43:38.405082 29253 sgd_solver.cpp:106] Iteration 660, lr = 0.01
I0302 01:44:07.545491 29253 solver.cpp:237] Iteration 680, loss = 0.163461
I0302 01:44:07.545523 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.163461 (* 1 = 0.163461 loss)
I0302 01:44:07.545532 29253 sgd_solver.cpp:106] Iteration 680, lr = 0.01
I0302 01:44:36.602617 29253 solver.cpp:237] Iteration 700, loss = 0.129409
I0302 01:44:36.602648 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.129409 (* 1 = 0.129409 loss)
I0302 01:44:36.602655 29253 sgd_solver.cpp:106] Iteration 700, lr = 0.01
I0302 01:45:05.389755 29253 solver.cpp:237] Iteration 720, loss = 0.208933
I0302 01:45:05.389788 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.208933 (* 1 = 0.208933 loss)
I0302 01:45:05.389797 29253 sgd_solver.cpp:106] Iteration 720, lr = 0.01
I0302 01:45:34.206262 29253 solver.cpp:237] Iteration 740, loss = 0.0714457
I0302 01:45:34.206295 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0714457 (* 1 = 0.0714457 loss)
I0302 01:45:34.206303 29253 sgd_solver.cpp:106] Iteration 740, lr = 0.01
I0302 01:46:03.532380 29253 solver.cpp:237] Iteration 760, loss = 0.0851108
I0302 01:46:03.532410 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0851108 (* 1 = 0.0851108 loss)
I0302 01:46:03.532419 29253 sgd_solver.cpp:106] Iteration 760, lr = 0.01
I0302 01:46:32.030834 29253 solver.cpp:237] Iteration 780, loss = 0.0660984
I0302 01:46:32.030867 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0660984 (* 1 = 0.0660984 loss)
I0302 01:46:32.030876 29253 sgd_solver.cpp:106] Iteration 780, lr = 0.01
I0302 01:47:00.863612 29253 solver.cpp:237] Iteration 800, loss = 0.0746889
I0302 01:47:00.863644 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0746889 (* 1 = 0.0746889 loss)
I0302 01:47:00.863653 29253 sgd_solver.cpp:106] Iteration 800, lr = 0.01
I0302 01:47:30.019556 29253 solver.cpp:237] Iteration 820, loss = 0.0658488
I0302 01:47:30.019584 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0658488 (* 1 = 0.0658488 loss)
I0302 01:47:30.019593 29253 sgd_solver.cpp:106] Iteration 820, lr = 0.01
I0302 01:47:59.439158 29253 solver.cpp:237] Iteration 840, loss = 0.0575065
I0302 01:47:59.439189 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0575065 (* 1 = 0.0575065 loss)
I0302 01:47:59.439198 29253 sgd_solver.cpp:106] Iteration 840, lr = 0.01
I0302 01:48:28.643836 29253 solver.cpp:237] Iteration 860, loss = 0.0368487
I0302 01:48:28.643865 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0368487 (* 1 = 0.0368487 loss)
I0302 01:48:28.643873 29253 sgd_solver.cpp:106] Iteration 860, lr = 0.01
I0302 01:48:57.717082 29253 solver.cpp:237] Iteration 880, loss = 0.0419689
I0302 01:48:57.717113 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0419689 (* 1 = 0.0419689 loss)
I0302 01:48:57.717120 29253 sgd_solver.cpp:106] Iteration 880, lr = 0.01
I0302 01:49:26.716087 29253 solver.cpp:237] Iteration 900, loss = 0.0333664
I0302 01:49:26.716120 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0333664 (* 1 = 0.0333664 loss)
I0302 01:49:26.716127 29253 sgd_solver.cpp:106] Iteration 900, lr = 0.01
I0302 01:49:55.775532 29253 solver.cpp:237] Iteration 920, loss = 0.0308203
I0302 01:49:55.775565 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0308203 (* 1 = 0.0308203 loss)
I0302 01:49:55.775573 29253 sgd_solver.cpp:106] Iteration 920, lr = 0.01
I0302 01:50:24.514292 29253 solver.cpp:237] Iteration 940, loss = 0.0294081
I0302 01:50:24.514323 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0294081 (* 1 = 0.0294081 loss)
I0302 01:50:24.514333 29253 sgd_solver.cpp:106] Iteration 940, lr = 0.01
I0302 01:50:53.579829 29253 solver.cpp:237] Iteration 960, loss = 0.0323825
I0302 01:50:53.579859 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0323825 (* 1 = 0.0323825 loss)
I0302 01:50:53.579867 29253 sgd_solver.cpp:106] Iteration 960, lr = 0.01
I0302 01:51:22.229770 29253 solver.cpp:237] Iteration 980, loss = 0.0190541
I0302 01:51:22.229804 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0190541 (* 1 = 0.0190541 loss)
I0302 01:51:22.229811 29253 sgd_solver.cpp:106] Iteration 980, lr = 0.01
I0302 01:51:50.720405 29253 solver.cpp:237] Iteration 1000, loss = 0.0229456
I0302 01:51:50.720439 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0229456 (* 1 = 0.0229456 loss)
I0302 01:51:50.720449 29253 sgd_solver.cpp:106] Iteration 1000, lr = 0.01
I0302 01:51:50.721529 29253 blocking_queue.cpp:50] Data layer prefetch queue empty
I0302 01:52:19.787178 29253 solver.cpp:237] Iteration 1020, loss = 0.0232893
I0302 01:52:19.787209 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0232893 (* 1 = 0.0232893 loss)
I0302 01:52:19.787219 29253 sgd_solver.cpp:106] Iteration 1020, lr = 0.01
I0302 01:52:49.329103 29253 solver.cpp:237] Iteration 1040, loss = 0.0154973
I0302 01:52:49.329134 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0154973 (* 1 = 0.0154973 loss)
I0302 01:52:49.329143 29253 sgd_solver.cpp:106] Iteration 1040, lr = 0.01
I0302 01:53:18.220805 29253 solver.cpp:237] Iteration 1060, loss = 0.0172496
I0302 01:53:18.220839 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0172496 (* 1 = 0.0172496 loss)
I0302 01:53:18.220846 29253 sgd_solver.cpp:106] Iteration 1060, lr = 0.01
I0302 01:53:46.970619 29253 solver.cpp:237] Iteration 1080, loss = 0.0162133
I0302 01:53:46.970651 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0162133 (* 1 = 0.0162133 loss)
I0302 01:53:46.970659 29253 sgd_solver.cpp:106] Iteration 1080, lr = 0.01
I0302 01:54:15.582049 29253 solver.cpp:237] Iteration 1100, loss = 0.0153251
I0302 01:54:15.582082 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0153251 (* 1 = 0.0153251 loss)
I0302 01:54:15.582092 29253 sgd_solver.cpp:106] Iteration 1100, lr = 0.01
I0302 01:54:44.681769 29253 solver.cpp:237] Iteration 1120, loss = 0.0171527
I0302 01:54:44.681800 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0171527 (* 1 = 0.0171527 loss)
I0302 01:54:44.681809 29253 sgd_solver.cpp:106] Iteration 1120, lr = 0.01
I0302 01:55:13.612710 29253 solver.cpp:237] Iteration 1140, loss = 0.0190801
I0302 01:55:13.612740 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0190801 (* 1 = 0.0190801 loss)
I0302 01:55:13.612749 29253 sgd_solver.cpp:106] Iteration 1140, lr = 0.01
I0302 01:55:42.710567 29253 solver.cpp:237] Iteration 1160, loss = 0.0205997
I0302 01:55:42.710599 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0205997 (* 1 = 0.0205997 loss)
I0302 01:55:42.710608 29253 sgd_solver.cpp:106] Iteration 1160, lr = 0.01
I0302 01:56:11.429803 29253 solver.cpp:237] Iteration 1180, loss = 0.0151865
I0302 01:56:11.429836 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0151865 (* 1 = 0.0151865 loss)
I0302 01:56:11.429843 29253 sgd_solver.cpp:106] Iteration 1180, lr = 0.01
I0302 01:56:40.563730 29253 solver.cpp:237] Iteration 1200, loss = 0.0140197
I0302 01:56:40.563760 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0140197 (* 1 = 0.0140197 loss)
I0302 01:56:40.563771 29253 sgd_solver.cpp:106] Iteration 1200, lr = 0.01
I0302 01:57:09.277946 29253 solver.cpp:237] Iteration 1220, loss = 0.00919977
I0302 01:57:09.277978 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00919977 (* 1 = 0.00919977 loss)
I0302 01:57:09.277988 29253 sgd_solver.cpp:106] Iteration 1220, lr = 0.01
I0302 01:57:38.459211 29253 solver.cpp:237] Iteration 1240, loss = 0.0145794
I0302 01:57:38.459242 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0145794 (* 1 = 0.0145794 loss)
I0302 01:57:38.459250 29253 sgd_solver.cpp:106] Iteration 1240, lr = 0.01
I0302 01:58:07.206696 29253 solver.cpp:237] Iteration 1260, loss = 0.0128654
I0302 01:58:07.206727 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0128654 (* 1 = 0.0128654 loss)
I0302 01:58:07.206737 29253 sgd_solver.cpp:106] Iteration 1260, lr = 0.01
I0302 01:58:36.284234 29253 solver.cpp:237] Iteration 1280, loss = 0.0111093
I0302 01:58:36.284265 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0111093 (* 1 = 0.0111093 loss)
I0302 01:58:36.284273 29253 sgd_solver.cpp:106] Iteration 1280, lr = 0.01
I0302 01:59:04.988258 29253 solver.cpp:237] Iteration 1300, loss = 0.0151126
I0302 01:59:04.988288 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0151126 (* 1 = 0.0151126 loss)
I0302 01:59:04.988298 29253 sgd_solver.cpp:106] Iteration 1300, lr = 0.01
I0302 01:59:34.145231 29253 solver.cpp:237] Iteration 1320, loss = 0.0110464
I0302 01:59:34.145263 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0110464 (* 1 = 0.0110464 loss)
I0302 01:59:34.145272 29253 sgd_solver.cpp:106] Iteration 1320, lr = 0.01
I0302 02:00:02.972532 29253 solver.cpp:237] Iteration 1340, loss = 0.0141082
I0302 02:00:02.972563 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0141082 (* 1 = 0.0141082 loss)
I0302 02:00:02.972571 29253 sgd_solver.cpp:106] Iteration 1340, lr = 0.01
I0302 02:00:31.902446 29253 solver.cpp:237] Iteration 1360, loss = 0.011214
I0302 02:00:31.902475 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.011214 (* 1 = 0.011214 loss)
I0302 02:00:31.902484 29253 sgd_solver.cpp:106] Iteration 1360, lr = 0.01
I0302 02:01:00.793488 29253 solver.cpp:237] Iteration 1380, loss = 0.0122031
I0302 02:01:00.793520 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0122031 (* 1 = 0.0122031 loss)
I0302 02:01:00.793529 29253 sgd_solver.cpp:106] Iteration 1380, lr = 0.01
I0302 02:01:29.693140 29253 solver.cpp:237] Iteration 1400, loss = 0.010747
I0302 02:01:29.693171 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.010747 (* 1 = 0.010747 loss)
I0302 02:01:29.693178 29253 sgd_solver.cpp:106] Iteration 1400, lr = 0.01
I0302 02:01:58.673153 29253 solver.cpp:237] Iteration 1420, loss = 0.00928968
I0302 02:01:58.673185 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00928969 (* 1 = 0.00928969 loss)
I0302 02:01:58.673194 29253 sgd_solver.cpp:106] Iteration 1420, lr = 0.01
I0302 02:02:27.759229 29253 solver.cpp:237] Iteration 1440, loss = 0.0102433
I0302 02:02:27.759260 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0102433 (* 1 = 0.0102433 loss)
I0302 02:02:27.759269 29253 sgd_solver.cpp:106] Iteration 1440, lr = 0.01
I0302 02:02:56.557303 29253 solver.cpp:237] Iteration 1460, loss = 0.0106504
I0302 02:02:56.557334 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0106504 (* 1 = 0.0106504 loss)
I0302 02:02:56.557343 29253 sgd_solver.cpp:106] Iteration 1460, lr = 0.01
I0302 02:03:25.553076 29253 solver.cpp:237] Iteration 1480, loss = 0.00899002
I0302 02:03:25.553107 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00899002 (* 1 = 0.00899002 loss)
I0302 02:03:25.553115 29253 sgd_solver.cpp:106] Iteration 1480, lr = 0.01
I0302 02:03:54.379475 29253 solver.cpp:237] Iteration 1500, loss = 0.012478
I0302 02:03:54.379506 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.012478 (* 1 = 0.012478 loss)
I0302 02:03:54.379515 29253 sgd_solver.cpp:106] Iteration 1500, lr = 0.01
I0302 02:04:23.309914 29253 solver.cpp:237] Iteration 1520, loss = 0.00761439
I0302 02:04:23.309945 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00761439 (* 1 = 0.00761439 loss)
I0302 02:04:23.309953 29253 sgd_solver.cpp:106] Iteration 1520, lr = 0.01
I0302 02:04:52.342830 29253 solver.cpp:237] Iteration 1540, loss = 0.0122671
I0302 02:04:52.342862 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0122671 (* 1 = 0.0122671 loss)
I0302 02:04:52.342870 29253 sgd_solver.cpp:106] Iteration 1540, lr = 0.01
I0302 02:05:21.301475 29253 solver.cpp:237] Iteration 1560, loss = 0.00815868
I0302 02:05:21.301506 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00815868 (* 1 = 0.00815868 loss)
I0302 02:05:21.301515 29253 sgd_solver.cpp:106] Iteration 1560, lr = 0.01
I0302 02:05:50.142433 29253 solver.cpp:237] Iteration 1580, loss = 0.012988
I0302 02:05:50.142467 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.012988 (* 1 = 0.012988 loss)
I0302 02:05:50.142475 29253 sgd_solver.cpp:106] Iteration 1580, lr = 0.01
I0302 02:06:19.124595 29253 solver.cpp:237] Iteration 1600, loss = 0.00733669
I0302 02:06:19.124627 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00733669 (* 1 = 0.00733669 loss)
I0302 02:06:19.124635 29253 sgd_solver.cpp:106] Iteration 1600, lr = 0.01
I0302 02:06:47.989639 29253 solver.cpp:237] Iteration 1620, loss = 0.00899166
I0302 02:06:47.989671 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00899166 (* 1 = 0.00899166 loss)
I0302 02:06:47.989681 29253 sgd_solver.cpp:106] Iteration 1620, lr = 0.01
I0302 02:07:16.905030 29253 solver.cpp:237] Iteration 1640, loss = 0.00922769
I0302 02:07:16.905063 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00922769 (* 1 = 0.00922769 loss)
I0302 02:07:16.905072 29253 sgd_solver.cpp:106] Iteration 1640, lr = 0.01
I0302 02:07:45.878875 29253 solver.cpp:237] Iteration 1660, loss = 0.00609326
I0302 02:07:45.878906 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00609327 (* 1 = 0.00609327 loss)
I0302 02:07:45.878913 29253 sgd_solver.cpp:106] Iteration 1660, lr = 0.01
I0302 02:08:14.865115 29253 solver.cpp:237] Iteration 1680, loss = 0.00820103
I0302 02:08:14.865146 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00820103 (* 1 = 0.00820103 loss)
I0302 02:08:14.865155 29253 sgd_solver.cpp:106] Iteration 1680, lr = 0.01
I0302 02:08:43.711861 29253 solver.cpp:237] Iteration 1700, loss = 0.00746588
I0302 02:08:43.711894 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00746588 (* 1 = 0.00746588 loss)
I0302 02:08:43.711902 29253 sgd_solver.cpp:106] Iteration 1700, lr = 0.01
I0302 02:09:12.553747 29253 solver.cpp:237] Iteration 1720, loss = 0.00849986
I0302 02:09:12.553778 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00849987 (* 1 = 0.00849987 loss)
I0302 02:09:12.553786 29253 sgd_solver.cpp:106] Iteration 1720, lr = 0.01
I0302 02:09:41.580893 29253 solver.cpp:237] Iteration 1740, loss = 0.00790387
I0302 02:09:41.580924 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00790387 (* 1 = 0.00790387 loss)
I0302 02:09:41.580932 29253 sgd_solver.cpp:106] Iteration 1740, lr = 0.01
I0302 02:10:10.620842 29253 solver.cpp:237] Iteration 1760, loss = 0.00721678
I0302 02:10:10.620875 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00721678 (* 1 = 0.00721678 loss)
I0302 02:10:10.620883 29253 sgd_solver.cpp:106] Iteration 1760, lr = 0.01
I0302 02:10:39.523386 29253 solver.cpp:237] Iteration 1780, loss = 0.00826084
I0302 02:10:39.523418 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00826084 (* 1 = 0.00826084 loss)
I0302 02:10:39.523427 29253 sgd_solver.cpp:106] Iteration 1780, lr = 0.01
I0302 02:11:08.592591 29253 solver.cpp:237] Iteration 1800, loss = 0.00622228
I0302 02:11:08.592728 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00622229 (* 1 = 0.00622229 loss)
I0302 02:11:08.592742 29253 sgd_solver.cpp:106] Iteration 1800, lr = 0.01
I0302 02:11:37.518599 29253 solver.cpp:237] Iteration 1820, loss = 0.00677781
I0302 02:11:37.518630 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00677781 (* 1 = 0.00677781 loss)
I0302 02:11:37.518637 29253 sgd_solver.cpp:106] Iteration 1820, lr = 0.01
I0302 02:12:06.508642 29253 solver.cpp:237] Iteration 1840, loss = 0.00727112
I0302 02:12:06.508676 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00727112 (* 1 = 0.00727112 loss)
I0302 02:12:06.508683 29253 sgd_solver.cpp:106] Iteration 1840, lr = 0.01
I0302 02:12:35.535012 29253 solver.cpp:237] Iteration 1860, loss = 0.00667804
I0302 02:12:35.535044 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00667805 (* 1 = 0.00667805 loss)
I0302 02:12:35.535053 29253 sgd_solver.cpp:106] Iteration 1860, lr = 0.01
I0302 02:13:04.661113 29253 solver.cpp:237] Iteration 1880, loss = 0.0060967
I0302 02:13:04.661144 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00609671 (* 1 = 0.00609671 loss)
I0302 02:13:04.661154 29253 sgd_solver.cpp:106] Iteration 1880, lr = 0.01
I0302 02:13:33.131322 29253 solver.cpp:237] Iteration 1900, loss = 0.00598815
I0302 02:13:33.131356 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00598816 (* 1 = 0.00598816 loss)
I0302 02:13:33.131364 29253 sgd_solver.cpp:106] Iteration 1900, lr = 0.01
I0302 02:14:02.118451 29253 solver.cpp:237] Iteration 1920, loss = 0.00696126
I0302 02:14:02.118484 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00696127 (* 1 = 0.00696127 loss)
I0302 02:14:02.118491 29253 sgd_solver.cpp:106] Iteration 1920, lr = 0.01
I0302 02:14:31.255388 29253 solver.cpp:237] Iteration 1940, loss = 0.00624656
I0302 02:14:31.255419 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00624656 (* 1 = 0.00624656 loss)
I0302 02:14:31.255431 29253 sgd_solver.cpp:106] Iteration 1940, lr = 0.01
I0302 02:15:00.250408 29253 solver.cpp:237] Iteration 1960, loss = 0.00773314
I0302 02:15:00.250440 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00773315 (* 1 = 0.00773315 loss)
I0302 02:15:00.250449 29253 sgd_solver.cpp:106] Iteration 1960, lr = 0.01
I0302 02:15:29.283056 29253 solver.cpp:237] Iteration 1980, loss = 0.00778322
I0302 02:15:29.283085 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00778323 (* 1 = 0.00778323 loss)
I0302 02:15:29.283093 29253 sgd_solver.cpp:106] Iteration 1980, lr = 0.01
I0302 02:15:58.136737 29253 solver.cpp:237] Iteration 2000, loss = 0.00470463
I0302 02:15:58.136770 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00470464 (* 1 = 0.00470464 loss)
I0302 02:15:58.136780 29253 sgd_solver.cpp:106] Iteration 2000, lr = 0.01
I0302 02:15:58.137858 29253 blocking_queue.cpp:50] Data layer prefetch queue empty
I0302 02:16:27.107679 29253 solver.cpp:237] Iteration 2020, loss = 0.00678005
I0302 02:16:27.107710 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00678005 (* 1 = 0.00678005 loss)
I0302 02:16:27.107719 29253 sgd_solver.cpp:106] Iteration 2020, lr = 0.01
I0302 02:16:55.683419 29253 solver.cpp:237] Iteration 2040, loss = 0.00680295
I0302 02:16:55.683452 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00680295 (* 1 = 0.00680295 loss)
I0302 02:16:55.683460 29253 sgd_solver.cpp:106] Iteration 2040, lr = 0.01
I0302 02:17:24.545838 29253 solver.cpp:237] Iteration 2060, loss = 0.00676161
I0302 02:17:24.545871 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00676161 (* 1 = 0.00676161 loss)
I0302 02:17:24.545879 29253 sgd_solver.cpp:106] Iteration 2060, lr = 0.01
I0302 02:17:53.375987 29253 solver.cpp:237] Iteration 2080, loss = 0.00627719
I0302 02:17:53.376019 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00627719 (* 1 = 0.00627719 loss)
I0302 02:17:53.376029 29253 sgd_solver.cpp:106] Iteration 2080, lr = 0.01
I0302 02:18:22.193686 29253 solver.cpp:237] Iteration 2100, loss = 0.0061474
I0302 02:18:22.193717 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00614741 (* 1 = 0.00614741 loss)
I0302 02:18:22.193727 29253 sgd_solver.cpp:106] Iteration 2100, lr = 0.01
I0302 02:18:51.456157 29253 solver.cpp:237] Iteration 2120, loss = 0.00695321
I0302 02:18:51.456190 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00695321 (* 1 = 0.00695321 loss)
I0302 02:18:51.456198 29253 sgd_solver.cpp:106] Iteration 2120, lr = 0.01
I0302 02:19:20.329346 29253 solver.cpp:237] Iteration 2140, loss = 0.00547249
I0302 02:19:20.329380 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0054725 (* 1 = 0.0054725 loss)
I0302 02:19:20.329388 29253 sgd_solver.cpp:106] Iteration 2140, lr = 0.01
I0302 02:19:49.323272 29253 solver.cpp:237] Iteration 2160, loss = 0.00579238
I0302 02:19:49.323305 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00579239 (* 1 = 0.00579239 loss)
I0302 02:19:49.323314 29253 sgd_solver.cpp:106] Iteration 2160, lr = 0.01
I0302 02:20:18.207969 29253 solver.cpp:237] Iteration 2180, loss = 0.00598864
I0302 02:20:18.208001 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00598864 (* 1 = 0.00598864 loss)
I0302 02:20:18.208010 29253 sgd_solver.cpp:106] Iteration 2180, lr = 0.01
I0302 02:20:47.008616 29253 solver.cpp:237] Iteration 2200, loss = 0.00542902
I0302 02:20:47.008649 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00542903 (* 1 = 0.00542903 loss)
I0302 02:20:47.008659 29253 sgd_solver.cpp:106] Iteration 2200, lr = 0.01
I0302 02:21:16.044432 29253 solver.cpp:237] Iteration 2220, loss = 0.00633304
I0302 02:21:16.044463 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00633304 (* 1 = 0.00633304 loss)
I0302 02:21:16.044472 29253 sgd_solver.cpp:106] Iteration 2220, lr = 0.01
I0302 02:21:45.041510 29253 solver.cpp:237] Iteration 2240, loss = 0.00662157
I0302 02:21:45.041543 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00662158 (* 1 = 0.00662158 loss)
I0302 02:21:45.041551 29253 sgd_solver.cpp:106] Iteration 2240, lr = 0.01
I0302 02:22:13.889658 29253 solver.cpp:237] Iteration 2260, loss = 0.00635831
I0302 02:22:13.889693 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00635832 (* 1 = 0.00635832 loss)
I0302 02:22:13.889701 29253 sgd_solver.cpp:106] Iteration 2260, lr = 0.01
I0302 02:22:42.858790 29253 solver.cpp:237] Iteration 2280, loss = 0.00736882
I0302 02:22:42.858821 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00736883 (* 1 = 0.00736883 loss)
I0302 02:22:42.858830 29253 sgd_solver.cpp:106] Iteration 2280, lr = 0.01
I0302 02:23:11.687726 29253 solver.cpp:237] Iteration 2300, loss = 0.00611602
I0302 02:23:11.687760 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00611602 (* 1 = 0.00611602 loss)
I0302 02:23:11.687769 29253 sgd_solver.cpp:106] Iteration 2300, lr = 0.01
I0302 02:23:40.635957 29253 solver.cpp:237] Iteration 2320, loss = 0.00583566
I0302 02:23:40.635989 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00583567 (* 1 = 0.00583567 loss)
I0302 02:23:40.635998 29253 sgd_solver.cpp:106] Iteration 2320, lr = 0.01
I0302 02:24:09.590950 29253 solver.cpp:237] Iteration 2340, loss = 0.00492389
I0302 02:24:09.590983 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00492389 (* 1 = 0.00492389 loss)
I0302 02:24:09.590991 29253 sgd_solver.cpp:106] Iteration 2340, lr = 0.01
I0302 02:24:38.412016 29253 solver.cpp:237] Iteration 2360, loss = 0.00596682
I0302 02:24:38.412048 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00596683 (* 1 = 0.00596683 loss)
I0302 02:24:38.412057 29253 sgd_solver.cpp:106] Iteration 2360, lr = 0.01
I0302 02:25:07.269090 29253 solver.cpp:237] Iteration 2380, loss = 0.00477533
I0302 02:25:07.269121 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00477533 (* 1 = 0.00477533 loss)
I0302 02:25:07.269130 29253 sgd_solver.cpp:106] Iteration 2380, lr = 0.01
I0302 02:25:36.241420 29253 solver.cpp:237] Iteration 2400, loss = 0.00502133
I0302 02:25:36.241451 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00502133 (* 1 = 0.00502133 loss)
I0302 02:25:36.241459 29253 sgd_solver.cpp:106] Iteration 2400, lr = 0.01
I0302 02:26:05.157675 29253 solver.cpp:237] Iteration 2420, loss = 0.00535916
I0302 02:26:05.157707 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00535916 (* 1 = 0.00535916 loss)
I0302 02:26:05.157716 29253 sgd_solver.cpp:106] Iteration 2420, lr = 0.01
I0302 02:26:34.044658 29253 solver.cpp:237] Iteration 2440, loss = 0.00426681
I0302 02:26:34.044690 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00426681 (* 1 = 0.00426681 loss)
I0302 02:26:34.044699 29253 sgd_solver.cpp:106] Iteration 2440, lr = 0.01
I0302 02:27:03.019568 29253 solver.cpp:237] Iteration 2460, loss = 0.00859942
I0302 02:27:03.019598 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00859942 (* 1 = 0.00859942 loss)
I0302 02:27:03.019608 29253 sgd_solver.cpp:106] Iteration 2460, lr = 0.01
I0302 02:27:31.960968 29253 solver.cpp:237] Iteration 2480, loss = 0.00466378
I0302 02:27:31.961000 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00466378 (* 1 = 0.00466378 loss)
I0302 02:27:31.961009 29253 sgd_solver.cpp:106] Iteration 2480, lr = 0.01
I0302 02:28:00.795297 29253 solver.cpp:237] Iteration 2500, loss = 0.00744922
I0302 02:28:00.795331 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00744922 (* 1 = 0.00744922 loss)
I0302 02:28:00.795339 29253 sgd_solver.cpp:106] Iteration 2500, lr = 0.01
I0302 02:28:29.715786 29253 solver.cpp:237] Iteration 2520, loss = 0.00862699
I0302 02:28:29.715819 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.008627 (* 1 = 0.008627 loss)
I0302 02:28:29.715827 29253 sgd_solver.cpp:106] Iteration 2520, lr = 0.01
I0302 02:28:58.568497 29253 solver.cpp:237] Iteration 2540, loss = 0.00543692
I0302 02:28:58.568528 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00543693 (* 1 = 0.00543693 loss)
I0302 02:28:58.568537 29253 sgd_solver.cpp:106] Iteration 2540, lr = 0.01
I0302 02:29:27.585084 29253 solver.cpp:237] Iteration 2560, loss = 0.00481084
I0302 02:29:27.585116 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00481084 (* 1 = 0.00481084 loss)
I0302 02:29:27.585124 29253 sgd_solver.cpp:106] Iteration 2560, lr = 0.01
I0302 02:29:56.527653 29253 solver.cpp:237] Iteration 2580, loss = 0.0051384
I0302 02:29:56.527685 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0051384 (* 1 = 0.0051384 loss)
I0302 02:29:56.527694 29253 sgd_solver.cpp:106] Iteration 2580, lr = 0.01
I0302 02:30:25.301012 29253 solver.cpp:237] Iteration 2600, loss = 0.00423634
I0302 02:30:25.301045 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00423635 (* 1 = 0.00423635 loss)
I0302 02:30:25.301054 29253 sgd_solver.cpp:106] Iteration 2600, lr = 0.01
I0302 02:30:54.410280 29253 solver.cpp:237] Iteration 2620, loss = 0.00454673
I0302 02:30:54.410311 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00454673 (* 1 = 0.00454673 loss)
I0302 02:30:54.410320 29253 sgd_solver.cpp:106] Iteration 2620, lr = 0.01
I0302 02:31:23.187232 29253 solver.cpp:237] Iteration 2640, loss = 0.00596806
I0302 02:31:23.187263 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00596806 (* 1 = 0.00596806 loss)
I0302 02:31:23.187273 29253 sgd_solver.cpp:106] Iteration 2640, lr = 0.01
I0302 02:31:52.152771 29253 solver.cpp:237] Iteration 2660, loss = 0.00544492
I0302 02:31:52.152804 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00544493 (* 1 = 0.00544493 loss)
I0302 02:31:52.152812 29253 sgd_solver.cpp:106] Iteration 2660, lr = 0.01
I0302 02:32:21.028574 29253 solver.cpp:237] Iteration 2680, loss = 0.00515271
I0302 02:32:21.028606 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00515272 (* 1 = 0.00515272 loss)
I0302 02:32:21.028615 29253 sgd_solver.cpp:106] Iteration 2680, lr = 0.01
I0302 02:32:49.910706 29253 solver.cpp:237] Iteration 2700, loss = 0.00528866
I0302 02:32:49.910738 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00528866 (* 1 = 0.00528866 loss)
I0302 02:32:49.910747 29253 sgd_solver.cpp:106] Iteration 2700, lr = 0.01
I0302 02:33:19.042346 29253 solver.cpp:237] Iteration 2720, loss = 0.00401709
I0302 02:33:19.042382 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0040171 (* 1 = 0.0040171 loss)
I0302 02:33:19.042390 29253 sgd_solver.cpp:106] Iteration 2720, lr = 0.01
I0302 02:33:47.932729 29253 solver.cpp:237] Iteration 2740, loss = 0.00493823
I0302 02:33:47.932761 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00493824 (* 1 = 0.00493824 loss)
I0302 02:33:47.932771 29253 sgd_solver.cpp:106] Iteration 2740, lr = 0.01
I0302 02:34:16.873270 29253 solver.cpp:237] Iteration 2760, loss = 0.0044179
I0302 02:34:16.873301 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0044179 (* 1 = 0.0044179 loss)
I0302 02:34:16.873309 29253 sgd_solver.cpp:106] Iteration 2760, lr = 0.01
I0302 02:34:45.792451 29253 solver.cpp:237] Iteration 2780, loss = 0.00530219
I0302 02:34:45.792486 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0053022 (* 1 = 0.0053022 loss)
I0302 02:34:45.792496 29253 sgd_solver.cpp:106] Iteration 2780, lr = 0.01
I0302 02:35:14.530783 29253 solver.cpp:237] Iteration 2800, loss = 0.00503993
I0302 02:35:14.530815 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00503994 (* 1 = 0.00503994 loss)
I0302 02:35:14.530824 29253 sgd_solver.cpp:106] Iteration 2800, lr = 0.01
I0302 02:35:43.440654 29253 solver.cpp:237] Iteration 2820, loss = 0.00435615
I0302 02:35:43.440686 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00435615 (* 1 = 0.00435615 loss)
I0302 02:35:43.440696 29253 sgd_solver.cpp:106] Iteration 2820, lr = 0.01
I0302 02:36:12.342197 29253 solver.cpp:237] Iteration 2840, loss = 0.00415313
I0302 02:36:12.342228 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00415313 (* 1 = 0.00415313 loss)
I0302 02:36:12.342237 29253 sgd_solver.cpp:106] Iteration 2840, lr = 0.01
I0302 02:36:41.182660 29253 solver.cpp:237] Iteration 2860, loss = 0.00401064
I0302 02:36:41.182693 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00401064 (* 1 = 0.00401064 loss)
I0302 02:36:41.182701 29253 sgd_solver.cpp:106] Iteration 2860, lr = 0.01
I0302 02:37:10.207314 29253 solver.cpp:237] Iteration 2880, loss = 0.00493644
I0302 02:37:10.207345 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00493644 (* 1 = 0.00493644 loss)
I0302 02:37:10.207352 29253 sgd_solver.cpp:106] Iteration 2880, lr = 0.01
I0302 02:37:39.141013 29253 solver.cpp:237] Iteration 2900, loss = 0.00477701
I0302 02:37:39.141044 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00477701 (* 1 = 0.00477701 loss)
I0302 02:37:39.141052 29253 sgd_solver.cpp:106] Iteration 2900, lr = 0.01
I0302 02:38:08.272572 29253 solver.cpp:237] Iteration 2920, loss = 0.00448401
I0302 02:38:08.272604 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00448401 (* 1 = 0.00448401 loss)
I0302 02:38:08.272614 29253 sgd_solver.cpp:106] Iteration 2920, lr = 0.01
I0302 02:38:37.094622 29253 solver.cpp:237] Iteration 2940, loss = 0.00383957
I0302 02:38:37.094655 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00383957 (* 1 = 0.00383957 loss)
I0302 02:38:37.094662 29253 sgd_solver.cpp:106] Iteration 2940, lr = 0.01
I0302 02:39:05.995692 29253 solver.cpp:237] Iteration 2960, loss = 0.00377263
I0302 02:39:05.995723 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00377263 (* 1 = 0.00377263 loss)
I0302 02:39:05.995733 29253 sgd_solver.cpp:106] Iteration 2960, lr = 0.01
I0302 02:39:35.070354 29253 solver.cpp:237] Iteration 2980, loss = 0.00427641
I0302 02:39:35.070390 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00427641 (* 1 = 0.00427641 loss)
I0302 02:39:35.070399 29253 sgd_solver.cpp:106] Iteration 2980, lr = 0.01
I0302 02:40:04.017168 29253 solver.cpp:237] Iteration 3000, loss = 0.00420258
I0302 02:40:04.017200 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00420259 (* 1 = 0.00420259 loss)
I0302 02:40:04.017209 29253 sgd_solver.cpp:106] Iteration 3000, lr = 0.01
I0302 02:40:04.024096 29253 blocking_queue.cpp:50] Data layer prefetch queue empty
I0302 02:40:32.321414 29253 solver.cpp:237] Iteration 3020, loss = 0.00442857
I0302 02:40:32.321446 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00442858 (* 1 = 0.00442858 loss)
I0302 02:40:32.321455 29253 sgd_solver.cpp:106] Iteration 3020, lr = 0.01
I0302 02:41:01.130271 29253 solver.cpp:237] Iteration 3040, loss = 0.00484963
I0302 02:41:01.130302 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00484963 (* 1 = 0.00484963 loss)
I0302 02:41:01.130311 29253 sgd_solver.cpp:106] Iteration 3040, lr = 0.01
I0302 02:41:30.273778 29253 solver.cpp:237] Iteration 3060, loss = 0.00361409
I0302 02:41:30.273811 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00361409 (* 1 = 0.00361409 loss)
I0302 02:41:30.273819 29253 sgd_solver.cpp:106] Iteration 3060, lr = 0.01
I0302 02:41:59.062326 29253 solver.cpp:237] Iteration 3080, loss = 0.00368088
I0302 02:41:59.062358 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00368089 (* 1 = 0.00368089 loss)
I0302 02:41:59.062367 29253 sgd_solver.cpp:106] Iteration 3080, lr = 0.01
I0302 02:42:28.205083 29253 solver.cpp:237] Iteration 3100, loss = 0.00491214
I0302 02:42:28.205114 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00491214 (* 1 = 0.00491214 loss)
I0302 02:42:28.205123 29253 sgd_solver.cpp:106] Iteration 3100, lr = 0.01
I0302 02:42:57.291020 29253 solver.cpp:237] Iteration 3120, loss = 0.00394281
I0302 02:42:57.291054 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00394281 (* 1 = 0.00394281 loss)
I0302 02:42:57.291061 29253 sgd_solver.cpp:106] Iteration 3120, lr = 0.01
I0302 02:43:25.979111 29253 solver.cpp:237] Iteration 3140, loss = 0.00392842
I0302 02:43:25.979141 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00392842 (* 1 = 0.00392842 loss)
I0302 02:43:25.979151 29253 sgd_solver.cpp:106] Iteration 3140, lr = 0.01
I0302 02:43:54.900890 29253 solver.cpp:237] Iteration 3160, loss = 0.00439744
I0302 02:43:54.900919 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00439744 (* 1 = 0.00439744 loss)
I0302 02:43:54.900928 29253 sgd_solver.cpp:106] Iteration 3160, lr = 0.01
I0302 02:44:23.808275 29253 solver.cpp:237] Iteration 3180, loss = 0.0054977
I0302 02:44:23.808305 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0054977 (* 1 = 0.0054977 loss)
I0302 02:44:23.808315 29253 sgd_solver.cpp:106] Iteration 3180, lr = 0.01
I0302 02:44:52.743304 29253 solver.cpp:237] Iteration 3200, loss = 0.00452694
I0302 02:44:52.743335 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00452694 (* 1 = 0.00452694 loss)
I0302 02:44:52.743343 29253 sgd_solver.cpp:106] Iteration 3200, lr = 0.01
I0302 02:45:21.353966 29253 solver.cpp:237] Iteration 3220, loss = 0.0045763
I0302 02:45:21.353998 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0045763 (* 1 = 0.0045763 loss)
I0302 02:45:21.354009 29253 sgd_solver.cpp:106] Iteration 3220, lr = 0.01
I0302 02:45:50.379097 29253 solver.cpp:237] Iteration 3240, loss = 0.0042155
I0302 02:45:50.379130 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0042155 (* 1 = 0.0042155 loss)
I0302 02:45:50.379138 29253 sgd_solver.cpp:106] Iteration 3240, lr = 0.01
I0302 02:46:19.466202 29253 solver.cpp:237] Iteration 3260, loss = 0.00404468
I0302 02:46:19.466233 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00404469 (* 1 = 0.00404469 loss)
I0302 02:46:19.466241 29253 sgd_solver.cpp:106] Iteration 3260, lr = 0.01
I0302 02:46:48.386037 29253 solver.cpp:237] Iteration 3280, loss = 0.00364521
I0302 02:46:48.386070 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00364521 (* 1 = 0.00364521 loss)
I0302 02:46:48.386078 29253 sgd_solver.cpp:106] Iteration 3280, lr = 0.01
I0302 02:47:17.300493 29253 solver.cpp:237] Iteration 3300, loss = 0.00345429
I0302 02:47:17.300525 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0034543 (* 1 = 0.0034543 loss)
I0302 02:47:17.300534 29253 sgd_solver.cpp:106] Iteration 3300, lr = 0.01
I0302 02:47:46.117254 29253 solver.cpp:237] Iteration 3320, loss = 0.00341239
I0302 02:47:46.117285 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00341239 (* 1 = 0.00341239 loss)
I0302 02:47:46.117293 29253 sgd_solver.cpp:106] Iteration 3320, lr = 0.01
I0302 02:48:15.332633 29253 solver.cpp:237] Iteration 3340, loss = 0.00422422
I0302 02:48:15.332666 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00422423 (* 1 = 0.00422423 loss)
I0302 02:48:15.332675 29253 sgd_solver.cpp:106] Iteration 3340, lr = 0.01
I0302 02:48:44.159775 29253 solver.cpp:237] Iteration 3360, loss = 0.00402237
I0302 02:48:44.159807 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00402238 (* 1 = 0.00402238 loss)
I0302 02:48:44.159816 29253 sgd_solver.cpp:106] Iteration 3360, lr = 0.01
I0302 02:49:13.339365 29253 solver.cpp:237] Iteration 3380, loss = 0.00388876
I0302 02:49:13.339398 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00388876 (* 1 = 0.00388876 loss)
I0302 02:49:13.339406 29253 sgd_solver.cpp:106] Iteration 3380, lr = 0.01
I0302 02:49:42.395603 29253 solver.cpp:237] Iteration 3400, loss = 0.00303556
I0302 02:49:42.395638 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00303556 (* 1 = 0.00303556 loss)
I0302 02:49:42.395648 29253 sgd_solver.cpp:106] Iteration 3400, lr = 0.01
I0302 02:50:11.018000 29253 solver.cpp:237] Iteration 3420, loss = 0.00499352
I0302 02:50:11.018033 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00499353 (* 1 = 0.00499353 loss)
I0302 02:50:11.018043 29253 sgd_solver.cpp:106] Iteration 3420, lr = 0.01
I0302 02:50:39.908869 29253 solver.cpp:237] Iteration 3440, loss = 0.00287661
I0302 02:50:39.908901 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00287662 (* 1 = 0.00287662 loss)
I0302 02:50:39.908910 29253 sgd_solver.cpp:106] Iteration 3440, lr = 0.01
I0302 02:51:09.229753 29253 solver.cpp:237] Iteration 3460, loss = 0.00377459
I0302 02:51:09.229784 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00377459 (* 1 = 0.00377459 loss)
I0302 02:51:09.229792 29253 sgd_solver.cpp:106] Iteration 3460, lr = 0.01
I0302 02:51:37.664345 29253 solver.cpp:237] Iteration 3480, loss = 0.00332858
I0302 02:51:37.664377 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00332858 (* 1 = 0.00332858 loss)
I0302 02:51:37.664386 29253 sgd_solver.cpp:106] Iteration 3480, lr = 0.01
I0302 02:52:06.508733 29253 solver.cpp:237] Iteration 3500, loss = 0.00390374
I0302 02:52:06.508764 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00390374 (* 1 = 0.00390374 loss)
I0302 02:52:06.508771 29253 sgd_solver.cpp:106] Iteration 3500, lr = 0.01
I0302 02:52:35.610875 29253 solver.cpp:237] Iteration 3520, loss = 0.00425945
I0302 02:52:35.610906 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00425946 (* 1 = 0.00425946 loss)
I0302 02:52:35.610914 29253 sgd_solver.cpp:106] Iteration 3520, lr = 0.01
I0302 02:53:04.394531 29253 solver.cpp:237] Iteration 3540, loss = 0.00378026
I0302 02:53:04.394563 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00378027 (* 1 = 0.00378027 loss)
I0302 02:53:04.394572 29253 sgd_solver.cpp:106] Iteration 3540, lr = 0.01
I0302 02:53:33.154567 29253 solver.cpp:237] Iteration 3560, loss = 0.00341691
I0302 02:53:33.154598 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00341692 (* 1 = 0.00341692 loss)
I0302 02:53:33.154608 29253 sgd_solver.cpp:106] Iteration 3560, lr = 0.01
I0302 02:54:02.190991 29253 solver.cpp:237] Iteration 3580, loss = 0.00336633
I0302 02:54:02.191023 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00336633 (* 1 = 0.00336633 loss)
I0302 02:54:02.191032 29253 sgd_solver.cpp:106] Iteration 3580, lr = 0.01
I0302 02:54:31.021399 29253 solver.cpp:237] Iteration 3600, loss = 0.00345549
I0302 02:54:31.021431 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00345549 (* 1 = 0.00345549 loss)
I0302 02:54:31.021440 29253 sgd_solver.cpp:106] Iteration 3600, lr = 0.01
I0302 02:55:00.132781 29253 solver.cpp:237] Iteration 3620, loss = 0.00359385
I0302 02:55:00.132812 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00359385 (* 1 = 0.00359385 loss)
I0302 02:55:00.132820 29253 sgd_solver.cpp:106] Iteration 3620, lr = 0.01
I0302 02:55:29.061722 29253 solver.cpp:237] Iteration 3640, loss = 0.00388298
I0302 02:55:29.061754 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00388298 (* 1 = 0.00388298 loss)
I0302 02:55:29.061763 29253 sgd_solver.cpp:106] Iteration 3640, lr = 0.01
I0302 02:55:57.956296 29253 solver.cpp:237] Iteration 3660, loss = 0.00282247
I0302 02:55:57.956328 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00282247 (* 1 = 0.00282247 loss)
I0302 02:55:57.956337 29253 sgd_solver.cpp:106] Iteration 3660, lr = 0.01
I0302 02:56:26.771157 29253 solver.cpp:237] Iteration 3680, loss = 0.00410653
I0302 02:56:26.771190 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00410653 (* 1 = 0.00410653 loss)
I0302 02:56:26.771199 29253 sgd_solver.cpp:106] Iteration 3680, lr = 0.01
I0302 02:56:55.686705 29253 solver.cpp:237] Iteration 3700, loss = 0.00469066
I0302 02:56:55.686738 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00469067 (* 1 = 0.00469067 loss)
I0302 02:56:55.686745 29253 sgd_solver.cpp:106] Iteration 3700, lr = 0.01
I0302 02:57:24.697854 29253 solver.cpp:237] Iteration 3720, loss = 0.00344558
I0302 02:57:24.697885 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00344559 (* 1 = 0.00344559 loss)
I0302 02:57:24.697893 29253 sgd_solver.cpp:106] Iteration 3720, lr = 0.01
I0302 02:57:53.639188 29253 solver.cpp:237] Iteration 3740, loss = 0.0031867
I0302 02:57:53.639219 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00318671 (* 1 = 0.00318671 loss)
I0302 02:57:53.639227 29253 sgd_solver.cpp:106] Iteration 3740, lr = 0.01
I0302 02:58:22.575419 29253 solver.cpp:237] Iteration 3760, loss = 0.00345191
I0302 02:58:22.575450 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00345191 (* 1 = 0.00345191 loss)
I0302 02:58:22.575459 29253 sgd_solver.cpp:106] Iteration 3760, lr = 0.01
I0302 02:58:51.315739 29253 solver.cpp:237] Iteration 3780, loss = 0.00301329
I0302 02:58:51.315771 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00301329 (* 1 = 0.00301329 loss)
I0302 02:58:51.315780 29253 sgd_solver.cpp:106] Iteration 3780, lr = 0.01
I0302 02:59:20.161285 29253 solver.cpp:237] Iteration 3800, loss = 0.00460639
I0302 02:59:20.161319 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0046064 (* 1 = 0.0046064 loss)
I0302 02:59:20.161326 29253 sgd_solver.cpp:106] Iteration 3800, lr = 0.01
I0302 02:59:48.913645 29253 solver.cpp:237] Iteration 3820, loss = 0.00342564
I0302 02:59:48.913676 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00342565 (* 1 = 0.00342565 loss)
I0302 02:59:48.913684 29253 sgd_solver.cpp:106] Iteration 3820, lr = 0.01
I0302 03:00:17.873289 29253 solver.cpp:237] Iteration 3840, loss = 0.0031745
I0302 03:00:17.873322 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00317451 (* 1 = 0.00317451 loss)
I0302 03:00:17.873332 29253 sgd_solver.cpp:106] Iteration 3840, lr = 0.01
I0302 03:00:46.803381 29253 solver.cpp:237] Iteration 3860, loss = 0.00377213
I0302 03:00:46.803412 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00377213 (* 1 = 0.00377213 loss)
I0302 03:00:46.803421 29253 sgd_solver.cpp:106] Iteration 3860, lr = 0.01
I0302 03:01:15.806097 29253 solver.cpp:237] Iteration 3880, loss = 0.00342446
I0302 03:01:15.806129 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00342446 (* 1 = 0.00342446 loss)
I0302 03:01:15.806138 29253 sgd_solver.cpp:106] Iteration 3880, lr = 0.01
I0302 03:01:44.803208 29253 solver.cpp:237] Iteration 3900, loss = 0.00364633
I0302 03:01:44.803238 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00364633 (* 1 = 0.00364633 loss)
I0302 03:01:44.803247 29253 sgd_solver.cpp:106] Iteration 3900, lr = 0.01
I0302 03:02:13.954074 29253 solver.cpp:237] Iteration 3920, loss = 0.00375869
I0302 03:02:13.954105 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0037587 (* 1 = 0.0037587 loss)
I0302 03:02:13.954114 29253 sgd_solver.cpp:106] Iteration 3920, lr = 0.01
I0302 03:02:42.821707 29253 solver.cpp:237] Iteration 3940, loss = 0.00351254
I0302 03:02:42.821738 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00351255 (* 1 = 0.00351255 loss)
I0302 03:02:42.821748 29253 sgd_solver.cpp:106] Iteration 3940, lr = 0.01
I0302 03:03:11.620733 29253 solver.cpp:237] Iteration 3960, loss = 0.00331829
I0302 03:03:11.620764 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00331829 (* 1 = 0.00331829 loss)
I0302 03:03:11.620771 29253 sgd_solver.cpp:106] Iteration 3960, lr = 0.01
I0302 03:03:40.486313 29253 solver.cpp:237] Iteration 3980, loss = 0.00433639
I0302 03:03:40.486345 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0043364 (* 1 = 0.0043364 loss)
I0302 03:03:40.486353 29253 sgd_solver.cpp:106] Iteration 3980, lr = 0.01
I0302 03:04:09.530222 29253 solver.cpp:237] Iteration 4000, loss = 0.00277238
I0302 03:04:09.530257 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00277238 (* 1 = 0.00277238 loss)
I0302 03:04:09.530266 29253 sgd_solver.cpp:106] Iteration 4000, lr = 0.01
I0302 03:04:09.531338 29253 blocking_queue.cpp:50] Data layer prefetch queue empty
I0302 03:04:38.371862 29253 solver.cpp:237] Iteration 4020, loss = 0.00644553
I0302 03:04:38.371896 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00644553 (* 1 = 0.00644553 loss)
I0302 03:04:38.371903 29253 sgd_solver.cpp:106] Iteration 4020, lr = 0.01
I0302 03:05:07.023998 29253 solver.cpp:237] Iteration 4040, loss = 0.00308143
I0302 03:05:07.024029 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00308143 (* 1 = 0.00308143 loss)
I0302 03:05:07.024039 29253 sgd_solver.cpp:106] Iteration 4040, lr = 0.01
I0302 03:05:36.034518 29253 solver.cpp:237] Iteration 4060, loss = 0.00290431
I0302 03:05:36.034550 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00290432 (* 1 = 0.00290432 loss)
I0302 03:05:36.034559 29253 sgd_solver.cpp:106] Iteration 4060, lr = 0.01
I0302 03:06:05.119351 29253 solver.cpp:237] Iteration 4080, loss = 0.00363875
I0302 03:06:05.119382 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00363875 (* 1 = 0.00363875 loss)
I0302 03:06:05.119391 29253 sgd_solver.cpp:106] Iteration 4080, lr = 0.01
I0302 03:06:33.896105 29253 solver.cpp:237] Iteration 4100, loss = 0.00361257
I0302 03:06:33.896134 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00361257 (* 1 = 0.00361257 loss)
I0302 03:06:33.896143 29253 sgd_solver.cpp:106] Iteration 4100, lr = 0.01
I0302 03:07:02.820623 29253 solver.cpp:237] Iteration 4120, loss = 0.00308072
I0302 03:07:02.820657 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00308072 (* 1 = 0.00308072 loss)
I0302 03:07:02.820665 29253 sgd_solver.cpp:106] Iteration 4120, lr = 0.01
I0302 03:07:31.944958 29253 solver.cpp:237] Iteration 4140, loss = 0.00346307
I0302 03:07:31.944990 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00346308 (* 1 = 0.00346308 loss)
I0302 03:07:31.944999 29253 sgd_solver.cpp:106] Iteration 4140, lr = 0.01
I0302 03:08:00.723242 29253 solver.cpp:237] Iteration 4160, loss = 0.00334041
I0302 03:08:00.723271 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00334042 (* 1 = 0.00334042 loss)
I0302 03:08:00.723279 29253 sgd_solver.cpp:106] Iteration 4160, lr = 0.01
I0302 03:08:29.512511 29253 solver.cpp:237] Iteration 4180, loss = 0.00359259
I0302 03:08:29.512544 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0035926 (* 1 = 0.0035926 loss)
I0302 03:08:29.512553 29253 sgd_solver.cpp:106] Iteration 4180, lr = 0.01
I0302 03:08:58.414716 29253 solver.cpp:237] Iteration 4200, loss = 0.00363205
I0302 03:08:58.414746 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00363206 (* 1 = 0.00363206 loss)
I0302 03:08:58.414754 29253 sgd_solver.cpp:106] Iteration 4200, lr = 0.01
I0302 03:09:27.304772 29253 solver.cpp:237] Iteration 4220, loss = 0.00411726
I0302 03:09:27.304807 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00411727 (* 1 = 0.00411727 loss)
I0302 03:09:27.304816 29253 sgd_solver.cpp:106] Iteration 4220, lr = 0.01
I0302 03:09:56.162680 29253 solver.cpp:237] Iteration 4240, loss = 0.00324795
I0302 03:09:56.162713 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00324796 (* 1 = 0.00324796 loss)
I0302 03:09:56.162720 29253 sgd_solver.cpp:106] Iteration 4240, lr = 0.01
I0302 03:10:25.135771 29253 solver.cpp:237] Iteration 4260, loss = 0.00279161
I0302 03:10:25.135803 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00279162 (* 1 = 0.00279162 loss)
I0302 03:10:25.135812 29253 sgd_solver.cpp:106] Iteration 4260, lr = 0.01
I0302 03:10:54.163331 29253 solver.cpp:237] Iteration 4280, loss = 0.00367345
I0302 03:10:54.163363 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00367345 (* 1 = 0.00367345 loss)
I0302 03:10:54.163372 29253 sgd_solver.cpp:106] Iteration 4280, lr = 0.01
I0302 03:11:22.869539 29253 solver.cpp:237] Iteration 4300, loss = 0.00357239
I0302 03:11:22.869571 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00357239 (* 1 = 0.00357239 loss)
I0302 03:11:22.869580 29253 sgd_solver.cpp:106] Iteration 4300, lr = 0.01
I0302 03:11:51.750777 29253 solver.cpp:237] Iteration 4320, loss = 0.00380209
I0302 03:11:51.750808 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00380209 (* 1 = 0.00380209 loss)
I0302 03:11:51.750818 29253 sgd_solver.cpp:106] Iteration 4320, lr = 0.01
I0302 03:12:20.681921 29253 solver.cpp:237] Iteration 4340, loss = 0.00322592
I0302 03:12:20.681948 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00322592 (* 1 = 0.00322592 loss)
I0302 03:12:20.681957 29253 sgd_solver.cpp:106] Iteration 4340, lr = 0.01
I0302 03:12:49.558576 29253 solver.cpp:237] Iteration 4360, loss = 0.00333747
I0302 03:12:49.558609 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00333747 (* 1 = 0.00333747 loss)
I0302 03:12:49.558617 29253 sgd_solver.cpp:106] Iteration 4360, lr = 0.01
I0302 03:13:18.555042 29253 solver.cpp:237] Iteration 4380, loss = 0.00345443
I0302 03:13:18.555073 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00345443 (* 1 = 0.00345443 loss)
I0302 03:13:18.555081 29253 sgd_solver.cpp:106] Iteration 4380, lr = 0.01
I0302 03:13:47.567078 29253 solver.cpp:237] Iteration 4400, loss = 0.00326447
I0302 03:13:47.567108 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00326447 (* 1 = 0.00326447 loss)
I0302 03:13:47.567117 29253 sgd_solver.cpp:106] Iteration 4400, lr = 0.01
I0302 03:14:16.306812 29253 solver.cpp:237] Iteration 4420, loss = 0.00298937
I0302 03:14:16.306843 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00298937 (* 1 = 0.00298937 loss)
I0302 03:14:16.306852 29253 sgd_solver.cpp:106] Iteration 4420, lr = 0.01
I0302 03:14:45.113402 29253 solver.cpp:237] Iteration 4440, loss = 0.00394399
I0302 03:14:45.113433 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00394399 (* 1 = 0.00394399 loss)
I0302 03:14:45.113442 29253 sgd_solver.cpp:106] Iteration 4440, lr = 0.01
I0302 03:15:14.182824 29253 solver.cpp:237] Iteration 4460, loss = 0.00259627
I0302 03:15:14.182857 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00259628 (* 1 = 0.00259628 loss)
I0302 03:15:14.182864 29253 sgd_solver.cpp:106] Iteration 4460, lr = 0.01
I0302 03:15:43.111438 29253 solver.cpp:237] Iteration 4480, loss = 0.00301185
I0302 03:15:43.111469 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00301186 (* 1 = 0.00301186 loss)
I0302 03:15:43.111477 29253 sgd_solver.cpp:106] Iteration 4480, lr = 0.01
I0302 03:16:11.986891 29253 solver.cpp:237] Iteration 4500, loss = 0.00314522
I0302 03:16:11.986922 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00314523 (* 1 = 0.00314523 loss)
I0302 03:16:11.986932 29253 sgd_solver.cpp:106] Iteration 4500, lr = 0.01
I0302 03:16:41.057693 29253 solver.cpp:237] Iteration 4520, loss = 0.00230954
I0302 03:16:41.057725 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00230955 (* 1 = 0.00230955 loss)
I0302 03:16:41.057734 29253 sgd_solver.cpp:106] Iteration 4520, lr = 0.01
I0302 03:17:09.854467 29253 solver.cpp:237] Iteration 4540, loss = 0.00334617
I0302 03:17:09.854497 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00334617 (* 1 = 0.00334617 loss)
I0302 03:17:09.854506 29253 sgd_solver.cpp:106] Iteration 4540, lr = 0.01
I0302 03:17:38.752722 29253 solver.cpp:237] Iteration 4560, loss = 0.00245775
I0302 03:17:38.752755 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00245775 (* 1 = 0.00245775 loss)
I0302 03:17:38.752763 29253 sgd_solver.cpp:106] Iteration 4560, lr = 0.01
I0302 03:18:07.641341 29253 solver.cpp:237] Iteration 4580, loss = 0.00346488
I0302 03:18:07.641366 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00346488 (* 1 = 0.00346488 loss)
I0302 03:18:07.641373 29253 sgd_solver.cpp:106] Iteration 4580, lr = 0.01
I0302 03:18:36.386284 29253 solver.cpp:237] Iteration 4600, loss = 0.00217714
I0302 03:18:36.386315 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00217714 (* 1 = 0.00217714 loss)
I0302 03:18:36.386324 29253 sgd_solver.cpp:106] Iteration 4600, lr = 0.01
I0302 03:19:05.531741 29253 solver.cpp:237] Iteration 4620, loss = 0.00391884
I0302 03:19:05.531774 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00391884 (* 1 = 0.00391884 loss)
I0302 03:19:05.531781 29253 sgd_solver.cpp:106] Iteration 4620, lr = 0.01
I0302 03:19:34.430346 29253 solver.cpp:237] Iteration 4640, loss = 0.00257962
I0302 03:19:34.430377 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00257962 (* 1 = 0.00257962 loss)
I0302 03:19:34.430384 29253 sgd_solver.cpp:106] Iteration 4640, lr = 0.01
I0302 03:20:02.985347 29253 solver.cpp:237] Iteration 4660, loss = 0.00252722
I0302 03:20:02.985379 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00252722 (* 1 = 0.00252722 loss)
I0302 03:20:02.985388 29253 sgd_solver.cpp:106] Iteration 4660, lr = 0.01
I0302 03:20:31.677088 29253 solver.cpp:237] Iteration 4680, loss = 0.00287558
I0302 03:20:31.677119 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00287558 (* 1 = 0.00287558 loss)
I0302 03:20:31.677129 29253 sgd_solver.cpp:106] Iteration 4680, lr = 0.01
I0302 03:21:00.758543 29253 solver.cpp:237] Iteration 4700, loss = 0.00299061
I0302 03:21:00.758575 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00299062 (* 1 = 0.00299062 loss)
I0302 03:21:00.758586 29253 sgd_solver.cpp:106] Iteration 4700, lr = 0.01
I0302 03:21:29.668424 29253 solver.cpp:237] Iteration 4720, loss = 0.00277726
I0302 03:21:29.668458 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00277726 (* 1 = 0.00277726 loss)
I0302 03:21:29.668467 29253 sgd_solver.cpp:106] Iteration 4720, lr = 0.01
I0302 03:21:58.688047 29253 solver.cpp:237] Iteration 4740, loss = 0.00285265
I0302 03:21:58.688079 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00285265 (* 1 = 0.00285265 loss)
I0302 03:21:58.688087 29253 sgd_solver.cpp:106] Iteration 4740, lr = 0.01
I0302 03:22:27.626874 29253 solver.cpp:237] Iteration 4760, loss = 0.0025963
I0302 03:22:27.626907 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0025963 (* 1 = 0.0025963 loss)
I0302 03:22:27.626915 29253 sgd_solver.cpp:106] Iteration 4760, lr = 0.01
I0302 03:22:56.317821 29253 solver.cpp:237] Iteration 4780, loss = 0.00299025
I0302 03:22:56.317854 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00299026 (* 1 = 0.00299026 loss)
I0302 03:22:56.317863 29253 sgd_solver.cpp:106] Iteration 4780, lr = 0.01
I0302 03:23:25.396875 29253 solver.cpp:237] Iteration 4800, loss = 0.00255769
I0302 03:23:25.396908 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00255769 (* 1 = 0.00255769 loss)
I0302 03:23:25.396916 29253 sgd_solver.cpp:106] Iteration 4800, lr = 0.01
I0302 03:23:54.217612 29253 solver.cpp:237] Iteration 4820, loss = 0.00247013
I0302 03:23:54.217645 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00247013 (* 1 = 0.00247013 loss)
I0302 03:23:54.217654 29253 sgd_solver.cpp:106] Iteration 4820, lr = 0.01
I0302 03:24:23.204174 29253 solver.cpp:237] Iteration 4840, loss = 0.0026061
I0302 03:24:23.204205 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0026061 (* 1 = 0.0026061 loss)
I0302 03:24:23.204213 29253 sgd_solver.cpp:106] Iteration 4840, lr = 0.01
I0302 03:24:51.974205 29253 solver.cpp:237] Iteration 4860, loss = 0.00342121
I0302 03:24:51.974236 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00342122 (* 1 = 0.00342122 loss)
I0302 03:24:51.974244 29253 sgd_solver.cpp:106] Iteration 4860, lr = 0.01
I0302 03:25:20.630533 29253 solver.cpp:237] Iteration 4880, loss = 0.00276659
I0302 03:25:20.630568 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0027666 (* 1 = 0.0027666 loss)
I0302 03:25:20.630576 29253 sgd_solver.cpp:106] Iteration 4880, lr = 0.01
I0302 03:25:49.510843 29253 solver.cpp:237] Iteration 4900, loss = 0.00285346
I0302 03:25:49.510875 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00285346 (* 1 = 0.00285346 loss)
I0302 03:25:49.510884 29253 sgd_solver.cpp:106] Iteration 4900, lr = 0.01
I0302 03:26:18.480917 29253 solver.cpp:237] Iteration 4920, loss = 0.00303197
I0302 03:26:18.480948 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00303198 (* 1 = 0.00303198 loss)
I0302 03:26:18.480957 29253 sgd_solver.cpp:106] Iteration 4920, lr = 0.01
I0302 03:26:47.377257 29253 solver.cpp:237] Iteration 4940, loss = 0.0033452
I0302 03:26:47.377290 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0033452 (* 1 = 0.0033452 loss)
I0302 03:26:47.377300 29253 sgd_solver.cpp:106] Iteration 4940, lr = 0.01
I0302 03:27:16.228581 29253 solver.cpp:237] Iteration 4960, loss = 0.00270995
I0302 03:27:16.228612 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00270995 (* 1 = 0.00270995 loss)
I0302 03:27:16.228621 29253 sgd_solver.cpp:106] Iteration 4960, lr = 0.01
I0302 03:27:45.195332 29253 solver.cpp:237] Iteration 4980, loss = 0.00230198
I0302 03:27:45.195365 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00230198 (* 1 = 0.00230198 loss)
I0302 03:27:45.195374 29253 sgd_solver.cpp:106] Iteration 4980, lr = 0.01
I0302 03:28:12.669188 29253 solver.cpp:459] Snapshotting to binary proto file /nfs.yoda/xiaolonw/fast_rcnn/models_sunrgbd/pre_cls_1fc_scratch/model__iter_5000.caffemodel
I0302 03:28:13.869200 29253 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /nfs.yoda/xiaolonw/fast_rcnn/models_sunrgbd/pre_cls_1fc_scratch/model__iter_5000.solverstate
I0302 03:28:14.348693 29253 solver.cpp:237] Iteration 5000, loss = 0.0030571
I0302 03:28:14.348726 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0030571 (* 1 = 0.0030571 loss)
I0302 03:28:14.348734 29253 sgd_solver.cpp:106] Iteration 5000, lr = 0.01
I0302 03:28:15.556385 29253 blocking_queue.cpp:50] Data layer prefetch queue empty
I0302 03:28:42.838924 29253 solver.cpp:237] Iteration 5020, loss = 0.00264163
I0302 03:28:42.838956 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00264163 (* 1 = 0.00264163 loss)
I0302 03:28:42.838965 29253 sgd_solver.cpp:106] Iteration 5020, lr = 0.01
I0302 03:29:11.694067 29253 solver.cpp:237] Iteration 5040, loss = 0.00232671
I0302 03:29:11.694097 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00232671 (* 1 = 0.00232671 loss)
I0302 03:29:11.694105 29253 sgd_solver.cpp:106] Iteration 5040, lr = 0.01
I0302 03:29:40.645022 29253 solver.cpp:237] Iteration 5060, loss = 0.00253823
I0302 03:29:40.645054 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00253823 (* 1 = 0.00253823 loss)
I0302 03:29:40.645062 29253 sgd_solver.cpp:106] Iteration 5060, lr = 0.01
I0302 03:30:09.563215 29253 solver.cpp:237] Iteration 5080, loss = 0.00340228
I0302 03:30:09.563247 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00340228 (* 1 = 0.00340228 loss)
I0302 03:30:09.563256 29253 sgd_solver.cpp:106] Iteration 5080, lr = 0.01
I0302 03:30:38.545454 29253 solver.cpp:237] Iteration 5100, loss = 0.00230567
I0302 03:30:38.545483 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00230568 (* 1 = 0.00230568 loss)
I0302 03:30:38.545492 29253 sgd_solver.cpp:106] Iteration 5100, lr = 0.01
I0302 03:31:07.311738 29253 solver.cpp:237] Iteration 5120, loss = 0.00283573
I0302 03:31:07.311770 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00283574 (* 1 = 0.00283574 loss)
I0302 03:31:07.311779 29253 sgd_solver.cpp:106] Iteration 5120, lr = 0.01
I0302 03:31:36.231673 29253 solver.cpp:237] Iteration 5140, loss = 0.00248715
I0302 03:31:36.231703 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00248715 (* 1 = 0.00248715 loss)
I0302 03:31:36.231712 29253 sgd_solver.cpp:106] Iteration 5140, lr = 0.01
I0302 03:32:04.998438 29253 solver.cpp:237] Iteration 5160, loss = 0.00278194
I0302 03:32:04.998471 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00278194 (* 1 = 0.00278194 loss)
I0302 03:32:04.998479 29253 sgd_solver.cpp:106] Iteration 5160, lr = 0.01
I0302 03:32:33.935690 29253 solver.cpp:237] Iteration 5180, loss = 0.0034304
I0302 03:32:33.935724 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0034304 (* 1 = 0.0034304 loss)
I0302 03:32:33.935732 29253 sgd_solver.cpp:106] Iteration 5180, lr = 0.01
I0302 03:33:02.827512 29253 solver.cpp:237] Iteration 5200, loss = 0.0025123
I0302 03:33:02.827544 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0025123 (* 1 = 0.0025123 loss)
I0302 03:33:02.827553 29253 sgd_solver.cpp:106] Iteration 5200, lr = 0.01
I0302 03:33:31.515038 29253 solver.cpp:237] Iteration 5220, loss = 0.00278949
I0302 03:33:31.515069 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00278949 (* 1 = 0.00278949 loss)
I0302 03:33:31.515079 29253 sgd_solver.cpp:106] Iteration 5220, lr = 0.01
I0302 03:34:00.594709 29253 solver.cpp:237] Iteration 5240, loss = 0.00282782
I0302 03:34:00.594741 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00282782 (* 1 = 0.00282782 loss)
I0302 03:34:00.594750 29253 sgd_solver.cpp:106] Iteration 5240, lr = 0.01
I0302 03:34:29.367254 29253 solver.cpp:237] Iteration 5260, loss = 0.00215548
I0302 03:34:29.367286 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00215548 (* 1 = 0.00215548 loss)
I0302 03:34:29.367295 29253 sgd_solver.cpp:106] Iteration 5260, lr = 0.01
I0302 03:34:58.188809 29253 solver.cpp:237] Iteration 5280, loss = 0.0031135
I0302 03:34:58.188843 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00311351 (* 1 = 0.00311351 loss)
I0302 03:34:58.188851 29253 sgd_solver.cpp:106] Iteration 5280, lr = 0.01
I0302 03:35:27.012693 29253 solver.cpp:237] Iteration 5300, loss = 0.00330785
I0302 03:35:27.012725 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00330786 (* 1 = 0.00330786 loss)
I0302 03:35:27.012734 29253 sgd_solver.cpp:106] Iteration 5300, lr = 0.01
I0302 03:35:55.885629 29253 solver.cpp:237] Iteration 5320, loss = 0.00252798
I0302 03:35:55.885661 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00252798 (* 1 = 0.00252798 loss)
I0302 03:35:55.885670 29253 sgd_solver.cpp:106] Iteration 5320, lr = 0.01
I0302 03:36:24.889170 29253 solver.cpp:237] Iteration 5340, loss = 0.00211218
I0302 03:36:24.889201 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00211219 (* 1 = 0.00211219 loss)
I0302 03:36:24.889210 29253 sgd_solver.cpp:106] Iteration 5340, lr = 0.01
I0302 03:36:53.355275 29253 solver.cpp:237] Iteration 5360, loss = 0.00261073
I0302 03:36:53.355307 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00261074 (* 1 = 0.00261074 loss)
I0302 03:36:53.355316 29253 sgd_solver.cpp:106] Iteration 5360, lr = 0.01
I0302 03:37:22.192436 29253 solver.cpp:237] Iteration 5380, loss = 0.00350661
I0302 03:37:22.192467 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00350661 (* 1 = 0.00350661 loss)
I0302 03:37:22.192476 29253 sgd_solver.cpp:106] Iteration 5380, lr = 0.01
I0302 03:37:51.380355 29253 solver.cpp:237] Iteration 5400, loss = 0.00279695
I0302 03:37:51.380386 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00279695 (* 1 = 0.00279695 loss)
I0302 03:37:51.380395 29253 sgd_solver.cpp:106] Iteration 5400, lr = 0.01
I0302 03:38:20.275324 29253 solver.cpp:237] Iteration 5420, loss = 0.00247135
I0302 03:38:20.275357 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00247135 (* 1 = 0.00247135 loss)
I0302 03:38:20.275367 29253 sgd_solver.cpp:106] Iteration 5420, lr = 0.01
I0302 03:38:49.369195 29253 solver.cpp:237] Iteration 5440, loss = 0.00245083
I0302 03:38:49.369226 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00245083 (* 1 = 0.00245083 loss)
I0302 03:38:49.369235 29253 sgd_solver.cpp:106] Iteration 5440, lr = 0.01
I0302 03:39:18.393350 29253 solver.cpp:237] Iteration 5460, loss = 0.00208805
I0302 03:39:18.393383 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00208805 (* 1 = 0.00208805 loss)
I0302 03:39:18.393391 29253 sgd_solver.cpp:106] Iteration 5460, lr = 0.01
I0302 03:39:47.344121 29253 solver.cpp:237] Iteration 5480, loss = 0.00215648
I0302 03:39:47.344153 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00215648 (* 1 = 0.00215648 loss)
I0302 03:39:47.344162 29253 sgd_solver.cpp:106] Iteration 5480, lr = 0.01
I0302 03:40:16.254672 29253 solver.cpp:237] Iteration 5500, loss = 0.00268247
I0302 03:40:16.254703 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00268247 (* 1 = 0.00268247 loss)
I0302 03:40:16.254711 29253 sgd_solver.cpp:106] Iteration 5500, lr = 0.01
I0302 03:40:45.262493 29253 solver.cpp:237] Iteration 5520, loss = 0.00221993
I0302 03:40:45.262526 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00221993 (* 1 = 0.00221993 loss)
I0302 03:40:45.262534 29253 sgd_solver.cpp:106] Iteration 5520, lr = 0.01
I0302 03:41:14.189015 29253 solver.cpp:237] Iteration 5540, loss = 0.00341752
I0302 03:41:14.189048 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00341752 (* 1 = 0.00341752 loss)
I0302 03:41:14.189056 29253 sgd_solver.cpp:106] Iteration 5540, lr = 0.01
I0302 03:41:43.322945 29253 solver.cpp:237] Iteration 5560, loss = 0.00272129
I0302 03:41:43.322976 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0027213 (* 1 = 0.0027213 loss)
I0302 03:41:43.322985 29253 sgd_solver.cpp:106] Iteration 5560, lr = 0.01
I0302 03:42:12.449050 29253 solver.cpp:237] Iteration 5580, loss = 0.0022264
I0302 03:42:12.449082 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00222641 (* 1 = 0.00222641 loss)
I0302 03:42:12.449090 29253 sgd_solver.cpp:106] Iteration 5580, lr = 0.01
I0302 03:42:41.392457 29253 solver.cpp:237] Iteration 5600, loss = 0.00296431
I0302 03:42:41.392488 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00296431 (* 1 = 0.00296431 loss)
I0302 03:42:41.392496 29253 sgd_solver.cpp:106] Iteration 5600, lr = 0.01
I0302 03:43:10.152132 29253 solver.cpp:237] Iteration 5620, loss = 0.00250702
I0302 03:43:10.152163 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00250703 (* 1 = 0.00250703 loss)
I0302 03:43:10.152173 29253 sgd_solver.cpp:106] Iteration 5620, lr = 0.01
I0302 03:43:39.132179 29253 solver.cpp:237] Iteration 5640, loss = 0.0026081
I0302 03:43:39.132210 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0026081 (* 1 = 0.0026081 loss)
I0302 03:43:39.132220 29253 sgd_solver.cpp:106] Iteration 5640, lr = 0.01
I0302 03:44:08.011936 29253 solver.cpp:237] Iteration 5660, loss = 0.00240131
I0302 03:44:08.011970 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00240131 (* 1 = 0.00240131 loss)
I0302 03:44:08.011977 29253 sgd_solver.cpp:106] Iteration 5660, lr = 0.01
I0302 03:44:36.879760 29253 solver.cpp:237] Iteration 5680, loss = 0.00255189
I0302 03:44:36.879791 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00255189 (* 1 = 0.00255189 loss)
I0302 03:44:36.879801 29253 sgd_solver.cpp:106] Iteration 5680, lr = 0.01
I0302 03:45:05.753926 29253 solver.cpp:237] Iteration 5700, loss = 0.00323963
I0302 03:45:05.753957 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00323963 (* 1 = 0.00323963 loss)
I0302 03:45:05.753967 29253 sgd_solver.cpp:106] Iteration 5700, lr = 0.01
I0302 03:45:34.683120 29253 solver.cpp:237] Iteration 5720, loss = 0.00347168
I0302 03:45:34.683152 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00347168 (* 1 = 0.00347168 loss)
I0302 03:45:34.683161 29253 sgd_solver.cpp:106] Iteration 5720, lr = 0.01
I0302 03:46:03.647752 29253 solver.cpp:237] Iteration 5740, loss = 0.00236936
I0302 03:46:03.647783 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00236937 (* 1 = 0.00236937 loss)
I0302 03:46:03.647792 29253 sgd_solver.cpp:106] Iteration 5740, lr = 0.01
I0302 03:46:32.415850 29253 solver.cpp:237] Iteration 5760, loss = 0.00238163
I0302 03:46:32.415884 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00238163 (* 1 = 0.00238163 loss)
I0302 03:46:32.415892 29253 sgd_solver.cpp:106] Iteration 5760, lr = 0.01
I0302 03:47:01.247575 29253 solver.cpp:237] Iteration 5780, loss = 0.00261036
I0302 03:47:01.247606 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00261037 (* 1 = 0.00261037 loss)
I0302 03:47:01.247616 29253 sgd_solver.cpp:106] Iteration 5780, lr = 0.01
I0302 03:47:30.133592 29253 solver.cpp:237] Iteration 5800, loss = 0.00222782
I0302 03:47:30.133625 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00222782 (* 1 = 0.00222782 loss)
I0302 03:47:30.133633 29253 sgd_solver.cpp:106] Iteration 5800, lr = 0.01
I0302 03:47:59.301825 29253 solver.cpp:237] Iteration 5820, loss = 0.00198774
I0302 03:47:59.301856 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00198774 (* 1 = 0.00198774 loss)
I0302 03:47:59.301865 29253 sgd_solver.cpp:106] Iteration 5820, lr = 0.01
I0302 03:48:28.225718 29253 solver.cpp:237] Iteration 5840, loss = 0.00212927
I0302 03:48:28.225749 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00212927 (* 1 = 0.00212927 loss)
I0302 03:48:28.225757 29253 sgd_solver.cpp:106] Iteration 5840, lr = 0.01
I0302 03:48:56.982101 29253 solver.cpp:237] Iteration 5860, loss = 0.00242991
I0302 03:48:56.982133 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00242991 (* 1 = 0.00242991 loss)
I0302 03:48:56.982142 29253 sgd_solver.cpp:106] Iteration 5860, lr = 0.01
I0302 03:49:25.876689 29253 solver.cpp:237] Iteration 5880, loss = 0.00306696
I0302 03:49:25.876723 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00306697 (* 1 = 0.00306697 loss)
I0302 03:49:25.876730 29253 sgd_solver.cpp:106] Iteration 5880, lr = 0.01
I0302 03:49:54.750715 29253 solver.cpp:237] Iteration 5900, loss = 0.00237328
I0302 03:49:54.750747 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00237328 (* 1 = 0.00237328 loss)
I0302 03:49:54.750756 29253 sgd_solver.cpp:106] Iteration 5900, lr = 0.01
I0302 03:50:23.732141 29253 solver.cpp:237] Iteration 5920, loss = 0.00224482
I0302 03:50:23.732172 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00224483 (* 1 = 0.00224483 loss)
I0302 03:50:23.732179 29253 sgd_solver.cpp:106] Iteration 5920, lr = 0.01
I0302 03:50:52.642616 29253 solver.cpp:237] Iteration 5940, loss = 0.00270726
I0302 03:50:52.642650 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00270727 (* 1 = 0.00270727 loss)
I0302 03:50:52.642659 29253 sgd_solver.cpp:106] Iteration 5940, lr = 0.01
I0302 03:51:21.511685 29253 solver.cpp:237] Iteration 5960, loss = 0.00238231
I0302 03:51:21.511718 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00238231 (* 1 = 0.00238231 loss)
I0302 03:51:21.511726 29253 sgd_solver.cpp:106] Iteration 5960, lr = 0.01
I0302 03:51:50.391816 29253 solver.cpp:237] Iteration 5980, loss = 0.00213627
I0302 03:51:50.391849 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00213627 (* 1 = 0.00213627 loss)
I0302 03:51:50.391856 29253 sgd_solver.cpp:106] Iteration 5980, lr = 0.01
I0302 03:52:19.125854 29253 solver.cpp:237] Iteration 6000, loss = 0.00268564
I0302 03:52:19.125885 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00268564 (* 1 = 0.00268564 loss)
I0302 03:52:19.125895 29253 sgd_solver.cpp:106] Iteration 6000, lr = 0.01
I0302 03:52:20.590615 29253 blocking_queue.cpp:50] Data layer prefetch queue empty
I0302 03:52:48.179224 29253 solver.cpp:237] Iteration 6020, loss = 0.00360098
I0302 03:52:48.179255 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00360098 (* 1 = 0.00360098 loss)
I0302 03:52:48.179263 29253 sgd_solver.cpp:106] Iteration 6020, lr = 0.01
I0302 03:53:16.971969 29253 solver.cpp:237] Iteration 6040, loss = 0.00240205
I0302 03:53:16.972002 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00240206 (* 1 = 0.00240206 loss)
I0302 03:53:16.972010 29253 sgd_solver.cpp:106] Iteration 6040, lr = 0.01
I0302 03:53:45.998399 29253 solver.cpp:237] Iteration 6060, loss = 0.00228475
I0302 03:53:45.998432 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00228476 (* 1 = 0.00228476 loss)
I0302 03:53:45.998440 29253 sgd_solver.cpp:106] Iteration 6060, lr = 0.01
I0302 03:54:14.881940 29253 solver.cpp:237] Iteration 6080, loss = 0.00288618
I0302 03:54:14.881973 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00288618 (* 1 = 0.00288618 loss)
I0302 03:54:14.881983 29253 sgd_solver.cpp:106] Iteration 6080, lr = 0.01
I0302 03:54:43.849663 29253 solver.cpp:237] Iteration 6100, loss = 0.00236316
I0302 03:54:43.849699 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00236316 (* 1 = 0.00236316 loss)
I0302 03:54:43.849707 29253 sgd_solver.cpp:106] Iteration 6100, lr = 0.01
I0302 03:55:12.731550 29253 solver.cpp:237] Iteration 6120, loss = 0.00250797
I0302 03:55:12.731582 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00250798 (* 1 = 0.00250798 loss)
I0302 03:55:12.731591 29253 sgd_solver.cpp:106] Iteration 6120, lr = 0.01
I0302 03:55:41.678817 29253 solver.cpp:237] Iteration 6140, loss = 0.00243017
I0302 03:55:41.678848 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00243018 (* 1 = 0.00243018 loss)
I0302 03:55:41.678856 29253 sgd_solver.cpp:106] Iteration 6140, lr = 0.01
I0302 03:56:10.405531 29253 solver.cpp:237] Iteration 6160, loss = 0.00177697
I0302 03:56:10.405562 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00177698 (* 1 = 0.00177698 loss)
I0302 03:56:10.405570 29253 sgd_solver.cpp:106] Iteration 6160, lr = 0.01
I0302 03:56:39.413277 29253 solver.cpp:237] Iteration 6180, loss = 0.00297865
I0302 03:56:39.413310 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00297865 (* 1 = 0.00297865 loss)
I0302 03:56:39.413317 29253 sgd_solver.cpp:106] Iteration 6180, lr = 0.01
I0302 03:57:08.321249 29253 solver.cpp:237] Iteration 6200, loss = 0.00318785
I0302 03:57:08.321282 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00318785 (* 1 = 0.00318785 loss)
I0302 03:57:08.321290 29253 sgd_solver.cpp:106] Iteration 6200, lr = 0.01
I0302 03:57:37.429453 29253 solver.cpp:237] Iteration 6220, loss = 0.00262951
I0302 03:57:37.429486 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00262951 (* 1 = 0.00262951 loss)
I0302 03:57:37.429494 29253 sgd_solver.cpp:106] Iteration 6220, lr = 0.01
I0302 03:58:06.391296 29253 solver.cpp:237] Iteration 6240, loss = 0.00201973
I0302 03:58:06.391329 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00201974 (* 1 = 0.00201974 loss)
I0302 03:58:06.391336 29253 sgd_solver.cpp:106] Iteration 6240, lr = 0.01
I0302 03:58:35.343271 29253 solver.cpp:237] Iteration 6260, loss = 0.00215815
I0302 03:58:35.343304 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00215815 (* 1 = 0.00215815 loss)
I0302 03:58:35.343312 29253 sgd_solver.cpp:106] Iteration 6260, lr = 0.01
I0302 03:59:04.244256 29253 solver.cpp:237] Iteration 6280, loss = 0.00266912
I0302 03:59:04.244292 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00266912 (* 1 = 0.00266912 loss)
I0302 03:59:04.244299 29253 sgd_solver.cpp:106] Iteration 6280, lr = 0.01
I0302 03:59:33.150887 29253 solver.cpp:237] Iteration 6300, loss = 0.00253897
I0302 03:59:33.150919 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00253898 (* 1 = 0.00253898 loss)
I0302 03:59:33.150928 29253 sgd_solver.cpp:106] Iteration 6300, lr = 0.01
I0302 04:00:02.087121 29253 solver.cpp:237] Iteration 6320, loss = 0.00188797
I0302 04:00:02.087146 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00188797 (* 1 = 0.00188797 loss)
I0302 04:00:02.087154 29253 sgd_solver.cpp:106] Iteration 6320, lr = 0.01
I0302 04:00:31.148216 29253 solver.cpp:237] Iteration 6340, loss = 0.00214555
I0302 04:00:31.148248 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00214555 (* 1 = 0.00214555 loss)
I0302 04:00:31.148257 29253 sgd_solver.cpp:106] Iteration 6340, lr = 0.01
I0302 04:01:00.110127 29253 solver.cpp:237] Iteration 6360, loss = 0.00234249
I0302 04:01:00.110158 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0023425 (* 1 = 0.0023425 loss)
I0302 04:01:00.110167 29253 sgd_solver.cpp:106] Iteration 6360, lr = 0.01
I0302 04:01:28.811439 29253 solver.cpp:237] Iteration 6380, loss = 0.00219932
I0302 04:01:28.811471 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00219932 (* 1 = 0.00219932 loss)
I0302 04:01:28.811480 29253 sgd_solver.cpp:106] Iteration 6380, lr = 0.01
I0302 04:01:57.696645 29253 solver.cpp:237] Iteration 6400, loss = 0.00190791
I0302 04:01:57.696678 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00190791 (* 1 = 0.00190791 loss)
I0302 04:01:57.696687 29253 sgd_solver.cpp:106] Iteration 6400, lr = 0.01
I0302 04:02:26.656524 29253 solver.cpp:237] Iteration 6420, loss = 0.00324996
I0302 04:02:26.656558 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00324996 (* 1 = 0.00324996 loss)
I0302 04:02:26.656568 29253 sgd_solver.cpp:106] Iteration 6420, lr = 0.01
I0302 04:02:55.693819 29253 solver.cpp:237] Iteration 6440, loss = 0.00211083
I0302 04:02:55.693850 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00211083 (* 1 = 0.00211083 loss)
I0302 04:02:55.693859 29253 sgd_solver.cpp:106] Iteration 6440, lr = 0.01
I0302 04:03:24.554352 29253 solver.cpp:237] Iteration 6460, loss = 0.00251865
I0302 04:03:24.554383 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00251866 (* 1 = 0.00251866 loss)
I0302 04:03:24.554393 29253 sgd_solver.cpp:106] Iteration 6460, lr = 0.01
I0302 04:03:53.406373 29253 solver.cpp:237] Iteration 6480, loss = 0.00251576
I0302 04:03:53.406404 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00251576 (* 1 = 0.00251576 loss)
I0302 04:03:53.406412 29253 sgd_solver.cpp:106] Iteration 6480, lr = 0.01
I0302 04:04:22.447063 29253 solver.cpp:237] Iteration 6500, loss = 0.00267572
I0302 04:04:22.447095 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00267572 (* 1 = 0.00267572 loss)
I0302 04:04:22.447104 29253 sgd_solver.cpp:106] Iteration 6500, lr = 0.01
I0302 04:04:51.377550 29253 solver.cpp:237] Iteration 6520, loss = 0.00334041
I0302 04:04:51.377583 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00334041 (* 1 = 0.00334041 loss)
I0302 04:04:51.377591 29253 sgd_solver.cpp:106] Iteration 6520, lr = 0.01
I0302 04:05:20.508569 29253 solver.cpp:237] Iteration 6540, loss = 0.00234809
I0302 04:05:20.508600 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0023481 (* 1 = 0.0023481 loss)
I0302 04:05:20.508610 29253 sgd_solver.cpp:106] Iteration 6540, lr = 0.01
I0302 04:05:49.182801 29253 solver.cpp:237] Iteration 6560, loss = 0.00216728
I0302 04:05:49.182833 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00216729 (* 1 = 0.00216729 loss)
I0302 04:05:49.182842 29253 sgd_solver.cpp:106] Iteration 6560, lr = 0.01
I0302 04:06:18.593261 29253 solver.cpp:237] Iteration 6580, loss = 0.00293119
I0302 04:06:18.593293 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00293119 (* 1 = 0.00293119 loss)
I0302 04:06:18.593302 29253 sgd_solver.cpp:106] Iteration 6580, lr = 0.01
I0302 04:06:47.169883 29253 solver.cpp:237] Iteration 6600, loss = 0.00253633
I0302 04:06:47.169914 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00253634 (* 1 = 0.00253634 loss)
I0302 04:06:47.169922 29253 sgd_solver.cpp:106] Iteration 6600, lr = 0.01
I0302 04:07:16.357264 29253 solver.cpp:237] Iteration 6620, loss = 0.00205186
I0302 04:07:16.357297 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00205186 (* 1 = 0.00205186 loss)
I0302 04:07:16.357306 29253 sgd_solver.cpp:106] Iteration 6620, lr = 0.01
I0302 04:07:45.016427 29253 solver.cpp:237] Iteration 6640, loss = 0.00258107
I0302 04:07:45.016458 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00258108 (* 1 = 0.00258108 loss)
I0302 04:07:45.016468 29253 sgd_solver.cpp:106] Iteration 6640, lr = 0.01
I0302 04:08:13.892647 29253 solver.cpp:237] Iteration 6660, loss = 0.00162437
I0302 04:08:13.892678 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00162438 (* 1 = 0.00162438 loss)
I0302 04:08:13.892688 29253 sgd_solver.cpp:106] Iteration 6660, lr = 0.01
I0302 04:08:42.717833 29253 solver.cpp:237] Iteration 6680, loss = 0.00281132
I0302 04:08:42.717864 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00281133 (* 1 = 0.00281133 loss)
I0302 04:08:42.717874 29253 sgd_solver.cpp:106] Iteration 6680, lr = 0.01
I0302 04:09:11.634122 29253 solver.cpp:237] Iteration 6700, loss = 0.00213163
I0302 04:09:11.634153 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00213163 (* 1 = 0.00213163 loss)
I0302 04:09:11.634162 29253 sgd_solver.cpp:106] Iteration 6700, lr = 0.01
I0302 04:09:40.496177 29253 solver.cpp:237] Iteration 6720, loss = 0.00208132
I0302 04:09:40.496208 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00208133 (* 1 = 0.00208133 loss)
I0302 04:09:40.496218 29253 sgd_solver.cpp:106] Iteration 6720, lr = 0.01
I0302 04:10:09.359254 29253 solver.cpp:237] Iteration 6740, loss = 0.00328727
I0302 04:10:09.359285 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00328727 (* 1 = 0.00328727 loss)
I0302 04:10:09.359294 29253 sgd_solver.cpp:106] Iteration 6740, lr = 0.01
I0302 04:10:38.331076 29253 solver.cpp:237] Iteration 6760, loss = 0.00223241
I0302 04:10:38.331107 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00223242 (* 1 = 0.00223242 loss)
I0302 04:10:38.331115 29253 sgd_solver.cpp:106] Iteration 6760, lr = 0.01
I0302 04:11:07.116994 29253 solver.cpp:237] Iteration 6780, loss = 0.00239753
I0302 04:11:07.117027 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00239754 (* 1 = 0.00239754 loss)
I0302 04:11:07.117035 29253 sgd_solver.cpp:106] Iteration 6780, lr = 0.01
I0302 04:11:36.228602 29253 solver.cpp:237] Iteration 6800, loss = 0.00324862
I0302 04:11:36.228633 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00324863 (* 1 = 0.00324863 loss)
I0302 04:11:36.228642 29253 sgd_solver.cpp:106] Iteration 6800, lr = 0.01
I0302 04:12:04.968103 29253 solver.cpp:237] Iteration 6820, loss = 0.00216368
I0302 04:12:04.968135 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00216368 (* 1 = 0.00216368 loss)
I0302 04:12:04.968144 29253 sgd_solver.cpp:106] Iteration 6820, lr = 0.01
I0302 04:12:33.908814 29253 solver.cpp:237] Iteration 6840, loss = 0.0024597
I0302 04:12:33.908846 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00245971 (* 1 = 0.00245971 loss)
I0302 04:12:33.908855 29253 sgd_solver.cpp:106] Iteration 6840, lr = 0.01
I0302 04:13:02.876591 29253 solver.cpp:237] Iteration 6860, loss = 0.00226357
I0302 04:13:02.876624 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00226357 (* 1 = 0.00226357 loss)
I0302 04:13:02.876633 29253 sgd_solver.cpp:106] Iteration 6860, lr = 0.01
I0302 04:13:31.643975 29253 solver.cpp:237] Iteration 6880, loss = 0.00217594
I0302 04:13:31.644006 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00217594 (* 1 = 0.00217594 loss)
I0302 04:13:31.644016 29253 sgd_solver.cpp:106] Iteration 6880, lr = 0.01
I0302 04:14:00.697929 29253 solver.cpp:237] Iteration 6900, loss = 0.00305026
I0302 04:14:00.697962 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00305026 (* 1 = 0.00305026 loss)
I0302 04:14:00.697970 29253 sgd_solver.cpp:106] Iteration 6900, lr = 0.01
I0302 04:14:29.689321 29253 solver.cpp:237] Iteration 6920, loss = 0.00216984
I0302 04:14:29.689352 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00216985 (* 1 = 0.00216985 loss)
I0302 04:14:29.689360 29253 sgd_solver.cpp:106] Iteration 6920, lr = 0.01
I0302 04:14:58.626935 29253 solver.cpp:237] Iteration 6940, loss = 0.00164244
I0302 04:14:58.626967 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00164245 (* 1 = 0.00164245 loss)
I0302 04:14:58.626976 29253 sgd_solver.cpp:106] Iteration 6940, lr = 0.01
I0302 04:15:27.550389 29253 solver.cpp:237] Iteration 6960, loss = 0.00211424
I0302 04:15:27.550420 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00211424 (* 1 = 0.00211424 loss)
I0302 04:15:27.550428 29253 sgd_solver.cpp:106] Iteration 6960, lr = 0.01
I0302 04:15:56.495760 29253 solver.cpp:237] Iteration 6980, loss = 0.00222568
I0302 04:15:56.495795 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00222568 (* 1 = 0.00222568 loss)
I0302 04:15:56.495805 29253 sgd_solver.cpp:106] Iteration 6980, lr = 0.01
I0302 04:16:25.383913 29253 solver.cpp:237] Iteration 7000, loss = 0.00259193
I0302 04:16:25.383945 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00259193 (* 1 = 0.00259193 loss)
I0302 04:16:25.383955 29253 sgd_solver.cpp:106] Iteration 7000, lr = 0.01
I0302 04:16:26.803321 29253 blocking_queue.cpp:50] Data layer prefetch queue empty
I0302 04:16:54.236315 29253 solver.cpp:237] Iteration 7020, loss = 0.00259925
I0302 04:16:54.236347 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00259925 (* 1 = 0.00259925 loss)
I0302 04:16:54.236356 29253 sgd_solver.cpp:106] Iteration 7020, lr = 0.01
I0302 04:17:23.207043 29253 solver.cpp:237] Iteration 7040, loss = 0.00188352
I0302 04:17:23.207077 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00188352 (* 1 = 0.00188352 loss)
I0302 04:17:23.207084 29253 sgd_solver.cpp:106] Iteration 7040, lr = 0.01
I0302 04:17:52.094864 29253 solver.cpp:237] Iteration 7060, loss = 0.00191986
I0302 04:17:52.094897 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00191987 (* 1 = 0.00191987 loss)
I0302 04:17:52.094904 29253 sgd_solver.cpp:106] Iteration 7060, lr = 0.01
I0302 04:18:21.071864 29253 solver.cpp:237] Iteration 7080, loss = 0.00225271
I0302 04:18:21.071897 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00225272 (* 1 = 0.00225272 loss)
I0302 04:18:21.071904 29253 sgd_solver.cpp:106] Iteration 7080, lr = 0.01
I0302 04:18:50.095136 29253 solver.cpp:237] Iteration 7100, loss = 0.00198959
I0302 04:18:50.095168 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0019896 (* 1 = 0.0019896 loss)
I0302 04:18:50.095177 29253 sgd_solver.cpp:106] Iteration 7100, lr = 0.01
I0302 04:19:18.930760 29253 solver.cpp:237] Iteration 7120, loss = 0.0017339
I0302 04:19:18.930791 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0017339 (* 1 = 0.0017339 loss)
I0302 04:19:18.930800 29253 sgd_solver.cpp:106] Iteration 7120, lr = 0.01
I0302 04:19:47.729373 29253 solver.cpp:237] Iteration 7140, loss = 0.00256565
I0302 04:19:47.729408 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00256566 (* 1 = 0.00256566 loss)
I0302 04:19:47.729416 29253 sgd_solver.cpp:106] Iteration 7140, lr = 0.01
I0302 04:20:16.613625 29253 solver.cpp:237] Iteration 7160, loss = 0.00256558
I0302 04:20:16.613656 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00256558 (* 1 = 0.00256558 loss)
I0302 04:20:16.613665 29253 sgd_solver.cpp:106] Iteration 7160, lr = 0.01
I0302 04:20:45.642930 29253 solver.cpp:237] Iteration 7180, loss = 0.00292085
I0302 04:20:45.642961 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00292086 (* 1 = 0.00292086 loss)
I0302 04:20:45.642969 29253 sgd_solver.cpp:106] Iteration 7180, lr = 0.01
I0302 04:21:14.538031 29253 solver.cpp:237] Iteration 7200, loss = 0.00203982
I0302 04:21:14.538064 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00203982 (* 1 = 0.00203982 loss)
I0302 04:21:14.538072 29253 sgd_solver.cpp:106] Iteration 7200, lr = 0.01
I0302 04:21:43.485893 29253 solver.cpp:237] Iteration 7220, loss = 0.00220078
I0302 04:21:43.485924 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00220078 (* 1 = 0.00220078 loss)
I0302 04:21:43.485932 29253 sgd_solver.cpp:106] Iteration 7220, lr = 0.01
I0302 04:22:12.405211 29253 solver.cpp:237] Iteration 7240, loss = 0.00192208
I0302 04:22:12.405244 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00192208 (* 1 = 0.00192208 loss)
I0302 04:22:12.405252 29253 sgd_solver.cpp:106] Iteration 7240, lr = 0.01
I0302 04:22:41.116060 29253 solver.cpp:237] Iteration 7260, loss = 0.00171901
I0302 04:22:41.116091 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00171901 (* 1 = 0.00171901 loss)
I0302 04:22:41.116101 29253 sgd_solver.cpp:106] Iteration 7260, lr = 0.01
I0302 04:23:10.294323 29253 solver.cpp:237] Iteration 7280, loss = 0.00203338
I0302 04:23:10.294355 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00203338 (* 1 = 0.00203338 loss)
I0302 04:23:10.294364 29253 sgd_solver.cpp:106] Iteration 7280, lr = 0.01
I0302 04:23:39.351727 29253 solver.cpp:237] Iteration 7300, loss = 0.00200845
I0302 04:23:39.351758 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00200845 (* 1 = 0.00200845 loss)
I0302 04:23:39.351766 29253 sgd_solver.cpp:106] Iteration 7300, lr = 0.01
I0302 04:24:08.120069 29253 solver.cpp:237] Iteration 7320, loss = 0.00177042
I0302 04:24:08.120100 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00177042 (* 1 = 0.00177042 loss)
I0302 04:24:08.120107 29253 sgd_solver.cpp:106] Iteration 7320, lr = 0.01
I0302 04:24:37.078920 29253 solver.cpp:237] Iteration 7340, loss = 0.00178322
I0302 04:24:37.078953 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00178322 (* 1 = 0.00178322 loss)
I0302 04:24:37.078961 29253 sgd_solver.cpp:106] Iteration 7340, lr = 0.01
I0302 04:25:05.968744 29253 solver.cpp:237] Iteration 7360, loss = 0.00225083
I0302 04:25:05.968776 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00225083 (* 1 = 0.00225083 loss)
I0302 04:25:05.968786 29253 sgd_solver.cpp:106] Iteration 7360, lr = 0.01
I0302 04:25:34.742040 29253 solver.cpp:237] Iteration 7380, loss = 0.00242886
I0302 04:25:34.742072 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00242887 (* 1 = 0.00242887 loss)
I0302 04:25:34.742081 29253 sgd_solver.cpp:106] Iteration 7380, lr = 0.01
I0302 04:26:03.897946 29253 solver.cpp:237] Iteration 7400, loss = 0.00206723
I0302 04:26:03.897979 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00206723 (* 1 = 0.00206723 loss)
I0302 04:26:03.897987 29253 sgd_solver.cpp:106] Iteration 7400, lr = 0.01
I0302 04:26:32.813752 29253 solver.cpp:237] Iteration 7420, loss = 0.00184139
I0302 04:26:32.813784 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00184139 (* 1 = 0.00184139 loss)
I0302 04:26:32.813792 29253 sgd_solver.cpp:106] Iteration 7420, lr = 0.01
I0302 04:27:01.488957 29253 solver.cpp:237] Iteration 7440, loss = 0.00189486
I0302 04:27:01.488989 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00189486 (* 1 = 0.00189486 loss)
I0302 04:27:01.488998 29253 sgd_solver.cpp:106] Iteration 7440, lr = 0.01
I0302 04:27:30.580451 29253 solver.cpp:237] Iteration 7460, loss = 0.00229891
I0302 04:27:30.580482 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00229892 (* 1 = 0.00229892 loss)
I0302 04:27:30.580492 29253 sgd_solver.cpp:106] Iteration 7460, lr = 0.01
I0302 04:27:59.544340 29253 solver.cpp:237] Iteration 7480, loss = 0.00250431
I0302 04:27:59.544373 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00250431 (* 1 = 0.00250431 loss)
I0302 04:27:59.544386 29253 sgd_solver.cpp:106] Iteration 7480, lr = 0.01
I0302 04:28:28.158795 29253 solver.cpp:237] Iteration 7500, loss = 0.00177858
I0302 04:28:28.158828 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00177859 (* 1 = 0.00177859 loss)
I0302 04:28:28.158836 29253 sgd_solver.cpp:106] Iteration 7500, lr = 0.01
I0302 04:28:56.989147 29253 solver.cpp:237] Iteration 7520, loss = 0.00265801
I0302 04:28:56.989181 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00265802 (* 1 = 0.00265802 loss)
I0302 04:28:56.989189 29253 sgd_solver.cpp:106] Iteration 7520, lr = 0.01
I0302 04:29:25.925583 29253 solver.cpp:237] Iteration 7540, loss = 0.00237429
I0302 04:29:25.925616 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00237429 (* 1 = 0.00237429 loss)
I0302 04:29:25.925624 29253 sgd_solver.cpp:106] Iteration 7540, lr = 0.01
I0302 04:29:54.760591 29253 solver.cpp:237] Iteration 7560, loss = 0.00210448
I0302 04:29:54.760622 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00210448 (* 1 = 0.00210448 loss)
I0302 04:29:54.760630 29253 sgd_solver.cpp:106] Iteration 7560, lr = 0.01
I0302 04:30:23.813681 29253 solver.cpp:237] Iteration 7580, loss = 0.00235754
I0302 04:30:23.813714 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00235754 (* 1 = 0.00235754 loss)
I0302 04:30:23.813721 29253 sgd_solver.cpp:106] Iteration 7580, lr = 0.01
I0302 04:30:52.710563 29253 solver.cpp:237] Iteration 7600, loss = 0.00194149
I0302 04:30:52.710597 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00194149 (* 1 = 0.00194149 loss)
I0302 04:30:52.710605 29253 sgd_solver.cpp:106] Iteration 7600, lr = 0.01
I0302 04:31:21.715960 29253 solver.cpp:237] Iteration 7620, loss = 0.00208054
I0302 04:31:21.715991 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00208055 (* 1 = 0.00208055 loss)
I0302 04:31:21.715999 29253 sgd_solver.cpp:106] Iteration 7620, lr = 0.01
I0302 04:31:50.676549 29253 solver.cpp:237] Iteration 7640, loss = 0.00220253
I0302 04:31:50.676583 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00220253 (* 1 = 0.00220253 loss)
I0302 04:31:50.676591 29253 sgd_solver.cpp:106] Iteration 7640, lr = 0.01
I0302 04:32:19.544734 29253 solver.cpp:237] Iteration 7660, loss = 0.00223022
I0302 04:32:19.544766 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00223023 (* 1 = 0.00223023 loss)
I0302 04:32:19.544775 29253 sgd_solver.cpp:106] Iteration 7660, lr = 0.01
I0302 04:32:48.726048 29253 solver.cpp:237] Iteration 7680, loss = 0.00295705
I0302 04:32:48.726080 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00295705 (* 1 = 0.00295705 loss)
I0302 04:32:48.726089 29253 sgd_solver.cpp:106] Iteration 7680, lr = 0.01
I0302 04:33:17.363071 29253 solver.cpp:237] Iteration 7700, loss = 0.0019192
I0302 04:33:17.363103 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0019192 (* 1 = 0.0019192 loss)
I0302 04:33:17.363112 29253 sgd_solver.cpp:106] Iteration 7700, lr = 0.01
I0302 04:33:46.387174 29253 solver.cpp:237] Iteration 7720, loss = 0.0026218
I0302 04:33:46.387207 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0026218 (* 1 = 0.0026218 loss)
I0302 04:33:46.387215 29253 sgd_solver.cpp:106] Iteration 7720, lr = 0.01
I0302 04:34:15.230016 29253 solver.cpp:237] Iteration 7740, loss = 0.00212614
I0302 04:34:15.230049 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00212614 (* 1 = 0.00212614 loss)
I0302 04:34:15.230058 29253 sgd_solver.cpp:106] Iteration 7740, lr = 0.01
I0302 04:34:44.165163 29253 solver.cpp:237] Iteration 7760, loss = 0.00256316
I0302 04:34:44.165196 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00256316 (* 1 = 0.00256316 loss)
I0302 04:34:44.165205 29253 sgd_solver.cpp:106] Iteration 7760, lr = 0.01
I0302 04:35:13.122100 29253 solver.cpp:237] Iteration 7780, loss = 0.00195844
I0302 04:35:13.122131 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00195844 (* 1 = 0.00195844 loss)
I0302 04:35:13.122139 29253 sgd_solver.cpp:106] Iteration 7780, lr = 0.01
I0302 04:35:41.866683 29253 solver.cpp:237] Iteration 7800, loss = 0.00223625
I0302 04:35:41.866715 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00223625 (* 1 = 0.00223625 loss)
I0302 04:35:41.866724 29253 sgd_solver.cpp:106] Iteration 7800, lr = 0.01
I0302 04:36:10.721196 29253 solver.cpp:237] Iteration 7820, loss = 0.00210967
I0302 04:36:10.721228 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00210967 (* 1 = 0.00210967 loss)
I0302 04:36:10.721237 29253 sgd_solver.cpp:106] Iteration 7820, lr = 0.01
I0302 04:36:39.698168 29253 solver.cpp:237] Iteration 7840, loss = 0.00270781
I0302 04:36:39.698199 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00270781 (* 1 = 0.00270781 loss)
I0302 04:36:39.698207 29253 sgd_solver.cpp:106] Iteration 7840, lr = 0.01
I0302 04:37:08.948832 29253 solver.cpp:237] Iteration 7860, loss = 0.00166895
I0302 04:37:08.948863 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00166895 (* 1 = 0.00166895 loss)
I0302 04:37:08.948873 29253 sgd_solver.cpp:106] Iteration 7860, lr = 0.01
I0302 04:37:37.879045 29253 solver.cpp:237] Iteration 7880, loss = 0.00224303
I0302 04:37:37.879078 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00224303 (* 1 = 0.00224303 loss)
I0302 04:37:37.879086 29253 sgd_solver.cpp:106] Iteration 7880, lr = 0.01
I0302 04:38:06.760440 29253 solver.cpp:237] Iteration 7900, loss = 0.002131
I0302 04:38:06.760473 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.002131 (* 1 = 0.002131 loss)
I0302 04:38:06.760481 29253 sgd_solver.cpp:106] Iteration 7900, lr = 0.01
I0302 04:38:35.733219 29253 solver.cpp:237] Iteration 7920, loss = 0.00205686
I0302 04:38:35.733253 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00205686 (* 1 = 0.00205686 loss)
I0302 04:38:35.733260 29253 sgd_solver.cpp:106] Iteration 7920, lr = 0.01
I0302 04:39:04.783475 29253 solver.cpp:237] Iteration 7940, loss = 0.00220233
I0302 04:39:04.783509 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00220233 (* 1 = 0.00220233 loss)
I0302 04:39:04.783516 29253 sgd_solver.cpp:106] Iteration 7940, lr = 0.01
I0302 04:39:33.525184 29253 solver.cpp:237] Iteration 7960, loss = 0.00195312
I0302 04:39:33.525218 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00195312 (* 1 = 0.00195312 loss)
I0302 04:39:33.525226 29253 sgd_solver.cpp:106] Iteration 7960, lr = 0.01
I0302 04:40:02.018452 29253 solver.cpp:237] Iteration 7980, loss = 0.00202987
I0302 04:40:02.018484 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00202988 (* 1 = 0.00202988 loss)
I0302 04:40:02.018493 29253 sgd_solver.cpp:106] Iteration 7980, lr = 0.01
I0302 04:40:31.064854 29253 solver.cpp:237] Iteration 8000, loss = 0.00206543
I0302 04:40:31.064887 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00206543 (* 1 = 0.00206543 loss)
I0302 04:40:31.064895 29253 sgd_solver.cpp:106] Iteration 8000, lr = 0.01
I0302 04:40:32.634112 29253 blocking_queue.cpp:50] Data layer prefetch queue empty
I0302 04:40:59.784379 29253 solver.cpp:237] Iteration 8020, loss = 0.00214246
I0302 04:40:59.784410 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00214246 (* 1 = 0.00214246 loss)
I0302 04:40:59.784420 29253 sgd_solver.cpp:106] Iteration 8020, lr = 0.01
I0302 04:41:29.251983 29253 solver.cpp:237] Iteration 8040, loss = 0.00233981
I0302 04:41:29.252017 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00233982 (* 1 = 0.00233982 loss)
I0302 04:41:29.252024 29253 sgd_solver.cpp:106] Iteration 8040, lr = 0.01
I0302 04:41:58.459951 29253 solver.cpp:237] Iteration 8060, loss = 0.00164515
I0302 04:41:58.459985 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00164515 (* 1 = 0.00164515 loss)
I0302 04:41:58.459992 29253 sgd_solver.cpp:106] Iteration 8060, lr = 0.01
I0302 04:42:27.353610 29253 solver.cpp:237] Iteration 8080, loss = 0.00230427
I0302 04:42:27.353642 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00230427 (* 1 = 0.00230427 loss)
I0302 04:42:27.353652 29253 sgd_solver.cpp:106] Iteration 8080, lr = 0.01
I0302 04:42:56.377647 29253 solver.cpp:237] Iteration 8100, loss = 0.00179681
I0302 04:42:56.377681 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00179681 (* 1 = 0.00179681 loss)
I0302 04:42:56.377691 29253 sgd_solver.cpp:106] Iteration 8100, lr = 0.01
I0302 04:43:25.850625 29253 solver.cpp:237] Iteration 8120, loss = 0.0019034
I0302 04:43:25.850658 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0019034 (* 1 = 0.0019034 loss)
I0302 04:43:25.850666 29253 sgd_solver.cpp:106] Iteration 8120, lr = 0.01
I0302 04:43:54.767562 29253 solver.cpp:237] Iteration 8140, loss = 0.00222979
I0302 04:43:54.767593 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0022298 (* 1 = 0.0022298 loss)
I0302 04:43:54.767601 29253 sgd_solver.cpp:106] Iteration 8140, lr = 0.01
I0302 04:44:23.449241 29253 solver.cpp:237] Iteration 8160, loss = 0.00217297
I0302 04:44:23.449275 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00217298 (* 1 = 0.00217298 loss)
I0302 04:44:23.449282 29253 sgd_solver.cpp:106] Iteration 8160, lr = 0.01
I0302 04:44:52.264163 29253 solver.cpp:237] Iteration 8180, loss = 0.00187483
I0302 04:44:52.264196 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00187483 (* 1 = 0.00187483 loss)
I0302 04:44:52.264204 29253 sgd_solver.cpp:106] Iteration 8180, lr = 0.01
I0302 04:45:21.029170 29253 solver.cpp:237] Iteration 8200, loss = 0.00184318
I0302 04:45:21.029201 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00184319 (* 1 = 0.00184319 loss)
I0302 04:45:21.029211 29253 sgd_solver.cpp:106] Iteration 8200, lr = 0.01
I0302 04:45:49.783478 29253 solver.cpp:237] Iteration 8220, loss = 0.00190254
I0302 04:45:49.783510 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00190254 (* 1 = 0.00190254 loss)
I0302 04:45:49.783519 29253 sgd_solver.cpp:106] Iteration 8220, lr = 0.01
I0302 04:46:18.882592 29253 solver.cpp:237] Iteration 8240, loss = 0.00192609
I0302 04:46:18.882624 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00192609 (* 1 = 0.00192609 loss)
I0302 04:46:18.882632 29253 sgd_solver.cpp:106] Iteration 8240, lr = 0.01
I0302 04:46:47.262382 29253 solver.cpp:237] Iteration 8260, loss = 0.0020804
I0302 04:46:47.262413 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0020804 (* 1 = 0.0020804 loss)
I0302 04:46:47.262421 29253 sgd_solver.cpp:106] Iteration 8260, lr = 0.01
I0302 04:47:16.577121 29253 solver.cpp:237] Iteration 8280, loss = 0.00164551
I0302 04:47:16.577153 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00164551 (* 1 = 0.00164551 loss)
I0302 04:47:16.577162 29253 sgd_solver.cpp:106] Iteration 8280, lr = 0.01
I0302 04:47:45.570102 29253 solver.cpp:237] Iteration 8300, loss = 0.00223396
I0302 04:47:45.570134 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00223396 (* 1 = 0.00223396 loss)
I0302 04:47:45.570142 29253 sgd_solver.cpp:106] Iteration 8300, lr = 0.01
I0302 04:48:14.276671 29253 solver.cpp:237] Iteration 8320, loss = 0.00239955
I0302 04:48:14.276702 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00239955 (* 1 = 0.00239955 loss)
I0302 04:48:14.276710 29253 sgd_solver.cpp:106] Iteration 8320, lr = 0.01
I0302 04:48:43.205616 29253 solver.cpp:237] Iteration 8340, loss = 0.0019504
I0302 04:48:43.205649 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0019504 (* 1 = 0.0019504 loss)
I0302 04:48:43.205658 29253 sgd_solver.cpp:106] Iteration 8340, lr = 0.01
I0302 04:49:12.246242 29253 solver.cpp:237] Iteration 8360, loss = 0.00218425
I0302 04:49:12.246274 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00218425 (* 1 = 0.00218425 loss)
I0302 04:49:12.246284 29253 sgd_solver.cpp:106] Iteration 8360, lr = 0.01
I0302 04:49:41.173127 29253 solver.cpp:237] Iteration 8380, loss = 0.00200274
I0302 04:49:41.173159 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00200274 (* 1 = 0.00200274 loss)
I0302 04:49:41.173167 29253 sgd_solver.cpp:106] Iteration 8380, lr = 0.01
I0302 04:50:10.113709 29253 solver.cpp:237] Iteration 8400, loss = 0.00202301
I0302 04:50:10.113741 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00202302 (* 1 = 0.00202302 loss)
I0302 04:50:10.113750 29253 sgd_solver.cpp:106] Iteration 8400, lr = 0.01
I0302 04:50:39.457294 29253 solver.cpp:237] Iteration 8420, loss = 0.00241585
I0302 04:50:39.457326 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00241586 (* 1 = 0.00241586 loss)
I0302 04:50:39.457335 29253 sgd_solver.cpp:106] Iteration 8420, lr = 0.01
I0302 04:51:08.406478 29253 solver.cpp:237] Iteration 8440, loss = 0.00252864
I0302 04:51:08.406512 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00252865 (* 1 = 0.00252865 loss)
I0302 04:51:08.406520 29253 sgd_solver.cpp:106] Iteration 8440, lr = 0.01
I0302 04:51:37.037677 29253 solver.cpp:237] Iteration 8460, loss = 0.00238135
I0302 04:51:37.037708 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00238135 (* 1 = 0.00238135 loss)
I0302 04:51:37.037716 29253 sgd_solver.cpp:106] Iteration 8460, lr = 0.01
I0302 04:52:06.308193 29253 solver.cpp:237] Iteration 8480, loss = 0.00200182
I0302 04:52:06.308225 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00200183 (* 1 = 0.00200183 loss)
I0302 04:52:06.308234 29253 sgd_solver.cpp:106] Iteration 8480, lr = 0.01
I0302 04:52:35.176282 29253 solver.cpp:237] Iteration 8500, loss = 0.00176283
I0302 04:52:35.176314 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00176284 (* 1 = 0.00176284 loss)
I0302 04:52:35.176323 29253 sgd_solver.cpp:106] Iteration 8500, lr = 0.01
I0302 04:53:04.124960 29253 solver.cpp:237] Iteration 8520, loss = 0.00239972
I0302 04:53:04.124992 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00239973 (* 1 = 0.00239973 loss)
I0302 04:53:04.125001 29253 sgd_solver.cpp:106] Iteration 8520, lr = 0.01
I0302 04:53:33.052278 29253 solver.cpp:237] Iteration 8540, loss = 0.0030299
I0302 04:53:33.052309 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0030299 (* 1 = 0.0030299 loss)
I0302 04:53:33.052319 29253 sgd_solver.cpp:106] Iteration 8540, lr = 0.01
I0302 04:54:01.866848 29253 solver.cpp:237] Iteration 8560, loss = 0.00177397
I0302 04:54:01.866881 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00177398 (* 1 = 0.00177398 loss)
I0302 04:54:01.866889 29253 sgd_solver.cpp:106] Iteration 8560, lr = 0.01
I0302 04:54:30.628190 29253 solver.cpp:237] Iteration 8580, loss = 0.00226055
I0302 04:54:30.628221 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00226055 (* 1 = 0.00226055 loss)
I0302 04:54:30.628231 29253 sgd_solver.cpp:106] Iteration 8580, lr = 0.01
I0302 04:54:59.781730 29253 solver.cpp:237] Iteration 8600, loss = 0.00172654
I0302 04:54:59.781762 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00172654 (* 1 = 0.00172654 loss)
I0302 04:54:59.781771 29253 sgd_solver.cpp:106] Iteration 8600, lr = 0.01
I0302 04:55:28.757565 29253 solver.cpp:237] Iteration 8620, loss = 0.00156899
I0302 04:55:28.757599 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00156899 (* 1 = 0.00156899 loss)
I0302 04:55:28.757608 29253 sgd_solver.cpp:106] Iteration 8620, lr = 0.01
I0302 04:55:57.828233 29253 solver.cpp:237] Iteration 8640, loss = 0.00206343
I0302 04:55:57.828265 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00206343 (* 1 = 0.00206343 loss)
I0302 04:55:57.828274 29253 sgd_solver.cpp:106] Iteration 8640, lr = 0.01
I0302 04:56:26.679779 29253 solver.cpp:237] Iteration 8660, loss = 0.00195737
I0302 04:56:26.679810 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00195737 (* 1 = 0.00195737 loss)
I0302 04:56:26.679818 29253 sgd_solver.cpp:106] Iteration 8660, lr = 0.01
I0302 04:56:55.631647 29253 solver.cpp:237] Iteration 8680, loss = 0.00250939
I0302 04:56:55.631680 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00250939 (* 1 = 0.00250939 loss)
I0302 04:56:55.631688 29253 sgd_solver.cpp:106] Iteration 8680, lr = 0.01
I0302 04:57:24.445030 29253 solver.cpp:237] Iteration 8700, loss = 0.00297044
I0302 04:57:24.445062 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00297044 (* 1 = 0.00297044 loss)
I0302 04:57:24.445071 29253 sgd_solver.cpp:106] Iteration 8700, lr = 0.01
I0302 04:57:53.239624 29253 solver.cpp:237] Iteration 8720, loss = 0.00188571
I0302 04:57:53.239655 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00188571 (* 1 = 0.00188571 loss)
I0302 04:57:53.239665 29253 sgd_solver.cpp:106] Iteration 8720, lr = 0.01
I0302 04:58:22.252511 29253 solver.cpp:237] Iteration 8740, loss = 0.00219794
I0302 04:58:22.252544 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00219795 (* 1 = 0.00219795 loss)
I0302 04:58:22.252553 29253 sgd_solver.cpp:106] Iteration 8740, lr = 0.01
I0302 04:58:51.227768 29253 solver.cpp:237] Iteration 8760, loss = 0.00193708
I0302 04:58:51.227802 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00193709 (* 1 = 0.00193709 loss)
I0302 04:58:51.227810 29253 sgd_solver.cpp:106] Iteration 8760, lr = 0.01
I0302 04:59:20.104763 29253 solver.cpp:237] Iteration 8780, loss = 0.00208391
I0302 04:59:20.104795 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00208391 (* 1 = 0.00208391 loss)
I0302 04:59:20.104804 29253 sgd_solver.cpp:106] Iteration 8780, lr = 0.01
I0302 04:59:49.018793 29253 solver.cpp:237] Iteration 8800, loss = 0.00231621
I0302 04:59:49.018824 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00231621 (* 1 = 0.00231621 loss)
I0302 04:59:49.018833 29253 sgd_solver.cpp:106] Iteration 8800, lr = 0.01
I0302 05:00:17.808050 29253 solver.cpp:237] Iteration 8820, loss = 0.00213692
I0302 05:00:17.808084 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00213692 (* 1 = 0.00213692 loss)
I0302 05:00:17.808092 29253 sgd_solver.cpp:106] Iteration 8820, lr = 0.01
I0302 05:00:46.931663 29253 solver.cpp:237] Iteration 8840, loss = 0.00211876
I0302 05:00:46.931694 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00211877 (* 1 = 0.00211877 loss)
I0302 05:00:46.931704 29253 sgd_solver.cpp:106] Iteration 8840, lr = 0.01
I0302 05:01:16.134416 29253 solver.cpp:237] Iteration 8860, loss = 0.00193696
I0302 05:01:16.134449 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00193697 (* 1 = 0.00193697 loss)
I0302 05:01:16.134457 29253 sgd_solver.cpp:106] Iteration 8860, lr = 0.01
I0302 05:01:44.615221 29253 solver.cpp:237] Iteration 8880, loss = 0.00205854
I0302 05:01:44.615254 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00205854 (* 1 = 0.00205854 loss)
I0302 05:01:44.615263 29253 sgd_solver.cpp:106] Iteration 8880, lr = 0.01
I0302 05:02:13.469213 29253 solver.cpp:237] Iteration 8900, loss = 0.00187546
I0302 05:02:13.469245 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00187546 (* 1 = 0.00187546 loss)
I0302 05:02:13.469254 29253 sgd_solver.cpp:106] Iteration 8900, lr = 0.01
I0302 05:02:42.433282 29253 solver.cpp:237] Iteration 8920, loss = 0.00160377
I0302 05:02:42.433313 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00160378 (* 1 = 0.00160378 loss)
I0302 05:02:42.433322 29253 sgd_solver.cpp:106] Iteration 8920, lr = 0.01
I0302 05:03:11.261467 29253 solver.cpp:237] Iteration 8940, loss = 0.00239735
I0302 05:03:11.261499 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00239736 (* 1 = 0.00239736 loss)
I0302 05:03:11.261508 29253 sgd_solver.cpp:106] Iteration 8940, lr = 0.01
I0302 05:03:40.238530 29253 solver.cpp:237] Iteration 8960, loss = 0.00189618
I0302 05:03:40.238561 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00189619 (* 1 = 0.00189619 loss)
I0302 05:03:40.238570 29253 sgd_solver.cpp:106] Iteration 8960, lr = 0.01
I0302 05:04:09.342269 29253 solver.cpp:237] Iteration 8980, loss = 0.00306039
I0302 05:04:09.342301 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00306039 (* 1 = 0.00306039 loss)
I0302 05:04:09.342310 29253 sgd_solver.cpp:106] Iteration 8980, lr = 0.01
I0302 05:04:38.394037 29253 solver.cpp:237] Iteration 9000, loss = 0.0019321
I0302 05:04:38.394068 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00193211 (* 1 = 0.00193211 loss)
I0302 05:04:38.394078 29253 sgd_solver.cpp:106] Iteration 9000, lr = 0.01
I0302 05:04:39.984412 29253 blocking_queue.cpp:50] Data layer prefetch queue empty
I0302 05:05:07.030552 29253 solver.cpp:237] Iteration 9020, loss = 0.0022202
I0302 05:05:07.030586 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0022202 (* 1 = 0.0022202 loss)
I0302 05:05:07.030596 29253 sgd_solver.cpp:106] Iteration 9020, lr = 0.01
I0302 05:05:36.279723 29253 solver.cpp:237] Iteration 9040, loss = 0.00238872
I0302 05:05:36.279755 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00238872 (* 1 = 0.00238872 loss)
I0302 05:05:36.279764 29253 sgd_solver.cpp:106] Iteration 9040, lr = 0.01
I0302 05:06:05.241171 29253 solver.cpp:237] Iteration 9060, loss = 0.00148887
I0302 05:06:05.241204 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00148887 (* 1 = 0.00148887 loss)
I0302 05:06:05.241212 29253 sgd_solver.cpp:106] Iteration 9060, lr = 0.01
I0302 05:06:33.806660 29253 solver.cpp:237] Iteration 9080, loss = 0.00171041
I0302 05:06:33.806694 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00171041 (* 1 = 0.00171041 loss)
I0302 05:06:33.806702 29253 sgd_solver.cpp:106] Iteration 9080, lr = 0.01
I0302 05:07:03.070140 29253 solver.cpp:237] Iteration 9100, loss = 0.0022557
I0302 05:07:03.070173 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0022557 (* 1 = 0.0022557 loss)
I0302 05:07:03.070181 29253 sgd_solver.cpp:106] Iteration 9100, lr = 0.01
I0302 05:07:32.004962 29253 solver.cpp:237] Iteration 9120, loss = 0.00219933
I0302 05:07:32.004994 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00219934 (* 1 = 0.00219934 loss)
I0302 05:07:32.005003 29253 sgd_solver.cpp:106] Iteration 9120, lr = 0.01
I0302 05:08:01.094729 29253 solver.cpp:237] Iteration 9140, loss = 0.00183444
I0302 05:08:01.094761 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00183445 (* 1 = 0.00183445 loss)
I0302 05:08:01.094770 29253 sgd_solver.cpp:106] Iteration 9140, lr = 0.01
I0302 05:08:30.097719 29253 solver.cpp:237] Iteration 9160, loss = 0.00205388
I0302 05:08:30.097750 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00205388 (* 1 = 0.00205388 loss)
I0302 05:08:30.097759 29253 sgd_solver.cpp:106] Iteration 9160, lr = 0.01
I0302 05:08:58.679780 29253 solver.cpp:237] Iteration 9180, loss = 0.00184313
I0302 05:08:58.679811 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00184314 (* 1 = 0.00184314 loss)
I0302 05:08:58.679819 29253 sgd_solver.cpp:106] Iteration 9180, lr = 0.01
I0302 05:09:27.610098 29253 solver.cpp:237] Iteration 9200, loss = 0.00172632
I0302 05:09:27.610132 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00172632 (* 1 = 0.00172632 loss)
I0302 05:09:27.610141 29253 sgd_solver.cpp:106] Iteration 9200, lr = 0.01
I0302 05:09:56.024246 29253 solver.cpp:237] Iteration 9220, loss = 0.00175262
I0302 05:09:56.024278 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00175262 (* 1 = 0.00175262 loss)
I0302 05:09:56.024287 29253 sgd_solver.cpp:106] Iteration 9220, lr = 0.01
I0302 05:10:24.867352 29253 solver.cpp:237] Iteration 9240, loss = 0.00183953
I0302 05:10:24.867383 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00183953 (* 1 = 0.00183953 loss)
I0302 05:10:24.867391 29253 sgd_solver.cpp:106] Iteration 9240, lr = 0.01
I0302 05:10:53.953775 29253 solver.cpp:237] Iteration 9260, loss = 0.00150968
I0302 05:10:53.953807 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00150968 (* 1 = 0.00150968 loss)
I0302 05:10:53.953816 29253 sgd_solver.cpp:106] Iteration 9260, lr = 0.01
I0302 05:11:23.399016 29253 solver.cpp:237] Iteration 9280, loss = 0.00170891
I0302 05:11:23.399049 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00170892 (* 1 = 0.00170892 loss)
I0302 05:11:23.399058 29253 sgd_solver.cpp:106] Iteration 9280, lr = 0.01
I0302 05:11:52.232033 29253 solver.cpp:237] Iteration 9300, loss = 0.00270876
I0302 05:11:52.232065 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00270876 (* 1 = 0.00270876 loss)
I0302 05:11:52.232074 29253 sgd_solver.cpp:106] Iteration 9300, lr = 0.01
I0302 05:12:20.808209 29253 solver.cpp:237] Iteration 9320, loss = 0.00235267
I0302 05:12:20.808241 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00235268 (* 1 = 0.00235268 loss)
I0302 05:12:20.808249 29253 sgd_solver.cpp:106] Iteration 9320, lr = 0.01
I0302 05:12:50.073041 29253 solver.cpp:237] Iteration 9340, loss = 0.00213895
I0302 05:12:50.073076 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00213895 (* 1 = 0.00213895 loss)
I0302 05:12:50.073084 29253 sgd_solver.cpp:106] Iteration 9340, lr = 0.01
I0302 05:13:18.567046 29253 solver.cpp:237] Iteration 9360, loss = 0.00180468
I0302 05:13:18.567078 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00180469 (* 1 = 0.00180469 loss)
I0302 05:13:18.567087 29253 sgd_solver.cpp:106] Iteration 9360, lr = 0.01
I0302 05:13:47.663552 29253 solver.cpp:237] Iteration 9380, loss = 0.00152488
I0302 05:13:47.663585 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00152488 (* 1 = 0.00152488 loss)
I0302 05:13:47.663594 29253 sgd_solver.cpp:106] Iteration 9380, lr = 0.01
I0302 05:14:16.798310 29253 solver.cpp:237] Iteration 9400, loss = 0.00176839
I0302 05:14:16.798341 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00176839 (* 1 = 0.00176839 loss)
I0302 05:14:16.798349 29253 sgd_solver.cpp:106] Iteration 9400, lr = 0.01
I0302 05:14:46.303606 29253 solver.cpp:237] Iteration 9420, loss = 0.00169991
I0302 05:14:46.303638 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00169991 (* 1 = 0.00169991 loss)
I0302 05:14:46.303647 29253 sgd_solver.cpp:106] Iteration 9420, lr = 0.01
I0302 05:15:14.912840 29253 solver.cpp:237] Iteration 9440, loss = 0.00177351
I0302 05:15:14.912870 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00177352 (* 1 = 0.00177352 loss)
I0302 05:15:14.912878 29253 sgd_solver.cpp:106] Iteration 9440, lr = 0.01
I0302 05:15:44.252940 29253 solver.cpp:237] Iteration 9460, loss = 0.00168622
I0302 05:15:44.252974 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00168622 (* 1 = 0.00168622 loss)
I0302 05:15:44.252982 29253 sgd_solver.cpp:106] Iteration 9460, lr = 0.01
I0302 05:16:13.190146 29253 solver.cpp:237] Iteration 9480, loss = 0.00162974
I0302 05:16:13.190179 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00162974 (* 1 = 0.00162974 loss)
I0302 05:16:13.190187 29253 sgd_solver.cpp:106] Iteration 9480, lr = 0.01
I0302 05:16:42.381213 29253 solver.cpp:237] Iteration 9500, loss = 0.00157895
I0302 05:16:42.381247 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00157896 (* 1 = 0.00157896 loss)
I0302 05:16:42.381255 29253 sgd_solver.cpp:106] Iteration 9500, lr = 0.01
I0302 05:17:11.123270 29253 solver.cpp:237] Iteration 9520, loss = 0.00156807
I0302 05:17:11.123303 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00156807 (* 1 = 0.00156807 loss)
I0302 05:17:11.123312 29253 sgd_solver.cpp:106] Iteration 9520, lr = 0.01
I0302 05:17:40.060690 29253 solver.cpp:237] Iteration 9540, loss = 0.00179764
I0302 05:17:40.060722 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00179765 (* 1 = 0.00179765 loss)
I0302 05:17:40.060730 29253 sgd_solver.cpp:106] Iteration 9540, lr = 0.01
I0302 05:18:08.948843 29253 solver.cpp:237] Iteration 9560, loss = 0.00184322
I0302 05:18:08.948876 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00184322 (* 1 = 0.00184322 loss)
I0302 05:18:08.948884 29253 sgd_solver.cpp:106] Iteration 9560, lr = 0.01
I0302 05:18:37.754120 29253 solver.cpp:237] Iteration 9580, loss = 0.00193095
I0302 05:18:37.754153 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00193095 (* 1 = 0.00193095 loss)
I0302 05:18:37.754161 29253 sgd_solver.cpp:106] Iteration 9580, lr = 0.01
I0302 05:19:06.795503 29253 solver.cpp:237] Iteration 9600, loss = 0.00187119
I0302 05:19:06.795534 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00187119 (* 1 = 0.00187119 loss)
I0302 05:19:06.795542 29253 sgd_solver.cpp:106] Iteration 9600, lr = 0.01
I0302 05:19:35.602542 29253 solver.cpp:237] Iteration 9620, loss = 0.00190073
I0302 05:19:35.602573 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00190073 (* 1 = 0.00190073 loss)
I0302 05:19:35.602582 29253 sgd_solver.cpp:106] Iteration 9620, lr = 0.01
I0302 05:20:04.547281 29253 solver.cpp:237] Iteration 9640, loss = 0.00183915
I0302 05:20:04.547315 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00183915 (* 1 = 0.00183915 loss)
I0302 05:20:04.547323 29253 sgd_solver.cpp:106] Iteration 9640, lr = 0.01
I0302 05:20:33.649648 29253 solver.cpp:237] Iteration 9660, loss = 0.00222058
I0302 05:20:33.649679 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00222058 (* 1 = 0.00222058 loss)
I0302 05:20:33.649688 29253 sgd_solver.cpp:106] Iteration 9660, lr = 0.01
I0302 05:21:02.496848 29253 solver.cpp:237] Iteration 9680, loss = 0.00183652
I0302 05:21:02.496881 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00183652 (* 1 = 0.00183652 loss)
I0302 05:21:02.496889 29253 sgd_solver.cpp:106] Iteration 9680, lr = 0.01
I0302 05:21:31.320688 29253 solver.cpp:237] Iteration 9700, loss = 0.00275409
I0302 05:21:31.320720 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00275409 (* 1 = 0.00275409 loss)
I0302 05:21:31.320729 29253 sgd_solver.cpp:106] Iteration 9700, lr = 0.01
I0302 05:22:00.414374 29253 solver.cpp:237] Iteration 9720, loss = 0.0018128
I0302 05:22:00.414405 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0018128 (* 1 = 0.0018128 loss)
I0302 05:22:00.414414 29253 sgd_solver.cpp:106] Iteration 9720, lr = 0.01
I0302 05:22:29.266492 29253 solver.cpp:237] Iteration 9740, loss = 0.00158426
I0302 05:22:29.266522 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00158426 (* 1 = 0.00158426 loss)
I0302 05:22:29.266531 29253 sgd_solver.cpp:106] Iteration 9740, lr = 0.01
I0302 05:22:58.362221 29253 solver.cpp:237] Iteration 9760, loss = 0.0015392
I0302 05:22:58.362253 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0015392 (* 1 = 0.0015392 loss)
I0302 05:22:58.362262 29253 sgd_solver.cpp:106] Iteration 9760, lr = 0.01
I0302 05:23:27.069279 29253 solver.cpp:237] Iteration 9780, loss = 0.00186944
I0302 05:23:27.069311 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00186944 (* 1 = 0.00186944 loss)
I0302 05:23:27.069320 29253 sgd_solver.cpp:106] Iteration 9780, lr = 0.01
I0302 05:23:55.792569 29253 solver.cpp:237] Iteration 9800, loss = 0.00159043
I0302 05:23:55.792600 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00159043 (* 1 = 0.00159043 loss)
I0302 05:23:55.792609 29253 sgd_solver.cpp:106] Iteration 9800, lr = 0.01
I0302 05:24:24.622222 29253 solver.cpp:237] Iteration 9820, loss = 0.00196006
I0302 05:24:24.622254 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00196007 (* 1 = 0.00196007 loss)
I0302 05:24:24.622262 29253 sgd_solver.cpp:106] Iteration 9820, lr = 0.01
I0302 05:24:53.704246 29253 solver.cpp:237] Iteration 9840, loss = 0.00182165
I0302 05:24:53.704279 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00182166 (* 1 = 0.00182166 loss)
I0302 05:24:53.704288 29253 sgd_solver.cpp:106] Iteration 9840, lr = 0.01
I0302 05:25:22.742687 29253 solver.cpp:237] Iteration 9860, loss = 0.001949
I0302 05:25:22.742719 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.001949 (* 1 = 0.001949 loss)
I0302 05:25:22.742728 29253 sgd_solver.cpp:106] Iteration 9860, lr = 0.01
I0302 05:25:51.972771 29253 solver.cpp:237] Iteration 9880, loss = 0.00223611
I0302 05:25:51.972805 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00223612 (* 1 = 0.00223612 loss)
I0302 05:25:51.972812 29253 sgd_solver.cpp:106] Iteration 9880, lr = 0.01
I0302 05:26:20.823282 29253 solver.cpp:237] Iteration 9900, loss = 0.0014015
I0302 05:26:20.823313 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0014015 (* 1 = 0.0014015 loss)
I0302 05:26:20.823323 29253 sgd_solver.cpp:106] Iteration 9900, lr = 0.01
I0302 05:26:49.906131 29253 solver.cpp:237] Iteration 9920, loss = 0.00186482
I0302 05:26:49.906163 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00186482 (* 1 = 0.00186482 loss)
I0302 05:26:49.906172 29253 sgd_solver.cpp:106] Iteration 9920, lr = 0.01
I0302 05:27:19.197280 29253 solver.cpp:237] Iteration 9940, loss = 0.00188425
I0302 05:27:19.197311 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00188425 (* 1 = 0.00188425 loss)
I0302 05:27:19.197319 29253 sgd_solver.cpp:106] Iteration 9940, lr = 0.01
I0302 05:27:48.058166 29253 solver.cpp:237] Iteration 9960, loss = 0.00178421
I0302 05:27:48.058197 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00178421 (* 1 = 0.00178421 loss)
I0302 05:27:48.058207 29253 sgd_solver.cpp:106] Iteration 9960, lr = 0.01
I0302 05:28:17.417881 29253 solver.cpp:237] Iteration 9980, loss = 0.00237824
I0302 05:28:17.417912 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00237825 (* 1 = 0.00237825 loss)
I0302 05:28:17.417920 29253 sgd_solver.cpp:106] Iteration 9980, lr = 0.01
I0302 05:28:44.881090 29253 solver.cpp:459] Snapshotting to binary proto file /nfs.yoda/xiaolonw/fast_rcnn/models_sunrgbd/pre_cls_1fc_scratch/model__iter_10000.caffemodel
I0302 05:29:20.061216 29253 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /nfs.yoda/xiaolonw/fast_rcnn/models_sunrgbd/pre_cls_1fc_scratch/model__iter_10000.solverstate
I0302 05:29:20.451310 29253 solver.cpp:237] Iteration 10000, loss = 0.00192573
I0302 05:29:20.451340 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00192574 (* 1 = 0.00192574 loss)
I0302 05:29:20.451349 29253 sgd_solver.cpp:106] Iteration 10000, lr = 0.001
I0302 05:29:23.298399 29253 blocking_queue.cpp:50] Data layer prefetch queue empty
I0302 05:29:46.693917 29253 solver.cpp:237] Iteration 10020, loss = 0.00156741
I0302 05:29:46.693950 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00156741 (* 1 = 0.00156741 loss)
I0302 05:29:46.693959 29253 sgd_solver.cpp:106] Iteration 10020, lr = 0.001
I0302 05:30:15.540232 29253 solver.cpp:237] Iteration 10040, loss = 0.00174003
I0302 05:30:15.540266 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00174004 (* 1 = 0.00174004 loss)
I0302 05:30:15.540274 29253 sgd_solver.cpp:106] Iteration 10040, lr = 0.001
I0302 05:30:44.384433 29253 solver.cpp:237] Iteration 10060, loss = 0.00208513
I0302 05:30:44.384462 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00208514 (* 1 = 0.00208514 loss)
I0302 05:30:44.384471 29253 sgd_solver.cpp:106] Iteration 10060, lr = 0.001
I0302 05:31:13.362166 29253 solver.cpp:237] Iteration 10080, loss = 0.00163637
I0302 05:31:13.362198 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00163638 (* 1 = 0.00163638 loss)
I0302 05:31:13.362207 29253 sgd_solver.cpp:106] Iteration 10080, lr = 0.001
I0302 05:31:42.380638 29253 solver.cpp:237] Iteration 10100, loss = 0.00183392
I0302 05:31:42.380671 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00183392 (* 1 = 0.00183392 loss)
I0302 05:31:42.380681 29253 sgd_solver.cpp:106] Iteration 10100, lr = 0.001
I0302 05:32:11.614375 29253 solver.cpp:237] Iteration 10120, loss = 0.00186399
I0302 05:32:11.614409 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00186399 (* 1 = 0.00186399 loss)
I0302 05:32:11.614418 29253 sgd_solver.cpp:106] Iteration 10120, lr = 0.001
I0302 05:32:40.793733 29253 solver.cpp:237] Iteration 10140, loss = 0.00191984
I0302 05:32:40.793766 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00191984 (* 1 = 0.00191984 loss)
I0302 05:32:40.793774 29253 sgd_solver.cpp:106] Iteration 10140, lr = 0.001
I0302 05:33:09.453925 29253 solver.cpp:237] Iteration 10160, loss = 0.00185374
I0302 05:33:09.453958 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00185375 (* 1 = 0.00185375 loss)
I0302 05:33:09.453968 29253 sgd_solver.cpp:106] Iteration 10160, lr = 0.001
I0302 05:33:38.275403 29253 solver.cpp:237] Iteration 10180, loss = 0.00134844
I0302 05:33:38.275435 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00134844 (* 1 = 0.00134844 loss)
I0302 05:33:38.275444 29253 sgd_solver.cpp:106] Iteration 10180, lr = 0.001
I0302 05:34:07.128681 29253 solver.cpp:237] Iteration 10200, loss = 0.00127983
I0302 05:34:07.128715 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00127983 (* 1 = 0.00127983 loss)
I0302 05:34:07.128723 29253 sgd_solver.cpp:106] Iteration 10200, lr = 0.001
I0302 05:34:36.200484 29253 solver.cpp:237] Iteration 10220, loss = 0.00191371
I0302 05:34:36.200516 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00191372 (* 1 = 0.00191372 loss)
I0302 05:34:36.200525 29253 sgd_solver.cpp:106] Iteration 10220, lr = 0.001
I0302 05:35:04.970260 29253 solver.cpp:237] Iteration 10240, loss = 0.00141347
I0302 05:35:04.970293 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00141348 (* 1 = 0.00141348 loss)
I0302 05:35:04.970302 29253 sgd_solver.cpp:106] Iteration 10240, lr = 0.001
I0302 05:35:33.995782 29253 solver.cpp:237] Iteration 10260, loss = 0.00210394
I0302 05:35:33.995813 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00210394 (* 1 = 0.00210394 loss)
I0302 05:35:33.995821 29253 sgd_solver.cpp:106] Iteration 10260, lr = 0.001
I0302 05:36:02.992326 29253 solver.cpp:237] Iteration 10280, loss = 0.00150161
I0302 05:36:02.992358 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00150161 (* 1 = 0.00150161 loss)
I0302 05:36:02.992367 29253 sgd_solver.cpp:106] Iteration 10280, lr = 0.001
I0302 05:36:32.507964 29253 solver.cpp:237] Iteration 10300, loss = 0.00140352
I0302 05:36:32.507997 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00140352 (* 1 = 0.00140352 loss)
I0302 05:36:32.508004 29253 sgd_solver.cpp:106] Iteration 10300, lr = 0.001
I0302 05:37:01.024757 29253 solver.cpp:237] Iteration 10320, loss = 0.00167728
I0302 05:37:01.024791 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00167729 (* 1 = 0.00167729 loss)
I0302 05:37:01.024799 29253 sgd_solver.cpp:106] Iteration 10320, lr = 0.001
I0302 05:37:29.694932 29253 solver.cpp:237] Iteration 10340, loss = 0.00155692
I0302 05:37:29.694964 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00155692 (* 1 = 0.00155692 loss)
I0302 05:37:29.694972 29253 sgd_solver.cpp:106] Iteration 10340, lr = 0.001
I0302 05:37:58.685251 29253 solver.cpp:237] Iteration 10360, loss = 0.00148079
I0302 05:37:58.685283 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00148079 (* 1 = 0.00148079 loss)
I0302 05:37:58.685292 29253 sgd_solver.cpp:106] Iteration 10360, lr = 0.001
I0302 05:38:27.617817 29253 solver.cpp:237] Iteration 10380, loss = 0.00195203
I0302 05:38:27.617848 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00195203 (* 1 = 0.00195203 loss)
I0302 05:38:27.617857 29253 sgd_solver.cpp:106] Iteration 10380, lr = 0.001
I0302 05:38:56.631960 29253 solver.cpp:237] Iteration 10400, loss = 0.00167808
I0302 05:38:56.631992 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00167808 (* 1 = 0.00167808 loss)
I0302 05:38:56.632001 29253 sgd_solver.cpp:106] Iteration 10400, lr = 0.001
I0302 05:39:25.320293 29253 solver.cpp:237] Iteration 10420, loss = 0.00190849
I0302 05:39:25.320325 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00190849 (* 1 = 0.00190849 loss)
I0302 05:39:25.320334 29253 sgd_solver.cpp:106] Iteration 10420, lr = 0.001
I0302 05:39:54.340035 29253 solver.cpp:237] Iteration 10440, loss = 0.00178092
I0302 05:39:54.340067 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00178092 (* 1 = 0.00178092 loss)
I0302 05:39:54.340075 29253 sgd_solver.cpp:106] Iteration 10440, lr = 0.001
I0302 05:40:23.220104 29253 solver.cpp:237] Iteration 10460, loss = 0.00155495
I0302 05:40:23.220135 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00155495 (* 1 = 0.00155495 loss)
I0302 05:40:23.220144 29253 sgd_solver.cpp:106] Iteration 10460, lr = 0.001
I0302 05:40:51.710238 29253 solver.cpp:237] Iteration 10480, loss = 0.0013368
I0302 05:40:51.710270 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0013368 (* 1 = 0.0013368 loss)
I0302 05:40:51.710279 29253 sgd_solver.cpp:106] Iteration 10480, lr = 0.001
I0302 05:41:20.910163 29253 solver.cpp:237] Iteration 10500, loss = 0.00172886
I0302 05:41:20.910193 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00172887 (* 1 = 0.00172887 loss)
I0302 05:41:20.910202 29253 sgd_solver.cpp:106] Iteration 10500, lr = 0.001
I0302 05:41:49.827817 29253 solver.cpp:237] Iteration 10520, loss = 0.00167025
I0302 05:41:49.827850 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00167025 (* 1 = 0.00167025 loss)
I0302 05:41:49.827858 29253 sgd_solver.cpp:106] Iteration 10520, lr = 0.001
I0302 05:42:18.691733 29253 solver.cpp:237] Iteration 10540, loss = 0.00136774
I0302 05:42:18.691766 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00136774 (* 1 = 0.00136774 loss)
I0302 05:42:18.691773 29253 sgd_solver.cpp:106] Iteration 10540, lr = 0.001
I0302 05:42:47.632809 29253 solver.cpp:237] Iteration 10560, loss = 0.00220141
I0302 05:42:47.632841 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00220141 (* 1 = 0.00220141 loss)
I0302 05:42:47.632850 29253 sgd_solver.cpp:106] Iteration 10560, lr = 0.001
I0302 05:43:16.403318 29253 solver.cpp:237] Iteration 10580, loss = 0.00193759
I0302 05:43:16.403350 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00193759 (* 1 = 0.00193759 loss)
I0302 05:43:16.403358 29253 sgd_solver.cpp:106] Iteration 10580, lr = 0.001
I0302 05:43:45.299022 29253 solver.cpp:237] Iteration 10600, loss = 0.00179417
I0302 05:43:45.299052 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00179417 (* 1 = 0.00179417 loss)
I0302 05:43:45.299060 29253 sgd_solver.cpp:106] Iteration 10600, lr = 0.001
I0302 05:44:14.187363 29253 solver.cpp:237] Iteration 10620, loss = 0.00162324
I0302 05:44:14.187398 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00162324 (* 1 = 0.00162324 loss)
I0302 05:44:14.187407 29253 sgd_solver.cpp:106] Iteration 10620, lr = 0.001
I0302 05:44:43.195910 29253 solver.cpp:237] Iteration 10640, loss = 0.0020566
I0302 05:44:43.195941 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0020566 (* 1 = 0.0020566 loss)
I0302 05:44:43.195950 29253 sgd_solver.cpp:106] Iteration 10640, lr = 0.001
I0302 05:45:12.084648 29253 solver.cpp:237] Iteration 10660, loss = 0.00212813
I0302 05:45:12.084681 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00212813 (* 1 = 0.00212813 loss)
I0302 05:45:12.084691 29253 sgd_solver.cpp:106] Iteration 10660, lr = 0.001
I0302 05:45:41.047575 29253 solver.cpp:237] Iteration 10680, loss = 0.00137305
I0302 05:45:41.047605 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00137305 (* 1 = 0.00137305 loss)
I0302 05:45:41.047613 29253 sgd_solver.cpp:106] Iteration 10680, lr = 0.001
I0302 05:46:09.890223 29253 solver.cpp:237] Iteration 10700, loss = 0.00151447
I0302 05:46:09.890249 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00151447 (* 1 = 0.00151447 loss)
I0302 05:46:09.890257 29253 sgd_solver.cpp:106] Iteration 10700, lr = 0.001
I0302 05:46:38.789240 29253 solver.cpp:237] Iteration 10720, loss = 0.00186666
I0302 05:46:38.789273 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00186666 (* 1 = 0.00186666 loss)
I0302 05:46:38.789281 29253 sgd_solver.cpp:106] Iteration 10720, lr = 0.001
I0302 05:47:07.817734 29253 solver.cpp:237] Iteration 10740, loss = 0.00239448
I0302 05:47:07.817764 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00239448 (* 1 = 0.00239448 loss)
I0302 05:47:07.817773 29253 sgd_solver.cpp:106] Iteration 10740, lr = 0.001
I0302 05:47:36.569977 29253 solver.cpp:237] Iteration 10760, loss = 0.00145106
I0302 05:47:36.570005 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00145107 (* 1 = 0.00145107 loss)
I0302 05:47:36.570014 29253 sgd_solver.cpp:106] Iteration 10760, lr = 0.001
I0302 05:48:05.508194 29253 solver.cpp:237] Iteration 10780, loss = 0.00155089
I0302 05:48:05.508222 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0015509 (* 1 = 0.0015509 loss)
I0302 05:48:05.508231 29253 sgd_solver.cpp:106] Iteration 10780, lr = 0.001
I0302 05:48:34.431017 29253 solver.cpp:237] Iteration 10800, loss = 0.00207754
I0302 05:48:34.431044 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00207755 (* 1 = 0.00207755 loss)
I0302 05:48:34.431052 29253 sgd_solver.cpp:106] Iteration 10800, lr = 0.001
I0302 05:49:03.324017 29253 solver.cpp:237] Iteration 10820, loss = 0.00161646
I0302 05:49:03.324046 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00161646 (* 1 = 0.00161646 loss)
I0302 05:49:03.324055 29253 sgd_solver.cpp:106] Iteration 10820, lr = 0.001
I0302 05:49:32.286766 29253 solver.cpp:237] Iteration 10840, loss = 0.0016307
I0302 05:49:32.286798 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00163071 (* 1 = 0.00163071 loss)
I0302 05:49:32.286806 29253 sgd_solver.cpp:106] Iteration 10840, lr = 0.001
I0302 05:50:01.279760 29253 solver.cpp:237] Iteration 10860, loss = 0.00154568
I0302 05:50:01.279794 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00154568 (* 1 = 0.00154568 loss)
I0302 05:50:01.279803 29253 sgd_solver.cpp:106] Iteration 10860, lr = 0.001
I0302 05:50:30.264638 29253 solver.cpp:237] Iteration 10880, loss = 0.00144397
I0302 05:50:30.264662 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00144397 (* 1 = 0.00144397 loss)
I0302 05:50:30.264670 29253 sgd_solver.cpp:106] Iteration 10880, lr = 0.001
I0302 05:50:59.032176 29253 solver.cpp:237] Iteration 10900, loss = 0.00171547
I0302 05:50:59.032208 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00171547 (* 1 = 0.00171547 loss)
I0302 05:50:59.032217 29253 sgd_solver.cpp:106] Iteration 10900, lr = 0.001
I0302 05:51:27.928928 29253 solver.cpp:237] Iteration 10920, loss = 0.00162104
I0302 05:51:27.928961 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00162105 (* 1 = 0.00162105 loss)
I0302 05:51:27.928969 29253 sgd_solver.cpp:106] Iteration 10920, lr = 0.001
I0302 05:51:56.855700 29253 solver.cpp:237] Iteration 10940, loss = 0.00150855
I0302 05:51:56.855733 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00150855 (* 1 = 0.00150855 loss)
I0302 05:51:56.855742 29253 sgd_solver.cpp:106] Iteration 10940, lr = 0.001
I0302 05:52:25.845235 29253 solver.cpp:237] Iteration 10960, loss = 0.00132389
I0302 05:52:25.845268 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00132389 (* 1 = 0.00132389 loss)
I0302 05:52:25.845278 29253 sgd_solver.cpp:106] Iteration 10960, lr = 0.001
I0302 05:52:54.779814 29253 solver.cpp:237] Iteration 10980, loss = 0.00150733
I0302 05:52:54.779839 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00150733 (* 1 = 0.00150733 loss)
I0302 05:52:54.779846 29253 sgd_solver.cpp:106] Iteration 10980, lr = 0.001
I0302 05:53:23.934087 29253 solver.cpp:237] Iteration 11000, loss = 0.00150211
I0302 05:53:23.934120 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00150211 (* 1 = 0.00150211 loss)
I0302 05:53:23.934128 29253 sgd_solver.cpp:106] Iteration 11000, lr = 0.001
I0302 05:53:29.640725 29253 blocking_queue.cpp:50] Data layer prefetch queue empty
I0302 05:53:52.877249 29253 solver.cpp:237] Iteration 11020, loss = 0.00175051
I0302 05:53:52.877282 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00175052 (* 1 = 0.00175052 loss)
I0302 05:53:52.877290 29253 sgd_solver.cpp:106] Iteration 11020, lr = 0.001
I0302 05:54:21.876466 29253 solver.cpp:237] Iteration 11040, loss = 0.0017471
I0302 05:54:21.876499 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0017471 (* 1 = 0.0017471 loss)
I0302 05:54:21.876507 29253 sgd_solver.cpp:106] Iteration 11040, lr = 0.001
I0302 05:54:50.629925 29253 solver.cpp:237] Iteration 11060, loss = 0.00177401
I0302 05:54:50.629957 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00177401 (* 1 = 0.00177401 loss)
I0302 05:54:50.629966 29253 sgd_solver.cpp:106] Iteration 11060, lr = 0.001
I0302 05:55:19.770833 29253 solver.cpp:237] Iteration 11080, loss = 0.00157767
I0302 05:55:19.770865 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00157767 (* 1 = 0.00157767 loss)
I0302 05:55:19.770874 29253 sgd_solver.cpp:106] Iteration 11080, lr = 0.001
I0302 05:55:48.712050 29253 solver.cpp:237] Iteration 11100, loss = 0.00174366
I0302 05:55:48.712082 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00174366 (* 1 = 0.00174366 loss)
I0302 05:55:48.712090 29253 sgd_solver.cpp:106] Iteration 11100, lr = 0.001
I0302 05:56:17.531617 29253 solver.cpp:237] Iteration 11120, loss = 0.00168994
I0302 05:56:17.531649 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00168994 (* 1 = 0.00168994 loss)
I0302 05:56:17.531658 29253 sgd_solver.cpp:106] Iteration 11120, lr = 0.001
I0302 05:56:46.639261 29253 solver.cpp:237] Iteration 11140, loss = 0.0017138
I0302 05:56:46.639293 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0017138 (* 1 = 0.0017138 loss)
I0302 05:56:46.639302 29253 sgd_solver.cpp:106] Iteration 11140, lr = 0.001
I0302 05:57:15.624531 29253 solver.cpp:237] Iteration 11160, loss = 0.00171982
I0302 05:57:15.624563 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00171982 (* 1 = 0.00171982 loss)
I0302 05:57:15.624572 29253 sgd_solver.cpp:106] Iteration 11160, lr = 0.001
I0302 05:57:44.577953 29253 solver.cpp:237] Iteration 11180, loss = 0.00205288
I0302 05:57:44.577986 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00205289 (* 1 = 0.00205289 loss)
I0302 05:57:44.577996 29253 sgd_solver.cpp:106] Iteration 11180, lr = 0.001
I0302 05:58:13.346356 29253 solver.cpp:237] Iteration 11200, loss = 0.00146629
I0302 05:58:13.346391 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0014663 (* 1 = 0.0014663 loss)
I0302 05:58:13.346400 29253 sgd_solver.cpp:106] Iteration 11200, lr = 0.001
I0302 05:58:42.267370 29253 solver.cpp:237] Iteration 11220, loss = 0.00146929
I0302 05:58:42.267402 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00146929 (* 1 = 0.00146929 loss)
I0302 05:58:42.267411 29253 sgd_solver.cpp:106] Iteration 11220, lr = 0.001
I0302 05:59:11.220319 29253 solver.cpp:237] Iteration 11240, loss = 0.00165357
I0302 05:59:11.220351 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00165357 (* 1 = 0.00165357 loss)
I0302 05:59:11.220360 29253 sgd_solver.cpp:106] Iteration 11240, lr = 0.001
I0302 05:59:40.063856 29253 solver.cpp:237] Iteration 11260, loss = 0.00166183
I0302 05:59:40.063889 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00166183 (* 1 = 0.00166183 loss)
I0302 05:59:40.063899 29253 sgd_solver.cpp:106] Iteration 11260, lr = 0.001
I0302 06:00:09.202035 29253 solver.cpp:237] Iteration 11280, loss = 0.00210099
I0302 06:00:09.202069 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00210099 (* 1 = 0.00210099 loss)
I0302 06:00:09.202080 29253 sgd_solver.cpp:106] Iteration 11280, lr = 0.001
I0302 06:00:38.257540 29253 solver.cpp:237] Iteration 11300, loss = 0.00196804
I0302 06:00:38.257571 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00196804 (* 1 = 0.00196804 loss)
I0302 06:00:38.257580 29253 sgd_solver.cpp:106] Iteration 11300, lr = 0.001
I0302 06:01:07.091246 29253 solver.cpp:237] Iteration 11320, loss = 0.0016761
I0302 06:01:07.091279 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00167611 (* 1 = 0.00167611 loss)
I0302 06:01:07.091286 29253 sgd_solver.cpp:106] Iteration 11320, lr = 0.001
I0302 06:01:36.096580 29253 solver.cpp:237] Iteration 11340, loss = 0.00166906
I0302 06:01:36.096611 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00166906 (* 1 = 0.00166906 loss)
I0302 06:01:36.096621 29253 sgd_solver.cpp:106] Iteration 11340, lr = 0.001
I0302 06:02:04.985311 29253 solver.cpp:237] Iteration 11360, loss = 0.00188335
I0302 06:02:04.985344 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00188335 (* 1 = 0.00188335 loss)
I0302 06:02:04.985353 29253 sgd_solver.cpp:106] Iteration 11360, lr = 0.001
I0302 06:02:33.888020 29253 solver.cpp:237] Iteration 11380, loss = 0.00193505
I0302 06:02:33.888051 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00193505 (* 1 = 0.00193505 loss)
I0302 06:02:33.888059 29253 sgd_solver.cpp:106] Iteration 11380, lr = 0.001
I0302 06:03:02.740321 29253 solver.cpp:237] Iteration 11400, loss = 0.00195528
I0302 06:03:02.740353 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00195528 (* 1 = 0.00195528 loss)
I0302 06:03:02.740362 29253 sgd_solver.cpp:106] Iteration 11400, lr = 0.001
I0302 06:03:31.771515 29253 solver.cpp:237] Iteration 11420, loss = 0.00154394
I0302 06:03:31.771548 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00154394 (* 1 = 0.00154394 loss)
I0302 06:03:31.771555 29253 sgd_solver.cpp:106] Iteration 11420, lr = 0.001
I0302 06:04:00.707310 29253 solver.cpp:237] Iteration 11440, loss = 0.00183165
I0302 06:04:00.707343 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00183165 (* 1 = 0.00183165 loss)
I0302 06:04:00.707351 29253 sgd_solver.cpp:106] Iteration 11440, lr = 0.001
I0302 06:04:29.707268 29253 solver.cpp:237] Iteration 11460, loss = 0.00181915
I0302 06:04:29.707301 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00181915 (* 1 = 0.00181915 loss)
I0302 06:04:29.707311 29253 sgd_solver.cpp:106] Iteration 11460, lr = 0.001
I0302 06:04:58.631445 29253 solver.cpp:237] Iteration 11480, loss = 0.00144877
I0302 06:04:58.631479 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00144878 (* 1 = 0.00144878 loss)
I0302 06:04:58.631487 29253 sgd_solver.cpp:106] Iteration 11480, lr = 0.001
I0302 06:05:27.292328 29253 solver.cpp:237] Iteration 11500, loss = 0.00160845
I0302 06:05:27.292361 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00160845 (* 1 = 0.00160845 loss)
I0302 06:05:27.292371 29253 sgd_solver.cpp:106] Iteration 11500, lr = 0.001
I0302 06:05:56.122192 29253 solver.cpp:237] Iteration 11520, loss = 0.0015865
I0302 06:05:56.122226 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0015865 (* 1 = 0.0015865 loss)
I0302 06:05:56.122236 29253 sgd_solver.cpp:106] Iteration 11520, lr = 0.001
I0302 06:06:25.152079 29253 solver.cpp:237] Iteration 11540, loss = 0.00180575
I0302 06:06:25.152112 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00180575 (* 1 = 0.00180575 loss)
I0302 06:06:25.152119 29253 sgd_solver.cpp:106] Iteration 11540, lr = 0.001
I0302 06:06:53.955015 29253 solver.cpp:237] Iteration 11560, loss = 0.00189719
I0302 06:06:53.955047 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0018972 (* 1 = 0.0018972 loss)
I0302 06:06:53.955056 29253 sgd_solver.cpp:106] Iteration 11560, lr = 0.001
I0302 06:07:22.910378 29253 solver.cpp:237] Iteration 11580, loss = 0.0017828
I0302 06:07:22.910413 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00178281 (* 1 = 0.00178281 loss)
I0302 06:07:22.910423 29253 sgd_solver.cpp:106] Iteration 11580, lr = 0.001
I0302 06:07:51.980322 29253 solver.cpp:237] Iteration 11600, loss = 0.0015677
I0302 06:07:51.980355 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00156771 (* 1 = 0.00156771 loss)
I0302 06:07:51.980365 29253 sgd_solver.cpp:106] Iteration 11600, lr = 0.001
I0302 06:08:20.961555 29253 solver.cpp:237] Iteration 11620, loss = 0.00149582
I0302 06:08:20.961588 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00149582 (* 1 = 0.00149582 loss)
I0302 06:08:20.961596 29253 sgd_solver.cpp:106] Iteration 11620, lr = 0.001
I0302 06:08:49.799679 29253 solver.cpp:237] Iteration 11640, loss = 0.00181036
I0302 06:08:49.799711 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00181037 (* 1 = 0.00181037 loss)
I0302 06:08:49.799721 29253 sgd_solver.cpp:106] Iteration 11640, lr = 0.001
I0302 06:09:18.597511 29253 solver.cpp:237] Iteration 11660, loss = 0.00148449
I0302 06:09:18.597543 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0014845 (* 1 = 0.0014845 loss)
I0302 06:09:18.597551 29253 sgd_solver.cpp:106] Iteration 11660, lr = 0.001
I0302 06:09:47.635529 29253 solver.cpp:237] Iteration 11680, loss = 0.00151178
I0302 06:09:47.635561 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00151178 (* 1 = 0.00151178 loss)
I0302 06:09:47.635571 29253 sgd_solver.cpp:106] Iteration 11680, lr = 0.001
I0302 06:10:16.124641 29253 solver.cpp:237] Iteration 11700, loss = 0.00163301
I0302 06:10:16.124673 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00163301 (* 1 = 0.00163301 loss)
I0302 06:10:16.124682 29253 sgd_solver.cpp:106] Iteration 11700, lr = 0.001
I0302 06:10:45.365555 29253 solver.cpp:237] Iteration 11720, loss = 0.00184074
I0302 06:10:45.365584 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00184075 (* 1 = 0.00184075 loss)
I0302 06:10:45.365593 29253 sgd_solver.cpp:106] Iteration 11720, lr = 0.001
I0302 06:11:14.210178 29253 solver.cpp:237] Iteration 11740, loss = 0.00153261
I0302 06:11:14.210212 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00153262 (* 1 = 0.00153262 loss)
I0302 06:11:14.210221 29253 sgd_solver.cpp:106] Iteration 11740, lr = 0.001
I0302 06:11:42.886173 29253 solver.cpp:237] Iteration 11760, loss = 0.00175853
I0302 06:11:42.886204 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00175853 (* 1 = 0.00175853 loss)
I0302 06:11:42.886212 29253 sgd_solver.cpp:106] Iteration 11760, lr = 0.001
I0302 06:12:11.706703 29253 solver.cpp:237] Iteration 11780, loss = 0.0020152
I0302 06:12:11.706734 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0020152 (* 1 = 0.0020152 loss)
I0302 06:12:11.706743 29253 sgd_solver.cpp:106] Iteration 11780, lr = 0.001
I0302 06:12:40.572636 29253 solver.cpp:237] Iteration 11800, loss = 0.00153786
I0302 06:12:40.572669 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00153786 (* 1 = 0.00153786 loss)
I0302 06:12:40.572677 29253 sgd_solver.cpp:106] Iteration 11800, lr = 0.001
I0302 06:13:09.741091 29253 solver.cpp:237] Iteration 11820, loss = 0.00174473
I0302 06:13:09.741122 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00174473 (* 1 = 0.00174473 loss)
I0302 06:13:09.741132 29253 sgd_solver.cpp:106] Iteration 11820, lr = 0.001
I0302 06:13:38.453708 29253 solver.cpp:237] Iteration 11840, loss = 0.00136432
I0302 06:13:38.453742 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00136432 (* 1 = 0.00136432 loss)
I0302 06:13:38.453749 29253 sgd_solver.cpp:106] Iteration 11840, lr = 0.001
I0302 06:14:08.015944 29253 solver.cpp:237] Iteration 11860, loss = 0.00167098
I0302 06:14:08.015975 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00167099 (* 1 = 0.00167099 loss)
I0302 06:14:08.015983 29253 sgd_solver.cpp:106] Iteration 11860, lr = 0.001
I0302 06:14:36.571593 29253 solver.cpp:237] Iteration 11880, loss = 0.00175398
I0302 06:14:36.571624 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00175398 (* 1 = 0.00175398 loss)
I0302 06:14:36.571633 29253 sgd_solver.cpp:106] Iteration 11880, lr = 0.001
I0302 06:15:05.303804 29253 solver.cpp:237] Iteration 11900, loss = 0.00167536
I0302 06:15:05.303836 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00167536 (* 1 = 0.00167536 loss)
I0302 06:15:05.303846 29253 sgd_solver.cpp:106] Iteration 11900, lr = 0.001
I0302 06:15:34.273216 29253 solver.cpp:237] Iteration 11920, loss = 0.0019485
I0302 06:15:34.273248 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0019485 (* 1 = 0.0019485 loss)
I0302 06:15:34.273257 29253 sgd_solver.cpp:106] Iteration 11920, lr = 0.001
I0302 06:16:03.173897 29253 solver.cpp:237] Iteration 11940, loss = 0.00177443
I0302 06:16:03.173928 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00177443 (* 1 = 0.00177443 loss)
I0302 06:16:03.173938 29253 sgd_solver.cpp:106] Iteration 11940, lr = 0.001
I0302 06:16:32.055681 29253 solver.cpp:237] Iteration 11960, loss = 0.00189942
I0302 06:16:32.055714 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00189942 (* 1 = 0.00189942 loss)
I0302 06:16:32.055723 29253 sgd_solver.cpp:106] Iteration 11960, lr = 0.001
I0302 06:17:00.988015 29253 solver.cpp:237] Iteration 11980, loss = 0.00174404
I0302 06:17:00.988049 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00174404 (* 1 = 0.00174404 loss)
I0302 06:17:00.988057 29253 sgd_solver.cpp:106] Iteration 11980, lr = 0.001
I0302 06:17:29.919446 29253 solver.cpp:237] Iteration 12000, loss = 0.00156832
I0302 06:17:29.919479 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00156833 (* 1 = 0.00156833 loss)
I0302 06:17:29.919488 29253 sgd_solver.cpp:106] Iteration 12000, lr = 0.001
I0302 06:17:35.769261 29253 blocking_queue.cpp:50] Data layer prefetch queue empty
I0302 06:17:58.876088 29253 solver.cpp:237] Iteration 12020, loss = 0.00186304
I0302 06:17:58.876121 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00186304 (* 1 = 0.00186304 loss)
I0302 06:17:58.876130 29253 sgd_solver.cpp:106] Iteration 12020, lr = 0.001
I0302 06:18:28.185987 29253 solver.cpp:237] Iteration 12040, loss = 0.00182555
I0302 06:18:28.186020 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00182556 (* 1 = 0.00182556 loss)
I0302 06:18:28.186028 29253 sgd_solver.cpp:106] Iteration 12040, lr = 0.001
I0302 06:18:56.897924 29253 solver.cpp:237] Iteration 12060, loss = 0.00167828
I0302 06:18:56.897956 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00167828 (* 1 = 0.00167828 loss)
I0302 06:18:56.897964 29253 sgd_solver.cpp:106] Iteration 12060, lr = 0.001
I0302 06:19:25.874977 29253 solver.cpp:237] Iteration 12080, loss = 0.00193419
I0302 06:19:25.875010 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00193419 (* 1 = 0.00193419 loss)
I0302 06:19:25.875018 29253 sgd_solver.cpp:106] Iteration 12080, lr = 0.001
I0302 06:19:54.813493 29253 solver.cpp:237] Iteration 12100, loss = 0.00166034
I0302 06:19:54.813524 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00166035 (* 1 = 0.00166035 loss)
I0302 06:19:54.813534 29253 sgd_solver.cpp:106] Iteration 12100, lr = 0.001
I0302 06:20:23.677590 29253 solver.cpp:237] Iteration 12120, loss = 0.00177423
I0302 06:20:23.677621 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00177424 (* 1 = 0.00177424 loss)
I0302 06:20:23.677629 29253 sgd_solver.cpp:106] Iteration 12120, lr = 0.001
I0302 06:20:52.688181 29253 solver.cpp:237] Iteration 12140, loss = 0.00166593
I0302 06:20:52.688213 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00166593 (* 1 = 0.00166593 loss)
I0302 06:20:52.688222 29253 sgd_solver.cpp:106] Iteration 12140, lr = 0.001
I0302 06:21:21.478708 29253 solver.cpp:237] Iteration 12160, loss = 0.00167917
I0302 06:21:21.478739 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00167918 (* 1 = 0.00167918 loss)
I0302 06:21:21.478747 29253 sgd_solver.cpp:106] Iteration 12160, lr = 0.001
I0302 06:21:50.435822 29253 solver.cpp:237] Iteration 12180, loss = 0.00197389
I0302 06:21:50.435853 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00197389 (* 1 = 0.00197389 loss)
I0302 06:21:50.435863 29253 sgd_solver.cpp:106] Iteration 12180, lr = 0.001
I0302 06:22:19.846076 29253 solver.cpp:237] Iteration 12200, loss = 0.00169374
I0302 06:22:19.846108 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00169374 (* 1 = 0.00169374 loss)
I0302 06:22:19.846117 29253 sgd_solver.cpp:106] Iteration 12200, lr = 0.001
I0302 06:22:48.891540 29253 solver.cpp:237] Iteration 12220, loss = 0.00173892
I0302 06:22:48.891571 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00173893 (* 1 = 0.00173893 loss)
I0302 06:22:48.891582 29253 sgd_solver.cpp:106] Iteration 12220, lr = 0.001
I0302 06:23:18.251049 29253 solver.cpp:237] Iteration 12240, loss = 0.00141996
I0302 06:23:18.251081 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00141996 (* 1 = 0.00141996 loss)
I0302 06:23:18.251091 29253 sgd_solver.cpp:106] Iteration 12240, lr = 0.001
I0302 06:23:46.658843 29253 solver.cpp:237] Iteration 12260, loss = 0.00141919
I0302 06:23:46.658874 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00141919 (* 1 = 0.00141919 loss)
I0302 06:23:46.658884 29253 sgd_solver.cpp:106] Iteration 12260, lr = 0.001
I0302 06:24:15.637923 29253 solver.cpp:237] Iteration 12280, loss = 0.00126381
I0302 06:24:15.637953 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00126381 (* 1 = 0.00126381 loss)
I0302 06:24:15.637961 29253 sgd_solver.cpp:106] Iteration 12280, lr = 0.001
I0302 06:24:44.562871 29253 solver.cpp:237] Iteration 12300, loss = 0.001928
I0302 06:24:44.562903 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.001928 (* 1 = 0.001928 loss)
I0302 06:24:44.562911 29253 sgd_solver.cpp:106] Iteration 12300, lr = 0.001
I0302 06:25:13.563473 29253 solver.cpp:237] Iteration 12320, loss = 0.00159298
I0302 06:25:13.563506 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00159299 (* 1 = 0.00159299 loss)
I0302 06:25:13.563515 29253 sgd_solver.cpp:106] Iteration 12320, lr = 0.001
I0302 06:25:42.409274 29253 solver.cpp:237] Iteration 12340, loss = 0.00161158
I0302 06:25:42.409304 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00161158 (* 1 = 0.00161158 loss)
I0302 06:25:42.409313 29253 sgd_solver.cpp:106] Iteration 12340, lr = 0.001
I0302 06:26:11.210155 29253 solver.cpp:237] Iteration 12360, loss = 0.00211187
I0302 06:26:11.210187 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00211187 (* 1 = 0.00211187 loss)
I0302 06:26:11.210196 29253 sgd_solver.cpp:106] Iteration 12360, lr = 0.001
I0302 06:26:40.250792 29253 solver.cpp:237] Iteration 12380, loss = 0.00170868
I0302 06:26:40.250823 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00170868 (* 1 = 0.00170868 loss)
I0302 06:26:40.250833 29253 sgd_solver.cpp:106] Iteration 12380, lr = 0.001
I0302 06:27:09.050762 29253 solver.cpp:237] Iteration 12400, loss = 0.00189701
I0302 06:27:09.050798 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00189701 (* 1 = 0.00189701 loss)
I0302 06:27:09.050807 29253 sgd_solver.cpp:106] Iteration 12400, lr = 0.001
I0302 06:27:37.973143 29253 solver.cpp:237] Iteration 12420, loss = 0.00153467
I0302 06:27:37.973176 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00153467 (* 1 = 0.00153467 loss)
I0302 06:27:37.973184 29253 sgd_solver.cpp:106] Iteration 12420, lr = 0.001
I0302 06:28:06.901203 29253 solver.cpp:237] Iteration 12440, loss = 0.00173551
I0302 06:28:06.901237 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00173551 (* 1 = 0.00173551 loss)
I0302 06:28:06.901245 29253 sgd_solver.cpp:106] Iteration 12440, lr = 0.001
I0302 06:28:35.770799 29253 solver.cpp:237] Iteration 12460, loss = 0.00146688
I0302 06:28:35.770831 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00146689 (* 1 = 0.00146689 loss)
I0302 06:28:35.770840 29253 sgd_solver.cpp:106] Iteration 12460, lr = 0.001
I0302 06:29:04.236244 29253 solver.cpp:237] Iteration 12480, loss = 0.00169923
I0302 06:29:04.236277 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00169923 (* 1 = 0.00169923 loss)
I0302 06:29:04.236286 29253 sgd_solver.cpp:106] Iteration 12480, lr = 0.001
I0302 06:29:33.266335 29253 solver.cpp:237] Iteration 12500, loss = 0.00144619
I0302 06:29:33.266368 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00144619 (* 1 = 0.00144619 loss)
I0302 06:29:33.266377 29253 sgd_solver.cpp:106] Iteration 12500, lr = 0.001
I0302 06:30:02.110242 29253 solver.cpp:237] Iteration 12520, loss = 0.00167917
I0302 06:30:02.110273 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00167918 (* 1 = 0.00167918 loss)
I0302 06:30:02.110282 29253 sgd_solver.cpp:106] Iteration 12520, lr = 0.001
I0302 06:30:31.134879 29253 solver.cpp:237] Iteration 12540, loss = 0.00198394
I0302 06:30:31.134912 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00198394 (* 1 = 0.00198394 loss)
I0302 06:30:31.134920 29253 sgd_solver.cpp:106] Iteration 12540, lr = 0.001
I0302 06:30:59.865478 29253 solver.cpp:237] Iteration 12560, loss = 0.00168965
I0302 06:30:59.865507 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00168966 (* 1 = 0.00168966 loss)
I0302 06:30:59.865515 29253 sgd_solver.cpp:106] Iteration 12560, lr = 0.001
I0302 06:31:28.752377 29253 solver.cpp:237] Iteration 12580, loss = 0.0015956
I0302 06:31:28.752408 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0015956 (* 1 = 0.0015956 loss)
I0302 06:31:28.752418 29253 sgd_solver.cpp:106] Iteration 12580, lr = 0.001
I0302 06:31:57.750478 29253 solver.cpp:237] Iteration 12600, loss = 0.00161996
I0302 06:31:57.750507 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00161996 (* 1 = 0.00161996 loss)
I0302 06:31:57.750516 29253 sgd_solver.cpp:106] Iteration 12600, lr = 0.001
I0302 06:32:26.670236 29253 solver.cpp:237] Iteration 12620, loss = 0.00157957
I0302 06:32:26.670267 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00157957 (* 1 = 0.00157957 loss)
I0302 06:32:26.670276 29253 sgd_solver.cpp:106] Iteration 12620, lr = 0.001
I0302 06:32:55.445168 29253 solver.cpp:237] Iteration 12640, loss = 0.00169175
I0302 06:32:55.445201 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00169175 (* 1 = 0.00169175 loss)
I0302 06:32:55.445210 29253 sgd_solver.cpp:106] Iteration 12640, lr = 0.001
I0302 06:33:24.384311 29253 solver.cpp:237] Iteration 12660, loss = 0.0015833
I0302 06:33:24.384343 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0015833 (* 1 = 0.0015833 loss)
I0302 06:33:24.384352 29253 sgd_solver.cpp:106] Iteration 12660, lr = 0.001
I0302 06:33:53.163251 29253 solver.cpp:237] Iteration 12680, loss = 0.001493
I0302 06:33:53.163285 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00149301 (* 1 = 0.00149301 loss)
I0302 06:33:53.163292 29253 sgd_solver.cpp:106] Iteration 12680, lr = 0.001
I0302 06:34:22.115171 29253 solver.cpp:237] Iteration 12700, loss = 0.00150837
I0302 06:34:22.115203 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00150837 (* 1 = 0.00150837 loss)
I0302 06:34:22.115212 29253 sgd_solver.cpp:106] Iteration 12700, lr = 0.001
I0302 06:34:51.032513 29253 solver.cpp:237] Iteration 12720, loss = 0.00129479
I0302 06:34:51.032548 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00129479 (* 1 = 0.00129479 loss)
I0302 06:34:51.032557 29253 sgd_solver.cpp:106] Iteration 12720, lr = 0.001
I0302 06:35:19.983510 29253 solver.cpp:237] Iteration 12740, loss = 0.00171483
I0302 06:35:19.983541 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00171483 (* 1 = 0.00171483 loss)
I0302 06:35:19.983549 29253 sgd_solver.cpp:106] Iteration 12740, lr = 0.001
I0302 06:35:48.908154 29253 solver.cpp:237] Iteration 12760, loss = 0.00159267
I0302 06:35:48.908186 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00159268 (* 1 = 0.00159268 loss)
I0302 06:35:48.908196 29253 sgd_solver.cpp:106] Iteration 12760, lr = 0.001
I0302 06:36:17.618866 29253 solver.cpp:237] Iteration 12780, loss = 0.00199432
I0302 06:36:17.618899 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00199433 (* 1 = 0.00199433 loss)
I0302 06:36:17.618907 29253 sgd_solver.cpp:106] Iteration 12780, lr = 0.001
I0302 06:36:46.665078 29253 solver.cpp:237] Iteration 12800, loss = 0.00168733
I0302 06:36:46.665110 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00168734 (* 1 = 0.00168734 loss)
I0302 06:36:46.665119 29253 sgd_solver.cpp:106] Iteration 12800, lr = 0.001
I0302 06:37:15.606417 29253 solver.cpp:237] Iteration 12820, loss = 0.00135488
I0302 06:37:15.606448 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00135488 (* 1 = 0.00135488 loss)
I0302 06:37:15.606456 29253 sgd_solver.cpp:106] Iteration 12820, lr = 0.001
I0302 06:37:44.224951 29253 solver.cpp:237] Iteration 12840, loss = 0.00168325
I0302 06:37:44.224982 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00168325 (* 1 = 0.00168325 loss)
I0302 06:37:44.224992 29253 sgd_solver.cpp:106] Iteration 12840, lr = 0.001
I0302 06:38:13.403105 29253 solver.cpp:237] Iteration 12860, loss = 0.00160682
I0302 06:38:13.403134 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00160682 (* 1 = 0.00160682 loss)
I0302 06:38:13.403142 29253 sgd_solver.cpp:106] Iteration 12860, lr = 0.001
I0302 06:38:42.215641 29253 solver.cpp:237] Iteration 12880, loss = 0.00169018
I0302 06:38:42.215673 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00169018 (* 1 = 0.00169018 loss)
I0302 06:38:42.215682 29253 sgd_solver.cpp:106] Iteration 12880, lr = 0.001
I0302 06:39:11.212978 29253 solver.cpp:237] Iteration 12900, loss = 0.00181518
I0302 06:39:11.213011 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00181518 (* 1 = 0.00181518 loss)
I0302 06:39:11.213018 29253 sgd_solver.cpp:106] Iteration 12900, lr = 0.001
I0302 06:39:39.792217 29253 solver.cpp:237] Iteration 12920, loss = 0.00168596
I0302 06:39:39.792248 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00168596 (* 1 = 0.00168596 loss)
I0302 06:39:39.792256 29253 sgd_solver.cpp:106] Iteration 12920, lr = 0.001
I0302 06:40:08.798434 29253 solver.cpp:237] Iteration 12940, loss = 0.00156695
I0302 06:40:08.798466 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00156695 (* 1 = 0.00156695 loss)
I0302 06:40:08.798502 29253 sgd_solver.cpp:106] Iteration 12940, lr = 0.001
I0302 06:40:38.066215 29253 solver.cpp:237] Iteration 12960, loss = 0.00171738
I0302 06:40:38.066248 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00171739 (* 1 = 0.00171739 loss)
I0302 06:40:38.066256 29253 sgd_solver.cpp:106] Iteration 12960, lr = 0.001
I0302 06:41:06.943228 29253 solver.cpp:237] Iteration 12980, loss = 0.00143799
I0302 06:41:06.943260 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.001438 (* 1 = 0.001438 loss)
I0302 06:41:06.943269 29253 sgd_solver.cpp:106] Iteration 12980, lr = 0.001
I0302 06:41:35.547917 29253 solver.cpp:237] Iteration 13000, loss = 0.00155098
I0302 06:41:35.547948 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00155099 (* 1 = 0.00155099 loss)
I0302 06:41:35.547957 29253 sgd_solver.cpp:106] Iteration 13000, lr = 0.001
I0302 06:41:41.334048 29253 blocking_queue.cpp:50] Data layer prefetch queue empty
I0302 06:42:04.579028 29253 solver.cpp:237] Iteration 13020, loss = 0.00145796
I0302 06:42:04.579059 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00145796 (* 1 = 0.00145796 loss)
I0302 06:42:04.579067 29253 sgd_solver.cpp:106] Iteration 13020, lr = 0.001
I0302 06:42:33.388870 29253 solver.cpp:237] Iteration 13040, loss = 0.00128616
I0302 06:42:33.388900 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00128616 (* 1 = 0.00128616 loss)
I0302 06:42:33.388908 29253 sgd_solver.cpp:106] Iteration 13040, lr = 0.001
I0302 06:43:02.358515 29253 solver.cpp:237] Iteration 13060, loss = 0.00167077
I0302 06:43:02.358548 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00167077 (* 1 = 0.00167077 loss)
I0302 06:43:02.358557 29253 sgd_solver.cpp:106] Iteration 13060, lr = 0.001
I0302 06:43:31.123044 29253 solver.cpp:237] Iteration 13080, loss = 0.00163335
I0302 06:43:31.123076 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00163335 (* 1 = 0.00163335 loss)
I0302 06:43:31.123085 29253 sgd_solver.cpp:106] Iteration 13080, lr = 0.001
I0302 06:44:00.239063 29253 solver.cpp:237] Iteration 13100, loss = 0.00154104
I0302 06:44:00.239095 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00154104 (* 1 = 0.00154104 loss)
I0302 06:44:00.239104 29253 sgd_solver.cpp:106] Iteration 13100, lr = 0.001
I0302 06:44:28.899317 29253 solver.cpp:237] Iteration 13120, loss = 0.00169681
I0302 06:44:28.899348 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00169681 (* 1 = 0.00169681 loss)
I0302 06:44:28.899356 29253 sgd_solver.cpp:106] Iteration 13120, lr = 0.001
I0302 06:44:57.693275 29253 solver.cpp:237] Iteration 13140, loss = 0.00187234
I0302 06:44:57.693307 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00187235 (* 1 = 0.00187235 loss)
I0302 06:44:57.693316 29253 sgd_solver.cpp:106] Iteration 13140, lr = 0.001
I0302 06:45:26.620580 29253 solver.cpp:237] Iteration 13160, loss = 0.0019513
I0302 06:45:26.620612 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0019513 (* 1 = 0.0019513 loss)
I0302 06:45:26.620621 29253 sgd_solver.cpp:106] Iteration 13160, lr = 0.001
I0302 06:45:55.510208 29253 solver.cpp:237] Iteration 13180, loss = 0.00156161
I0302 06:45:55.510239 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00156161 (* 1 = 0.00156161 loss)
I0302 06:45:55.510248 29253 sgd_solver.cpp:106] Iteration 13180, lr = 0.001
I0302 06:46:24.496247 29253 solver.cpp:237] Iteration 13200, loss = 0.00157312
I0302 06:46:24.496279 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00157312 (* 1 = 0.00157312 loss)
I0302 06:46:24.496289 29253 sgd_solver.cpp:106] Iteration 13200, lr = 0.001
I0302 06:46:53.217362 29253 solver.cpp:237] Iteration 13220, loss = 0.00155252
I0302 06:46:53.217396 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00155252 (* 1 = 0.00155252 loss)
I0302 06:46:53.217403 29253 sgd_solver.cpp:106] Iteration 13220, lr = 0.001
I0302 06:47:22.188083 29253 solver.cpp:237] Iteration 13240, loss = 0.00172592
I0302 06:47:22.188115 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00172593 (* 1 = 0.00172593 loss)
I0302 06:47:22.188124 29253 sgd_solver.cpp:106] Iteration 13240, lr = 0.001
I0302 06:47:51.448942 29253 solver.cpp:237] Iteration 13260, loss = 0.00285874
I0302 06:47:51.448971 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00285874 (* 1 = 0.00285874 loss)
I0302 06:47:51.448978 29253 sgd_solver.cpp:106] Iteration 13260, lr = 0.001
I0302 06:48:20.385993 29253 solver.cpp:237] Iteration 13280, loss = 0.0016988
I0302 06:48:20.386025 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00169881 (* 1 = 0.00169881 loss)
I0302 06:48:20.386034 29253 sgd_solver.cpp:106] Iteration 13280, lr = 0.001
I0302 06:48:49.299371 29253 solver.cpp:237] Iteration 13300, loss = 0.0016917
I0302 06:48:49.299402 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00169171 (* 1 = 0.00169171 loss)
I0302 06:48:49.299412 29253 sgd_solver.cpp:106] Iteration 13300, lr = 0.001
I0302 06:49:18.222961 29253 solver.cpp:237] Iteration 13320, loss = 0.00200286
I0302 06:49:18.222995 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00200287 (* 1 = 0.00200287 loss)
I0302 06:49:18.223002 29253 sgd_solver.cpp:106] Iteration 13320, lr = 0.001
I0302 06:49:47.100778 29253 solver.cpp:237] Iteration 13340, loss = 0.00178298
I0302 06:49:47.100811 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00178298 (* 1 = 0.00178298 loss)
I0302 06:49:47.100821 29253 sgd_solver.cpp:106] Iteration 13340, lr = 0.001
I0302 06:50:15.862810 29253 solver.cpp:237] Iteration 13360, loss = 0.00177729
I0302 06:50:15.862843 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00177729 (* 1 = 0.00177729 loss)
I0302 06:50:15.862851 29253 sgd_solver.cpp:106] Iteration 13360, lr = 0.001
I0302 06:50:45.134919 29253 solver.cpp:237] Iteration 13380, loss = 0.00147577
I0302 06:50:45.134950 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00147578 (* 1 = 0.00147578 loss)
I0302 06:50:45.134959 29253 sgd_solver.cpp:106] Iteration 13380, lr = 0.001
I0302 06:51:14.138056 29253 solver.cpp:237] Iteration 13400, loss = 0.00193212
I0302 06:51:14.138087 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00193213 (* 1 = 0.00193213 loss)
I0302 06:51:14.138095 29253 sgd_solver.cpp:106] Iteration 13400, lr = 0.001
I0302 06:51:43.033278 29253 solver.cpp:237] Iteration 13420, loss = 0.00191997
I0302 06:51:43.033310 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00191998 (* 1 = 0.00191998 loss)
I0302 06:51:43.033319 29253 sgd_solver.cpp:106] Iteration 13420, lr = 0.001
I0302 06:52:11.989096 29253 solver.cpp:237] Iteration 13440, loss = 0.00185109
I0302 06:52:11.989130 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00185109 (* 1 = 0.00185109 loss)
I0302 06:52:11.989138 29253 sgd_solver.cpp:106] Iteration 13440, lr = 0.001
I0302 06:52:41.109014 29253 solver.cpp:237] Iteration 13460, loss = 0.00144166
I0302 06:52:41.109046 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00144166 (* 1 = 0.00144166 loss)
I0302 06:52:41.109055 29253 sgd_solver.cpp:106] Iteration 13460, lr = 0.001
I0302 06:53:10.094884 29253 solver.cpp:237] Iteration 13480, loss = 0.00154616
I0302 06:53:10.094915 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00154616 (* 1 = 0.00154616 loss)
I0302 06:53:10.094923 29253 sgd_solver.cpp:106] Iteration 13480, lr = 0.001
I0302 06:53:38.931787 29253 solver.cpp:237] Iteration 13500, loss = 0.00236549
I0302 06:53:38.931820 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00236549 (* 1 = 0.00236549 loss)
I0302 06:53:38.931829 29253 sgd_solver.cpp:106] Iteration 13500, lr = 0.001
I0302 06:54:07.859390 29253 solver.cpp:237] Iteration 13520, loss = 0.00222018
I0302 06:54:07.859422 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00222019 (* 1 = 0.00222019 loss)
I0302 06:54:07.859431 29253 sgd_solver.cpp:106] Iteration 13520, lr = 0.001
I0302 06:54:36.831034 29253 solver.cpp:237] Iteration 13540, loss = 0.00165815
I0302 06:54:36.831065 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00165815 (* 1 = 0.00165815 loss)
I0302 06:54:36.831074 29253 sgd_solver.cpp:106] Iteration 13540, lr = 0.001
I0302 06:55:05.676928 29253 solver.cpp:237] Iteration 13560, loss = 0.00137319
I0302 06:55:05.676959 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00137319 (* 1 = 0.00137319 loss)
I0302 06:55:05.676967 29253 sgd_solver.cpp:106] Iteration 13560, lr = 0.001
I0302 06:55:34.578579 29253 solver.cpp:237] Iteration 13580, loss = 0.00167798
I0302 06:55:34.578613 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00167798 (* 1 = 0.00167798 loss)
I0302 06:55:34.578620 29253 sgd_solver.cpp:106] Iteration 13580, lr = 0.001
I0302 06:56:03.584339 29253 solver.cpp:237] Iteration 13600, loss = 0.00190896
I0302 06:56:03.584369 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00190897 (* 1 = 0.00190897 loss)
I0302 06:56:03.584378 29253 sgd_solver.cpp:106] Iteration 13600, lr = 0.001
I0302 06:56:32.591008 29253 solver.cpp:237] Iteration 13620, loss = 0.00183639
I0302 06:56:32.591040 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00183639 (* 1 = 0.00183639 loss)
I0302 06:56:32.591048 29253 sgd_solver.cpp:106] Iteration 13620, lr = 0.001
I0302 06:57:01.226878 29253 solver.cpp:237] Iteration 13640, loss = 0.00172128
I0302 06:57:01.226910 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00172128 (* 1 = 0.00172128 loss)
I0302 06:57:01.226919 29253 sgd_solver.cpp:106] Iteration 13640, lr = 0.001
I0302 06:57:30.057587 29253 solver.cpp:237] Iteration 13660, loss = 0.00189719
I0302 06:57:30.057621 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00189719 (* 1 = 0.00189719 loss)
I0302 06:57:30.057629 29253 sgd_solver.cpp:106] Iteration 13660, lr = 0.001
I0302 06:57:58.889770 29253 solver.cpp:237] Iteration 13680, loss = 0.00176534
I0302 06:57:58.889803 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00176534 (* 1 = 0.00176534 loss)
I0302 06:57:58.889813 29253 sgd_solver.cpp:106] Iteration 13680, lr = 0.001
I0302 06:58:27.618173 29253 solver.cpp:237] Iteration 13700, loss = 0.0019302
I0302 06:58:27.618206 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00193021 (* 1 = 0.00193021 loss)
I0302 06:58:27.618214 29253 sgd_solver.cpp:106] Iteration 13700, lr = 0.001
I0302 06:58:56.842216 29253 solver.cpp:237] Iteration 13720, loss = 0.00161746
I0302 06:58:56.842247 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00161746 (* 1 = 0.00161746 loss)
I0302 06:58:56.842255 29253 sgd_solver.cpp:106] Iteration 13720, lr = 0.001
I0302 06:59:25.802814 29253 solver.cpp:237] Iteration 13740, loss = 0.00221418
I0302 06:59:25.802846 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00221419 (* 1 = 0.00221419 loss)
I0302 06:59:25.802855 29253 sgd_solver.cpp:106] Iteration 13740, lr = 0.001
I0302 06:59:54.632057 29253 solver.cpp:237] Iteration 13760, loss = 0.00165523
I0302 06:59:54.632089 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00165523 (* 1 = 0.00165523 loss)
I0302 06:59:54.632098 29253 sgd_solver.cpp:106] Iteration 13760, lr = 0.001
I0302 07:00:23.574640 29253 solver.cpp:237] Iteration 13780, loss = 0.00212696
I0302 07:00:23.574671 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00212696 (* 1 = 0.00212696 loss)
I0302 07:00:23.574681 29253 sgd_solver.cpp:106] Iteration 13780, lr = 0.001
I0302 07:00:52.514962 29253 solver.cpp:237] Iteration 13800, loss = 0.0014859
I0302 07:00:52.514996 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00148591 (* 1 = 0.00148591 loss)
I0302 07:00:52.515003 29253 sgd_solver.cpp:106] Iteration 13800, lr = 0.001
I0302 07:01:21.320690 29253 solver.cpp:237] Iteration 13820, loss = 0.00158333
I0302 07:01:21.320722 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00158333 (* 1 = 0.00158333 loss)
I0302 07:01:21.320731 29253 sgd_solver.cpp:106] Iteration 13820, lr = 0.001
I0302 07:01:50.378000 29253 solver.cpp:237] Iteration 13840, loss = 0.00142488
I0302 07:01:50.378031 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00142489 (* 1 = 0.00142489 loss)
I0302 07:01:50.378041 29253 sgd_solver.cpp:106] Iteration 13840, lr = 0.001
I0302 07:02:19.509315 29253 solver.cpp:237] Iteration 13860, loss = 0.0018684
I0302 07:02:19.509344 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00186841 (* 1 = 0.00186841 loss)
I0302 07:02:19.509353 29253 sgd_solver.cpp:106] Iteration 13860, lr = 0.001
I0302 07:02:48.518160 29253 solver.cpp:237] Iteration 13880, loss = 0.00154554
I0302 07:02:48.518192 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00154555 (* 1 = 0.00154555 loss)
I0302 07:02:48.518200 29253 sgd_solver.cpp:106] Iteration 13880, lr = 0.001
I0302 07:03:17.482055 29253 solver.cpp:237] Iteration 13900, loss = 0.0018448
I0302 07:03:17.482086 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00184481 (* 1 = 0.00184481 loss)
I0302 07:03:17.482095 29253 sgd_solver.cpp:106] Iteration 13900, lr = 0.001
I0302 07:03:46.724313 29253 solver.cpp:237] Iteration 13920, loss = 0.00162984
I0302 07:03:46.724344 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00162985 (* 1 = 0.00162985 loss)
I0302 07:03:46.724352 29253 sgd_solver.cpp:106] Iteration 13920, lr = 0.001
I0302 07:04:15.788990 29253 solver.cpp:237] Iteration 13940, loss = 0.00190946
I0302 07:04:15.789021 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00190946 (* 1 = 0.00190946 loss)
I0302 07:04:15.789029 29253 sgd_solver.cpp:106] Iteration 13940, lr = 0.001
I0302 07:04:44.631319 29253 solver.cpp:237] Iteration 13960, loss = 0.00177411
I0302 07:04:44.631350 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00177412 (* 1 = 0.00177412 loss)
I0302 07:04:44.631357 29253 sgd_solver.cpp:106] Iteration 13960, lr = 0.001
I0302 07:05:13.522399 29253 solver.cpp:237] Iteration 13980, loss = 0.00170428
I0302 07:05:13.522430 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00170428 (* 1 = 0.00170428 loss)
I0302 07:05:13.522439 29253 sgd_solver.cpp:106] Iteration 13980, lr = 0.001
I0302 07:05:42.332623 29253 solver.cpp:237] Iteration 14000, loss = 0.00163889
I0302 07:05:42.332655 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00163889 (* 1 = 0.00163889 loss)
I0302 07:05:42.332664 29253 sgd_solver.cpp:106] Iteration 14000, lr = 0.001
I0302 07:05:48.064795 29253 blocking_queue.cpp:50] Data layer prefetch queue empty
I0302 07:06:11.133510 29253 solver.cpp:237] Iteration 14020, loss = 0.00147313
I0302 07:06:11.133543 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00147313 (* 1 = 0.00147313 loss)
I0302 07:06:11.133551 29253 sgd_solver.cpp:106] Iteration 14020, lr = 0.001
I0302 07:06:40.115109 29253 solver.cpp:237] Iteration 14040, loss = 0.00224757
I0302 07:06:40.115142 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00224757 (* 1 = 0.00224757 loss)
I0302 07:06:40.115151 29253 sgd_solver.cpp:106] Iteration 14040, lr = 0.001
I0302 07:07:09.044036 29253 solver.cpp:237] Iteration 14060, loss = 0.00166678
I0302 07:07:09.044069 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00166679 (* 1 = 0.00166679 loss)
I0302 07:07:09.044077 29253 sgd_solver.cpp:106] Iteration 14060, lr = 0.001
I0302 07:07:37.895540 29253 solver.cpp:237] Iteration 14080, loss = 0.00192237
I0302 07:07:37.895573 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00192237 (* 1 = 0.00192237 loss)
I0302 07:07:37.895582 29253 sgd_solver.cpp:106] Iteration 14080, lr = 0.001
I0302 07:08:06.776006 29253 solver.cpp:237] Iteration 14100, loss = 0.00192987
I0302 07:08:06.776037 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00192988 (* 1 = 0.00192988 loss)
I0302 07:08:06.776046 29253 sgd_solver.cpp:106] Iteration 14100, lr = 0.001
I0302 07:08:35.776087 29253 solver.cpp:237] Iteration 14120, loss = 0.00166692
I0302 07:08:35.776119 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00166692 (* 1 = 0.00166692 loss)
I0302 07:08:35.776127 29253 sgd_solver.cpp:106] Iteration 14120, lr = 0.001
I0302 07:09:04.718369 29253 solver.cpp:237] Iteration 14140, loss = 0.00180778
I0302 07:09:04.718400 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00180778 (* 1 = 0.00180778 loss)
I0302 07:09:04.718410 29253 sgd_solver.cpp:106] Iteration 14140, lr = 0.001
I0302 07:09:33.921630 29253 solver.cpp:237] Iteration 14160, loss = 0.0016167
I0302 07:09:33.921663 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00161671 (* 1 = 0.00161671 loss)
I0302 07:09:33.921670 29253 sgd_solver.cpp:106] Iteration 14160, lr = 0.001
I0302 07:10:02.856343 29253 solver.cpp:237] Iteration 14180, loss = 0.00146632
I0302 07:10:02.856374 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00146633 (* 1 = 0.00146633 loss)
I0302 07:10:02.856384 29253 sgd_solver.cpp:106] Iteration 14180, lr = 0.001
I0302 07:10:31.724594 29253 solver.cpp:237] Iteration 14200, loss = 0.00167211
I0302 07:10:31.724627 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00167212 (* 1 = 0.00167212 loss)
I0302 07:10:31.724635 29253 sgd_solver.cpp:106] Iteration 14200, lr = 0.001
I0302 07:11:00.748539 29253 solver.cpp:237] Iteration 14220, loss = 0.00129999
I0302 07:11:00.748572 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0013 (* 1 = 0.0013 loss)
I0302 07:11:00.748581 29253 sgd_solver.cpp:106] Iteration 14220, lr = 0.001
I0302 07:11:29.736588 29253 solver.cpp:237] Iteration 14240, loss = 0.00163471
I0302 07:11:29.736620 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00163471 (* 1 = 0.00163471 loss)
I0302 07:11:29.736629 29253 sgd_solver.cpp:106] Iteration 14240, lr = 0.001
I0302 07:11:58.635490 29253 solver.cpp:237] Iteration 14260, loss = 0.00180332
I0302 07:11:58.635522 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00180333 (* 1 = 0.00180333 loss)
I0302 07:11:58.635535 29253 sgd_solver.cpp:106] Iteration 14260, lr = 0.001
I0302 07:12:27.540485 29253 solver.cpp:237] Iteration 14280, loss = 0.00180761
I0302 07:12:27.540515 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00180762 (* 1 = 0.00180762 loss)
I0302 07:12:27.540524 29253 sgd_solver.cpp:106] Iteration 14280, lr = 0.001
I0302 07:12:56.561089 29253 solver.cpp:237] Iteration 14300, loss = 0.00163881
I0302 07:12:56.561120 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00163881 (* 1 = 0.00163881 loss)
I0302 07:12:56.561127 29253 sgd_solver.cpp:106] Iteration 14300, lr = 0.001
I0302 07:13:25.350323 29253 solver.cpp:237] Iteration 14320, loss = 0.00188221
I0302 07:13:25.350358 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00188221 (* 1 = 0.00188221 loss)
I0302 07:13:25.350366 29253 sgd_solver.cpp:106] Iteration 14320, lr = 0.001
I0302 07:13:54.270978 29253 solver.cpp:237] Iteration 14340, loss = 0.00192544
I0302 07:13:54.271011 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00192545 (* 1 = 0.00192545 loss)
I0302 07:13:54.271020 29253 sgd_solver.cpp:106] Iteration 14340, lr = 0.001
I0302 07:14:23.298995 29253 solver.cpp:237] Iteration 14360, loss = 0.00159839
I0302 07:14:23.299027 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00159839 (* 1 = 0.00159839 loss)
I0302 07:14:23.299036 29253 sgd_solver.cpp:106] Iteration 14360, lr = 0.001
I0302 07:14:52.266589 29253 solver.cpp:237] Iteration 14380, loss = 0.00161181
I0302 07:14:52.266621 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00161182 (* 1 = 0.00161182 loss)
I0302 07:14:52.266633 29253 sgd_solver.cpp:106] Iteration 14380, lr = 0.001
I0302 07:15:21.173679 29253 solver.cpp:237] Iteration 14400, loss = 0.00160531
I0302 07:15:21.173712 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00160532 (* 1 = 0.00160532 loss)
I0302 07:15:21.173720 29253 sgd_solver.cpp:106] Iteration 14400, lr = 0.001
I0302 07:15:49.929787 29253 solver.cpp:237] Iteration 14420, loss = 0.00198669
I0302 07:15:49.929819 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00198669 (* 1 = 0.00198669 loss)
I0302 07:15:49.929857 29253 sgd_solver.cpp:106] Iteration 14420, lr = 0.001
I0302 07:16:19.128947 29253 solver.cpp:237] Iteration 14440, loss = 0.00194473
I0302 07:16:19.128981 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00194474 (* 1 = 0.00194474 loss)
I0302 07:16:19.128989 29253 sgd_solver.cpp:106] Iteration 14440, lr = 0.001
I0302 07:16:48.030278 29253 solver.cpp:237] Iteration 14460, loss = 0.00217468
I0302 07:16:48.030309 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00217469 (* 1 = 0.00217469 loss)
I0302 07:16:48.030318 29253 sgd_solver.cpp:106] Iteration 14460, lr = 0.001
I0302 07:17:16.994410 29253 solver.cpp:237] Iteration 14480, loss = 0.00172352
I0302 07:17:16.994441 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00172352 (* 1 = 0.00172352 loss)
I0302 07:17:16.994451 29253 sgd_solver.cpp:106] Iteration 14480, lr = 0.001
I0302 07:17:45.906548 29253 solver.cpp:237] Iteration 14500, loss = 0.00156058
I0302 07:17:45.906579 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00156058 (* 1 = 0.00156058 loss)
I0302 07:17:45.906589 29253 sgd_solver.cpp:106] Iteration 14500, lr = 0.001
I0302 07:18:14.856909 29253 solver.cpp:237] Iteration 14520, loss = 0.00171874
I0302 07:18:14.856940 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00171874 (* 1 = 0.00171874 loss)
I0302 07:18:14.856950 29253 sgd_solver.cpp:106] Iteration 14520, lr = 0.001
I0302 07:18:43.976125 29253 solver.cpp:237] Iteration 14540, loss = 0.00154198
I0302 07:18:43.976156 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00154198 (* 1 = 0.00154198 loss)
I0302 07:18:43.976164 29253 sgd_solver.cpp:106] Iteration 14540, lr = 0.001
I0302 07:19:12.899092 29253 solver.cpp:237] Iteration 14560, loss = 0.00188275
I0302 07:19:12.899124 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00188275 (* 1 = 0.00188275 loss)
I0302 07:19:12.899133 29253 sgd_solver.cpp:106] Iteration 14560, lr = 0.001
I0302 07:19:41.841975 29253 solver.cpp:237] Iteration 14580, loss = 0.00144488
I0302 07:19:41.842007 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00144488 (* 1 = 0.00144488 loss)
I0302 07:19:41.842016 29253 sgd_solver.cpp:106] Iteration 14580, lr = 0.001
I0302 07:20:10.717234 29253 solver.cpp:237] Iteration 14600, loss = 0.00223387
I0302 07:20:10.717265 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00223387 (* 1 = 0.00223387 loss)
I0302 07:20:10.717273 29253 sgd_solver.cpp:106] Iteration 14600, lr = 0.001
I0302 07:20:39.663213 29253 solver.cpp:237] Iteration 14620, loss = 0.00236668
I0302 07:20:39.663245 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00236668 (* 1 = 0.00236668 loss)
I0302 07:20:39.663254 29253 sgd_solver.cpp:106] Iteration 14620, lr = 0.001
I0302 07:21:08.598685 29253 solver.cpp:237] Iteration 14640, loss = 0.00171338
I0302 07:21:08.598718 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00171338 (* 1 = 0.00171338 loss)
I0302 07:21:08.598727 29253 sgd_solver.cpp:106] Iteration 14640, lr = 0.001
I0302 07:21:37.609231 29253 solver.cpp:237] Iteration 14660, loss = 0.0022257
I0302 07:21:37.609263 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00222571 (* 1 = 0.00222571 loss)
I0302 07:21:37.609272 29253 sgd_solver.cpp:106] Iteration 14660, lr = 0.001
I0302 07:22:06.513329 29253 solver.cpp:237] Iteration 14680, loss = 0.00167627
I0302 07:22:06.513361 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00167627 (* 1 = 0.00167627 loss)
I0302 07:22:06.513370 29253 sgd_solver.cpp:106] Iteration 14680, lr = 0.001
I0302 07:22:35.488319 29253 solver.cpp:237] Iteration 14700, loss = 0.00173046
I0302 07:22:35.488351 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00173046 (* 1 = 0.00173046 loss)
I0302 07:22:35.488359 29253 sgd_solver.cpp:106] Iteration 14700, lr = 0.001
I0302 07:23:04.346657 29253 solver.cpp:237] Iteration 14720, loss = 0.00198375
I0302 07:23:04.346689 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00198375 (* 1 = 0.00198375 loss)
I0302 07:23:04.346698 29253 sgd_solver.cpp:106] Iteration 14720, lr = 0.001
I0302 07:23:33.130700 29253 solver.cpp:237] Iteration 14740, loss = 0.00170296
I0302 07:23:33.130734 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00170296 (* 1 = 0.00170296 loss)
I0302 07:23:33.130743 29253 sgd_solver.cpp:106] Iteration 14740, lr = 0.001
I0302 07:24:02.160850 29253 solver.cpp:237] Iteration 14760, loss = 0.00190179
I0302 07:24:02.160881 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00190179 (* 1 = 0.00190179 loss)
I0302 07:24:02.160889 29253 sgd_solver.cpp:106] Iteration 14760, lr = 0.001
I0302 07:24:31.115633 29253 solver.cpp:237] Iteration 14780, loss = 0.00199827
I0302 07:24:31.115664 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00199827 (* 1 = 0.00199827 loss)
I0302 07:24:31.115674 29253 sgd_solver.cpp:106] Iteration 14780, lr = 0.001
I0302 07:25:00.000084 29253 solver.cpp:237] Iteration 14800, loss = 0.00167505
I0302 07:25:00.000118 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00167505 (* 1 = 0.00167505 loss)
I0302 07:25:00.000126 29253 sgd_solver.cpp:106] Iteration 14800, lr = 0.001
I0302 07:25:28.874569 29253 solver.cpp:237] Iteration 14820, loss = 0.00192775
I0302 07:25:28.874603 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00192776 (* 1 = 0.00192776 loss)
I0302 07:25:28.874611 29253 sgd_solver.cpp:106] Iteration 14820, lr = 0.001
I0302 07:25:57.841845 29253 solver.cpp:237] Iteration 14840, loss = 0.00170627
I0302 07:25:57.841877 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00170627 (* 1 = 0.00170627 loss)
I0302 07:25:57.841886 29253 sgd_solver.cpp:106] Iteration 14840, lr = 0.001
I0302 07:26:26.708467 29253 solver.cpp:237] Iteration 14860, loss = 0.0026678
I0302 07:26:26.708501 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0026678 (* 1 = 0.0026678 loss)
I0302 07:26:26.708510 29253 sgd_solver.cpp:106] Iteration 14860, lr = 0.001
I0302 07:26:55.701926 29253 solver.cpp:237] Iteration 14880, loss = 0.0017262
I0302 07:26:55.701959 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0017262 (* 1 = 0.0017262 loss)
I0302 07:26:55.701968 29253 sgd_solver.cpp:106] Iteration 14880, lr = 0.001
I0302 07:27:24.418278 29253 solver.cpp:237] Iteration 14900, loss = 0.00146306
I0302 07:27:24.418310 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00146306 (* 1 = 0.00146306 loss)
I0302 07:27:24.418319 29253 sgd_solver.cpp:106] Iteration 14900, lr = 0.001
I0302 07:27:53.353577 29253 solver.cpp:237] Iteration 14920, loss = 0.00158694
I0302 07:27:53.353610 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00158694 (* 1 = 0.00158694 loss)
I0302 07:27:53.353618 29253 sgd_solver.cpp:106] Iteration 14920, lr = 0.001
I0302 07:28:22.263950 29253 solver.cpp:237] Iteration 14940, loss = 0.0015279
I0302 07:28:22.263983 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0015279 (* 1 = 0.0015279 loss)
I0302 07:28:22.263990 29253 sgd_solver.cpp:106] Iteration 14940, lr = 0.001
I0302 07:28:51.236238 29253 solver.cpp:237] Iteration 14960, loss = 0.00158433
I0302 07:28:51.236269 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00158433 (* 1 = 0.00158433 loss)
I0302 07:28:51.236279 29253 sgd_solver.cpp:106] Iteration 14960, lr = 0.001
I0302 07:29:19.993247 29253 solver.cpp:237] Iteration 14980, loss = 0.00140361
I0302 07:29:19.993275 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00140361 (* 1 = 0.00140361 loss)
I0302 07:29:19.993283 29253 sgd_solver.cpp:106] Iteration 14980, lr = 0.001
I0302 07:29:47.480000 29253 solver.cpp:459] Snapshotting to binary proto file /nfs.yoda/xiaolonw/fast_rcnn/models_sunrgbd/pre_cls_1fc_scratch/model__iter_15000.caffemodel
I0302 07:31:12.282984 29253 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /nfs.yoda/xiaolonw/fast_rcnn/models_sunrgbd/pre_cls_1fc_scratch/model__iter_15000.solverstate
I0302 07:31:12.804996 29253 solver.cpp:237] Iteration 15000, loss = 0.00133655
I0302 07:31:12.805027 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00133656 (* 1 = 0.00133656 loss)
I0302 07:31:12.805037 29253 sgd_solver.cpp:106] Iteration 15000, lr = 0.001
I0302 07:31:20.000988 29253 blocking_queue.cpp:50] Data layer prefetch queue empty
I0302 07:31:38.730816 29253 solver.cpp:237] Iteration 15020, loss = 0.00262067
I0302 07:31:38.730850 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00262067 (* 1 = 0.00262067 loss)
I0302 07:31:38.730859 29253 sgd_solver.cpp:106] Iteration 15020, lr = 0.001
I0302 07:32:07.713340 29253 solver.cpp:237] Iteration 15040, loss = 0.00155517
I0302 07:32:07.713371 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00155517 (* 1 = 0.00155517 loss)
I0302 07:32:07.713379 29253 sgd_solver.cpp:106] Iteration 15040, lr = 0.001
I0302 07:32:36.712262 29253 solver.cpp:237] Iteration 15060, loss = 0.00162072
I0302 07:32:36.712294 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00162072 (* 1 = 0.00162072 loss)
I0302 07:32:36.712303 29253 sgd_solver.cpp:106] Iteration 15060, lr = 0.001
I0302 07:33:05.598167 29253 solver.cpp:237] Iteration 15080, loss = 0.00166244
I0302 07:33:05.598201 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00166245 (* 1 = 0.00166245 loss)
I0302 07:33:05.598209 29253 sgd_solver.cpp:106] Iteration 15080, lr = 0.001
I0302 07:33:34.569098 29253 solver.cpp:237] Iteration 15100, loss = 0.00167519
I0302 07:33:34.569128 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00167519 (* 1 = 0.00167519 loss)
I0302 07:33:34.569138 29253 sgd_solver.cpp:106] Iteration 15100, lr = 0.001
I0302 07:34:03.663296 29253 solver.cpp:237] Iteration 15120, loss = 0.00169863
I0302 07:34:03.663329 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00169863 (* 1 = 0.00169863 loss)
I0302 07:34:03.663338 29253 sgd_solver.cpp:106] Iteration 15120, lr = 0.001
I0302 07:34:32.562538 29253 solver.cpp:237] Iteration 15140, loss = 0.00160775
I0302 07:34:32.562572 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00160776 (* 1 = 0.00160776 loss)
I0302 07:34:32.562607 29253 sgd_solver.cpp:106] Iteration 15140, lr = 0.001
I0302 07:35:01.531687 29253 solver.cpp:237] Iteration 15160, loss = 0.00143902
I0302 07:35:01.531718 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00143903 (* 1 = 0.00143903 loss)
I0302 07:35:01.531726 29253 sgd_solver.cpp:106] Iteration 15160, lr = 0.001
I0302 07:35:30.261972 29253 solver.cpp:237] Iteration 15180, loss = 0.00127637
I0302 07:35:30.262004 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00127637 (* 1 = 0.00127637 loss)
I0302 07:35:30.262013 29253 sgd_solver.cpp:106] Iteration 15180, lr = 0.001
I0302 07:35:59.266728 29253 solver.cpp:237] Iteration 15200, loss = 0.00175979
I0302 07:35:59.266760 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00175979 (* 1 = 0.00175979 loss)
I0302 07:35:59.266769 29253 sgd_solver.cpp:106] Iteration 15200, lr = 0.001
I0302 07:36:28.175158 29253 solver.cpp:237] Iteration 15220, loss = 0.00134097
I0302 07:36:28.175191 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00134097 (* 1 = 0.00134097 loss)
I0302 07:36:28.175200 29253 sgd_solver.cpp:106] Iteration 15220, lr = 0.001
I0302 07:36:56.991034 29253 solver.cpp:237] Iteration 15240, loss = 0.00316347
I0302 07:36:56.991066 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00316347 (* 1 = 0.00316347 loss)
I0302 07:36:56.991075 29253 sgd_solver.cpp:106] Iteration 15240, lr = 0.001
I0302 07:37:26.034574 29253 solver.cpp:237] Iteration 15260, loss = 0.00169354
I0302 07:37:26.034607 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00169354 (* 1 = 0.00169354 loss)
I0302 07:37:26.034615 29253 sgd_solver.cpp:106] Iteration 15260, lr = 0.001
I0302 07:37:55.334573 29253 solver.cpp:237] Iteration 15280, loss = 0.00157711
I0302 07:37:55.334605 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00157711 (* 1 = 0.00157711 loss)
I0302 07:37:55.334614 29253 sgd_solver.cpp:106] Iteration 15280, lr = 0.001
I0302 07:38:24.418118 29253 solver.cpp:237] Iteration 15300, loss = 0.00174118
I0302 07:38:24.418149 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00174119 (* 1 = 0.00174119 loss)
I0302 07:38:24.418159 29253 sgd_solver.cpp:106] Iteration 15300, lr = 0.001
I0302 07:38:53.233594 29253 solver.cpp:237] Iteration 15320, loss = 0.00190496
I0302 07:38:53.233726 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00190497 (* 1 = 0.00190497 loss)
I0302 07:38:53.233734 29253 sgd_solver.cpp:106] Iteration 15320, lr = 0.001
I0302 07:39:22.325578 29253 solver.cpp:237] Iteration 15340, loss = 0.00157386
I0302 07:39:22.325610 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00157387 (* 1 = 0.00157387 loss)
I0302 07:39:22.325619 29253 sgd_solver.cpp:106] Iteration 15340, lr = 0.001
I0302 07:39:50.972605 29253 solver.cpp:237] Iteration 15360, loss = 0.00195719
I0302 07:39:50.972638 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00195719 (* 1 = 0.00195719 loss)
I0302 07:39:50.972647 29253 sgd_solver.cpp:106] Iteration 15360, lr = 0.001
I0302 07:40:19.711011 29253 solver.cpp:237] Iteration 15380, loss = 0.00139774
I0302 07:40:19.711045 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00139775 (* 1 = 0.00139775 loss)
I0302 07:40:19.711052 29253 sgd_solver.cpp:106] Iteration 15380, lr = 0.001
I0302 07:40:48.628558 29253 solver.cpp:237] Iteration 15400, loss = 0.00132805
I0302 07:40:48.628592 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00132806 (* 1 = 0.00132806 loss)
I0302 07:40:48.628600 29253 sgd_solver.cpp:106] Iteration 15400, lr = 0.001
I0302 07:41:17.541082 29253 solver.cpp:237] Iteration 15420, loss = 0.00159357
I0302 07:41:17.541115 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00159358 (* 1 = 0.00159358 loss)
I0302 07:41:17.541123 29253 sgd_solver.cpp:106] Iteration 15420, lr = 0.001
I0302 07:41:46.513103 29253 solver.cpp:237] Iteration 15440, loss = 0.00257509
I0302 07:41:46.513134 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0025751 (* 1 = 0.0025751 loss)
I0302 07:41:46.513144 29253 sgd_solver.cpp:106] Iteration 15440, lr = 0.001
I0302 07:42:15.303462 29253 solver.cpp:237] Iteration 15460, loss = 0.00178455
I0302 07:42:15.303493 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00178455 (* 1 = 0.00178455 loss)
I0302 07:42:15.303501 29253 sgd_solver.cpp:106] Iteration 15460, lr = 0.001
I0302 07:42:44.239661 29253 solver.cpp:237] Iteration 15480, loss = 0.00143747
I0302 07:42:44.239692 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00143747 (* 1 = 0.00143747 loss)
I0302 07:42:44.239701 29253 sgd_solver.cpp:106] Iteration 15480, lr = 0.001
I0302 07:43:13.593466 29253 solver.cpp:237] Iteration 15500, loss = 0.001673
I0302 07:43:13.593499 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00167301 (* 1 = 0.00167301 loss)
I0302 07:43:13.593508 29253 sgd_solver.cpp:106] Iteration 15500, lr = 0.001
I0302 07:43:42.158252 29253 solver.cpp:237] Iteration 15520, loss = 0.00142359
I0302 07:43:42.158284 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00142359 (* 1 = 0.00142359 loss)
I0302 07:43:42.158293 29253 sgd_solver.cpp:106] Iteration 15520, lr = 0.001
I0302 07:44:11.216487 29253 solver.cpp:237] Iteration 15540, loss = 0.00161604
I0302 07:44:11.216521 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00161605 (* 1 = 0.00161605 loss)
I0302 07:44:11.216531 29253 sgd_solver.cpp:106] Iteration 15540, lr = 0.001
I0302 07:44:39.845155 29253 solver.cpp:237] Iteration 15560, loss = 0.00140732
I0302 07:44:39.845188 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00140732 (* 1 = 0.00140732 loss)
I0302 07:44:39.845196 29253 sgd_solver.cpp:106] Iteration 15560, lr = 0.001
I0302 07:45:09.093332 29253 solver.cpp:237] Iteration 15580, loss = 0.00161463
I0302 07:45:09.093363 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00161464 (* 1 = 0.00161464 loss)
I0302 07:45:09.093372 29253 sgd_solver.cpp:106] Iteration 15580, lr = 0.001
I0302 07:45:38.236182 29253 solver.cpp:237] Iteration 15600, loss = 0.00217452
I0302 07:45:38.236215 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00217452 (* 1 = 0.00217452 loss)
I0302 07:45:38.236224 29253 sgd_solver.cpp:106] Iteration 15600, lr = 0.001
I0302 07:46:07.873962 29253 solver.cpp:237] Iteration 15620, loss = 0.00165841
I0302 07:46:07.873994 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00165842 (* 1 = 0.00165842 loss)
I0302 07:46:07.874002 29253 sgd_solver.cpp:106] Iteration 15620, lr = 0.001
I0302 07:46:37.070899 29253 solver.cpp:237] Iteration 15640, loss = 0.00171583
I0302 07:46:37.070933 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00171584 (* 1 = 0.00171584 loss)
I0302 07:46:37.070942 29253 sgd_solver.cpp:106] Iteration 15640, lr = 0.001
I0302 07:47:05.934958 29253 solver.cpp:237] Iteration 15660, loss = 0.001699
I0302 07:47:05.934991 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.001699 (* 1 = 0.001699 loss)
I0302 07:47:05.935000 29253 sgd_solver.cpp:106] Iteration 15660, lr = 0.001
I0302 07:47:34.833344 29253 solver.cpp:237] Iteration 15680, loss = 0.00145964
I0302 07:47:34.833377 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00145964 (* 1 = 0.00145964 loss)
I0302 07:47:34.833386 29253 sgd_solver.cpp:106] Iteration 15680, lr = 0.001
I0302 07:48:03.549157 29253 solver.cpp:237] Iteration 15700, loss = 0.00169412
I0302 07:48:03.549190 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00169412 (* 1 = 0.00169412 loss)
I0302 07:48:03.549199 29253 sgd_solver.cpp:106] Iteration 15700, lr = 0.001
I0302 07:48:32.558831 29253 solver.cpp:237] Iteration 15720, loss = 0.0015531
I0302 07:48:32.558864 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0015531 (* 1 = 0.0015531 loss)
I0302 07:48:32.558874 29253 sgd_solver.cpp:106] Iteration 15720, lr = 0.001
I0302 07:49:01.975682 29253 solver.cpp:237] Iteration 15740, loss = 0.00177056
I0302 07:49:01.975713 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00177057 (* 1 = 0.00177057 loss)
I0302 07:49:01.975721 29253 sgd_solver.cpp:106] Iteration 15740, lr = 0.001
I0302 07:49:30.774696 29253 solver.cpp:237] Iteration 15760, loss = 0.001532
I0302 07:49:30.774729 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.001532 (* 1 = 0.001532 loss)
I0302 07:49:30.774737 29253 sgd_solver.cpp:106] Iteration 15760, lr = 0.001
I0302 07:49:59.744410 29253 solver.cpp:237] Iteration 15780, loss = 0.00151197
I0302 07:49:59.744441 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00151198 (* 1 = 0.00151198 loss)
I0302 07:49:59.744451 29253 sgd_solver.cpp:106] Iteration 15780, lr = 0.001
I0302 07:50:28.659420 29253 solver.cpp:237] Iteration 15800, loss = 0.00174291
I0302 07:50:28.659453 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00174292 (* 1 = 0.00174292 loss)
I0302 07:50:28.659462 29253 sgd_solver.cpp:106] Iteration 15800, lr = 0.001
I0302 07:50:57.967562 29253 solver.cpp:237] Iteration 15820, loss = 0.00168794
I0302 07:50:57.967597 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00168794 (* 1 = 0.00168794 loss)
I0302 07:50:57.967605 29253 sgd_solver.cpp:106] Iteration 15820, lr = 0.001
I0302 07:51:26.678711 29253 solver.cpp:237] Iteration 15840, loss = 0.00172496
I0302 07:51:26.678745 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00172496 (* 1 = 0.00172496 loss)
I0302 07:51:26.678752 29253 sgd_solver.cpp:106] Iteration 15840, lr = 0.001
I0302 07:51:55.405177 29253 solver.cpp:237] Iteration 15860, loss = 0.00125797
I0302 07:51:55.405210 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00125797 (* 1 = 0.00125797 loss)
I0302 07:51:55.405220 29253 sgd_solver.cpp:106] Iteration 15860, lr = 0.001
I0302 07:52:24.078096 29253 solver.cpp:237] Iteration 15880, loss = 0.0020418
I0302 07:52:24.078129 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00204181 (* 1 = 0.00204181 loss)
I0302 07:52:24.078138 29253 sgd_solver.cpp:106] Iteration 15880, lr = 0.001
I0302 07:52:52.981909 29253 solver.cpp:237] Iteration 15900, loss = 0.00160562
I0302 07:52:52.981942 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00160562 (* 1 = 0.00160562 loss)
I0302 07:52:52.981951 29253 sgd_solver.cpp:106] Iteration 15900, lr = 0.001
I0302 07:53:21.880673 29253 solver.cpp:237] Iteration 15920, loss = 0.00176412
I0302 07:53:21.880704 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00176412 (* 1 = 0.00176412 loss)
I0302 07:53:21.880712 29253 sgd_solver.cpp:106] Iteration 15920, lr = 0.001
I0302 07:53:50.858683 29253 solver.cpp:237] Iteration 15940, loss = 0.00159213
I0302 07:53:50.858717 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00159214 (* 1 = 0.00159214 loss)
I0302 07:53:50.858726 29253 sgd_solver.cpp:106] Iteration 15940, lr = 0.001
I0302 07:54:19.555763 29253 solver.cpp:237] Iteration 15960, loss = 0.00154301
I0302 07:54:19.555796 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00154301 (* 1 = 0.00154301 loss)
I0302 07:54:19.555804 29253 sgd_solver.cpp:106] Iteration 15960, lr = 0.001
I0302 07:54:48.625421 29253 solver.cpp:237] Iteration 15980, loss = 0.00211292
I0302 07:54:48.625453 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00211292 (* 1 = 0.00211292 loss)
I0302 07:54:48.625463 29253 sgd_solver.cpp:106] Iteration 15980, lr = 0.001
I0302 07:55:17.783339 29253 solver.cpp:237] Iteration 16000, loss = 0.00128204
I0302 07:55:17.783371 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00128204 (* 1 = 0.00128204 loss)
I0302 07:55:17.783380 29253 sgd_solver.cpp:106] Iteration 16000, lr = 0.001
I0302 07:55:27.587214 29253 blocking_queue.cpp:50] Data layer prefetch queue empty
I0302 07:55:46.433873 29253 solver.cpp:237] Iteration 16020, loss = 0.00152507
I0302 07:55:46.433905 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00152507 (* 1 = 0.00152507 loss)
I0302 07:55:46.433914 29253 sgd_solver.cpp:106] Iteration 16020, lr = 0.001
I0302 07:56:15.410936 29253 solver.cpp:237] Iteration 16040, loss = 0.00138804
I0302 07:56:15.410969 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00138805 (* 1 = 0.00138805 loss)
I0302 07:56:15.410977 29253 sgd_solver.cpp:106] Iteration 16040, lr = 0.001
I0302 07:56:44.366760 29253 solver.cpp:237] Iteration 16060, loss = 0.00142807
I0302 07:56:44.366793 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00142807 (* 1 = 0.00142807 loss)
I0302 07:56:44.366801 29253 sgd_solver.cpp:106] Iteration 16060, lr = 0.001
I0302 07:57:13.530299 29253 solver.cpp:237] Iteration 16080, loss = 0.00200577
I0302 07:57:13.530330 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00200578 (* 1 = 0.00200578 loss)
I0302 07:57:13.530339 29253 sgd_solver.cpp:106] Iteration 16080, lr = 0.001
I0302 07:57:42.495605 29253 solver.cpp:237] Iteration 16100, loss = 0.00178878
I0302 07:57:42.495636 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00178878 (* 1 = 0.00178878 loss)
I0302 07:57:42.495645 29253 sgd_solver.cpp:106] Iteration 16100, lr = 0.001
I0302 07:58:11.511981 29253 solver.cpp:237] Iteration 16120, loss = 0.00185388
I0302 07:58:11.512012 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00185389 (* 1 = 0.00185389 loss)
I0302 07:58:11.512022 29253 sgd_solver.cpp:106] Iteration 16120, lr = 0.001
I0302 07:58:40.338206 29253 solver.cpp:237] Iteration 16140, loss = 0.00191404
I0302 07:58:40.338238 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00191404 (* 1 = 0.00191404 loss)
I0302 07:58:40.338248 29253 sgd_solver.cpp:106] Iteration 16140, lr = 0.001
I0302 07:59:09.401885 29253 solver.cpp:237] Iteration 16160, loss = 0.00132117
I0302 07:59:09.401918 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00132117 (* 1 = 0.00132117 loss)
I0302 07:59:09.401926 29253 sgd_solver.cpp:106] Iteration 16160, lr = 0.001
I0302 07:59:38.225965 29253 solver.cpp:237] Iteration 16180, loss = 0.00150344
I0302 07:59:38.225997 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00150344 (* 1 = 0.00150344 loss)
I0302 07:59:38.226006 29253 sgd_solver.cpp:106] Iteration 16180, lr = 0.001
I0302 08:00:07.157826 29253 solver.cpp:237] Iteration 16200, loss = 0.00175972
I0302 08:00:07.157858 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00175972 (* 1 = 0.00175972 loss)
I0302 08:00:07.157868 29253 sgd_solver.cpp:106] Iteration 16200, lr = 0.001
I0302 08:00:36.161576 29253 solver.cpp:237] Iteration 16220, loss = 0.00179443
I0302 08:00:36.161607 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00179443 (* 1 = 0.00179443 loss)
I0302 08:00:36.161617 29253 sgd_solver.cpp:106] Iteration 16220, lr = 0.001
I0302 08:01:04.806463 29253 solver.cpp:237] Iteration 16240, loss = 0.00173542
I0302 08:01:04.806495 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00173542 (* 1 = 0.00173542 loss)
I0302 08:01:04.806505 29253 sgd_solver.cpp:106] Iteration 16240, lr = 0.001
I0302 08:01:33.712494 29253 solver.cpp:237] Iteration 16260, loss = 0.00169548
I0302 08:01:33.712527 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00169548 (* 1 = 0.00169548 loss)
I0302 08:01:33.712538 29253 sgd_solver.cpp:106] Iteration 16260, lr = 0.001
I0302 08:02:02.590221 29253 solver.cpp:237] Iteration 16280, loss = 0.00154488
I0302 08:02:02.590253 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00154489 (* 1 = 0.00154489 loss)
I0302 08:02:02.590262 29253 sgd_solver.cpp:106] Iteration 16280, lr = 0.001
I0302 08:02:31.450809 29253 solver.cpp:237] Iteration 16300, loss = 0.001564
I0302 08:02:31.450842 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00156401 (* 1 = 0.00156401 loss)
I0302 08:02:31.450851 29253 sgd_solver.cpp:106] Iteration 16300, lr = 0.001
I0302 08:03:00.220618 29253 solver.cpp:237] Iteration 16320, loss = 0.00136352
I0302 08:03:00.220650 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00136352 (* 1 = 0.00136352 loss)
I0302 08:03:00.220659 29253 sgd_solver.cpp:106] Iteration 16320, lr = 0.001
I0302 08:03:29.256676 29253 solver.cpp:237] Iteration 16340, loss = 0.00196714
I0302 08:03:29.256710 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00196715 (* 1 = 0.00196715 loss)
I0302 08:03:29.256718 29253 sgd_solver.cpp:106] Iteration 16340, lr = 0.001
I0302 08:03:58.201010 29253 solver.cpp:237] Iteration 16360, loss = 0.00170606
I0302 08:03:58.201042 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00170606 (* 1 = 0.00170606 loss)
I0302 08:03:58.201051 29253 sgd_solver.cpp:106] Iteration 16360, lr = 0.001
I0302 08:04:26.954553 29253 solver.cpp:237] Iteration 16380, loss = 0.00149456
I0302 08:04:26.954586 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00149457 (* 1 = 0.00149457 loss)
I0302 08:04:26.954596 29253 sgd_solver.cpp:106] Iteration 16380, lr = 0.001
I0302 08:04:55.840397 29253 solver.cpp:237] Iteration 16400, loss = 0.0013677
I0302 08:04:55.840431 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0013677 (* 1 = 0.0013677 loss)
I0302 08:04:55.840441 29253 sgd_solver.cpp:106] Iteration 16400, lr = 0.001
I0302 08:05:24.615053 29253 solver.cpp:237] Iteration 16420, loss = 0.00190911
I0302 08:05:24.615087 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00190912 (* 1 = 0.00190912 loss)
I0302 08:05:24.615097 29253 sgd_solver.cpp:106] Iteration 16420, lr = 0.001
I0302 08:05:53.676386 29253 solver.cpp:237] Iteration 16440, loss = 0.00196937
I0302 08:05:53.676419 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00196938 (* 1 = 0.00196938 loss)
I0302 08:05:53.676429 29253 sgd_solver.cpp:106] Iteration 16440, lr = 0.001
I0302 08:06:22.667140 29253 solver.cpp:237] Iteration 16460, loss = 0.00196513
I0302 08:06:22.667173 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00196513 (* 1 = 0.00196513 loss)
I0302 08:06:22.667183 29253 sgd_solver.cpp:106] Iteration 16460, lr = 0.001
I0302 08:06:51.691231 29253 solver.cpp:237] Iteration 16480, loss = 0.00177308
I0302 08:06:51.691262 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00177308 (* 1 = 0.00177308 loss)
I0302 08:06:51.691272 29253 sgd_solver.cpp:106] Iteration 16480, lr = 0.001
I0302 08:07:20.524525 29253 solver.cpp:237] Iteration 16500, loss = 0.00197188
I0302 08:07:20.524556 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00197189 (* 1 = 0.00197189 loss)
I0302 08:07:20.524565 29253 sgd_solver.cpp:106] Iteration 16500, lr = 0.001
I0302 08:07:49.440065 29253 solver.cpp:237] Iteration 16520, loss = 0.00130119
I0302 08:07:49.440098 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00130119 (* 1 = 0.00130119 loss)
I0302 08:07:49.440106 29253 sgd_solver.cpp:106] Iteration 16520, lr = 0.001
I0302 08:08:18.397086 29253 solver.cpp:237] Iteration 16540, loss = 0.00173073
I0302 08:08:18.397119 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00173074 (* 1 = 0.00173074 loss)
I0302 08:08:18.397128 29253 sgd_solver.cpp:106] Iteration 16540, lr = 0.001
I0302 08:08:47.883898 29253 solver.cpp:237] Iteration 16560, loss = 0.00186685
I0302 08:08:47.883929 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00186685 (* 1 = 0.00186685 loss)
I0302 08:08:47.883939 29253 sgd_solver.cpp:106] Iteration 16560, lr = 0.001
I0302 08:09:16.611956 29253 solver.cpp:237] Iteration 16580, loss = 0.0014967
I0302 08:09:16.611989 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0014967 (* 1 = 0.0014967 loss)
I0302 08:09:16.611999 29253 sgd_solver.cpp:106] Iteration 16580, lr = 0.001
I0302 08:09:45.264551 29253 solver.cpp:237] Iteration 16600, loss = 0.00175004
I0302 08:09:45.264585 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00175004 (* 1 = 0.00175004 loss)
I0302 08:09:45.264593 29253 sgd_solver.cpp:106] Iteration 16600, lr = 0.001
I0302 08:10:14.250134 29253 solver.cpp:237] Iteration 16620, loss = 0.00126431
I0302 08:10:14.250169 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00126431 (* 1 = 0.00126431 loss)
I0302 08:10:14.250177 29253 sgd_solver.cpp:106] Iteration 16620, lr = 0.001
I0302 08:10:43.545398 29253 solver.cpp:237] Iteration 16640, loss = 0.00164695
I0302 08:10:43.545428 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00164696 (* 1 = 0.00164696 loss)
I0302 08:10:43.545438 29253 sgd_solver.cpp:106] Iteration 16640, lr = 0.001
I0302 08:11:12.620538 29253 solver.cpp:237] Iteration 16660, loss = 0.00249174
I0302 08:11:12.620570 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00249175 (* 1 = 0.00249175 loss)
I0302 08:11:12.620579 29253 sgd_solver.cpp:106] Iteration 16660, lr = 0.001
I0302 08:11:41.459930 29253 solver.cpp:237] Iteration 16680, loss = 0.00159935
I0302 08:11:41.459964 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00159936 (* 1 = 0.00159936 loss)
I0302 08:11:41.459972 29253 sgd_solver.cpp:106] Iteration 16680, lr = 0.001
I0302 08:12:10.411790 29253 solver.cpp:237] Iteration 16700, loss = 0.00190788
I0302 08:12:10.411824 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00190788 (* 1 = 0.00190788 loss)
I0302 08:12:10.411834 29253 sgd_solver.cpp:106] Iteration 16700, lr = 0.001
I0302 08:12:38.986261 29253 solver.cpp:237] Iteration 16720, loss = 0.00186131
I0302 08:12:38.986294 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00186131 (* 1 = 0.00186131 loss)
I0302 08:12:38.986302 29253 sgd_solver.cpp:106] Iteration 16720, lr = 0.001
I0302 08:13:07.991228 29253 solver.cpp:237] Iteration 16740, loss = 0.00176891
I0302 08:13:07.991261 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00176892 (* 1 = 0.00176892 loss)
I0302 08:13:07.991271 29253 sgd_solver.cpp:106] Iteration 16740, lr = 0.001
I0302 08:13:36.735855 29253 solver.cpp:237] Iteration 16760, loss = 0.00225746
I0302 08:13:36.735887 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00225747 (* 1 = 0.00225747 loss)
I0302 08:13:36.735895 29253 sgd_solver.cpp:106] Iteration 16760, lr = 0.001
I0302 08:14:05.781688 29253 solver.cpp:237] Iteration 16780, loss = 0.00170595
I0302 08:14:05.781720 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00170595 (* 1 = 0.00170595 loss)
I0302 08:14:05.781729 29253 sgd_solver.cpp:106] Iteration 16780, lr = 0.001
I0302 08:14:34.685318 29253 solver.cpp:237] Iteration 16800, loss = 0.0016348
I0302 08:14:34.685350 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0016348 (* 1 = 0.0016348 loss)
I0302 08:14:34.685359 29253 sgd_solver.cpp:106] Iteration 16800, lr = 0.001
I0302 08:15:03.532032 29253 solver.cpp:237] Iteration 16820, loss = 0.00173104
I0302 08:15:03.532063 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00173104 (* 1 = 0.00173104 loss)
I0302 08:15:03.532073 29253 sgd_solver.cpp:106] Iteration 16820, lr = 0.001
I0302 08:15:32.929242 29253 solver.cpp:237] Iteration 16840, loss = 0.00141186
I0302 08:15:32.929275 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00141187 (* 1 = 0.00141187 loss)
I0302 08:15:32.929283 29253 sgd_solver.cpp:106] Iteration 16840, lr = 0.001
I0302 08:16:01.726339 29253 solver.cpp:237] Iteration 16860, loss = 0.00134798
I0302 08:16:01.726373 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00134799 (* 1 = 0.00134799 loss)
I0302 08:16:01.726382 29253 sgd_solver.cpp:106] Iteration 16860, lr = 0.001
I0302 08:16:30.546421 29253 solver.cpp:237] Iteration 16880, loss = 0.00168235
I0302 08:16:30.546452 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00168235 (* 1 = 0.00168235 loss)
I0302 08:16:30.546461 29253 sgd_solver.cpp:106] Iteration 16880, lr = 0.001
I0302 08:16:59.403086 29253 solver.cpp:237] Iteration 16900, loss = 0.00165339
I0302 08:16:59.403120 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0016534 (* 1 = 0.0016534 loss)
I0302 08:16:59.403128 29253 sgd_solver.cpp:106] Iteration 16900, lr = 0.001
I0302 08:17:28.302000 29253 solver.cpp:237] Iteration 16920, loss = 0.00165574
I0302 08:17:28.302033 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00165574 (* 1 = 0.00165574 loss)
I0302 08:17:28.302042 29253 sgd_solver.cpp:106] Iteration 16920, lr = 0.001
I0302 08:17:57.244089 29253 solver.cpp:237] Iteration 16940, loss = 0.00168714
I0302 08:17:57.244120 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00168715 (* 1 = 0.00168715 loss)
I0302 08:17:57.244129 29253 sgd_solver.cpp:106] Iteration 16940, lr = 0.001
I0302 08:18:26.137689 29253 solver.cpp:237] Iteration 16960, loss = 0.0016072
I0302 08:18:26.137722 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00160721 (* 1 = 0.00160721 loss)
I0302 08:18:26.137729 29253 sgd_solver.cpp:106] Iteration 16960, lr = 0.001
I0302 08:18:55.051690 29253 solver.cpp:237] Iteration 16980, loss = 0.00178723
I0302 08:18:55.051723 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00178724 (* 1 = 0.00178724 loss)
I0302 08:18:55.051731 29253 sgd_solver.cpp:106] Iteration 16980, lr = 0.001
I0302 08:19:23.918545 29253 solver.cpp:237] Iteration 17000, loss = 0.00180467
I0302 08:19:23.918578 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00180467 (* 1 = 0.00180467 loss)
I0302 08:19:23.918586 29253 sgd_solver.cpp:106] Iteration 17000, lr = 0.001
I0302 08:19:33.905551 29253 blocking_queue.cpp:50] Data layer prefetch queue empty
I0302 08:19:52.676901 29253 solver.cpp:237] Iteration 17020, loss = 0.00143453
I0302 08:19:52.676933 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00143454 (* 1 = 0.00143454 loss)
I0302 08:19:52.676941 29253 sgd_solver.cpp:106] Iteration 17020, lr = 0.001
I0302 08:20:21.755563 29253 solver.cpp:237] Iteration 17040, loss = 0.00131333
I0302 08:20:21.755594 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00131334 (* 1 = 0.00131334 loss)
I0302 08:20:21.755602 29253 sgd_solver.cpp:106] Iteration 17040, lr = 0.001
I0302 08:20:50.653821 29253 solver.cpp:237] Iteration 17060, loss = 0.00155271
I0302 08:20:50.653856 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00155272 (* 1 = 0.00155272 loss)
I0302 08:20:50.653863 29253 sgd_solver.cpp:106] Iteration 17060, lr = 0.001
I0302 08:21:19.595875 29253 solver.cpp:237] Iteration 17080, loss = 0.00172485
I0302 08:21:19.595906 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00172485 (* 1 = 0.00172485 loss)
I0302 08:21:19.595914 29253 sgd_solver.cpp:106] Iteration 17080, lr = 0.001
I0302 08:21:48.319376 29253 solver.cpp:237] Iteration 17100, loss = 0.00172183
I0302 08:21:48.319407 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00172183 (* 1 = 0.00172183 loss)
I0302 08:21:48.319416 29253 sgd_solver.cpp:106] Iteration 17100, lr = 0.001
I0302 08:22:17.276144 29253 solver.cpp:237] Iteration 17120, loss = 0.0015016
I0302 08:22:17.276175 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0015016 (* 1 = 0.0015016 loss)
I0302 08:22:17.276183 29253 sgd_solver.cpp:106] Iteration 17120, lr = 0.001
I0302 08:22:46.262353 29253 solver.cpp:237] Iteration 17140, loss = 0.00135027
I0302 08:22:46.262389 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00135027 (* 1 = 0.00135027 loss)
I0302 08:22:46.262398 29253 sgd_solver.cpp:106] Iteration 17140, lr = 0.001
I0302 08:23:15.170955 29253 solver.cpp:237] Iteration 17160, loss = 0.0016376
I0302 08:23:15.170989 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0016376 (* 1 = 0.0016376 loss)
I0302 08:23:15.170999 29253 sgd_solver.cpp:106] Iteration 17160, lr = 0.001
I0302 08:23:43.986984 29253 solver.cpp:237] Iteration 17180, loss = 0.00158129
I0302 08:23:43.987015 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00158129 (* 1 = 0.00158129 loss)
I0302 08:23:43.987023 29253 sgd_solver.cpp:106] Iteration 17180, lr = 0.001
I0302 08:24:12.918123 29253 solver.cpp:237] Iteration 17200, loss = 0.00187287
I0302 08:24:12.918154 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00187287 (* 1 = 0.00187287 loss)
I0302 08:24:12.918164 29253 sgd_solver.cpp:106] Iteration 17200, lr = 0.001
I0302 08:24:41.875072 29253 solver.cpp:237] Iteration 17220, loss = 0.00169677
I0302 08:24:41.875105 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00169677 (* 1 = 0.00169677 loss)
I0302 08:24:41.875114 29253 sgd_solver.cpp:106] Iteration 17220, lr = 0.001
I0302 08:25:10.886373 29253 solver.cpp:237] Iteration 17240, loss = 0.00135288
I0302 08:25:10.886404 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00135288 (* 1 = 0.00135288 loss)
I0302 08:25:10.886412 29253 sgd_solver.cpp:106] Iteration 17240, lr = 0.001
I0302 08:25:39.693608 29253 solver.cpp:237] Iteration 17260, loss = 0.00163834
I0302 08:25:39.693640 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00163834 (* 1 = 0.00163834 loss)
I0302 08:25:39.693650 29253 sgd_solver.cpp:106] Iteration 17260, lr = 0.001
I0302 08:26:08.668743 29253 solver.cpp:237] Iteration 17280, loss = 0.00162978
I0302 08:26:08.668774 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00162979 (* 1 = 0.00162979 loss)
I0302 08:26:08.668783 29253 sgd_solver.cpp:106] Iteration 17280, lr = 0.001
I0302 08:26:37.373072 29253 solver.cpp:237] Iteration 17300, loss = 0.00181891
I0302 08:26:37.373106 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00181892 (* 1 = 0.00181892 loss)
I0302 08:26:37.373113 29253 sgd_solver.cpp:106] Iteration 17300, lr = 0.001
I0302 08:27:06.454152 29253 solver.cpp:237] Iteration 17320, loss = 0.0018411
I0302 08:27:06.454185 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00184111 (* 1 = 0.00184111 loss)
I0302 08:27:06.454193 29253 sgd_solver.cpp:106] Iteration 17320, lr = 0.001
I0302 08:27:35.259882 29253 solver.cpp:237] Iteration 17340, loss = 0.001697
I0302 08:27:35.259914 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00169701 (* 1 = 0.00169701 loss)
I0302 08:27:35.259923 29253 sgd_solver.cpp:106] Iteration 17340, lr = 0.001
I0302 08:28:04.252655 29253 solver.cpp:237] Iteration 17360, loss = 0.00121661
I0302 08:28:04.252687 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00121661 (* 1 = 0.00121661 loss)
I0302 08:28:04.252696 29253 sgd_solver.cpp:106] Iteration 17360, lr = 0.001
I0302 08:28:33.303256 29253 solver.cpp:237] Iteration 17380, loss = 0.0016809
I0302 08:28:33.303289 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0016809 (* 1 = 0.0016809 loss)
I0302 08:28:33.303297 29253 sgd_solver.cpp:106] Iteration 17380, lr = 0.001
I0302 08:29:02.213495 29253 solver.cpp:237] Iteration 17400, loss = 0.00218026
I0302 08:29:02.213527 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00218027 (* 1 = 0.00218027 loss)
I0302 08:29:02.213536 29253 sgd_solver.cpp:106] Iteration 17400, lr = 0.001
I0302 08:29:31.332168 29253 solver.cpp:237] Iteration 17420, loss = 0.00186187
I0302 08:29:31.332201 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00186187 (* 1 = 0.00186187 loss)
I0302 08:29:31.332211 29253 sgd_solver.cpp:106] Iteration 17420, lr = 0.001
I0302 08:30:00.254142 29253 solver.cpp:237] Iteration 17440, loss = 0.00160849
I0302 08:30:00.254174 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00160849 (* 1 = 0.00160849 loss)
I0302 08:30:00.254184 29253 sgd_solver.cpp:106] Iteration 17440, lr = 0.001
I0302 08:30:29.218310 29253 solver.cpp:237] Iteration 17460, loss = 0.00178163
I0302 08:30:29.218341 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00178163 (* 1 = 0.00178163 loss)
I0302 08:30:29.218351 29253 sgd_solver.cpp:106] Iteration 17460, lr = 0.001
I0302 08:30:58.001245 29253 solver.cpp:237] Iteration 17480, loss = 0.00171035
I0302 08:30:58.001276 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00171036 (* 1 = 0.00171036 loss)
I0302 08:30:58.001284 29253 sgd_solver.cpp:106] Iteration 17480, lr = 0.001
I0302 08:31:26.886091 29253 solver.cpp:237] Iteration 17500, loss = 0.00158712
I0302 08:31:26.886122 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00158713 (* 1 = 0.00158713 loss)
I0302 08:31:26.886132 29253 sgd_solver.cpp:106] Iteration 17500, lr = 0.001
I0302 08:31:55.840668 29253 solver.cpp:237] Iteration 17520, loss = 0.00180997
I0302 08:31:55.840700 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00180997 (* 1 = 0.00180997 loss)
I0302 08:31:55.840709 29253 sgd_solver.cpp:106] Iteration 17520, lr = 0.001
I0302 08:32:24.732266 29253 solver.cpp:237] Iteration 17540, loss = 0.00159875
I0302 08:32:24.732297 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00159875 (* 1 = 0.00159875 loss)
I0302 08:32:24.732306 29253 sgd_solver.cpp:106] Iteration 17540, lr = 0.001
I0302 08:32:53.609797 29253 solver.cpp:237] Iteration 17560, loss = 0.00153009
I0302 08:32:53.609827 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00153009 (* 1 = 0.00153009 loss)
I0302 08:32:53.609838 29253 sgd_solver.cpp:106] Iteration 17560, lr = 0.001
I0302 08:33:22.524538 29253 solver.cpp:237] Iteration 17580, loss = 0.00179002
I0302 08:33:22.524569 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00179003 (* 1 = 0.00179003 loss)
I0302 08:33:22.524577 29253 sgd_solver.cpp:106] Iteration 17580, lr = 0.001
I0302 08:33:51.573982 29253 solver.cpp:237] Iteration 17600, loss = 0.00151444
I0302 08:33:51.574015 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00151444 (* 1 = 0.00151444 loss)
I0302 08:33:51.574024 29253 sgd_solver.cpp:106] Iteration 17600, lr = 0.001
I0302 08:34:20.902143 29253 solver.cpp:237] Iteration 17620, loss = 0.00157501
I0302 08:34:20.902175 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00157502 (* 1 = 0.00157502 loss)
I0302 08:34:20.902184 29253 sgd_solver.cpp:106] Iteration 17620, lr = 0.001
I0302 08:34:49.361749 29253 solver.cpp:237] Iteration 17640, loss = 0.0013643
I0302 08:34:49.361781 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0013643 (* 1 = 0.0013643 loss)
I0302 08:34:49.361791 29253 sgd_solver.cpp:106] Iteration 17640, lr = 0.001
I0302 08:35:18.465446 29253 solver.cpp:237] Iteration 17660, loss = 0.00163829
I0302 08:35:18.465478 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00163829 (* 1 = 0.00163829 loss)
I0302 08:35:18.465487 29253 sgd_solver.cpp:106] Iteration 17660, lr = 0.001
I0302 08:35:47.426570 29253 solver.cpp:237] Iteration 17680, loss = 0.00208541
I0302 08:35:47.426601 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00208541 (* 1 = 0.00208541 loss)
I0302 08:35:47.426610 29253 sgd_solver.cpp:106] Iteration 17680, lr = 0.001
I0302 08:36:16.522048 29253 solver.cpp:237] Iteration 17700, loss = 0.00159136
I0302 08:36:16.522079 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00159137 (* 1 = 0.00159137 loss)
I0302 08:36:16.522088 29253 sgd_solver.cpp:106] Iteration 17700, lr = 0.001
I0302 08:36:45.307919 29253 solver.cpp:237] Iteration 17720, loss = 0.00172637
I0302 08:36:45.307951 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00172638 (* 1 = 0.00172638 loss)
I0302 08:36:45.307960 29253 sgd_solver.cpp:106] Iteration 17720, lr = 0.001
I0302 08:37:14.264299 29253 solver.cpp:237] Iteration 17740, loss = 0.00173615
I0302 08:37:14.264329 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00173615 (* 1 = 0.00173615 loss)
I0302 08:37:14.264338 29253 sgd_solver.cpp:106] Iteration 17740, lr = 0.001
I0302 08:37:43.085243 29253 solver.cpp:237] Iteration 17760, loss = 0.00156278
I0302 08:37:43.085275 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00156278 (* 1 = 0.00156278 loss)
I0302 08:37:43.085284 29253 sgd_solver.cpp:106] Iteration 17760, lr = 0.001
I0302 08:38:12.029928 29253 solver.cpp:237] Iteration 17780, loss = 0.00159464
I0302 08:38:12.029959 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00159465 (* 1 = 0.00159465 loss)
I0302 08:38:12.029968 29253 sgd_solver.cpp:106] Iteration 17780, lr = 0.001
I0302 08:38:41.240878 29253 solver.cpp:237] Iteration 17800, loss = 0.0023071
I0302 08:38:41.240911 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00230711 (* 1 = 0.00230711 loss)
I0302 08:38:41.240921 29253 sgd_solver.cpp:106] Iteration 17800, lr = 0.001
I0302 08:39:09.972158 29253 solver.cpp:237] Iteration 17820, loss = 0.00157805
I0302 08:39:09.972192 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00157805 (* 1 = 0.00157805 loss)
I0302 08:39:09.972200 29253 sgd_solver.cpp:106] Iteration 17820, lr = 0.001
I0302 08:39:38.498926 29253 solver.cpp:237] Iteration 17840, loss = 0.0022513
I0302 08:39:38.498958 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00225131 (* 1 = 0.00225131 loss)
I0302 08:39:38.498967 29253 sgd_solver.cpp:106] Iteration 17840, lr = 0.001
I0302 08:40:07.459337 29253 solver.cpp:237] Iteration 17860, loss = 0.0014929
I0302 08:40:07.459368 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00149291 (* 1 = 0.00149291 loss)
I0302 08:40:07.459378 29253 sgd_solver.cpp:106] Iteration 17860, lr = 0.001
I0302 08:40:36.370009 29253 solver.cpp:237] Iteration 17880, loss = 0.00143267
I0302 08:40:36.370043 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00143268 (* 1 = 0.00143268 loss)
I0302 08:40:36.370051 29253 sgd_solver.cpp:106] Iteration 17880, lr = 0.001
I0302 08:41:05.536944 29253 solver.cpp:237] Iteration 17900, loss = 0.00176597
I0302 08:41:05.536978 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00176598 (* 1 = 0.00176598 loss)
I0302 08:41:05.536985 29253 sgd_solver.cpp:106] Iteration 17900, lr = 0.001
I0302 08:41:34.359864 29253 solver.cpp:237] Iteration 17920, loss = 0.00196559
I0302 08:41:34.359897 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0019656 (* 1 = 0.0019656 loss)
I0302 08:41:34.359906 29253 sgd_solver.cpp:106] Iteration 17920, lr = 0.001
I0302 08:42:03.235473 29253 solver.cpp:237] Iteration 17940, loss = 0.00151722
I0302 08:42:03.235504 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00151722 (* 1 = 0.00151722 loss)
I0302 08:42:03.235513 29253 sgd_solver.cpp:106] Iteration 17940, lr = 0.001
I0302 08:42:32.193408 29253 solver.cpp:237] Iteration 17960, loss = 0.00134428
I0302 08:42:32.193442 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00134428 (* 1 = 0.00134428 loss)
I0302 08:42:32.193451 29253 sgd_solver.cpp:106] Iteration 17960, lr = 0.001
I0302 08:43:00.792814 29253 solver.cpp:237] Iteration 17980, loss = 0.00146551
I0302 08:43:00.792845 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00146552 (* 1 = 0.00146552 loss)
I0302 08:43:00.792855 29253 sgd_solver.cpp:106] Iteration 17980, lr = 0.001
I0302 08:43:29.681627 29253 solver.cpp:237] Iteration 18000, loss = 0.00183943
I0302 08:43:29.681660 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00183944 (* 1 = 0.00183944 loss)
I0302 08:43:29.681669 29253 sgd_solver.cpp:106] Iteration 18000, lr = 0.001
I0302 08:43:39.847204 29253 blocking_queue.cpp:50] Data layer prefetch queue empty
I0302 08:43:58.829442 29253 solver.cpp:237] Iteration 18020, loss = 0.00180507
I0302 08:43:58.829478 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00180508 (* 1 = 0.00180508 loss)
I0302 08:43:58.829488 29253 sgd_solver.cpp:106] Iteration 18020, lr = 0.001
I0302 08:44:27.703251 29253 solver.cpp:237] Iteration 18040, loss = 0.0014596
I0302 08:44:27.703284 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00145961 (* 1 = 0.00145961 loss)
I0302 08:44:27.703294 29253 sgd_solver.cpp:106] Iteration 18040, lr = 0.001
I0302 08:44:56.671699 29253 solver.cpp:237] Iteration 18060, loss = 0.0013381
I0302 08:44:56.671731 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00133811 (* 1 = 0.00133811 loss)
I0302 08:44:56.671741 29253 sgd_solver.cpp:106] Iteration 18060, lr = 0.001
I0302 08:45:25.663918 29253 solver.cpp:237] Iteration 18080, loss = 0.00225553
I0302 08:45:25.663949 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00225553 (* 1 = 0.00225553 loss)
I0302 08:45:25.663959 29253 sgd_solver.cpp:106] Iteration 18080, lr = 0.001
I0302 08:45:54.308156 29253 solver.cpp:237] Iteration 18100, loss = 0.00155996
I0302 08:45:54.308187 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00155997 (* 1 = 0.00155997 loss)
I0302 08:45:54.308197 29253 sgd_solver.cpp:106] Iteration 18100, lr = 0.001
I0302 08:46:23.127854 29253 solver.cpp:237] Iteration 18120, loss = 0.00153283
I0302 08:46:23.127887 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00153283 (* 1 = 0.00153283 loss)
I0302 08:46:23.127897 29253 sgd_solver.cpp:106] Iteration 18120, lr = 0.001
I0302 08:46:52.018010 29253 solver.cpp:237] Iteration 18140, loss = 0.00155879
I0302 08:46:52.018043 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00155879 (* 1 = 0.00155879 loss)
I0302 08:46:52.018051 29253 sgd_solver.cpp:106] Iteration 18140, lr = 0.001
I0302 08:47:20.746247 29253 solver.cpp:237] Iteration 18160, loss = 0.0015891
I0302 08:47:20.746279 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0015891 (* 1 = 0.0015891 loss)
I0302 08:47:20.746289 29253 sgd_solver.cpp:106] Iteration 18160, lr = 0.001
I0302 08:47:49.720607 29253 solver.cpp:237] Iteration 18180, loss = 0.00178865
I0302 08:47:49.720638 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00178865 (* 1 = 0.00178865 loss)
I0302 08:47:49.720646 29253 sgd_solver.cpp:106] Iteration 18180, lr = 0.001
I0302 08:48:18.469338 29253 solver.cpp:237] Iteration 18200, loss = 0.00169241
I0302 08:48:18.469372 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00169241 (* 1 = 0.00169241 loss)
I0302 08:48:18.469380 29253 sgd_solver.cpp:106] Iteration 18200, lr = 0.001
I0302 08:48:47.309650 29253 solver.cpp:237] Iteration 18220, loss = 0.00145668
I0302 08:48:47.309684 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00145668 (* 1 = 0.00145668 loss)
I0302 08:48:47.309692 29253 sgd_solver.cpp:106] Iteration 18220, lr = 0.001
I0302 08:49:16.287750 29253 solver.cpp:237] Iteration 18240, loss = 0.00166231
I0302 08:49:16.287782 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00166231 (* 1 = 0.00166231 loss)
I0302 08:49:16.287792 29253 sgd_solver.cpp:106] Iteration 18240, lr = 0.001
I0302 08:49:45.137020 29253 solver.cpp:237] Iteration 18260, loss = 0.00163309
I0302 08:49:45.137053 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00163309 (* 1 = 0.00163309 loss)
I0302 08:49:45.137063 29253 sgd_solver.cpp:106] Iteration 18260, lr = 0.001
I0302 08:50:14.029508 29253 solver.cpp:237] Iteration 18280, loss = 0.00175292
I0302 08:50:14.029542 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00175292 (* 1 = 0.00175292 loss)
I0302 08:50:14.029551 29253 sgd_solver.cpp:106] Iteration 18280, lr = 0.001
I0302 08:50:43.141226 29253 solver.cpp:237] Iteration 18300, loss = 0.00187946
I0302 08:50:43.141258 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00187946 (* 1 = 0.00187946 loss)
I0302 08:50:43.141266 29253 sgd_solver.cpp:106] Iteration 18300, lr = 0.001
I0302 08:51:12.126513 29253 solver.cpp:237] Iteration 18320, loss = 0.00155729
I0302 08:51:12.126544 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0015573 (* 1 = 0.0015573 loss)
I0302 08:51:12.126554 29253 sgd_solver.cpp:106] Iteration 18320, lr = 0.001
I0302 08:51:41.009037 29253 solver.cpp:237] Iteration 18340, loss = 0.00162402
I0302 08:51:41.009068 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00162403 (* 1 = 0.00162403 loss)
I0302 08:51:41.009078 29253 sgd_solver.cpp:106] Iteration 18340, lr = 0.001
I0302 08:52:10.018961 29253 solver.cpp:237] Iteration 18360, loss = 0.00141018
I0302 08:52:10.018995 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00141019 (* 1 = 0.00141019 loss)
I0302 08:52:10.019003 29253 sgd_solver.cpp:106] Iteration 18360, lr = 0.001
I0302 08:52:38.756573 29253 solver.cpp:237] Iteration 18380, loss = 0.00150659
I0302 08:52:38.756606 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00150659 (* 1 = 0.00150659 loss)
I0302 08:52:38.756614 29253 sgd_solver.cpp:106] Iteration 18380, lr = 0.001
I0302 08:53:07.639415 29253 solver.cpp:237] Iteration 18400, loss = 0.00167861
I0302 08:53:07.639448 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00167861 (* 1 = 0.00167861 loss)
I0302 08:53:07.639456 29253 sgd_solver.cpp:106] Iteration 18400, lr = 0.001
I0302 08:53:36.650578 29253 solver.cpp:237] Iteration 18420, loss = 0.00148314
I0302 08:53:36.650610 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00148314 (* 1 = 0.00148314 loss)
I0302 08:53:36.650619 29253 sgd_solver.cpp:106] Iteration 18420, lr = 0.001
I0302 08:54:05.652004 29253 solver.cpp:237] Iteration 18440, loss = 0.00142458
I0302 08:54:05.652036 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00142458 (* 1 = 0.00142458 loss)
I0302 08:54:05.652045 29253 sgd_solver.cpp:106] Iteration 18440, lr = 0.001
I0302 08:54:34.506984 29253 solver.cpp:237] Iteration 18460, loss = 0.0014989
I0302 08:54:34.507016 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0014989 (* 1 = 0.0014989 loss)
I0302 08:54:34.507025 29253 sgd_solver.cpp:106] Iteration 18460, lr = 0.001
I0302 08:55:03.359037 29253 solver.cpp:237] Iteration 18480, loss = 0.00229775
I0302 08:55:03.359068 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00229776 (* 1 = 0.00229776 loss)
I0302 08:55:03.359077 29253 sgd_solver.cpp:106] Iteration 18480, lr = 0.001
I0302 08:55:32.280822 29253 solver.cpp:237] Iteration 18500, loss = 0.00171239
I0302 08:55:32.280854 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00171239 (* 1 = 0.00171239 loss)
I0302 08:55:32.280864 29253 sgd_solver.cpp:106] Iteration 18500, lr = 0.001
I0302 08:56:01.259644 29253 solver.cpp:237] Iteration 18520, loss = 0.00155288
I0302 08:56:01.259676 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00155289 (* 1 = 0.00155289 loss)
I0302 08:56:01.259685 29253 sgd_solver.cpp:106] Iteration 18520, lr = 0.001
I0302 08:56:30.023560 29253 solver.cpp:237] Iteration 18540, loss = 0.00155981
I0302 08:56:30.023591 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00155981 (* 1 = 0.00155981 loss)
I0302 08:56:30.023599 29253 sgd_solver.cpp:106] Iteration 18540, lr = 0.001
I0302 08:56:59.014842 29253 solver.cpp:237] Iteration 18560, loss = 0.00160633
I0302 08:56:59.014873 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00160633 (* 1 = 0.00160633 loss)
I0302 08:56:59.014883 29253 sgd_solver.cpp:106] Iteration 18560, lr = 0.001
I0302 08:57:27.938024 29253 solver.cpp:237] Iteration 18580, loss = 0.00154074
I0302 08:57:27.938057 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00154074 (* 1 = 0.00154074 loss)
I0302 08:57:27.938066 29253 sgd_solver.cpp:106] Iteration 18580, lr = 0.001
I0302 08:57:56.551965 29253 solver.cpp:237] Iteration 18600, loss = 0.00217712
I0302 08:57:56.551997 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00217712 (* 1 = 0.00217712 loss)
I0302 08:57:56.552006 29253 sgd_solver.cpp:106] Iteration 18600, lr = 0.001
I0302 08:58:25.463291 29253 solver.cpp:237] Iteration 18620, loss = 0.00182832
I0302 08:58:25.463322 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00182832 (* 1 = 0.00182832 loss)
I0302 08:58:25.463331 29253 sgd_solver.cpp:106] Iteration 18620, lr = 0.001
I0302 08:58:54.448720 29253 solver.cpp:237] Iteration 18640, loss = 0.00162921
I0302 08:58:54.448751 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00162921 (* 1 = 0.00162921 loss)
I0302 08:58:54.448760 29253 sgd_solver.cpp:106] Iteration 18640, lr = 0.001
I0302 08:59:23.226701 29253 solver.cpp:237] Iteration 18660, loss = 0.00138193
I0302 08:59:23.226732 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00138193 (* 1 = 0.00138193 loss)
I0302 08:59:23.226742 29253 sgd_solver.cpp:106] Iteration 18660, lr = 0.001
I0302 08:59:52.071882 29253 solver.cpp:237] Iteration 18680, loss = 0.00153928
I0302 08:59:52.071915 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00153929 (* 1 = 0.00153929 loss)
I0302 08:59:52.071924 29253 sgd_solver.cpp:106] Iteration 18680, lr = 0.001
I0302 09:00:21.104001 29253 solver.cpp:237] Iteration 18700, loss = 0.00182124
I0302 09:00:21.104033 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00182124 (* 1 = 0.00182124 loss)
I0302 09:00:21.104043 29253 sgd_solver.cpp:106] Iteration 18700, lr = 0.001
I0302 09:00:49.834785 29253 solver.cpp:237] Iteration 18720, loss = 0.00144276
I0302 09:00:49.834815 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00144276 (* 1 = 0.00144276 loss)
I0302 09:00:49.834825 29253 sgd_solver.cpp:106] Iteration 18720, lr = 0.001
I0302 09:01:18.887014 29253 solver.cpp:237] Iteration 18740, loss = 0.00191531
I0302 09:01:18.887045 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00191531 (* 1 = 0.00191531 loss)
I0302 09:01:18.887054 29253 sgd_solver.cpp:106] Iteration 18740, lr = 0.001
I0302 09:01:47.975661 29253 solver.cpp:237] Iteration 18760, loss = 0.00140661
I0302 09:01:47.975693 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00140661 (* 1 = 0.00140661 loss)
I0302 09:01:47.975703 29253 sgd_solver.cpp:106] Iteration 18760, lr = 0.001
I0302 09:02:16.635447 29253 solver.cpp:237] Iteration 18780, loss = 0.00148476
I0302 09:02:16.635478 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00148476 (* 1 = 0.00148476 loss)
I0302 09:02:16.635488 29253 sgd_solver.cpp:106] Iteration 18780, lr = 0.001
I0302 09:02:45.469027 29253 solver.cpp:237] Iteration 18800, loss = 0.00260169
I0302 09:02:45.469059 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00260169 (* 1 = 0.00260169 loss)
I0302 09:02:45.469068 29253 sgd_solver.cpp:106] Iteration 18800, lr = 0.001
I0302 09:03:14.869191 29253 solver.cpp:237] Iteration 18820, loss = 0.00151654
I0302 09:03:14.869222 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00151654 (* 1 = 0.00151654 loss)
I0302 09:03:14.869231 29253 sgd_solver.cpp:106] Iteration 18820, lr = 0.001
I0302 09:03:43.379854 29253 solver.cpp:237] Iteration 18840, loss = 0.00189074
I0302 09:03:43.379886 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00189074 (* 1 = 0.00189074 loss)
I0302 09:03:43.379895 29253 sgd_solver.cpp:106] Iteration 18840, lr = 0.001
I0302 09:04:11.898803 29253 solver.cpp:237] Iteration 18860, loss = 0.00143845
I0302 09:04:11.898839 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00143845 (* 1 = 0.00143845 loss)
I0302 09:04:11.898849 29253 sgd_solver.cpp:106] Iteration 18860, lr = 0.001
I0302 09:04:40.910372 29253 solver.cpp:237] Iteration 18880, loss = 0.00182783
I0302 09:04:40.910404 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00182784 (* 1 = 0.00182784 loss)
I0302 09:04:40.910414 29253 sgd_solver.cpp:106] Iteration 18880, lr = 0.001
I0302 09:05:09.796340 29253 solver.cpp:237] Iteration 18900, loss = 0.00137785
I0302 09:05:09.796372 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00137785 (* 1 = 0.00137785 loss)
I0302 09:05:09.796381 29253 sgd_solver.cpp:106] Iteration 18900, lr = 0.001
I0302 09:05:38.614562 29253 solver.cpp:237] Iteration 18920, loss = 0.0017795
I0302 09:05:38.614593 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0017795 (* 1 = 0.0017795 loss)
I0302 09:05:38.614603 29253 sgd_solver.cpp:106] Iteration 18920, lr = 0.001
I0302 09:06:07.632585 29253 solver.cpp:237] Iteration 18940, loss = 0.00162407
I0302 09:06:07.632617 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00162407 (* 1 = 0.00162407 loss)
I0302 09:06:07.632625 29253 sgd_solver.cpp:106] Iteration 18940, lr = 0.001
I0302 09:06:36.332643 29253 solver.cpp:237] Iteration 18960, loss = 0.00160227
I0302 09:06:36.332675 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00160228 (* 1 = 0.00160228 loss)
I0302 09:06:36.332684 29253 sgd_solver.cpp:106] Iteration 18960, lr = 0.001
I0302 09:07:05.307458 29253 solver.cpp:237] Iteration 18980, loss = 0.00160945
I0302 09:07:05.307490 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00160946 (* 1 = 0.00160946 loss)
I0302 09:07:05.307499 29253 sgd_solver.cpp:106] Iteration 18980, lr = 0.001
I0302 09:07:34.193123 29253 solver.cpp:237] Iteration 19000, loss = 0.00158919
I0302 09:07:34.193156 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0015892 (* 1 = 0.0015892 loss)
I0302 09:07:34.193166 29253 sgd_solver.cpp:106] Iteration 19000, lr = 0.001
I0302 09:07:44.293957 29253 blocking_queue.cpp:50] Data layer prefetch queue empty
I0302 09:08:03.290524 29253 solver.cpp:237] Iteration 19020, loss = 0.00132683
I0302 09:08:03.290558 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00132683 (* 1 = 0.00132683 loss)
I0302 09:08:03.290568 29253 sgd_solver.cpp:106] Iteration 19020, lr = 0.001
I0302 09:08:32.111218 29253 solver.cpp:237] Iteration 19040, loss = 0.00167092
I0302 09:08:32.111249 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00167092 (* 1 = 0.00167092 loss)
I0302 09:08:32.111258 29253 sgd_solver.cpp:106] Iteration 19040, lr = 0.001
I0302 09:09:00.929808 29253 solver.cpp:237] Iteration 19060, loss = 0.00159923
I0302 09:09:00.929841 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00159924 (* 1 = 0.00159924 loss)
I0302 09:09:00.929850 29253 sgd_solver.cpp:106] Iteration 19060, lr = 0.001
I0302 09:09:29.871332 29253 solver.cpp:237] Iteration 19080, loss = 0.00153691
I0302 09:09:29.871366 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00153692 (* 1 = 0.00153692 loss)
I0302 09:09:29.871374 29253 sgd_solver.cpp:106] Iteration 19080, lr = 0.001
I0302 09:09:58.982868 29253 solver.cpp:237] Iteration 19100, loss = 0.00207169
I0302 09:09:58.982899 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00207169 (* 1 = 0.00207169 loss)
I0302 09:09:58.982908 29253 sgd_solver.cpp:106] Iteration 19100, lr = 0.001
I0302 09:10:27.741907 29253 solver.cpp:237] Iteration 19120, loss = 0.00185467
I0302 09:10:27.741940 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00185468 (* 1 = 0.00185468 loss)
I0302 09:10:27.741948 29253 sgd_solver.cpp:106] Iteration 19120, lr = 0.001
I0302 09:10:56.654902 29253 solver.cpp:237] Iteration 19140, loss = 0.00166614
I0302 09:10:56.654933 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00166614 (* 1 = 0.00166614 loss)
I0302 09:10:56.654942 29253 sgd_solver.cpp:106] Iteration 19140, lr = 0.001
I0302 09:11:25.548634 29253 solver.cpp:237] Iteration 19160, loss = 0.00128235
I0302 09:11:25.548666 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00128236 (* 1 = 0.00128236 loss)
I0302 09:11:25.548674 29253 sgd_solver.cpp:106] Iteration 19160, lr = 0.001
I0302 09:11:54.484813 29253 solver.cpp:237] Iteration 19180, loss = 0.00180908
I0302 09:11:54.484848 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00180909 (* 1 = 0.00180909 loss)
I0302 09:11:54.484856 29253 sgd_solver.cpp:106] Iteration 19180, lr = 0.001
I0302 09:12:23.891973 29253 solver.cpp:237] Iteration 19200, loss = 0.00177643
I0302 09:12:23.892005 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00177644 (* 1 = 0.00177644 loss)
I0302 09:12:23.892014 29253 sgd_solver.cpp:106] Iteration 19200, lr = 0.001
I0302 09:12:52.628649 29253 solver.cpp:237] Iteration 19220, loss = 0.00242856
I0302 09:12:52.628682 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00242856 (* 1 = 0.00242856 loss)
I0302 09:12:52.628690 29253 sgd_solver.cpp:106] Iteration 19220, lr = 0.001
I0302 09:13:22.016176 29253 solver.cpp:237] Iteration 19240, loss = 0.00168574
I0302 09:13:22.016208 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00168574 (* 1 = 0.00168574 loss)
I0302 09:13:22.016217 29253 sgd_solver.cpp:106] Iteration 19240, lr = 0.001
I0302 09:13:50.506032 29253 solver.cpp:237] Iteration 19260, loss = 0.00183207
I0302 09:13:50.506063 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00183208 (* 1 = 0.00183208 loss)
I0302 09:13:50.506072 29253 sgd_solver.cpp:106] Iteration 19260, lr = 0.001
I0302 09:14:19.693693 29253 solver.cpp:237] Iteration 19280, loss = 0.00183357
I0302 09:14:19.693727 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00183358 (* 1 = 0.00183358 loss)
I0302 09:14:19.693735 29253 sgd_solver.cpp:106] Iteration 19280, lr = 0.001
I0302 09:14:48.343260 29253 solver.cpp:237] Iteration 19300, loss = 0.00147181
I0302 09:14:48.343292 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00147182 (* 1 = 0.00147182 loss)
I0302 09:14:48.343302 29253 sgd_solver.cpp:106] Iteration 19300, lr = 0.001
I0302 09:15:17.156678 29253 solver.cpp:237] Iteration 19320, loss = 0.00157088
I0302 09:15:17.156710 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00157088 (* 1 = 0.00157088 loss)
I0302 09:15:17.156719 29253 sgd_solver.cpp:106] Iteration 19320, lr = 0.001
I0302 09:15:46.204677 29253 solver.cpp:237] Iteration 19340, loss = 0.00154898
I0302 09:15:46.204710 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00154899 (* 1 = 0.00154899 loss)
I0302 09:15:46.204720 29253 sgd_solver.cpp:106] Iteration 19340, lr = 0.001
I0302 09:16:15.187265 29253 solver.cpp:237] Iteration 19360, loss = 0.00173657
I0302 09:16:15.187299 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00173657 (* 1 = 0.00173657 loss)
I0302 09:16:15.187307 29253 sgd_solver.cpp:106] Iteration 19360, lr = 0.001
I0302 09:16:43.864717 29253 solver.cpp:237] Iteration 19380, loss = 0.00177375
I0302 09:16:43.864749 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00177375 (* 1 = 0.00177375 loss)
I0302 09:16:43.864758 29253 sgd_solver.cpp:106] Iteration 19380, lr = 0.001
I0302 09:17:12.927678 29253 solver.cpp:237] Iteration 19400, loss = 0.00178974
I0302 09:17:12.927711 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00178974 (* 1 = 0.00178974 loss)
I0302 09:17:12.927721 29253 sgd_solver.cpp:106] Iteration 19400, lr = 0.001
I0302 09:17:41.594288 29253 solver.cpp:237] Iteration 19420, loss = 0.00156764
I0302 09:17:41.594321 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00156764 (* 1 = 0.00156764 loss)
I0302 09:17:41.594329 29253 sgd_solver.cpp:106] Iteration 19420, lr = 0.001
I0302 09:18:10.576581 29253 solver.cpp:237] Iteration 19440, loss = 0.00177601
I0302 09:18:10.576614 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00177601 (* 1 = 0.00177601 loss)
I0302 09:18:10.576623 29253 sgd_solver.cpp:106] Iteration 19440, lr = 0.001
I0302 09:18:39.328858 29253 solver.cpp:237] Iteration 19460, loss = 0.0012319
I0302 09:18:39.328889 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00123191 (* 1 = 0.00123191 loss)
I0302 09:18:39.328898 29253 sgd_solver.cpp:106] Iteration 19460, lr = 0.001
I0302 09:19:08.549782 29253 solver.cpp:237] Iteration 19480, loss = 0.00149677
I0302 09:19:08.549814 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00149677 (* 1 = 0.00149677 loss)
I0302 09:19:08.549823 29253 sgd_solver.cpp:106] Iteration 19480, lr = 0.001
I0302 09:19:37.301372 29253 solver.cpp:237] Iteration 19500, loss = 0.00157779
I0302 09:19:37.301405 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00157779 (* 1 = 0.00157779 loss)
I0302 09:19:37.301414 29253 sgd_solver.cpp:106] Iteration 19500, lr = 0.001
I0302 09:20:06.077126 29253 solver.cpp:237] Iteration 19520, loss = 0.00124547
I0302 09:20:06.077158 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00124547 (* 1 = 0.00124547 loss)
I0302 09:20:06.077167 29253 sgd_solver.cpp:106] Iteration 19520, lr = 0.001
I0302 09:20:35.072656 29253 solver.cpp:237] Iteration 19540, loss = 0.00129492
I0302 09:20:35.072690 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00129493 (* 1 = 0.00129493 loss)
I0302 09:20:35.072700 29253 sgd_solver.cpp:106] Iteration 19540, lr = 0.001
I0302 09:21:03.805887 29253 solver.cpp:237] Iteration 19560, loss = 0.00191993
I0302 09:21:03.805920 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00191993 (* 1 = 0.00191993 loss)
I0302 09:21:03.805929 29253 sgd_solver.cpp:106] Iteration 19560, lr = 0.001
I0302 09:21:32.581785 29253 solver.cpp:237] Iteration 19580, loss = 0.00156008
I0302 09:21:32.581817 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00156008 (* 1 = 0.00156008 loss)
I0302 09:21:32.581825 29253 sgd_solver.cpp:106] Iteration 19580, lr = 0.001
I0302 09:22:01.488380 29253 solver.cpp:237] Iteration 19600, loss = 0.00174321
I0302 09:22:01.488412 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00174322 (* 1 = 0.00174322 loss)
I0302 09:22:01.488422 29253 sgd_solver.cpp:106] Iteration 19600, lr = 0.001
I0302 09:22:30.527794 29253 solver.cpp:237] Iteration 19620, loss = 0.00180607
I0302 09:22:30.527827 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00180607 (* 1 = 0.00180607 loss)
I0302 09:22:30.527835 29253 sgd_solver.cpp:106] Iteration 19620, lr = 0.001
I0302 09:22:59.579383 29253 solver.cpp:237] Iteration 19640, loss = 0.00231399
I0302 09:22:59.579416 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.002314 (* 1 = 0.002314 loss)
I0302 09:22:59.579423 29253 sgd_solver.cpp:106] Iteration 19640, lr = 0.001
I0302 09:23:28.602565 29253 solver.cpp:237] Iteration 19660, loss = 0.00142371
I0302 09:23:28.602596 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00142371 (* 1 = 0.00142371 loss)
I0302 09:23:28.602604 29253 sgd_solver.cpp:106] Iteration 19660, lr = 0.001
I0302 09:23:57.418995 29253 solver.cpp:237] Iteration 19680, loss = 0.00155797
I0302 09:23:57.419028 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00155798 (* 1 = 0.00155798 loss)
I0302 09:23:57.419037 29253 sgd_solver.cpp:106] Iteration 19680, lr = 0.001
I0302 09:24:26.424654 29253 solver.cpp:237] Iteration 19700, loss = 0.00153828
I0302 09:24:26.424688 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00153828 (* 1 = 0.00153828 loss)
I0302 09:24:26.424697 29253 sgd_solver.cpp:106] Iteration 19700, lr = 0.001
I0302 09:24:55.012564 29253 solver.cpp:237] Iteration 19720, loss = 0.0019001
I0302 09:24:55.012596 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00190011 (* 1 = 0.00190011 loss)
I0302 09:24:55.012604 29253 sgd_solver.cpp:106] Iteration 19720, lr = 0.001
I0302 09:25:24.283529 29253 solver.cpp:237] Iteration 19740, loss = 0.00138336
I0302 09:25:24.283560 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00138337 (* 1 = 0.00138337 loss)
I0302 09:25:24.283568 29253 sgd_solver.cpp:106] Iteration 19740, lr = 0.001
I0302 09:25:53.151444 29253 solver.cpp:237] Iteration 19760, loss = 0.00140723
I0302 09:25:53.151474 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00140723 (* 1 = 0.00140723 loss)
I0302 09:25:53.151484 29253 sgd_solver.cpp:106] Iteration 19760, lr = 0.001
I0302 09:26:22.114229 29253 solver.cpp:237] Iteration 19780, loss = 0.00159028
I0302 09:26:22.114262 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00159029 (* 1 = 0.00159029 loss)
I0302 09:26:22.114271 29253 sgd_solver.cpp:106] Iteration 19780, lr = 0.001
I0302 09:26:51.073185 29253 solver.cpp:237] Iteration 19800, loss = 0.00153086
I0302 09:26:51.073218 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00153087 (* 1 = 0.00153087 loss)
I0302 09:26:51.073227 29253 sgd_solver.cpp:106] Iteration 19800, lr = 0.001
I0302 09:27:20.000113 29253 solver.cpp:237] Iteration 19820, loss = 0.00179983
I0302 09:27:20.000145 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00179984 (* 1 = 0.00179984 loss)
I0302 09:27:20.000154 29253 sgd_solver.cpp:106] Iteration 19820, lr = 0.001
I0302 09:27:48.479884 29253 solver.cpp:237] Iteration 19840, loss = 0.00136482
I0302 09:27:48.479918 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00136483 (* 1 = 0.00136483 loss)
I0302 09:27:48.479925 29253 sgd_solver.cpp:106] Iteration 19840, lr = 0.001
I0302 09:28:17.641491 29253 solver.cpp:237] Iteration 19860, loss = 0.00131046
I0302 09:28:17.641525 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00131046 (* 1 = 0.00131046 loss)
I0302 09:28:17.641533 29253 sgd_solver.cpp:106] Iteration 19860, lr = 0.001
I0302 09:28:46.498875 29253 solver.cpp:237] Iteration 19880, loss = 0.00143535
I0302 09:28:46.498908 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00143536 (* 1 = 0.00143536 loss)
I0302 09:28:46.498917 29253 sgd_solver.cpp:106] Iteration 19880, lr = 0.001
I0302 09:29:15.631441 29253 solver.cpp:237] Iteration 19900, loss = 0.00175494
I0302 09:29:15.631474 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00175494 (* 1 = 0.00175494 loss)
I0302 09:29:15.631486 29253 sgd_solver.cpp:106] Iteration 19900, lr = 0.001
I0302 09:29:44.540309 29253 solver.cpp:237] Iteration 19920, loss = 0.00140614
I0302 09:29:44.540341 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00140614 (* 1 = 0.00140614 loss)
I0302 09:29:44.540350 29253 sgd_solver.cpp:106] Iteration 19920, lr = 0.001
I0302 09:30:13.280589 29253 solver.cpp:237] Iteration 19940, loss = 0.00149517
I0302 09:30:13.280622 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00149517 (* 1 = 0.00149517 loss)
I0302 09:30:13.280632 29253 sgd_solver.cpp:106] Iteration 19940, lr = 0.001
I0302 09:30:42.044050 29253 solver.cpp:237] Iteration 19960, loss = 0.00188714
I0302 09:30:42.044083 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00188714 (* 1 = 0.00188714 loss)
I0302 09:30:42.044091 29253 sgd_solver.cpp:106] Iteration 19960, lr = 0.001
I0302 09:31:11.055373 29253 solver.cpp:237] Iteration 19980, loss = 0.00171163
I0302 09:31:11.055408 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00171164 (* 1 = 0.00171164 loss)
I0302 09:31:11.055418 29253 sgd_solver.cpp:106] Iteration 19980, lr = 0.001
I0302 09:31:38.407582 29253 solver.cpp:459] Snapshotting to binary proto file /nfs.yoda/xiaolonw/fast_rcnn/models_sunrgbd/pre_cls_1fc_scratch/model__iter_20000.caffemodel
I0302 09:31:58.678766 29253 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /nfs.yoda/xiaolonw/fast_rcnn/models_sunrgbd/pre_cls_1fc_scratch/model__iter_20000.solverstate
I0302 09:31:59.057767 29253 solver.cpp:237] Iteration 20000, loss = 0.001551
I0302 09:31:59.057799 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00155101 (* 1 = 0.00155101 loss)
I0302 09:31:59.057808 29253 sgd_solver.cpp:106] Iteration 20000, lr = 0.0001
I0302 09:32:10.724550 29253 blocking_queue.cpp:50] Data layer prefetch queue empty
I0302 09:32:25.109073 29253 solver.cpp:237] Iteration 20020, loss = 0.00162993
I0302 09:32:25.109107 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00162993 (* 1 = 0.00162993 loss)
I0302 09:32:25.109117 29253 sgd_solver.cpp:106] Iteration 20020, lr = 0.0001
I0302 09:32:54.154183 29253 solver.cpp:237] Iteration 20040, loss = 0.00128494
I0302 09:32:54.154217 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00128494 (* 1 = 0.00128494 loss)
I0302 09:32:54.154224 29253 sgd_solver.cpp:106] Iteration 20040, lr = 0.0001
I0302 09:33:23.207806 29253 solver.cpp:237] Iteration 20060, loss = 0.00161203
I0302 09:33:23.207840 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00161203 (* 1 = 0.00161203 loss)
I0302 09:33:23.207849 29253 sgd_solver.cpp:106] Iteration 20060, lr = 0.0001
I0302 09:33:52.039577 29253 solver.cpp:237] Iteration 20080, loss = 0.00161653
I0302 09:33:52.039608 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00161653 (* 1 = 0.00161653 loss)
I0302 09:33:52.039615 29253 sgd_solver.cpp:106] Iteration 20080, lr = 0.0001
I0302 09:34:20.880156 29253 solver.cpp:237] Iteration 20100, loss = 0.00152714
I0302 09:34:20.880189 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00152714 (* 1 = 0.00152714 loss)
I0302 09:34:20.880198 29253 sgd_solver.cpp:106] Iteration 20100, lr = 0.0001
I0302 09:34:49.817431 29253 solver.cpp:237] Iteration 20120, loss = 0.0014063
I0302 09:34:49.817463 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0014063 (* 1 = 0.0014063 loss)
I0302 09:34:49.817472 29253 sgd_solver.cpp:106] Iteration 20120, lr = 0.0001
I0302 09:35:18.472718 29253 solver.cpp:237] Iteration 20140, loss = 0.00140486
I0302 09:35:18.472749 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00140486 (* 1 = 0.00140486 loss)
I0302 09:35:18.472759 29253 sgd_solver.cpp:106] Iteration 20140, lr = 0.0001
I0302 09:35:47.594152 29253 solver.cpp:237] Iteration 20160, loss = 0.001621
I0302 09:35:47.594185 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00162101 (* 1 = 0.00162101 loss)
I0302 09:35:47.594194 29253 sgd_solver.cpp:106] Iteration 20160, lr = 0.0001
I0302 09:36:16.342393 29253 solver.cpp:237] Iteration 20180, loss = 0.00209839
I0302 09:36:16.342427 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0020984 (* 1 = 0.0020984 loss)
I0302 09:36:16.342435 29253 sgd_solver.cpp:106] Iteration 20180, lr = 0.0001
I0302 09:36:45.076551 29253 solver.cpp:237] Iteration 20200, loss = 0.00187214
I0302 09:36:45.076583 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00187214 (* 1 = 0.00187214 loss)
I0302 09:36:45.076592 29253 sgd_solver.cpp:106] Iteration 20200, lr = 0.0001
I0302 09:37:14.147683 29253 solver.cpp:237] Iteration 20220, loss = 0.00161359
I0302 09:37:14.147714 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0016136 (* 1 = 0.0016136 loss)
I0302 09:37:14.147723 29253 sgd_solver.cpp:106] Iteration 20220, lr = 0.0001
I0302 09:37:42.824988 29253 solver.cpp:237] Iteration 20240, loss = 0.00189181
I0302 09:37:42.825021 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00189181 (* 1 = 0.00189181 loss)
I0302 09:37:42.825031 29253 sgd_solver.cpp:106] Iteration 20240, lr = 0.0001
I0302 09:38:11.818217 29253 solver.cpp:237] Iteration 20260, loss = 0.00151977
I0302 09:38:11.818246 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00151977 (* 1 = 0.00151977 loss)
I0302 09:38:11.818255 29253 sgd_solver.cpp:106] Iteration 20260, lr = 0.0001
I0302 09:38:40.985957 29253 solver.cpp:237] Iteration 20280, loss = 0.00168109
I0302 09:38:40.985991 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0016811 (* 1 = 0.0016811 loss)
I0302 09:38:40.985999 29253 sgd_solver.cpp:106] Iteration 20280, lr = 0.0001
I0302 09:39:09.870403 29253 solver.cpp:237] Iteration 20300, loss = 0.00227606
I0302 09:39:09.870434 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00227606 (* 1 = 0.00227606 loss)
I0302 09:39:09.870442 29253 sgd_solver.cpp:106] Iteration 20300, lr = 0.0001
I0302 09:39:38.688815 29253 solver.cpp:237] Iteration 20320, loss = 0.00164794
I0302 09:39:38.688848 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00164794 (* 1 = 0.00164794 loss)
I0302 09:39:38.688858 29253 sgd_solver.cpp:106] Iteration 20320, lr = 0.0001
I0302 09:40:07.793284 29253 solver.cpp:237] Iteration 20340, loss = 0.00165683
I0302 09:40:07.793315 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00165683 (* 1 = 0.00165683 loss)
I0302 09:40:07.793324 29253 sgd_solver.cpp:106] Iteration 20340, lr = 0.0001
I0302 09:40:36.690038 29253 solver.cpp:237] Iteration 20360, loss = 0.00166736
I0302 09:40:36.690071 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00166736 (* 1 = 0.00166736 loss)
I0302 09:40:36.690080 29253 sgd_solver.cpp:106] Iteration 20360, lr = 0.0001
I0302 09:41:05.809142 29253 solver.cpp:237] Iteration 20380, loss = 0.00144412
I0302 09:41:05.809175 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00144412 (* 1 = 0.00144412 loss)
I0302 09:41:05.809183 29253 sgd_solver.cpp:106] Iteration 20380, lr = 0.0001
I0302 09:41:34.580981 29253 solver.cpp:237] Iteration 20400, loss = 0.0016697
I0302 09:41:34.581013 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00166971 (* 1 = 0.00166971 loss)
I0302 09:41:34.581023 29253 sgd_solver.cpp:106] Iteration 20400, lr = 0.0001
I0302 09:42:03.210495 29253 solver.cpp:237] Iteration 20420, loss = 0.00152766
I0302 09:42:03.210527 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00152767 (* 1 = 0.00152767 loss)
I0302 09:42:03.210536 29253 sgd_solver.cpp:106] Iteration 20420, lr = 0.0001
I0302 09:42:31.965981 29253 solver.cpp:237] Iteration 20440, loss = 0.00148341
I0302 09:42:31.966012 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00148342 (* 1 = 0.00148342 loss)
I0302 09:42:31.966022 29253 sgd_solver.cpp:106] Iteration 20440, lr = 0.0001
I0302 09:43:01.101542 29253 solver.cpp:237] Iteration 20460, loss = 0.0013328
I0302 09:43:01.101574 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0013328 (* 1 = 0.0013328 loss)
I0302 09:43:01.101583 29253 sgd_solver.cpp:106] Iteration 20460, lr = 0.0001
I0302 09:43:30.044212 29253 solver.cpp:237] Iteration 20480, loss = 0.00141919
I0302 09:43:30.044245 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00141919 (* 1 = 0.00141919 loss)
I0302 09:43:30.044255 29253 sgd_solver.cpp:106] Iteration 20480, lr = 0.0001
I0302 09:43:58.739455 29253 solver.cpp:237] Iteration 20500, loss = 0.00223112
I0302 09:43:58.739488 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00223112 (* 1 = 0.00223112 loss)
I0302 09:43:58.739497 29253 sgd_solver.cpp:106] Iteration 20500, lr = 0.0001
I0302 09:44:27.813302 29253 solver.cpp:237] Iteration 20520, loss = 0.00131959
I0302 09:44:27.813334 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0013196 (* 1 = 0.0013196 loss)
I0302 09:44:27.813344 29253 sgd_solver.cpp:106] Iteration 20520, lr = 0.0001
I0302 09:44:56.710294 29253 solver.cpp:237] Iteration 20540, loss = 0.00194542
I0302 09:44:56.710325 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00194542 (* 1 = 0.00194542 loss)
I0302 09:44:56.710335 29253 sgd_solver.cpp:106] Iteration 20540, lr = 0.0001
I0302 09:45:25.586493 29253 solver.cpp:237] Iteration 20560, loss = 0.00164454
I0302 09:45:25.586526 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00164454 (* 1 = 0.00164454 loss)
I0302 09:45:25.586535 29253 sgd_solver.cpp:106] Iteration 20560, lr = 0.0001
I0302 09:45:54.546952 29253 solver.cpp:237] Iteration 20580, loss = 0.00135048
I0302 09:45:54.546984 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00135049 (* 1 = 0.00135049 loss)
I0302 09:45:54.546993 29253 sgd_solver.cpp:106] Iteration 20580, lr = 0.0001
I0302 09:46:23.392798 29253 solver.cpp:237] Iteration 20600, loss = 0.00146611
I0302 09:46:23.392830 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00146611 (* 1 = 0.00146611 loss)
I0302 09:46:23.392839 29253 sgd_solver.cpp:106] Iteration 20600, lr = 0.0001
I0302 09:46:52.184028 29253 solver.cpp:237] Iteration 20620, loss = 0.00150983
I0302 09:46:52.184061 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00150983 (* 1 = 0.00150983 loss)
I0302 09:46:52.184068 29253 sgd_solver.cpp:106] Iteration 20620, lr = 0.0001
I0302 09:47:21.110313 29253 solver.cpp:237] Iteration 20640, loss = 0.00174216
I0302 09:47:21.110344 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00174217 (* 1 = 0.00174217 loss)
I0302 09:47:21.110353 29253 sgd_solver.cpp:106] Iteration 20640, lr = 0.0001
I0302 09:47:50.083596 29253 solver.cpp:237] Iteration 20660, loss = 0.0015857
I0302 09:47:50.083627 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00158571 (* 1 = 0.00158571 loss)
I0302 09:47:50.083636 29253 sgd_solver.cpp:106] Iteration 20660, lr = 0.0001
I0302 09:48:18.758608 29253 solver.cpp:237] Iteration 20680, loss = 0.00145033
I0302 09:48:18.758641 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00145033 (* 1 = 0.00145033 loss)
I0302 09:48:18.758649 29253 sgd_solver.cpp:106] Iteration 20680, lr = 0.0001
I0302 09:48:47.590107 29253 solver.cpp:237] Iteration 20700, loss = 0.00167087
I0302 09:48:47.590139 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00167088 (* 1 = 0.00167088 loss)
I0302 09:48:47.590148 29253 sgd_solver.cpp:106] Iteration 20700, lr = 0.0001
I0302 09:49:16.434295 29253 solver.cpp:237] Iteration 20720, loss = 0.00159629
I0302 09:49:16.434326 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00159629 (* 1 = 0.00159629 loss)
I0302 09:49:16.434335 29253 sgd_solver.cpp:106] Iteration 20720, lr = 0.0001
I0302 09:49:45.586282 29253 solver.cpp:237] Iteration 20740, loss = 0.00159493
I0302 09:49:45.586313 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00159493 (* 1 = 0.00159493 loss)
I0302 09:49:45.586323 29253 sgd_solver.cpp:106] Iteration 20740, lr = 0.0001
I0302 09:50:14.301403 29253 solver.cpp:237] Iteration 20760, loss = 0.00141721
I0302 09:50:14.301434 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00141722 (* 1 = 0.00141722 loss)
I0302 09:50:14.301443 29253 sgd_solver.cpp:106] Iteration 20760, lr = 0.0001
I0302 09:50:43.275427 29253 solver.cpp:237] Iteration 20780, loss = 0.00143277
I0302 09:50:43.275460 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00143277 (* 1 = 0.00143277 loss)
I0302 09:50:43.275470 29253 sgd_solver.cpp:106] Iteration 20780, lr = 0.0001
I0302 09:51:12.070333 29253 solver.cpp:237] Iteration 20800, loss = 0.00166096
I0302 09:51:12.070364 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00166096 (* 1 = 0.00166096 loss)
I0302 09:51:12.070374 29253 sgd_solver.cpp:106] Iteration 20800, lr = 0.0001
I0302 09:51:41.023671 29253 solver.cpp:237] Iteration 20820, loss = 0.00184938
I0302 09:51:41.023705 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00184938 (* 1 = 0.00184938 loss)
I0302 09:51:41.023713 29253 sgd_solver.cpp:106] Iteration 20820, lr = 0.0001
I0302 09:52:09.843144 29253 solver.cpp:237] Iteration 20840, loss = 0.00161222
I0302 09:52:09.843176 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00161222 (* 1 = 0.00161222 loss)
I0302 09:52:09.843185 29253 sgd_solver.cpp:106] Iteration 20840, lr = 0.0001
I0302 09:52:38.692790 29253 solver.cpp:237] Iteration 20860, loss = 0.00161621
I0302 09:52:38.692821 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00161621 (* 1 = 0.00161621 loss)
I0302 09:52:38.692829 29253 sgd_solver.cpp:106] Iteration 20860, lr = 0.0001
I0302 09:53:07.670003 29253 solver.cpp:237] Iteration 20880, loss = 0.00166531
I0302 09:53:07.670035 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00166532 (* 1 = 0.00166532 loss)
I0302 09:53:07.670044 29253 sgd_solver.cpp:106] Iteration 20880, lr = 0.0001
I0302 09:53:36.756834 29253 solver.cpp:237] Iteration 20900, loss = 0.00178963
I0302 09:53:36.756865 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00178963 (* 1 = 0.00178963 loss)
I0302 09:53:36.756873 29253 sgd_solver.cpp:106] Iteration 20900, lr = 0.0001
I0302 09:54:05.590922 29253 solver.cpp:237] Iteration 20920, loss = 0.00172172
I0302 09:54:05.590955 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00172172 (* 1 = 0.00172172 loss)
I0302 09:54:05.590963 29253 sgd_solver.cpp:106] Iteration 20920, lr = 0.0001
I0302 09:54:34.657646 29253 solver.cpp:237] Iteration 20940, loss = 0.0014317
I0302 09:54:34.657678 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0014317 (* 1 = 0.0014317 loss)
I0302 09:54:34.657687 29253 sgd_solver.cpp:106] Iteration 20940, lr = 0.0001
I0302 09:55:03.339421 29253 solver.cpp:237] Iteration 20960, loss = 0.00131807
I0302 09:55:03.339452 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00131807 (* 1 = 0.00131807 loss)
I0302 09:55:03.339462 29253 sgd_solver.cpp:106] Iteration 20960, lr = 0.0001
I0302 09:55:32.323400 29253 solver.cpp:237] Iteration 20980, loss = 0.00133919
I0302 09:55:32.323432 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00133919 (* 1 = 0.00133919 loss)
I0302 09:55:32.323441 29253 sgd_solver.cpp:106] Iteration 20980, lr = 0.0001
I0302 09:56:01.116600 29253 solver.cpp:237] Iteration 21000, loss = 0.0012551
I0302 09:56:01.116632 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0012551 (* 1 = 0.0012551 loss)
I0302 09:56:01.116641 29253 sgd_solver.cpp:106] Iteration 21000, lr = 0.0001
I0302 09:56:15.556323 29253 blocking_queue.cpp:50] Data layer prefetch queue empty
I0302 09:56:29.907922 29253 solver.cpp:237] Iteration 21020, loss = 0.00196285
I0302 09:56:29.907953 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00196285 (* 1 = 0.00196285 loss)
I0302 09:56:29.907963 29253 sgd_solver.cpp:106] Iteration 21020, lr = 0.0001
I0302 09:56:58.834350 29253 solver.cpp:237] Iteration 21040, loss = 0.0012949
I0302 09:56:58.834384 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0012949 (* 1 = 0.0012949 loss)
I0302 09:56:58.834393 29253 sgd_solver.cpp:106] Iteration 21040, lr = 0.0001
I0302 09:57:27.778847 29253 solver.cpp:237] Iteration 21060, loss = 0.00212107
I0302 09:57:27.778880 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00212107 (* 1 = 0.00212107 loss)
I0302 09:57:27.778889 29253 sgd_solver.cpp:106] Iteration 21060, lr = 0.0001
I0302 09:57:56.770705 29253 solver.cpp:237] Iteration 21080, loss = 0.00162266
I0302 09:57:56.770737 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00162267 (* 1 = 0.00162267 loss)
I0302 09:57:56.770746 29253 sgd_solver.cpp:106] Iteration 21080, lr = 0.0001
I0302 09:58:25.616065 29253 solver.cpp:237] Iteration 21100, loss = 0.00231989
I0302 09:58:25.616097 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00231989 (* 1 = 0.00231989 loss)
I0302 09:58:25.616106 29253 sgd_solver.cpp:106] Iteration 21100, lr = 0.0001
I0302 09:58:54.535274 29253 solver.cpp:237] Iteration 21120, loss = 0.00163597
I0302 09:58:54.535305 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00163598 (* 1 = 0.00163598 loss)
I0302 09:58:54.535313 29253 sgd_solver.cpp:106] Iteration 21120, lr = 0.0001
I0302 09:59:23.386998 29253 solver.cpp:237] Iteration 21140, loss = 0.0019938
I0302 09:59:23.387032 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00199381 (* 1 = 0.00199381 loss)
I0302 09:59:23.387040 29253 sgd_solver.cpp:106] Iteration 21140, lr = 0.0001
I0302 09:59:52.429405 29253 solver.cpp:237] Iteration 21160, loss = 0.00157773
I0302 09:59:52.429438 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00157773 (* 1 = 0.00157773 loss)
I0302 09:59:52.429446 29253 sgd_solver.cpp:106] Iteration 21160, lr = 0.0001
I0302 10:00:21.357630 29253 solver.cpp:237] Iteration 21180, loss = 0.00185047
I0302 10:00:21.357663 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00185048 (* 1 = 0.00185048 loss)
I0302 10:00:21.357672 29253 sgd_solver.cpp:106] Iteration 21180, lr = 0.0001
I0302 10:00:50.321406 29253 solver.cpp:237] Iteration 21200, loss = 0.00142026
I0302 10:00:50.321440 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00142026 (* 1 = 0.00142026 loss)
I0302 10:00:50.321449 29253 sgd_solver.cpp:106] Iteration 21200, lr = 0.0001
I0302 10:01:19.318253 29253 solver.cpp:237] Iteration 21220, loss = 0.00209803
I0302 10:01:19.318284 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00209803 (* 1 = 0.00209803 loss)
I0302 10:01:19.318292 29253 sgd_solver.cpp:106] Iteration 21220, lr = 0.0001
I0302 10:01:48.167371 29253 solver.cpp:237] Iteration 21240, loss = 0.00179092
I0302 10:01:48.167402 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00179092 (* 1 = 0.00179092 loss)
I0302 10:01:48.167410 29253 sgd_solver.cpp:106] Iteration 21240, lr = 0.0001
I0302 10:02:17.091150 29253 solver.cpp:237] Iteration 21260, loss = 0.00122053
I0302 10:02:17.091183 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00122053 (* 1 = 0.00122053 loss)
I0302 10:02:17.091192 29253 sgd_solver.cpp:106] Iteration 21260, lr = 0.0001
I0302 10:02:46.053720 29253 solver.cpp:237] Iteration 21280, loss = 0.00155419
I0302 10:02:46.053752 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0015542 (* 1 = 0.0015542 loss)
I0302 10:02:46.053761 29253 sgd_solver.cpp:106] Iteration 21280, lr = 0.0001
I0302 10:03:14.907486 29253 solver.cpp:237] Iteration 21300, loss = 0.00140345
I0302 10:03:14.907517 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00140346 (* 1 = 0.00140346 loss)
I0302 10:03:14.907526 29253 sgd_solver.cpp:106] Iteration 21300, lr = 0.0001
I0302 10:03:43.604527 29253 solver.cpp:237] Iteration 21320, loss = 0.00224752
I0302 10:03:43.604560 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00224753 (* 1 = 0.00224753 loss)
I0302 10:03:43.604568 29253 sgd_solver.cpp:106] Iteration 21320, lr = 0.0001
I0302 10:04:12.500179 29253 solver.cpp:237] Iteration 21340, loss = 0.00185097
I0302 10:04:12.500211 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00185097 (* 1 = 0.00185097 loss)
I0302 10:04:12.500219 29253 sgd_solver.cpp:106] Iteration 21340, lr = 0.0001
I0302 10:04:41.369983 29253 solver.cpp:237] Iteration 21360, loss = 0.00151956
I0302 10:04:41.370015 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00151956 (* 1 = 0.00151956 loss)
I0302 10:04:41.370024 29253 sgd_solver.cpp:106] Iteration 21360, lr = 0.0001
I0302 10:05:10.370584 29253 solver.cpp:237] Iteration 21380, loss = 0.00177747
I0302 10:05:10.370615 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00177748 (* 1 = 0.00177748 loss)
I0302 10:05:10.370623 29253 sgd_solver.cpp:106] Iteration 21380, lr = 0.0001
I0302 10:05:39.578811 29253 solver.cpp:237] Iteration 21400, loss = 0.00140117
I0302 10:05:39.578843 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00140117 (* 1 = 0.00140117 loss)
I0302 10:05:39.578852 29253 sgd_solver.cpp:106] Iteration 21400, lr = 0.0001
I0302 10:06:08.453701 29253 solver.cpp:237] Iteration 21420, loss = 0.00147353
I0302 10:06:08.453734 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00147353 (* 1 = 0.00147353 loss)
I0302 10:06:08.453743 29253 sgd_solver.cpp:106] Iteration 21420, lr = 0.0001
I0302 10:06:37.191375 29253 solver.cpp:237] Iteration 21440, loss = 0.00210355
I0302 10:06:37.191406 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00210355 (* 1 = 0.00210355 loss)
I0302 10:06:37.191413 29253 sgd_solver.cpp:106] Iteration 21440, lr = 0.0001
I0302 10:07:06.206918 29253 solver.cpp:237] Iteration 21460, loss = 0.00173975
I0302 10:07:06.206950 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00173975 (* 1 = 0.00173975 loss)
I0302 10:07:06.206959 29253 sgd_solver.cpp:106] Iteration 21460, lr = 0.0001
I0302 10:07:35.159164 29253 solver.cpp:237] Iteration 21480, loss = 0.00176882
I0302 10:07:35.159196 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00176882 (* 1 = 0.00176882 loss)
I0302 10:07:35.159204 29253 sgd_solver.cpp:106] Iteration 21480, lr = 0.0001
I0302 10:08:04.021349 29253 solver.cpp:237] Iteration 21500, loss = 0.00174545
I0302 10:08:04.021380 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00174545 (* 1 = 0.00174545 loss)
I0302 10:08:04.021389 29253 sgd_solver.cpp:106] Iteration 21500, lr = 0.0001
I0302 10:08:32.843612 29253 solver.cpp:237] Iteration 21520, loss = 0.00236569
I0302 10:08:32.843646 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0023657 (* 1 = 0.0023657 loss)
I0302 10:08:32.843654 29253 sgd_solver.cpp:106] Iteration 21520, lr = 0.0001
I0302 10:09:01.768888 29253 solver.cpp:237] Iteration 21540, loss = 0.00146415
I0302 10:09:01.768920 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00146415 (* 1 = 0.00146415 loss)
I0302 10:09:01.768929 29253 sgd_solver.cpp:106] Iteration 21540, lr = 0.0001
I0302 10:09:30.843381 29253 solver.cpp:237] Iteration 21560, loss = 0.00159159
I0302 10:09:30.843413 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0015916 (* 1 = 0.0015916 loss)
I0302 10:09:30.843422 29253 sgd_solver.cpp:106] Iteration 21560, lr = 0.0001
I0302 10:09:59.893887 29253 solver.cpp:237] Iteration 21580, loss = 0.00164757
I0302 10:09:59.893918 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00164758 (* 1 = 0.00164758 loss)
I0302 10:09:59.893926 29253 sgd_solver.cpp:106] Iteration 21580, lr = 0.0001
I0302 10:10:28.744484 29253 solver.cpp:237] Iteration 21600, loss = 0.00129436
I0302 10:10:28.744518 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00129436 (* 1 = 0.00129436 loss)
I0302 10:10:28.744527 29253 sgd_solver.cpp:106] Iteration 21600, lr = 0.0001
I0302 10:10:57.708943 29253 solver.cpp:237] Iteration 21620, loss = 0.00184453
I0302 10:10:57.708976 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00184453 (* 1 = 0.00184453 loss)
I0302 10:10:57.708984 29253 sgd_solver.cpp:106] Iteration 21620, lr = 0.0001
I0302 10:11:27.083600 29253 solver.cpp:237] Iteration 21640, loss = 0.00189916
I0302 10:11:27.083632 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00189916 (* 1 = 0.00189916 loss)
I0302 10:11:27.083642 29253 sgd_solver.cpp:106] Iteration 21640, lr = 0.0001
I0302 10:11:55.850502 29253 solver.cpp:237] Iteration 21660, loss = 0.00211752
I0302 10:11:55.850538 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00211753 (* 1 = 0.00211753 loss)
I0302 10:11:55.850548 29253 sgd_solver.cpp:106] Iteration 21660, lr = 0.0001
I0302 10:12:24.801102 29253 solver.cpp:237] Iteration 21680, loss = 0.00164138
I0302 10:12:24.801136 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00164139 (* 1 = 0.00164139 loss)
I0302 10:12:24.801144 29253 sgd_solver.cpp:106] Iteration 21680, lr = 0.0001
I0302 10:12:53.669831 29253 solver.cpp:237] Iteration 21700, loss = 0.0020547
I0302 10:12:53.669862 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00205471 (* 1 = 0.00205471 loss)
I0302 10:12:53.669869 29253 sgd_solver.cpp:106] Iteration 21700, lr = 0.0001
I0302 10:13:22.698813 29253 solver.cpp:237] Iteration 21720, loss = 0.00170955
I0302 10:13:22.698848 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00170955 (* 1 = 0.00170955 loss)
I0302 10:13:22.698855 29253 sgd_solver.cpp:106] Iteration 21720, lr = 0.0001
I0302 10:13:51.829429 29253 solver.cpp:237] Iteration 21740, loss = 0.00148757
I0302 10:13:51.829463 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00148757 (* 1 = 0.00148757 loss)
I0302 10:13:51.829473 29253 sgd_solver.cpp:106] Iteration 21740, lr = 0.0001
I0302 10:14:20.519266 29253 solver.cpp:237] Iteration 21760, loss = 0.00167977
I0302 10:14:20.519299 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00167977 (* 1 = 0.00167977 loss)
I0302 10:14:20.519307 29253 sgd_solver.cpp:106] Iteration 21760, lr = 0.0001
I0302 10:14:49.541267 29253 solver.cpp:237] Iteration 21780, loss = 0.00142084
I0302 10:14:49.541301 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00142085 (* 1 = 0.00142085 loss)
I0302 10:14:49.541309 29253 sgd_solver.cpp:106] Iteration 21780, lr = 0.0001
I0302 10:15:18.379194 29253 solver.cpp:237] Iteration 21800, loss = 0.00168902
I0302 10:15:18.379226 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00168902 (* 1 = 0.00168902 loss)
I0302 10:15:18.379235 29253 sgd_solver.cpp:106] Iteration 21800, lr = 0.0001
I0302 10:15:47.455600 29253 solver.cpp:237] Iteration 21820, loss = 0.00174335
I0302 10:15:47.455634 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00174335 (* 1 = 0.00174335 loss)
I0302 10:15:47.455643 29253 sgd_solver.cpp:106] Iteration 21820, lr = 0.0001
I0302 10:16:16.367878 29253 solver.cpp:237] Iteration 21840, loss = 0.00157416
I0302 10:16:16.367911 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00157416 (* 1 = 0.00157416 loss)
I0302 10:16:16.367920 29253 sgd_solver.cpp:106] Iteration 21840, lr = 0.0001
I0302 10:16:45.231431 29253 solver.cpp:237] Iteration 21860, loss = 0.0018866
I0302 10:16:45.231463 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00188661 (* 1 = 0.00188661 loss)
I0302 10:16:45.231472 29253 sgd_solver.cpp:106] Iteration 21860, lr = 0.0001
I0302 10:17:14.060612 29253 solver.cpp:237] Iteration 21880, loss = 0.00162878
I0302 10:17:14.060645 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00162879 (* 1 = 0.00162879 loss)
I0302 10:17:14.060654 29253 sgd_solver.cpp:106] Iteration 21880, lr = 0.0001
I0302 10:17:42.915257 29253 solver.cpp:237] Iteration 21900, loss = 0.00136335
I0302 10:17:42.915289 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00136335 (* 1 = 0.00136335 loss)
I0302 10:17:42.915298 29253 sgd_solver.cpp:106] Iteration 21900, lr = 0.0001
I0302 10:18:11.870535 29253 solver.cpp:237] Iteration 21920, loss = 0.00164777
I0302 10:18:11.870566 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00164778 (* 1 = 0.00164778 loss)
I0302 10:18:11.870574 29253 sgd_solver.cpp:106] Iteration 21920, lr = 0.0001
I0302 10:18:40.831135 29253 solver.cpp:237] Iteration 21940, loss = 0.00160369
I0302 10:18:40.831168 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0016037 (* 1 = 0.0016037 loss)
I0302 10:18:40.831178 29253 sgd_solver.cpp:106] Iteration 21940, lr = 0.0001
I0302 10:19:09.826750 29253 solver.cpp:237] Iteration 21960, loss = 0.00190679
I0302 10:19:09.826782 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00190679 (* 1 = 0.00190679 loss)
I0302 10:19:09.826792 29253 sgd_solver.cpp:106] Iteration 21960, lr = 0.0001
I0302 10:19:38.877836 29253 solver.cpp:237] Iteration 21980, loss = 0.002686
I0302 10:19:38.877869 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.002686 (* 1 = 0.002686 loss)
I0302 10:19:38.877877 29253 sgd_solver.cpp:106] Iteration 21980, lr = 0.0001
I0302 10:20:07.972579 29253 solver.cpp:237] Iteration 22000, loss = 0.00176581
I0302 10:20:07.972612 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00176581 (* 1 = 0.00176581 loss)
I0302 10:20:07.972620 29253 sgd_solver.cpp:106] Iteration 22000, lr = 0.0001
I0302 10:20:22.431633 29253 blocking_queue.cpp:50] Data layer prefetch queue empty
I0302 10:20:36.859814 29253 solver.cpp:237] Iteration 22020, loss = 0.00209891
I0302 10:20:36.859849 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00209891 (* 1 = 0.00209891 loss)
I0302 10:20:36.859858 29253 sgd_solver.cpp:106] Iteration 22020, lr = 0.0001
I0302 10:21:05.866233 29253 solver.cpp:237] Iteration 22040, loss = 0.001571
I0302 10:21:05.866263 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.001571 (* 1 = 0.001571 loss)
I0302 10:21:05.866272 29253 sgd_solver.cpp:106] Iteration 22040, lr = 0.0001
I0302 10:21:34.708228 29253 solver.cpp:237] Iteration 22060, loss = 0.00157404
I0302 10:21:34.708261 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00157405 (* 1 = 0.00157405 loss)
I0302 10:21:34.708268 29253 sgd_solver.cpp:106] Iteration 22060, lr = 0.0001
I0302 10:22:03.733815 29253 solver.cpp:237] Iteration 22080, loss = 0.00179349
I0302 10:22:03.733847 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00179349 (* 1 = 0.00179349 loss)
I0302 10:22:03.733856 29253 sgd_solver.cpp:106] Iteration 22080, lr = 0.0001
I0302 10:22:32.266525 29253 solver.cpp:237] Iteration 22100, loss = 0.00161799
I0302 10:22:32.266558 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00161799 (* 1 = 0.00161799 loss)
I0302 10:22:32.266567 29253 sgd_solver.cpp:106] Iteration 22100, lr = 0.0001
I0302 10:23:01.478791 29253 solver.cpp:237] Iteration 22120, loss = 0.00135774
I0302 10:23:01.478823 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00135774 (* 1 = 0.00135774 loss)
I0302 10:23:01.478832 29253 sgd_solver.cpp:106] Iteration 22120, lr = 0.0001
I0302 10:23:30.147454 29253 solver.cpp:237] Iteration 22140, loss = 0.00147704
I0302 10:23:30.147487 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00147704 (* 1 = 0.00147704 loss)
I0302 10:23:30.147496 29253 sgd_solver.cpp:106] Iteration 22140, lr = 0.0001
I0302 10:23:59.135738 29253 solver.cpp:237] Iteration 22160, loss = 0.00144302
I0302 10:23:59.135771 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00144302 (* 1 = 0.00144302 loss)
I0302 10:23:59.135779 29253 sgd_solver.cpp:106] Iteration 22160, lr = 0.0001
I0302 10:24:28.093904 29253 solver.cpp:237] Iteration 22180, loss = 0.00161214
I0302 10:24:28.093933 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00161215 (* 1 = 0.00161215 loss)
I0302 10:24:28.093942 29253 sgd_solver.cpp:106] Iteration 22180, lr = 0.0001
I0302 10:24:57.032155 29253 solver.cpp:237] Iteration 22200, loss = 0.00208052
I0302 10:24:57.032186 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00208052 (* 1 = 0.00208052 loss)
I0302 10:24:57.032194 29253 sgd_solver.cpp:106] Iteration 22200, lr = 0.0001
I0302 10:25:26.023186 29253 solver.cpp:237] Iteration 22220, loss = 0.00186849
I0302 10:25:26.023217 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00186849 (* 1 = 0.00186849 loss)
I0302 10:25:26.023226 29253 sgd_solver.cpp:106] Iteration 22220, lr = 0.0001
I0302 10:25:54.830824 29253 solver.cpp:237] Iteration 22240, loss = 0.00175729
I0302 10:25:54.830859 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00175729 (* 1 = 0.00175729 loss)
I0302 10:25:54.830868 29253 sgd_solver.cpp:106] Iteration 22240, lr = 0.0001
I0302 10:26:23.822860 29253 solver.cpp:237] Iteration 22260, loss = 0.00142499
I0302 10:26:23.822892 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.001425 (* 1 = 0.001425 loss)
I0302 10:26:23.822901 29253 sgd_solver.cpp:106] Iteration 22260, lr = 0.0001
I0302 10:26:52.784037 29253 solver.cpp:237] Iteration 22280, loss = 0.00151574
I0302 10:26:52.784070 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00151575 (* 1 = 0.00151575 loss)
I0302 10:26:52.784078 29253 sgd_solver.cpp:106] Iteration 22280, lr = 0.0001
I0302 10:27:21.728801 29253 solver.cpp:237] Iteration 22300, loss = 0.00171635
I0302 10:27:21.728834 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00171635 (* 1 = 0.00171635 loss)
I0302 10:27:21.728843 29253 sgd_solver.cpp:106] Iteration 22300, lr = 0.0001
I0302 10:27:50.733238 29253 solver.cpp:237] Iteration 22320, loss = 0.00152048
I0302 10:27:50.733268 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00152048 (* 1 = 0.00152048 loss)
I0302 10:27:50.733276 29253 sgd_solver.cpp:106] Iteration 22320, lr = 0.0001
I0302 10:28:19.565161 29253 solver.cpp:237] Iteration 22340, loss = 0.00150388
I0302 10:28:19.565192 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00150388 (* 1 = 0.00150388 loss)
I0302 10:28:19.565201 29253 sgd_solver.cpp:106] Iteration 22340, lr = 0.0001
I0302 10:28:48.525822 29253 solver.cpp:237] Iteration 22360, loss = 0.0018979
I0302 10:28:48.525856 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00189791 (* 1 = 0.00189791 loss)
I0302 10:28:48.525864 29253 sgd_solver.cpp:106] Iteration 22360, lr = 0.0001
I0302 10:29:17.665556 29253 solver.cpp:237] Iteration 22380, loss = 0.00147343
I0302 10:29:17.665587 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00147343 (* 1 = 0.00147343 loss)
I0302 10:29:17.665596 29253 sgd_solver.cpp:106] Iteration 22380, lr = 0.0001
I0302 10:29:46.375241 29253 solver.cpp:237] Iteration 22400, loss = 0.00166159
I0302 10:29:46.375273 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00166159 (* 1 = 0.00166159 loss)
I0302 10:29:46.375283 29253 sgd_solver.cpp:106] Iteration 22400, lr = 0.0001
I0302 10:30:15.399056 29253 solver.cpp:237] Iteration 22420, loss = 0.00175223
I0302 10:30:15.399087 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00175224 (* 1 = 0.00175224 loss)
I0302 10:30:15.399096 29253 sgd_solver.cpp:106] Iteration 22420, lr = 0.0001
I0302 10:30:44.103754 29253 solver.cpp:237] Iteration 22440, loss = 0.00156047
I0302 10:30:44.103786 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00156047 (* 1 = 0.00156047 loss)
I0302 10:30:44.103796 29253 sgd_solver.cpp:106] Iteration 22440, lr = 0.0001
I0302 10:31:12.797922 29253 solver.cpp:237] Iteration 22460, loss = 0.00170372
I0302 10:31:12.797955 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00170372 (* 1 = 0.00170372 loss)
I0302 10:31:12.797963 29253 sgd_solver.cpp:106] Iteration 22460, lr = 0.0001
I0302 10:31:41.935947 29253 solver.cpp:237] Iteration 22480, loss = 0.00176575
I0302 10:31:41.935979 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00176575 (* 1 = 0.00176575 loss)
I0302 10:31:41.935989 29253 sgd_solver.cpp:106] Iteration 22480, lr = 0.0001
I0302 10:32:10.873909 29253 solver.cpp:237] Iteration 22500, loss = 0.00192716
I0302 10:32:10.873940 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00192717 (* 1 = 0.00192717 loss)
I0302 10:32:10.873950 29253 sgd_solver.cpp:106] Iteration 22500, lr = 0.0001
I0302 10:32:39.732758 29253 solver.cpp:237] Iteration 22520, loss = 0.00177327
I0302 10:32:39.732789 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00177327 (* 1 = 0.00177327 loss)
I0302 10:32:39.732797 29253 sgd_solver.cpp:106] Iteration 22520, lr = 0.0001
I0302 10:33:08.654578 29253 solver.cpp:237] Iteration 22540, loss = 0.00188186
I0302 10:33:08.654610 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00188186 (* 1 = 0.00188186 loss)
I0302 10:33:08.654619 29253 sgd_solver.cpp:106] Iteration 22540, lr = 0.0001
I0302 10:33:37.576905 29253 solver.cpp:237] Iteration 22560, loss = 0.00207544
I0302 10:33:37.576936 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00207545 (* 1 = 0.00207545 loss)
I0302 10:33:37.576946 29253 sgd_solver.cpp:106] Iteration 22560, lr = 0.0001
I0302 10:34:06.499766 29253 solver.cpp:237] Iteration 22580, loss = 0.0016354
I0302 10:34:06.499800 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0016354 (* 1 = 0.0016354 loss)
I0302 10:34:06.499809 29253 sgd_solver.cpp:106] Iteration 22580, lr = 0.0001
I0302 10:34:35.299914 29253 solver.cpp:237] Iteration 22600, loss = 0.00143384
I0302 10:34:35.299947 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00143384 (* 1 = 0.00143384 loss)
I0302 10:34:35.299955 29253 sgd_solver.cpp:106] Iteration 22600, lr = 0.0001
I0302 10:35:04.409471 29253 solver.cpp:237] Iteration 22620, loss = 0.00145976
I0302 10:35:04.409500 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00145976 (* 1 = 0.00145976 loss)
I0302 10:35:04.409509 29253 sgd_solver.cpp:106] Iteration 22620, lr = 0.0001
I0302 10:35:33.110827 29253 solver.cpp:237] Iteration 22640, loss = 0.00230247
I0302 10:35:33.110859 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00230247 (* 1 = 0.00230247 loss)
I0302 10:35:33.110868 29253 sgd_solver.cpp:106] Iteration 22640, lr = 0.0001
I0302 10:36:01.962437 29253 solver.cpp:237] Iteration 22660, loss = 0.0016808
I0302 10:36:01.962469 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00168081 (* 1 = 0.00168081 loss)
I0302 10:36:01.962478 29253 sgd_solver.cpp:106] Iteration 22660, lr = 0.0001
I0302 10:36:30.715827 29253 solver.cpp:237] Iteration 22680, loss = 0.00172885
I0302 10:36:30.715858 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00172885 (* 1 = 0.00172885 loss)
I0302 10:36:30.715867 29253 sgd_solver.cpp:106] Iteration 22680, lr = 0.0001
I0302 10:36:59.730449 29253 solver.cpp:237] Iteration 22700, loss = 0.00147269
I0302 10:36:59.730481 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0014727 (* 1 = 0.0014727 loss)
I0302 10:36:59.730490 29253 sgd_solver.cpp:106] Iteration 22700, lr = 0.0001
I0302 10:37:28.740483 29253 solver.cpp:237] Iteration 22720, loss = 0.00161393
I0302 10:37:28.740514 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00161393 (* 1 = 0.00161393 loss)
I0302 10:37:28.740522 29253 sgd_solver.cpp:106] Iteration 22720, lr = 0.0001
I0302 10:37:57.637234 29253 solver.cpp:237] Iteration 22740, loss = 0.00179182
I0302 10:37:57.637266 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00179182 (* 1 = 0.00179182 loss)
I0302 10:37:57.637275 29253 sgd_solver.cpp:106] Iteration 22740, lr = 0.0001
I0302 10:38:26.668236 29253 solver.cpp:237] Iteration 22760, loss = 0.00200029
I0302 10:38:26.668267 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00200029 (* 1 = 0.00200029 loss)
I0302 10:38:26.668274 29253 sgd_solver.cpp:106] Iteration 22760, lr = 0.0001
I0302 10:38:55.373078 29253 solver.cpp:237] Iteration 22780, loss = 0.0014377
I0302 10:38:55.373111 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0014377 (* 1 = 0.0014377 loss)
I0302 10:38:55.373119 29253 sgd_solver.cpp:106] Iteration 22780, lr = 0.0001
I0302 10:39:24.311425 29253 solver.cpp:237] Iteration 22800, loss = 0.00168074
I0302 10:39:24.311456 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00168074 (* 1 = 0.00168074 loss)
I0302 10:39:24.311465 29253 sgd_solver.cpp:106] Iteration 22800, lr = 0.0001
I0302 10:39:53.339962 29253 solver.cpp:237] Iteration 22820, loss = 0.00157795
I0302 10:39:53.339993 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00157795 (* 1 = 0.00157795 loss)
I0302 10:39:53.340003 29253 sgd_solver.cpp:106] Iteration 22820, lr = 0.0001
I0302 10:40:22.365321 29253 solver.cpp:237] Iteration 22840, loss = 0.0015909
I0302 10:40:22.365355 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0015909 (* 1 = 0.0015909 loss)
I0302 10:40:22.365362 29253 sgd_solver.cpp:106] Iteration 22840, lr = 0.0001
I0302 10:40:51.370081 29253 solver.cpp:237] Iteration 22860, loss = 0.00140557
I0302 10:40:51.370112 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00140557 (* 1 = 0.00140557 loss)
I0302 10:40:51.370121 29253 sgd_solver.cpp:106] Iteration 22860, lr = 0.0001
I0302 10:41:20.341624 29253 solver.cpp:237] Iteration 22880, loss = 0.00176335
I0302 10:41:20.341655 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00176335 (* 1 = 0.00176335 loss)
I0302 10:41:20.341665 29253 sgd_solver.cpp:106] Iteration 22880, lr = 0.0001
I0302 10:41:49.256366 29253 solver.cpp:237] Iteration 22900, loss = 0.00134546
I0302 10:41:49.256398 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00134546 (* 1 = 0.00134546 loss)
I0302 10:41:49.256407 29253 sgd_solver.cpp:106] Iteration 22900, lr = 0.0001
I0302 10:42:18.009603 29253 solver.cpp:237] Iteration 22920, loss = 0.00152913
I0302 10:42:18.009634 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00152913 (* 1 = 0.00152913 loss)
I0302 10:42:18.009642 29253 sgd_solver.cpp:106] Iteration 22920, lr = 0.0001
I0302 10:42:47.053980 29253 solver.cpp:237] Iteration 22940, loss = 0.00133823
I0302 10:42:47.054013 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00133823 (* 1 = 0.00133823 loss)
I0302 10:42:47.054020 29253 sgd_solver.cpp:106] Iteration 22940, lr = 0.0001
I0302 10:43:15.798244 29253 solver.cpp:237] Iteration 22960, loss = 0.00187939
I0302 10:43:15.798277 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0018794 (* 1 = 0.0018794 loss)
I0302 10:43:15.798286 29253 sgd_solver.cpp:106] Iteration 22960, lr = 0.0001
I0302 10:43:44.741350 29253 solver.cpp:237] Iteration 22980, loss = 0.0015839
I0302 10:43:44.741384 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00158391 (* 1 = 0.00158391 loss)
I0302 10:43:44.741392 29253 sgd_solver.cpp:106] Iteration 22980, lr = 0.0001
I0302 10:44:13.593703 29253 solver.cpp:237] Iteration 23000, loss = 0.00163815
I0302 10:44:13.593735 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00163816 (* 1 = 0.00163816 loss)
I0302 10:44:13.593745 29253 sgd_solver.cpp:106] Iteration 23000, lr = 0.0001
I0302 10:44:27.806535 29253 blocking_queue.cpp:50] Data layer prefetch queue empty
I0302 10:44:42.258469 29253 solver.cpp:237] Iteration 23020, loss = 0.00177797
I0302 10:44:42.258501 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00177798 (* 1 = 0.00177798 loss)
I0302 10:44:42.258508 29253 sgd_solver.cpp:106] Iteration 23020, lr = 0.0001
I0302 10:45:11.255928 29253 solver.cpp:237] Iteration 23040, loss = 0.00132845
I0302 10:45:11.255959 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00132845 (* 1 = 0.00132845 loss)
I0302 10:45:11.255967 29253 sgd_solver.cpp:106] Iteration 23040, lr = 0.0001
I0302 10:45:40.011059 29253 solver.cpp:237] Iteration 23060, loss = 0.00170996
I0302 10:45:40.011091 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00170997 (* 1 = 0.00170997 loss)
I0302 10:45:40.011099 29253 sgd_solver.cpp:106] Iteration 23060, lr = 0.0001
I0302 10:46:08.902282 29253 solver.cpp:237] Iteration 23080, loss = 0.00167923
I0302 10:46:08.902312 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00167923 (* 1 = 0.00167923 loss)
I0302 10:46:08.902323 29253 sgd_solver.cpp:106] Iteration 23080, lr = 0.0001
I0302 10:46:37.653218 29253 solver.cpp:237] Iteration 23100, loss = 0.00146684
I0302 10:46:37.653249 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00146684 (* 1 = 0.00146684 loss)
I0302 10:46:37.653259 29253 sgd_solver.cpp:106] Iteration 23100, lr = 0.0001
I0302 10:47:06.656342 29253 solver.cpp:237] Iteration 23120, loss = 0.00135273
I0302 10:47:06.656373 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00135273 (* 1 = 0.00135273 loss)
I0302 10:47:06.656383 29253 sgd_solver.cpp:106] Iteration 23120, lr = 0.0001
I0302 10:47:35.421794 29253 solver.cpp:237] Iteration 23140, loss = 0.00131962
I0302 10:47:35.421825 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00131963 (* 1 = 0.00131963 loss)
I0302 10:47:35.421833 29253 sgd_solver.cpp:106] Iteration 23140, lr = 0.0001
I0302 10:48:04.374594 29253 solver.cpp:237] Iteration 23160, loss = 0.00285463
I0302 10:48:04.374629 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00285464 (* 1 = 0.00285464 loss)
I0302 10:48:04.374639 29253 sgd_solver.cpp:106] Iteration 23160, lr = 0.0001
I0302 10:48:33.041195 29253 solver.cpp:237] Iteration 23180, loss = 0.0013731
I0302 10:48:33.041226 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0013731 (* 1 = 0.0013731 loss)
I0302 10:48:33.041235 29253 sgd_solver.cpp:106] Iteration 23180, lr = 0.0001
