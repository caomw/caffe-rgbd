Vendor:  Continuum Analytics, Inc.
Package: mkl
Message: trial mode expires in 10 days
Vendor:  Continuum Analytics, Inc.
Package: mkl
Message: trial mode expires in 10 days
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0302 01:27:40.205600 29253 solver.cpp:48] Initializing solver from parameters: 
base_lr: 0.01
display: 20
max_iter: 100000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 10000
snapshot: 5000
snapshot_prefix: "/nfs.yoda/xiaolonw/fast_rcnn/models_sunrgbd/pre_cls_1fc_scratch/model_"
solver_mode: GPU
net: "train.prototxt"
I0302 01:27:40.207401 29253 solver.cpp:91] Creating training net from net file: train.prototxt
I0302 01:27:40.208941 29253 net.cpp:49] Initializing net from parameters: 
name: "sungrbd"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: false
    crop_size: 128
    mean_value: 1
  }
  image_data_param {
    source: "/nfs/hn38/users/xiaolonw/sunrgbd/SUNRGBDtoolbox/trainlist2.txt"
    batch_size: 100
    shuffle: true
    new_height: 128
    new_width: 128
    root_folder: "/scratch/xiaolonw/sunrgbd/data/"
  }
}
layer {
  name: "da_conv1"
  type: "Convolution"
  bottom: "data"
  top: "da_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "da_conv1"
  top: "bn1"
}
layer {
  name: "da_relu1"
  type: "ReLU"
  bottom: "bn1"
  top: "bn1"
  relu_param {
    negative_slope: 0.2
  }
}
layer {
  name: "da_conv2"
  type: "Convolution"
  bottom: "bn1"
  top: "da_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 2
    kernel_size: 5
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "da_conv2"
  top: "bn2"
}
layer {
  name: "da_relu2"
  type: "ReLU"
  bottom: "bn2"
  top: "bn2"
  relu_param {
    negative_slope: 0.2
  }
}
layer {
  name: "da_conv3"
  type: "Convolution"
  bottom: "bn2"
  top: "da_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "da_conv3"
  top: "bn3"
}
layer {
  name: "da_relu3"
  type: "ReLU"
  bottom: "bn3"
  top: "bn3"
  relu_param {
    negative_slope: 0.2
  }
}
layer {
  name: "da_conv4"
  type: "Convolution"
  bottom: "bn3"
  top: "da_conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "da_conv4"
  top: "bn4"
}
layer {
  name: "da_relu4"
  type: "ReLU"
  bottom: "bn4"
  top: "bn4"
  relu_param {
    negative_slope: 0.2
  }
}
layer {
  name: "da_conv5"
  type: "Convolution"
  bottom: "bn4"
  top: "da_conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn5"
  type: "BatchNorm"
  bottom: "da_conv5"
  top: "bn5"
}
layer {
  name: "da_relu5"
  type: "ReLU"
  bottom: "bn5"
  top: "bn5"
  relu_param {
    negative_slope: 0.2
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "bn5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "cls_score"
  type: "InnerProduct"
  bottom: "pool5"
  top: "cls_score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 19
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss_cls"
  type: "SoftmaxWithLoss"
  bottom: "cls_score"
  bottom: "label"
  top: "loss_cls"
}
I0302 01:27:40.209038 29253 layer_factory.hpp:77] Creating layer data
I0302 01:27:40.209059 29253 net.cpp:106] Creating Layer data
I0302 01:27:40.209065 29253 net.cpp:411] data -> data
I0302 01:27:40.209081 29253 net.cpp:411] data -> label
I0302 01:27:40.209682 29253 image_data_layer.cpp:38] Opening file /nfs/hn38/users/xiaolonw/sunrgbd/SUNRGBDtoolbox/trainlist2.txt
I0302 01:27:40.281720 29253 image_data_layer.cpp:51] Shuffling data
I0302 01:27:40.282872 29253 image_data_layer.cpp:56] A total of 4845 images.
I0302 01:27:40.297765 29253 image_data_layer.cpp:84] output data size: 100,6,128,128
I0302 01:27:40.359657 29253 net.cpp:150] Setting up data
I0302 01:27:40.359699 29253 net.cpp:157] Top shape: 100 6 128 128 (9830400)
I0302 01:27:40.359707 29253 net.cpp:157] Top shape: 100 (100)
I0302 01:27:40.359710 29253 net.cpp:165] Memory required for data: 39322000
I0302 01:27:40.359719 29253 layer_factory.hpp:77] Creating layer da_conv1
I0302 01:27:40.359741 29253 net.cpp:106] Creating Layer da_conv1
I0302 01:27:40.359746 29253 net.cpp:454] da_conv1 <- data
I0302 01:27:40.359755 29253 net.cpp:411] da_conv1 -> da_conv1
I0302 01:27:40.361129 29253 net.cpp:150] Setting up da_conv1
I0302 01:27:40.361142 29253 net.cpp:157] Top shape: 100 64 64 64 (26214400)
I0302 01:27:40.361146 29253 net.cpp:165] Memory required for data: 144179600
I0302 01:27:40.361160 29253 layer_factory.hpp:77] Creating layer bn1
I0302 01:27:40.361169 29253 net.cpp:106] Creating Layer bn1
I0302 01:27:40.361174 29253 net.cpp:454] bn1 <- da_conv1
I0302 01:27:40.361181 29253 net.cpp:411] bn1 -> bn1
I0302 01:27:40.361408 29253 net.cpp:150] Setting up bn1
I0302 01:27:40.361418 29253 net.cpp:157] Top shape: 100 64 64 64 (26214400)
I0302 01:27:40.361420 29253 net.cpp:165] Memory required for data: 249037200
I0302 01:27:40.361435 29253 layer_factory.hpp:77] Creating layer da_relu1
I0302 01:27:40.361443 29253 net.cpp:106] Creating Layer da_relu1
I0302 01:27:40.361448 29253 net.cpp:454] da_relu1 <- bn1
I0302 01:27:40.361452 29253 net.cpp:397] da_relu1 -> bn1 (in-place)
I0302 01:27:40.361465 29253 net.cpp:150] Setting up da_relu1
I0302 01:27:40.361470 29253 net.cpp:157] Top shape: 100 64 64 64 (26214400)
I0302 01:27:40.361474 29253 net.cpp:165] Memory required for data: 353894800
I0302 01:27:40.361479 29253 layer_factory.hpp:77] Creating layer da_conv2
I0302 01:27:40.361488 29253 net.cpp:106] Creating Layer da_conv2
I0302 01:27:40.361492 29253 net.cpp:454] da_conv2 <- bn1
I0302 01:27:40.361498 29253 net.cpp:411] da_conv2 -> da_conv2
I0302 01:27:40.365769 29253 net.cpp:150] Setting up da_conv2
I0302 01:27:40.365783 29253 net.cpp:157] Top shape: 100 128 32 32 (13107200)
I0302 01:27:40.365787 29253 net.cpp:165] Memory required for data: 406323600
I0302 01:27:40.365793 29253 layer_factory.hpp:77] Creating layer bn2
I0302 01:27:40.365800 29253 net.cpp:106] Creating Layer bn2
I0302 01:27:40.365803 29253 net.cpp:454] bn2 <- da_conv2
I0302 01:27:40.365808 29253 net.cpp:411] bn2 -> bn2
I0302 01:27:40.365994 29253 net.cpp:150] Setting up bn2
I0302 01:27:40.366003 29253 net.cpp:157] Top shape: 100 128 32 32 (13107200)
I0302 01:27:40.366006 29253 net.cpp:165] Memory required for data: 458752400
I0302 01:27:40.366017 29253 layer_factory.hpp:77] Creating layer da_relu2
I0302 01:27:40.366025 29253 net.cpp:106] Creating Layer da_relu2
I0302 01:27:40.366030 29253 net.cpp:454] da_relu2 <- bn2
I0302 01:27:40.366034 29253 net.cpp:397] da_relu2 -> bn2 (in-place)
I0302 01:27:40.366042 29253 net.cpp:150] Setting up da_relu2
I0302 01:27:40.366046 29253 net.cpp:157] Top shape: 100 128 32 32 (13107200)
I0302 01:27:40.366050 29253 net.cpp:165] Memory required for data: 511181200
I0302 01:27:40.366053 29253 layer_factory.hpp:77] Creating layer da_conv3
I0302 01:27:40.366060 29253 net.cpp:106] Creating Layer da_conv3
I0302 01:27:40.366065 29253 net.cpp:454] da_conv3 <- bn2
I0302 01:27:40.366070 29253 net.cpp:411] da_conv3 -> da_conv3
I0302 01:27:40.372233 29253 net.cpp:150] Setting up da_conv3
I0302 01:27:40.372248 29253 net.cpp:157] Top shape: 100 256 16 16 (6553600)
I0302 01:27:40.372251 29253 net.cpp:165] Memory required for data: 537395600
I0302 01:27:40.372259 29253 layer_factory.hpp:77] Creating layer bn3
I0302 01:27:40.372267 29253 net.cpp:106] Creating Layer bn3
I0302 01:27:40.372272 29253 net.cpp:454] bn3 <- da_conv3
I0302 01:27:40.372277 29253 net.cpp:411] bn3 -> bn3
I0302 01:27:40.372454 29253 net.cpp:150] Setting up bn3
I0302 01:27:40.372462 29253 net.cpp:157] Top shape: 100 256 16 16 (6553600)
I0302 01:27:40.372467 29253 net.cpp:165] Memory required for data: 563610000
I0302 01:27:40.372474 29253 layer_factory.hpp:77] Creating layer da_relu3
I0302 01:27:40.372483 29253 net.cpp:106] Creating Layer da_relu3
I0302 01:27:40.372488 29253 net.cpp:454] da_relu3 <- bn3
I0302 01:27:40.372493 29253 net.cpp:397] da_relu3 -> bn3 (in-place)
I0302 01:27:40.372498 29253 net.cpp:150] Setting up da_relu3
I0302 01:27:40.372503 29253 net.cpp:157] Top shape: 100 256 16 16 (6553600)
I0302 01:27:40.372505 29253 net.cpp:165] Memory required for data: 589824400
I0302 01:27:40.372509 29253 layer_factory.hpp:77] Creating layer da_conv4
I0302 01:27:40.372515 29253 net.cpp:106] Creating Layer da_conv4
I0302 01:27:40.372519 29253 net.cpp:454] da_conv4 <- bn3
I0302 01:27:40.372524 29253 net.cpp:411] da_conv4 -> da_conv4
I0302 01:27:40.392678 29253 net.cpp:150] Setting up da_conv4
I0302 01:27:40.392695 29253 net.cpp:157] Top shape: 100 512 8 8 (3276800)
I0302 01:27:40.392699 29253 net.cpp:165] Memory required for data: 602931600
I0302 01:27:40.392710 29253 layer_factory.hpp:77] Creating layer bn4
I0302 01:27:40.392719 29253 net.cpp:106] Creating Layer bn4
I0302 01:27:40.392724 29253 net.cpp:454] bn4 <- da_conv4
I0302 01:27:40.392732 29253 net.cpp:411] bn4 -> bn4
I0302 01:27:40.392920 29253 net.cpp:150] Setting up bn4
I0302 01:27:40.392928 29253 net.cpp:157] Top shape: 100 512 8 8 (3276800)
I0302 01:27:40.392932 29253 net.cpp:165] Memory required for data: 616038800
I0302 01:27:40.392941 29253 layer_factory.hpp:77] Creating layer da_relu4
I0302 01:27:40.392948 29253 net.cpp:106] Creating Layer da_relu4
I0302 01:27:40.392953 29253 net.cpp:454] da_relu4 <- bn4
I0302 01:27:40.392957 29253 net.cpp:397] da_relu4 -> bn4 (in-place)
I0302 01:27:40.392966 29253 net.cpp:150] Setting up da_relu4
I0302 01:27:40.392971 29253 net.cpp:157] Top shape: 100 512 8 8 (3276800)
I0302 01:27:40.392973 29253 net.cpp:165] Memory required for data: 629146000
I0302 01:27:40.392976 29253 layer_factory.hpp:77] Creating layer da_conv5
I0302 01:27:40.392983 29253 net.cpp:106] Creating Layer da_conv5
I0302 01:27:40.392987 29253 net.cpp:454] da_conv5 <- bn4
I0302 01:27:40.392994 29253 net.cpp:411] da_conv5 -> da_conv5
I0302 01:27:40.403224 29253 net.cpp:150] Setting up da_conv5
I0302 01:27:40.403237 29253 net.cpp:157] Top shape: 100 128 8 8 (819200)
I0302 01:27:40.403240 29253 net.cpp:165] Memory required for data: 632422800
I0302 01:27:40.403247 29253 layer_factory.hpp:77] Creating layer bn5
I0302 01:27:40.403255 29253 net.cpp:106] Creating Layer bn5
I0302 01:27:40.403259 29253 net.cpp:454] bn5 <- da_conv5
I0302 01:27:40.403264 29253 net.cpp:411] bn5 -> bn5
I0302 01:27:40.403444 29253 net.cpp:150] Setting up bn5
I0302 01:27:40.403450 29253 net.cpp:157] Top shape: 100 128 8 8 (819200)
I0302 01:27:40.403455 29253 net.cpp:165] Memory required for data: 635699600
I0302 01:27:40.403463 29253 layer_factory.hpp:77] Creating layer da_relu5
I0302 01:27:40.403470 29253 net.cpp:106] Creating Layer da_relu5
I0302 01:27:40.403475 29253 net.cpp:454] da_relu5 <- bn5
I0302 01:27:40.403480 29253 net.cpp:397] da_relu5 -> bn5 (in-place)
I0302 01:27:40.403486 29253 net.cpp:150] Setting up da_relu5
I0302 01:27:40.403491 29253 net.cpp:157] Top shape: 100 128 8 8 (819200)
I0302 01:27:40.403493 29253 net.cpp:165] Memory required for data: 638976400
I0302 01:27:40.403496 29253 layer_factory.hpp:77] Creating layer pool5
I0302 01:27:40.403504 29253 net.cpp:106] Creating Layer pool5
I0302 01:27:40.403507 29253 net.cpp:454] pool5 <- bn5
I0302 01:27:40.403512 29253 net.cpp:411] pool5 -> pool5
I0302 01:27:40.403553 29253 net.cpp:150] Setting up pool5
I0302 01:27:40.403559 29253 net.cpp:157] Top shape: 100 128 4 4 (204800)
I0302 01:27:40.403563 29253 net.cpp:165] Memory required for data: 639795600
I0302 01:27:40.403565 29253 layer_factory.hpp:77] Creating layer cls_score
I0302 01:27:40.403578 29253 net.cpp:106] Creating Layer cls_score
I0302 01:27:40.403583 29253 net.cpp:454] cls_score <- pool5
I0302 01:27:40.403587 29253 net.cpp:411] cls_score -> cls_score
I0302 01:27:40.404788 29253 net.cpp:150] Setting up cls_score
I0302 01:27:40.404800 29253 net.cpp:157] Top shape: 100 19 (1900)
I0302 01:27:40.404803 29253 net.cpp:165] Memory required for data: 639803200
I0302 01:27:40.404811 29253 layer_factory.hpp:77] Creating layer loss_cls
I0302 01:27:40.404819 29253 net.cpp:106] Creating Layer loss_cls
I0302 01:27:40.404824 29253 net.cpp:454] loss_cls <- cls_score
I0302 01:27:40.404829 29253 net.cpp:454] loss_cls <- label
I0302 01:27:40.404834 29253 net.cpp:411] loss_cls -> loss_cls
I0302 01:27:40.404847 29253 layer_factory.hpp:77] Creating layer loss_cls
I0302 01:27:40.404937 29253 net.cpp:150] Setting up loss_cls
I0302 01:27:40.404943 29253 net.cpp:157] Top shape: (1)
I0302 01:27:40.404947 29253 net.cpp:160]     with loss weight 1
I0302 01:27:40.404955 29253 net.cpp:165] Memory required for data: 639803204
I0302 01:27:40.404959 29253 net.cpp:226] loss_cls needs backward computation.
I0302 01:27:40.404963 29253 net.cpp:226] cls_score needs backward computation.
I0302 01:27:40.404968 29253 net.cpp:226] pool5 needs backward computation.
I0302 01:27:40.404970 29253 net.cpp:226] da_relu5 needs backward computation.
I0302 01:27:40.404974 29253 net.cpp:226] bn5 needs backward computation.
I0302 01:27:40.404978 29253 net.cpp:226] da_conv5 needs backward computation.
I0302 01:27:40.404980 29253 net.cpp:226] da_relu4 needs backward computation.
I0302 01:27:40.404984 29253 net.cpp:226] bn4 needs backward computation.
I0302 01:27:40.404988 29253 net.cpp:226] da_conv4 needs backward computation.
I0302 01:27:40.404991 29253 net.cpp:226] da_relu3 needs backward computation.
I0302 01:27:40.404994 29253 net.cpp:226] bn3 needs backward computation.
I0302 01:27:40.404997 29253 net.cpp:226] da_conv3 needs backward computation.
I0302 01:27:40.405001 29253 net.cpp:226] da_relu2 needs backward computation.
I0302 01:27:40.405004 29253 net.cpp:226] bn2 needs backward computation.
I0302 01:27:40.405009 29253 net.cpp:226] da_conv2 needs backward computation.
I0302 01:27:40.405011 29253 net.cpp:226] da_relu1 needs backward computation.
I0302 01:27:40.405015 29253 net.cpp:226] bn1 needs backward computation.
I0302 01:27:40.405019 29253 net.cpp:226] da_conv1 needs backward computation.
I0302 01:27:40.405024 29253 net.cpp:228] data does not need backward computation.
I0302 01:27:40.405027 29253 net.cpp:270] This network produces output loss_cls
I0302 01:27:40.405045 29253 net.cpp:283] Network initialization done.
I0302 01:27:40.405107 29253 solver.cpp:60] Solver scaffolding done.
I0302 01:27:42.199970 29253 net.cpp:816] Ignoring source layer da_roi_pool5
I0302 01:27:42.199988 29253 net.cpp:816] Ignoring source layer da_fc6
I0302 01:27:42.199992 29253 net.cpp:816] Ignoring source layer bn6_2
I0302 01:27:42.199995 29253 net.cpp:816] Ignoring source layer da_relu6
I0302 01:27:42.199998 29253 net.cpp:816] Ignoring source layer da_drop6
I0302 01:27:42.200001 29253 net.cpp:816] Ignoring source layer da_fc7
I0302 01:27:42.200003 29253 net.cpp:816] Ignoring source layer bn7
I0302 01:27:42.200006 29253 net.cpp:816] Ignoring source layer da_relu7
I0302 01:27:42.200009 29253 net.cpp:816] Ignoring source layer da_drop7
I0302 01:27:42.200011 29253 net.cpp:816] Ignoring source layer bn7_da_drop7_0_split
I0302 01:27:42.200014 29253 net.cpp:816] Ignoring source layer da_cls_score
I0302 01:27:42.200016 29253 net.cpp:816] Ignoring source layer da_bbox_pred
I0302 01:27:42.200018 29253 net.cpp:816] Ignoring source layer da_loss_cls
I0302 01:27:42.200021 29253 net.cpp:816] Ignoring source layer da_loss_bbox
I0302 01:27:42.435448 29253 solver.cpp:237] Iteration 0, loss = 3.16784
I0302 01:27:42.435482 29253 solver.cpp:253]     Train net output #0: loss_cls = 3.16784 (* 1 = 3.16784 loss)
I0302 01:27:42.435492 29253 sgd_solver.cpp:106] Iteration 0, lr = 0.01
I0302 01:27:42.437265 29253 blocking_queue.cpp:50] Data layer prefetch queue empty
I0302 01:28:11.536866 29253 solver.cpp:237] Iteration 20, loss = 4.66288
I0302 01:28:11.536896 29253 solver.cpp:253]     Train net output #0: loss_cls = 4.66288 (* 1 = 4.66288 loss)
I0302 01:28:11.536905 29253 sgd_solver.cpp:106] Iteration 20, lr = 0.01
I0302 01:28:41.386526 29253 solver.cpp:237] Iteration 40, loss = 2.2039
I0302 01:28:41.386557 29253 solver.cpp:253]     Train net output #0: loss_cls = 2.2039 (* 1 = 2.2039 loss)
I0302 01:28:41.386565 29253 sgd_solver.cpp:106] Iteration 40, lr = 0.01
I0302 01:29:10.787991 29253 solver.cpp:237] Iteration 60, loss = 2.01626
I0302 01:29:10.788022 29253 solver.cpp:253]     Train net output #0: loss_cls = 2.01626 (* 1 = 2.01626 loss)
I0302 01:29:10.788029 29253 sgd_solver.cpp:106] Iteration 60, lr = 0.01
I0302 01:29:39.820272 29253 solver.cpp:237] Iteration 80, loss = 2.07329
I0302 01:29:39.820302 29253 solver.cpp:253]     Train net output #0: loss_cls = 2.07329 (* 1 = 2.07329 loss)
I0302 01:29:39.820312 29253 sgd_solver.cpp:106] Iteration 80, lr = 0.01
I0302 01:30:08.727838 29253 solver.cpp:237] Iteration 100, loss = 1.90712
I0302 01:30:08.727869 29253 solver.cpp:253]     Train net output #0: loss_cls = 1.90712 (* 1 = 1.90712 loss)
I0302 01:30:08.727877 29253 sgd_solver.cpp:106] Iteration 100, lr = 0.01
I0302 01:30:37.756769 29253 solver.cpp:237] Iteration 120, loss = 1.64091
I0302 01:30:37.756801 29253 solver.cpp:253]     Train net output #0: loss_cls = 1.64091 (* 1 = 1.64091 loss)
I0302 01:30:37.756809 29253 sgd_solver.cpp:106] Iteration 120, lr = 0.01
I0302 01:31:06.738243 29253 solver.cpp:237] Iteration 140, loss = 1.80336
I0302 01:31:06.738272 29253 solver.cpp:253]     Train net output #0: loss_cls = 1.80336 (* 1 = 1.80336 loss)
I0302 01:31:06.738281 29253 sgd_solver.cpp:106] Iteration 140, lr = 0.01
I0302 01:31:35.623497 29253 solver.cpp:237] Iteration 160, loss = 1.45966
I0302 01:31:35.623528 29253 solver.cpp:253]     Train net output #0: loss_cls = 1.45966 (* 1 = 1.45966 loss)
I0302 01:31:35.623536 29253 sgd_solver.cpp:106] Iteration 160, lr = 0.01
I0302 01:32:04.292593 29253 solver.cpp:237] Iteration 180, loss = 1.46739
I0302 01:32:04.292624 29253 solver.cpp:253]     Train net output #0: loss_cls = 1.46739 (* 1 = 1.46739 loss)
I0302 01:32:04.292636 29253 sgd_solver.cpp:106] Iteration 180, lr = 0.01
I0302 01:32:33.374837 29253 solver.cpp:237] Iteration 200, loss = 1.35356
I0302 01:32:33.374866 29253 solver.cpp:253]     Train net output #0: loss_cls = 1.35356 (* 1 = 1.35356 loss)
I0302 01:32:33.374876 29253 sgd_solver.cpp:106] Iteration 200, lr = 0.01
I0302 01:33:02.290057 29253 solver.cpp:237] Iteration 220, loss = 1.43655
I0302 01:33:02.290087 29253 solver.cpp:253]     Train net output #0: loss_cls = 1.43655 (* 1 = 1.43655 loss)
I0302 01:33:02.290096 29253 sgd_solver.cpp:106] Iteration 220, lr = 0.01
I0302 01:33:31.123045 29253 solver.cpp:237] Iteration 240, loss = 1.73474
I0302 01:33:31.123075 29253 solver.cpp:253]     Train net output #0: loss_cls = 1.73474 (* 1 = 1.73474 loss)
I0302 01:33:31.123085 29253 sgd_solver.cpp:106] Iteration 240, lr = 0.01
I0302 01:33:59.958238 29253 solver.cpp:237] Iteration 260, loss = 1.23256
I0302 01:33:59.958268 29253 solver.cpp:253]     Train net output #0: loss_cls = 1.23256 (* 1 = 1.23256 loss)
I0302 01:33:59.958277 29253 sgd_solver.cpp:106] Iteration 260, lr = 0.01
I0302 01:34:29.051833 29253 solver.cpp:237] Iteration 280, loss = 1.19891
I0302 01:34:29.051865 29253 solver.cpp:253]     Train net output #0: loss_cls = 1.19891 (* 1 = 1.19891 loss)
I0302 01:34:29.051873 29253 sgd_solver.cpp:106] Iteration 280, lr = 0.01
I0302 01:34:57.714675 29253 solver.cpp:237] Iteration 300, loss = 1.04689
I0302 01:34:57.714707 29253 solver.cpp:253]     Train net output #0: loss_cls = 1.04689 (* 1 = 1.04689 loss)
I0302 01:34:57.714717 29253 sgd_solver.cpp:106] Iteration 300, lr = 0.01
I0302 01:35:26.755158 29253 solver.cpp:237] Iteration 320, loss = 1.19219
I0302 01:35:26.755188 29253 solver.cpp:253]     Train net output #0: loss_cls = 1.19219 (* 1 = 1.19219 loss)
I0302 01:35:26.755197 29253 sgd_solver.cpp:106] Iteration 320, lr = 0.01
I0302 01:35:55.731731 29253 solver.cpp:237] Iteration 340, loss = 0.97967
I0302 01:35:55.731762 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.97967 (* 1 = 0.97967 loss)
I0302 01:35:55.731771 29253 sgd_solver.cpp:106] Iteration 340, lr = 0.01
I0302 01:36:24.663491 29253 solver.cpp:237] Iteration 360, loss = 0.868895
I0302 01:36:24.663521 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.868895 (* 1 = 0.868895 loss)
I0302 01:36:24.663528 29253 sgd_solver.cpp:106] Iteration 360, lr = 0.01
I0302 01:36:53.414307 29253 solver.cpp:237] Iteration 380, loss = 1.27038
I0302 01:36:53.414340 29253 solver.cpp:253]     Train net output #0: loss_cls = 1.27038 (* 1 = 1.27038 loss)
I0302 01:36:53.414348 29253 sgd_solver.cpp:106] Iteration 380, lr = 0.01
I0302 01:37:22.301221 29253 solver.cpp:237] Iteration 400, loss = 0.737602
I0302 01:37:22.301252 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.737602 (* 1 = 0.737602 loss)
I0302 01:37:22.301261 29253 sgd_solver.cpp:106] Iteration 400, lr = 0.01
I0302 01:37:51.314324 29253 solver.cpp:237] Iteration 420, loss = 0.833788
I0302 01:37:51.314357 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.833788 (* 1 = 0.833788 loss)
I0302 01:37:51.314365 29253 sgd_solver.cpp:106] Iteration 420, lr = 0.01
I0302 01:38:20.003123 29253 solver.cpp:237] Iteration 440, loss = 0.758669
I0302 01:38:20.003155 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.758669 (* 1 = 0.758669 loss)
I0302 01:38:20.003165 29253 sgd_solver.cpp:106] Iteration 440, lr = 0.01
I0302 01:38:49.025081 29253 solver.cpp:237] Iteration 460, loss = 0.536218
I0302 01:38:49.025112 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.536218 (* 1 = 0.536218 loss)
I0302 01:38:49.025121 29253 sgd_solver.cpp:106] Iteration 460, lr = 0.01
I0302 01:39:18.152137 29253 solver.cpp:237] Iteration 480, loss = 0.881449
I0302 01:39:18.152169 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.881449 (* 1 = 0.881449 loss)
I0302 01:39:18.152179 29253 sgd_solver.cpp:106] Iteration 480, lr = 0.01
I0302 01:39:47.084761 29253 solver.cpp:237] Iteration 500, loss = 0.396941
I0302 01:39:47.084794 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.396941 (* 1 = 0.396941 loss)
I0302 01:39:47.084802 29253 sgd_solver.cpp:106] Iteration 500, lr = 0.01
I0302 01:40:16.122215 29253 solver.cpp:237] Iteration 520, loss = 0.594515
I0302 01:40:16.122246 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.594515 (* 1 = 0.594515 loss)
I0302 01:40:16.122254 29253 sgd_solver.cpp:106] Iteration 520, lr = 0.01
I0302 01:40:44.978704 29253 solver.cpp:237] Iteration 540, loss = 0.403991
I0302 01:40:44.978739 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.403991 (* 1 = 0.403991 loss)
I0302 01:40:44.978746 29253 sgd_solver.cpp:106] Iteration 540, lr = 0.01
I0302 01:41:13.607704 29253 solver.cpp:237] Iteration 560, loss = 0.39287
I0302 01:41:13.607738 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.39287 (* 1 = 0.39287 loss)
I0302 01:41:13.607748 29253 sgd_solver.cpp:106] Iteration 560, lr = 0.01
I0302 01:41:42.861737 29253 solver.cpp:237] Iteration 580, loss = 0.504868
I0302 01:41:42.861768 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.504868 (* 1 = 0.504868 loss)
I0302 01:41:42.861776 29253 sgd_solver.cpp:106] Iteration 580, lr = 0.01
I0302 01:42:11.750022 29253 solver.cpp:237] Iteration 600, loss = 0.303206
I0302 01:42:11.750053 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.303206 (* 1 = 0.303206 loss)
I0302 01:42:11.750062 29253 sgd_solver.cpp:106] Iteration 600, lr = 0.01
I0302 01:42:40.744731 29253 solver.cpp:237] Iteration 620, loss = 0.344103
I0302 01:42:40.744762 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.344103 (* 1 = 0.344103 loss)
I0302 01:42:40.744771 29253 sgd_solver.cpp:106] Iteration 620, lr = 0.01
I0302 01:43:09.571292 29253 solver.cpp:237] Iteration 640, loss = 0.196338
I0302 01:43:09.571322 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.196338 (* 1 = 0.196338 loss)
I0302 01:43:09.571331 29253 sgd_solver.cpp:106] Iteration 640, lr = 0.01
I0302 01:43:38.405042 29253 solver.cpp:237] Iteration 660, loss = 0.214922
I0302 01:43:38.405073 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.214922 (* 1 = 0.214922 loss)
I0302 01:43:38.405082 29253 sgd_solver.cpp:106] Iteration 660, lr = 0.01
I0302 01:44:07.545491 29253 solver.cpp:237] Iteration 680, loss = 0.163461
I0302 01:44:07.545523 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.163461 (* 1 = 0.163461 loss)
I0302 01:44:07.545532 29253 sgd_solver.cpp:106] Iteration 680, lr = 0.01
I0302 01:44:36.602617 29253 solver.cpp:237] Iteration 700, loss = 0.129409
I0302 01:44:36.602648 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.129409 (* 1 = 0.129409 loss)
I0302 01:44:36.602655 29253 sgd_solver.cpp:106] Iteration 700, lr = 0.01
I0302 01:45:05.389755 29253 solver.cpp:237] Iteration 720, loss = 0.208933
I0302 01:45:05.389788 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.208933 (* 1 = 0.208933 loss)
I0302 01:45:05.389797 29253 sgd_solver.cpp:106] Iteration 720, lr = 0.01
I0302 01:45:34.206262 29253 solver.cpp:237] Iteration 740, loss = 0.0714457
I0302 01:45:34.206295 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0714457 (* 1 = 0.0714457 loss)
I0302 01:45:34.206303 29253 sgd_solver.cpp:106] Iteration 740, lr = 0.01
I0302 01:46:03.532380 29253 solver.cpp:237] Iteration 760, loss = 0.0851108
I0302 01:46:03.532410 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0851108 (* 1 = 0.0851108 loss)
I0302 01:46:03.532419 29253 sgd_solver.cpp:106] Iteration 760, lr = 0.01
I0302 01:46:32.030834 29253 solver.cpp:237] Iteration 780, loss = 0.0660984
I0302 01:46:32.030867 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0660984 (* 1 = 0.0660984 loss)
I0302 01:46:32.030876 29253 sgd_solver.cpp:106] Iteration 780, lr = 0.01
I0302 01:47:00.863612 29253 solver.cpp:237] Iteration 800, loss = 0.0746889
I0302 01:47:00.863644 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0746889 (* 1 = 0.0746889 loss)
I0302 01:47:00.863653 29253 sgd_solver.cpp:106] Iteration 800, lr = 0.01
I0302 01:47:30.019556 29253 solver.cpp:237] Iteration 820, loss = 0.0658488
I0302 01:47:30.019584 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0658488 (* 1 = 0.0658488 loss)
I0302 01:47:30.019593 29253 sgd_solver.cpp:106] Iteration 820, lr = 0.01
I0302 01:47:59.439158 29253 solver.cpp:237] Iteration 840, loss = 0.0575065
I0302 01:47:59.439189 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0575065 (* 1 = 0.0575065 loss)
I0302 01:47:59.439198 29253 sgd_solver.cpp:106] Iteration 840, lr = 0.01
I0302 01:48:28.643836 29253 solver.cpp:237] Iteration 860, loss = 0.0368487
I0302 01:48:28.643865 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0368487 (* 1 = 0.0368487 loss)
I0302 01:48:28.643873 29253 sgd_solver.cpp:106] Iteration 860, lr = 0.01
I0302 01:48:57.717082 29253 solver.cpp:237] Iteration 880, loss = 0.0419689
I0302 01:48:57.717113 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0419689 (* 1 = 0.0419689 loss)
I0302 01:48:57.717120 29253 sgd_solver.cpp:106] Iteration 880, lr = 0.01
I0302 01:49:26.716087 29253 solver.cpp:237] Iteration 900, loss = 0.0333664
I0302 01:49:26.716120 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0333664 (* 1 = 0.0333664 loss)
I0302 01:49:26.716127 29253 sgd_solver.cpp:106] Iteration 900, lr = 0.01
I0302 01:49:55.775532 29253 solver.cpp:237] Iteration 920, loss = 0.0308203
I0302 01:49:55.775565 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0308203 (* 1 = 0.0308203 loss)
I0302 01:49:55.775573 29253 sgd_solver.cpp:106] Iteration 920, lr = 0.01
I0302 01:50:24.514292 29253 solver.cpp:237] Iteration 940, loss = 0.0294081
I0302 01:50:24.514323 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0294081 (* 1 = 0.0294081 loss)
I0302 01:50:24.514333 29253 sgd_solver.cpp:106] Iteration 940, lr = 0.01
I0302 01:50:53.579829 29253 solver.cpp:237] Iteration 960, loss = 0.0323825
I0302 01:50:53.579859 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0323825 (* 1 = 0.0323825 loss)
I0302 01:50:53.579867 29253 sgd_solver.cpp:106] Iteration 960, lr = 0.01
I0302 01:51:22.229770 29253 solver.cpp:237] Iteration 980, loss = 0.0190541
I0302 01:51:22.229804 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0190541 (* 1 = 0.0190541 loss)
I0302 01:51:22.229811 29253 sgd_solver.cpp:106] Iteration 980, lr = 0.01
I0302 01:51:50.720405 29253 solver.cpp:237] Iteration 1000, loss = 0.0229456
I0302 01:51:50.720439 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0229456 (* 1 = 0.0229456 loss)
I0302 01:51:50.720449 29253 sgd_solver.cpp:106] Iteration 1000, lr = 0.01
I0302 01:51:50.721529 29253 blocking_queue.cpp:50] Data layer prefetch queue empty
I0302 01:52:19.787178 29253 solver.cpp:237] Iteration 1020, loss = 0.0232893
I0302 01:52:19.787209 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0232893 (* 1 = 0.0232893 loss)
I0302 01:52:19.787219 29253 sgd_solver.cpp:106] Iteration 1020, lr = 0.01
I0302 01:52:49.329103 29253 solver.cpp:237] Iteration 1040, loss = 0.0154973
I0302 01:52:49.329134 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0154973 (* 1 = 0.0154973 loss)
I0302 01:52:49.329143 29253 sgd_solver.cpp:106] Iteration 1040, lr = 0.01
I0302 01:53:18.220805 29253 solver.cpp:237] Iteration 1060, loss = 0.0172496
I0302 01:53:18.220839 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0172496 (* 1 = 0.0172496 loss)
I0302 01:53:18.220846 29253 sgd_solver.cpp:106] Iteration 1060, lr = 0.01
I0302 01:53:46.970619 29253 solver.cpp:237] Iteration 1080, loss = 0.0162133
I0302 01:53:46.970651 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0162133 (* 1 = 0.0162133 loss)
I0302 01:53:46.970659 29253 sgd_solver.cpp:106] Iteration 1080, lr = 0.01
I0302 01:54:15.582049 29253 solver.cpp:237] Iteration 1100, loss = 0.0153251
I0302 01:54:15.582082 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0153251 (* 1 = 0.0153251 loss)
I0302 01:54:15.582092 29253 sgd_solver.cpp:106] Iteration 1100, lr = 0.01
I0302 01:54:44.681769 29253 solver.cpp:237] Iteration 1120, loss = 0.0171527
I0302 01:54:44.681800 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0171527 (* 1 = 0.0171527 loss)
I0302 01:54:44.681809 29253 sgd_solver.cpp:106] Iteration 1120, lr = 0.01
I0302 01:55:13.612710 29253 solver.cpp:237] Iteration 1140, loss = 0.0190801
I0302 01:55:13.612740 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0190801 (* 1 = 0.0190801 loss)
I0302 01:55:13.612749 29253 sgd_solver.cpp:106] Iteration 1140, lr = 0.01
I0302 01:55:42.710567 29253 solver.cpp:237] Iteration 1160, loss = 0.0205997
I0302 01:55:42.710599 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0205997 (* 1 = 0.0205997 loss)
I0302 01:55:42.710608 29253 sgd_solver.cpp:106] Iteration 1160, lr = 0.01
I0302 01:56:11.429803 29253 solver.cpp:237] Iteration 1180, loss = 0.0151865
I0302 01:56:11.429836 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0151865 (* 1 = 0.0151865 loss)
I0302 01:56:11.429843 29253 sgd_solver.cpp:106] Iteration 1180, lr = 0.01
I0302 01:56:40.563730 29253 solver.cpp:237] Iteration 1200, loss = 0.0140197
I0302 01:56:40.563760 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0140197 (* 1 = 0.0140197 loss)
I0302 01:56:40.563771 29253 sgd_solver.cpp:106] Iteration 1200, lr = 0.01
I0302 01:57:09.277946 29253 solver.cpp:237] Iteration 1220, loss = 0.00919977
I0302 01:57:09.277978 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00919977 (* 1 = 0.00919977 loss)
I0302 01:57:09.277988 29253 sgd_solver.cpp:106] Iteration 1220, lr = 0.01
I0302 01:57:38.459211 29253 solver.cpp:237] Iteration 1240, loss = 0.0145794
I0302 01:57:38.459242 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0145794 (* 1 = 0.0145794 loss)
I0302 01:57:38.459250 29253 sgd_solver.cpp:106] Iteration 1240, lr = 0.01
I0302 01:58:07.206696 29253 solver.cpp:237] Iteration 1260, loss = 0.0128654
I0302 01:58:07.206727 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0128654 (* 1 = 0.0128654 loss)
I0302 01:58:07.206737 29253 sgd_solver.cpp:106] Iteration 1260, lr = 0.01
I0302 01:58:36.284234 29253 solver.cpp:237] Iteration 1280, loss = 0.0111093
I0302 01:58:36.284265 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0111093 (* 1 = 0.0111093 loss)
I0302 01:58:36.284273 29253 sgd_solver.cpp:106] Iteration 1280, lr = 0.01
I0302 01:59:04.988258 29253 solver.cpp:237] Iteration 1300, loss = 0.0151126
I0302 01:59:04.988288 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0151126 (* 1 = 0.0151126 loss)
I0302 01:59:04.988298 29253 sgd_solver.cpp:106] Iteration 1300, lr = 0.01
I0302 01:59:34.145231 29253 solver.cpp:237] Iteration 1320, loss = 0.0110464
I0302 01:59:34.145263 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0110464 (* 1 = 0.0110464 loss)
I0302 01:59:34.145272 29253 sgd_solver.cpp:106] Iteration 1320, lr = 0.01
I0302 02:00:02.972532 29253 solver.cpp:237] Iteration 1340, loss = 0.0141082
I0302 02:00:02.972563 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0141082 (* 1 = 0.0141082 loss)
I0302 02:00:02.972571 29253 sgd_solver.cpp:106] Iteration 1340, lr = 0.01
I0302 02:00:31.902446 29253 solver.cpp:237] Iteration 1360, loss = 0.011214
I0302 02:00:31.902475 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.011214 (* 1 = 0.011214 loss)
I0302 02:00:31.902484 29253 sgd_solver.cpp:106] Iteration 1360, lr = 0.01
I0302 02:01:00.793488 29253 solver.cpp:237] Iteration 1380, loss = 0.0122031
I0302 02:01:00.793520 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0122031 (* 1 = 0.0122031 loss)
I0302 02:01:00.793529 29253 sgd_solver.cpp:106] Iteration 1380, lr = 0.01
I0302 02:01:29.693140 29253 solver.cpp:237] Iteration 1400, loss = 0.010747
I0302 02:01:29.693171 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.010747 (* 1 = 0.010747 loss)
I0302 02:01:29.693178 29253 sgd_solver.cpp:106] Iteration 1400, lr = 0.01
I0302 02:01:58.673153 29253 solver.cpp:237] Iteration 1420, loss = 0.00928968
I0302 02:01:58.673185 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00928969 (* 1 = 0.00928969 loss)
I0302 02:01:58.673194 29253 sgd_solver.cpp:106] Iteration 1420, lr = 0.01
I0302 02:02:27.759229 29253 solver.cpp:237] Iteration 1440, loss = 0.0102433
I0302 02:02:27.759260 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0102433 (* 1 = 0.0102433 loss)
I0302 02:02:27.759269 29253 sgd_solver.cpp:106] Iteration 1440, lr = 0.01
I0302 02:02:56.557303 29253 solver.cpp:237] Iteration 1460, loss = 0.0106504
I0302 02:02:56.557334 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0106504 (* 1 = 0.0106504 loss)
I0302 02:02:56.557343 29253 sgd_solver.cpp:106] Iteration 1460, lr = 0.01
I0302 02:03:25.553076 29253 solver.cpp:237] Iteration 1480, loss = 0.00899002
I0302 02:03:25.553107 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00899002 (* 1 = 0.00899002 loss)
I0302 02:03:25.553115 29253 sgd_solver.cpp:106] Iteration 1480, lr = 0.01
I0302 02:03:54.379475 29253 solver.cpp:237] Iteration 1500, loss = 0.012478
I0302 02:03:54.379506 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.012478 (* 1 = 0.012478 loss)
I0302 02:03:54.379515 29253 sgd_solver.cpp:106] Iteration 1500, lr = 0.01
I0302 02:04:23.309914 29253 solver.cpp:237] Iteration 1520, loss = 0.00761439
I0302 02:04:23.309945 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00761439 (* 1 = 0.00761439 loss)
I0302 02:04:23.309953 29253 sgd_solver.cpp:106] Iteration 1520, lr = 0.01
I0302 02:04:52.342830 29253 solver.cpp:237] Iteration 1540, loss = 0.0122671
I0302 02:04:52.342862 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0122671 (* 1 = 0.0122671 loss)
I0302 02:04:52.342870 29253 sgd_solver.cpp:106] Iteration 1540, lr = 0.01
I0302 02:05:21.301475 29253 solver.cpp:237] Iteration 1560, loss = 0.00815868
I0302 02:05:21.301506 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00815868 (* 1 = 0.00815868 loss)
I0302 02:05:21.301515 29253 sgd_solver.cpp:106] Iteration 1560, lr = 0.01
I0302 02:05:50.142433 29253 solver.cpp:237] Iteration 1580, loss = 0.012988
I0302 02:05:50.142467 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.012988 (* 1 = 0.012988 loss)
I0302 02:05:50.142475 29253 sgd_solver.cpp:106] Iteration 1580, lr = 0.01
I0302 02:06:19.124595 29253 solver.cpp:237] Iteration 1600, loss = 0.00733669
I0302 02:06:19.124627 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00733669 (* 1 = 0.00733669 loss)
I0302 02:06:19.124635 29253 sgd_solver.cpp:106] Iteration 1600, lr = 0.01
I0302 02:06:47.989639 29253 solver.cpp:237] Iteration 1620, loss = 0.00899166
I0302 02:06:47.989671 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00899166 (* 1 = 0.00899166 loss)
I0302 02:06:47.989681 29253 sgd_solver.cpp:106] Iteration 1620, lr = 0.01
I0302 02:07:16.905030 29253 solver.cpp:237] Iteration 1640, loss = 0.00922769
I0302 02:07:16.905063 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00922769 (* 1 = 0.00922769 loss)
I0302 02:07:16.905072 29253 sgd_solver.cpp:106] Iteration 1640, lr = 0.01
I0302 02:07:45.878875 29253 solver.cpp:237] Iteration 1660, loss = 0.00609326
I0302 02:07:45.878906 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00609327 (* 1 = 0.00609327 loss)
I0302 02:07:45.878913 29253 sgd_solver.cpp:106] Iteration 1660, lr = 0.01
I0302 02:08:14.865115 29253 solver.cpp:237] Iteration 1680, loss = 0.00820103
I0302 02:08:14.865146 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00820103 (* 1 = 0.00820103 loss)
I0302 02:08:14.865155 29253 sgd_solver.cpp:106] Iteration 1680, lr = 0.01
I0302 02:08:43.711861 29253 solver.cpp:237] Iteration 1700, loss = 0.00746588
I0302 02:08:43.711894 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00746588 (* 1 = 0.00746588 loss)
I0302 02:08:43.711902 29253 sgd_solver.cpp:106] Iteration 1700, lr = 0.01
I0302 02:09:12.553747 29253 solver.cpp:237] Iteration 1720, loss = 0.00849986
I0302 02:09:12.553778 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00849987 (* 1 = 0.00849987 loss)
I0302 02:09:12.553786 29253 sgd_solver.cpp:106] Iteration 1720, lr = 0.01
I0302 02:09:41.580893 29253 solver.cpp:237] Iteration 1740, loss = 0.00790387
I0302 02:09:41.580924 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00790387 (* 1 = 0.00790387 loss)
I0302 02:09:41.580932 29253 sgd_solver.cpp:106] Iteration 1740, lr = 0.01
I0302 02:10:10.620842 29253 solver.cpp:237] Iteration 1760, loss = 0.00721678
I0302 02:10:10.620875 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00721678 (* 1 = 0.00721678 loss)
I0302 02:10:10.620883 29253 sgd_solver.cpp:106] Iteration 1760, lr = 0.01
I0302 02:10:39.523386 29253 solver.cpp:237] Iteration 1780, loss = 0.00826084
I0302 02:10:39.523418 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00826084 (* 1 = 0.00826084 loss)
I0302 02:10:39.523427 29253 sgd_solver.cpp:106] Iteration 1780, lr = 0.01
I0302 02:11:08.592591 29253 solver.cpp:237] Iteration 1800, loss = 0.00622228
I0302 02:11:08.592728 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00622229 (* 1 = 0.00622229 loss)
I0302 02:11:08.592742 29253 sgd_solver.cpp:106] Iteration 1800, lr = 0.01
I0302 02:11:37.518599 29253 solver.cpp:237] Iteration 1820, loss = 0.00677781
I0302 02:11:37.518630 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00677781 (* 1 = 0.00677781 loss)
I0302 02:11:37.518637 29253 sgd_solver.cpp:106] Iteration 1820, lr = 0.01
I0302 02:12:06.508642 29253 solver.cpp:237] Iteration 1840, loss = 0.00727112
I0302 02:12:06.508676 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00727112 (* 1 = 0.00727112 loss)
I0302 02:12:06.508683 29253 sgd_solver.cpp:106] Iteration 1840, lr = 0.01
I0302 02:12:35.535012 29253 solver.cpp:237] Iteration 1860, loss = 0.00667804
I0302 02:12:35.535044 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00667805 (* 1 = 0.00667805 loss)
I0302 02:12:35.535053 29253 sgd_solver.cpp:106] Iteration 1860, lr = 0.01
I0302 02:13:04.661113 29253 solver.cpp:237] Iteration 1880, loss = 0.0060967
I0302 02:13:04.661144 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00609671 (* 1 = 0.00609671 loss)
I0302 02:13:04.661154 29253 sgd_solver.cpp:106] Iteration 1880, lr = 0.01
I0302 02:13:33.131322 29253 solver.cpp:237] Iteration 1900, loss = 0.00598815
I0302 02:13:33.131356 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00598816 (* 1 = 0.00598816 loss)
I0302 02:13:33.131364 29253 sgd_solver.cpp:106] Iteration 1900, lr = 0.01
I0302 02:14:02.118451 29253 solver.cpp:237] Iteration 1920, loss = 0.00696126
I0302 02:14:02.118484 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00696127 (* 1 = 0.00696127 loss)
I0302 02:14:02.118491 29253 sgd_solver.cpp:106] Iteration 1920, lr = 0.01
I0302 02:14:31.255388 29253 solver.cpp:237] Iteration 1940, loss = 0.00624656
I0302 02:14:31.255419 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00624656 (* 1 = 0.00624656 loss)
I0302 02:14:31.255431 29253 sgd_solver.cpp:106] Iteration 1940, lr = 0.01
I0302 02:15:00.250408 29253 solver.cpp:237] Iteration 1960, loss = 0.00773314
I0302 02:15:00.250440 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00773315 (* 1 = 0.00773315 loss)
I0302 02:15:00.250449 29253 sgd_solver.cpp:106] Iteration 1960, lr = 0.01
I0302 02:15:29.283056 29253 solver.cpp:237] Iteration 1980, loss = 0.00778322
I0302 02:15:29.283085 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00778323 (* 1 = 0.00778323 loss)
I0302 02:15:29.283093 29253 sgd_solver.cpp:106] Iteration 1980, lr = 0.01
I0302 02:15:58.136737 29253 solver.cpp:237] Iteration 2000, loss = 0.00470463
I0302 02:15:58.136770 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00470464 (* 1 = 0.00470464 loss)
I0302 02:15:58.136780 29253 sgd_solver.cpp:106] Iteration 2000, lr = 0.01
I0302 02:15:58.137858 29253 blocking_queue.cpp:50] Data layer prefetch queue empty
I0302 02:16:27.107679 29253 solver.cpp:237] Iteration 2020, loss = 0.00678005
I0302 02:16:27.107710 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00678005 (* 1 = 0.00678005 loss)
I0302 02:16:27.107719 29253 sgd_solver.cpp:106] Iteration 2020, lr = 0.01
I0302 02:16:55.683419 29253 solver.cpp:237] Iteration 2040, loss = 0.00680295
I0302 02:16:55.683452 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00680295 (* 1 = 0.00680295 loss)
I0302 02:16:55.683460 29253 sgd_solver.cpp:106] Iteration 2040, lr = 0.01
I0302 02:17:24.545838 29253 solver.cpp:237] Iteration 2060, loss = 0.00676161
I0302 02:17:24.545871 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00676161 (* 1 = 0.00676161 loss)
I0302 02:17:24.545879 29253 sgd_solver.cpp:106] Iteration 2060, lr = 0.01
I0302 02:17:53.375987 29253 solver.cpp:237] Iteration 2080, loss = 0.00627719
I0302 02:17:53.376019 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00627719 (* 1 = 0.00627719 loss)
I0302 02:17:53.376029 29253 sgd_solver.cpp:106] Iteration 2080, lr = 0.01
I0302 02:18:22.193686 29253 solver.cpp:237] Iteration 2100, loss = 0.0061474
I0302 02:18:22.193717 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00614741 (* 1 = 0.00614741 loss)
I0302 02:18:22.193727 29253 sgd_solver.cpp:106] Iteration 2100, lr = 0.01
I0302 02:18:51.456157 29253 solver.cpp:237] Iteration 2120, loss = 0.00695321
I0302 02:18:51.456190 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00695321 (* 1 = 0.00695321 loss)
I0302 02:18:51.456198 29253 sgd_solver.cpp:106] Iteration 2120, lr = 0.01
I0302 02:19:20.329346 29253 solver.cpp:237] Iteration 2140, loss = 0.00547249
I0302 02:19:20.329380 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0054725 (* 1 = 0.0054725 loss)
I0302 02:19:20.329388 29253 sgd_solver.cpp:106] Iteration 2140, lr = 0.01
I0302 02:19:49.323272 29253 solver.cpp:237] Iteration 2160, loss = 0.00579238
I0302 02:19:49.323305 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00579239 (* 1 = 0.00579239 loss)
I0302 02:19:49.323314 29253 sgd_solver.cpp:106] Iteration 2160, lr = 0.01
I0302 02:20:18.207969 29253 solver.cpp:237] Iteration 2180, loss = 0.00598864
I0302 02:20:18.208001 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00598864 (* 1 = 0.00598864 loss)
I0302 02:20:18.208010 29253 sgd_solver.cpp:106] Iteration 2180, lr = 0.01
I0302 02:20:47.008616 29253 solver.cpp:237] Iteration 2200, loss = 0.00542902
I0302 02:20:47.008649 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00542903 (* 1 = 0.00542903 loss)
I0302 02:20:47.008659 29253 sgd_solver.cpp:106] Iteration 2200, lr = 0.01
I0302 02:21:16.044432 29253 solver.cpp:237] Iteration 2220, loss = 0.00633304
I0302 02:21:16.044463 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00633304 (* 1 = 0.00633304 loss)
I0302 02:21:16.044472 29253 sgd_solver.cpp:106] Iteration 2220, lr = 0.01
I0302 02:21:45.041510 29253 solver.cpp:237] Iteration 2240, loss = 0.00662157
I0302 02:21:45.041543 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00662158 (* 1 = 0.00662158 loss)
I0302 02:21:45.041551 29253 sgd_solver.cpp:106] Iteration 2240, lr = 0.01
I0302 02:22:13.889658 29253 solver.cpp:237] Iteration 2260, loss = 0.00635831
I0302 02:22:13.889693 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00635832 (* 1 = 0.00635832 loss)
I0302 02:22:13.889701 29253 sgd_solver.cpp:106] Iteration 2260, lr = 0.01
I0302 02:22:42.858790 29253 solver.cpp:237] Iteration 2280, loss = 0.00736882
I0302 02:22:42.858821 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00736883 (* 1 = 0.00736883 loss)
I0302 02:22:42.858830 29253 sgd_solver.cpp:106] Iteration 2280, lr = 0.01
I0302 02:23:11.687726 29253 solver.cpp:237] Iteration 2300, loss = 0.00611602
I0302 02:23:11.687760 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00611602 (* 1 = 0.00611602 loss)
I0302 02:23:11.687769 29253 sgd_solver.cpp:106] Iteration 2300, lr = 0.01
I0302 02:23:40.635957 29253 solver.cpp:237] Iteration 2320, loss = 0.00583566
I0302 02:23:40.635989 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00583567 (* 1 = 0.00583567 loss)
I0302 02:23:40.635998 29253 sgd_solver.cpp:106] Iteration 2320, lr = 0.01
I0302 02:24:09.590950 29253 solver.cpp:237] Iteration 2340, loss = 0.00492389
I0302 02:24:09.590983 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00492389 (* 1 = 0.00492389 loss)
I0302 02:24:09.590991 29253 sgd_solver.cpp:106] Iteration 2340, lr = 0.01
I0302 02:24:38.412016 29253 solver.cpp:237] Iteration 2360, loss = 0.00596682
I0302 02:24:38.412048 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00596683 (* 1 = 0.00596683 loss)
I0302 02:24:38.412057 29253 sgd_solver.cpp:106] Iteration 2360, lr = 0.01
I0302 02:25:07.269090 29253 solver.cpp:237] Iteration 2380, loss = 0.00477533
I0302 02:25:07.269121 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00477533 (* 1 = 0.00477533 loss)
I0302 02:25:07.269130 29253 sgd_solver.cpp:106] Iteration 2380, lr = 0.01
I0302 02:25:36.241420 29253 solver.cpp:237] Iteration 2400, loss = 0.00502133
I0302 02:25:36.241451 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00502133 (* 1 = 0.00502133 loss)
I0302 02:25:36.241459 29253 sgd_solver.cpp:106] Iteration 2400, lr = 0.01
I0302 02:26:05.157675 29253 solver.cpp:237] Iteration 2420, loss = 0.00535916
I0302 02:26:05.157707 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00535916 (* 1 = 0.00535916 loss)
I0302 02:26:05.157716 29253 sgd_solver.cpp:106] Iteration 2420, lr = 0.01
I0302 02:26:34.044658 29253 solver.cpp:237] Iteration 2440, loss = 0.00426681
I0302 02:26:34.044690 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00426681 (* 1 = 0.00426681 loss)
I0302 02:26:34.044699 29253 sgd_solver.cpp:106] Iteration 2440, lr = 0.01
I0302 02:27:03.019568 29253 solver.cpp:237] Iteration 2460, loss = 0.00859942
I0302 02:27:03.019598 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00859942 (* 1 = 0.00859942 loss)
I0302 02:27:03.019608 29253 sgd_solver.cpp:106] Iteration 2460, lr = 0.01
I0302 02:27:31.960968 29253 solver.cpp:237] Iteration 2480, loss = 0.00466378
I0302 02:27:31.961000 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00466378 (* 1 = 0.00466378 loss)
I0302 02:27:31.961009 29253 sgd_solver.cpp:106] Iteration 2480, lr = 0.01
I0302 02:28:00.795297 29253 solver.cpp:237] Iteration 2500, loss = 0.00744922
I0302 02:28:00.795331 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00744922 (* 1 = 0.00744922 loss)
I0302 02:28:00.795339 29253 sgd_solver.cpp:106] Iteration 2500, lr = 0.01
I0302 02:28:29.715786 29253 solver.cpp:237] Iteration 2520, loss = 0.00862699
I0302 02:28:29.715819 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.008627 (* 1 = 0.008627 loss)
I0302 02:28:29.715827 29253 sgd_solver.cpp:106] Iteration 2520, lr = 0.01
I0302 02:28:58.568497 29253 solver.cpp:237] Iteration 2540, loss = 0.00543692
I0302 02:28:58.568528 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00543693 (* 1 = 0.00543693 loss)
I0302 02:28:58.568537 29253 sgd_solver.cpp:106] Iteration 2540, lr = 0.01
I0302 02:29:27.585084 29253 solver.cpp:237] Iteration 2560, loss = 0.00481084
I0302 02:29:27.585116 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00481084 (* 1 = 0.00481084 loss)
I0302 02:29:27.585124 29253 sgd_solver.cpp:106] Iteration 2560, lr = 0.01
I0302 02:29:56.527653 29253 solver.cpp:237] Iteration 2580, loss = 0.0051384
I0302 02:29:56.527685 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0051384 (* 1 = 0.0051384 loss)
I0302 02:29:56.527694 29253 sgd_solver.cpp:106] Iteration 2580, lr = 0.01
I0302 02:30:25.301012 29253 solver.cpp:237] Iteration 2600, loss = 0.00423634
I0302 02:30:25.301045 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00423635 (* 1 = 0.00423635 loss)
I0302 02:30:25.301054 29253 sgd_solver.cpp:106] Iteration 2600, lr = 0.01
I0302 02:30:54.410280 29253 solver.cpp:237] Iteration 2620, loss = 0.00454673
I0302 02:30:54.410311 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00454673 (* 1 = 0.00454673 loss)
I0302 02:30:54.410320 29253 sgd_solver.cpp:106] Iteration 2620, lr = 0.01
I0302 02:31:23.187232 29253 solver.cpp:237] Iteration 2640, loss = 0.00596806
I0302 02:31:23.187263 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00596806 (* 1 = 0.00596806 loss)
I0302 02:31:23.187273 29253 sgd_solver.cpp:106] Iteration 2640, lr = 0.01
I0302 02:31:52.152771 29253 solver.cpp:237] Iteration 2660, loss = 0.00544492
I0302 02:31:52.152804 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00544493 (* 1 = 0.00544493 loss)
I0302 02:31:52.152812 29253 sgd_solver.cpp:106] Iteration 2660, lr = 0.01
I0302 02:32:21.028574 29253 solver.cpp:237] Iteration 2680, loss = 0.00515271
I0302 02:32:21.028606 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00515272 (* 1 = 0.00515272 loss)
I0302 02:32:21.028615 29253 sgd_solver.cpp:106] Iteration 2680, lr = 0.01
I0302 02:32:49.910706 29253 solver.cpp:237] Iteration 2700, loss = 0.00528866
I0302 02:32:49.910738 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00528866 (* 1 = 0.00528866 loss)
I0302 02:32:49.910747 29253 sgd_solver.cpp:106] Iteration 2700, lr = 0.01
I0302 02:33:19.042346 29253 solver.cpp:237] Iteration 2720, loss = 0.00401709
I0302 02:33:19.042382 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0040171 (* 1 = 0.0040171 loss)
I0302 02:33:19.042390 29253 sgd_solver.cpp:106] Iteration 2720, lr = 0.01
I0302 02:33:47.932729 29253 solver.cpp:237] Iteration 2740, loss = 0.00493823
I0302 02:33:47.932761 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00493824 (* 1 = 0.00493824 loss)
I0302 02:33:47.932771 29253 sgd_solver.cpp:106] Iteration 2740, lr = 0.01
I0302 02:34:16.873270 29253 solver.cpp:237] Iteration 2760, loss = 0.0044179
I0302 02:34:16.873301 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0044179 (* 1 = 0.0044179 loss)
I0302 02:34:16.873309 29253 sgd_solver.cpp:106] Iteration 2760, lr = 0.01
I0302 02:34:45.792451 29253 solver.cpp:237] Iteration 2780, loss = 0.00530219
I0302 02:34:45.792486 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0053022 (* 1 = 0.0053022 loss)
I0302 02:34:45.792496 29253 sgd_solver.cpp:106] Iteration 2780, lr = 0.01
I0302 02:35:14.530783 29253 solver.cpp:237] Iteration 2800, loss = 0.00503993
I0302 02:35:14.530815 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00503994 (* 1 = 0.00503994 loss)
I0302 02:35:14.530824 29253 sgd_solver.cpp:106] Iteration 2800, lr = 0.01
I0302 02:35:43.440654 29253 solver.cpp:237] Iteration 2820, loss = 0.00435615
I0302 02:35:43.440686 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00435615 (* 1 = 0.00435615 loss)
I0302 02:35:43.440696 29253 sgd_solver.cpp:106] Iteration 2820, lr = 0.01
I0302 02:36:12.342197 29253 solver.cpp:237] Iteration 2840, loss = 0.00415313
I0302 02:36:12.342228 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00415313 (* 1 = 0.00415313 loss)
I0302 02:36:12.342237 29253 sgd_solver.cpp:106] Iteration 2840, lr = 0.01
I0302 02:36:41.182660 29253 solver.cpp:237] Iteration 2860, loss = 0.00401064
I0302 02:36:41.182693 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00401064 (* 1 = 0.00401064 loss)
I0302 02:36:41.182701 29253 sgd_solver.cpp:106] Iteration 2860, lr = 0.01
I0302 02:37:10.207314 29253 solver.cpp:237] Iteration 2880, loss = 0.00493644
I0302 02:37:10.207345 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00493644 (* 1 = 0.00493644 loss)
I0302 02:37:10.207352 29253 sgd_solver.cpp:106] Iteration 2880, lr = 0.01
I0302 02:37:39.141013 29253 solver.cpp:237] Iteration 2900, loss = 0.00477701
I0302 02:37:39.141044 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00477701 (* 1 = 0.00477701 loss)
I0302 02:37:39.141052 29253 sgd_solver.cpp:106] Iteration 2900, lr = 0.01
I0302 02:38:08.272572 29253 solver.cpp:237] Iteration 2920, loss = 0.00448401
I0302 02:38:08.272604 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00448401 (* 1 = 0.00448401 loss)
I0302 02:38:08.272614 29253 sgd_solver.cpp:106] Iteration 2920, lr = 0.01
I0302 02:38:37.094622 29253 solver.cpp:237] Iteration 2940, loss = 0.00383957
I0302 02:38:37.094655 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00383957 (* 1 = 0.00383957 loss)
I0302 02:38:37.094662 29253 sgd_solver.cpp:106] Iteration 2940, lr = 0.01
I0302 02:39:05.995692 29253 solver.cpp:237] Iteration 2960, loss = 0.00377263
I0302 02:39:05.995723 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00377263 (* 1 = 0.00377263 loss)
I0302 02:39:05.995733 29253 sgd_solver.cpp:106] Iteration 2960, lr = 0.01
I0302 02:39:35.070354 29253 solver.cpp:237] Iteration 2980, loss = 0.00427641
I0302 02:39:35.070390 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00427641 (* 1 = 0.00427641 loss)
I0302 02:39:35.070399 29253 sgd_solver.cpp:106] Iteration 2980, lr = 0.01
I0302 02:40:04.017168 29253 solver.cpp:237] Iteration 3000, loss = 0.00420258
I0302 02:40:04.017200 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00420259 (* 1 = 0.00420259 loss)
I0302 02:40:04.017209 29253 sgd_solver.cpp:106] Iteration 3000, lr = 0.01
I0302 02:40:04.024096 29253 blocking_queue.cpp:50] Data layer prefetch queue empty
I0302 02:40:32.321414 29253 solver.cpp:237] Iteration 3020, loss = 0.00442857
I0302 02:40:32.321446 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00442858 (* 1 = 0.00442858 loss)
I0302 02:40:32.321455 29253 sgd_solver.cpp:106] Iteration 3020, lr = 0.01
I0302 02:41:01.130271 29253 solver.cpp:237] Iteration 3040, loss = 0.00484963
I0302 02:41:01.130302 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00484963 (* 1 = 0.00484963 loss)
I0302 02:41:01.130311 29253 sgd_solver.cpp:106] Iteration 3040, lr = 0.01
I0302 02:41:30.273778 29253 solver.cpp:237] Iteration 3060, loss = 0.00361409
I0302 02:41:30.273811 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00361409 (* 1 = 0.00361409 loss)
I0302 02:41:30.273819 29253 sgd_solver.cpp:106] Iteration 3060, lr = 0.01
I0302 02:41:59.062326 29253 solver.cpp:237] Iteration 3080, loss = 0.00368088
I0302 02:41:59.062358 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00368089 (* 1 = 0.00368089 loss)
I0302 02:41:59.062367 29253 sgd_solver.cpp:106] Iteration 3080, lr = 0.01
I0302 02:42:28.205083 29253 solver.cpp:237] Iteration 3100, loss = 0.00491214
I0302 02:42:28.205114 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00491214 (* 1 = 0.00491214 loss)
I0302 02:42:28.205123 29253 sgd_solver.cpp:106] Iteration 3100, lr = 0.01
I0302 02:42:57.291020 29253 solver.cpp:237] Iteration 3120, loss = 0.00394281
I0302 02:42:57.291054 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00394281 (* 1 = 0.00394281 loss)
I0302 02:42:57.291061 29253 sgd_solver.cpp:106] Iteration 3120, lr = 0.01
I0302 02:43:25.979111 29253 solver.cpp:237] Iteration 3140, loss = 0.00392842
I0302 02:43:25.979141 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00392842 (* 1 = 0.00392842 loss)
I0302 02:43:25.979151 29253 sgd_solver.cpp:106] Iteration 3140, lr = 0.01
I0302 02:43:54.900890 29253 solver.cpp:237] Iteration 3160, loss = 0.00439744
I0302 02:43:54.900919 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00439744 (* 1 = 0.00439744 loss)
I0302 02:43:54.900928 29253 sgd_solver.cpp:106] Iteration 3160, lr = 0.01
I0302 02:44:23.808275 29253 solver.cpp:237] Iteration 3180, loss = 0.0054977
I0302 02:44:23.808305 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0054977 (* 1 = 0.0054977 loss)
I0302 02:44:23.808315 29253 sgd_solver.cpp:106] Iteration 3180, lr = 0.01
I0302 02:44:52.743304 29253 solver.cpp:237] Iteration 3200, loss = 0.00452694
I0302 02:44:52.743335 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00452694 (* 1 = 0.00452694 loss)
I0302 02:44:52.743343 29253 sgd_solver.cpp:106] Iteration 3200, lr = 0.01
I0302 02:45:21.353966 29253 solver.cpp:237] Iteration 3220, loss = 0.0045763
I0302 02:45:21.353998 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0045763 (* 1 = 0.0045763 loss)
I0302 02:45:21.354009 29253 sgd_solver.cpp:106] Iteration 3220, lr = 0.01
I0302 02:45:50.379097 29253 solver.cpp:237] Iteration 3240, loss = 0.0042155
I0302 02:45:50.379130 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0042155 (* 1 = 0.0042155 loss)
I0302 02:45:50.379138 29253 sgd_solver.cpp:106] Iteration 3240, lr = 0.01
I0302 02:46:19.466202 29253 solver.cpp:237] Iteration 3260, loss = 0.00404468
I0302 02:46:19.466233 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00404469 (* 1 = 0.00404469 loss)
I0302 02:46:19.466241 29253 sgd_solver.cpp:106] Iteration 3260, lr = 0.01
I0302 02:46:48.386037 29253 solver.cpp:237] Iteration 3280, loss = 0.00364521
I0302 02:46:48.386070 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00364521 (* 1 = 0.00364521 loss)
I0302 02:46:48.386078 29253 sgd_solver.cpp:106] Iteration 3280, lr = 0.01
I0302 02:47:17.300493 29253 solver.cpp:237] Iteration 3300, loss = 0.00345429
I0302 02:47:17.300525 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0034543 (* 1 = 0.0034543 loss)
I0302 02:47:17.300534 29253 sgd_solver.cpp:106] Iteration 3300, lr = 0.01
I0302 02:47:46.117254 29253 solver.cpp:237] Iteration 3320, loss = 0.00341239
I0302 02:47:46.117285 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00341239 (* 1 = 0.00341239 loss)
I0302 02:47:46.117293 29253 sgd_solver.cpp:106] Iteration 3320, lr = 0.01
I0302 02:48:15.332633 29253 solver.cpp:237] Iteration 3340, loss = 0.00422422
I0302 02:48:15.332666 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00422423 (* 1 = 0.00422423 loss)
I0302 02:48:15.332675 29253 sgd_solver.cpp:106] Iteration 3340, lr = 0.01
I0302 02:48:44.159775 29253 solver.cpp:237] Iteration 3360, loss = 0.00402237
I0302 02:48:44.159807 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00402238 (* 1 = 0.00402238 loss)
I0302 02:48:44.159816 29253 sgd_solver.cpp:106] Iteration 3360, lr = 0.01
I0302 02:49:13.339365 29253 solver.cpp:237] Iteration 3380, loss = 0.00388876
I0302 02:49:13.339398 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00388876 (* 1 = 0.00388876 loss)
I0302 02:49:13.339406 29253 sgd_solver.cpp:106] Iteration 3380, lr = 0.01
I0302 02:49:42.395603 29253 solver.cpp:237] Iteration 3400, loss = 0.00303556
I0302 02:49:42.395638 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00303556 (* 1 = 0.00303556 loss)
I0302 02:49:42.395648 29253 sgd_solver.cpp:106] Iteration 3400, lr = 0.01
I0302 02:50:11.018000 29253 solver.cpp:237] Iteration 3420, loss = 0.00499352
I0302 02:50:11.018033 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00499353 (* 1 = 0.00499353 loss)
I0302 02:50:11.018043 29253 sgd_solver.cpp:106] Iteration 3420, lr = 0.01
I0302 02:50:39.908869 29253 solver.cpp:237] Iteration 3440, loss = 0.00287661
I0302 02:50:39.908901 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00287662 (* 1 = 0.00287662 loss)
I0302 02:50:39.908910 29253 sgd_solver.cpp:106] Iteration 3440, lr = 0.01
I0302 02:51:09.229753 29253 solver.cpp:237] Iteration 3460, loss = 0.00377459
I0302 02:51:09.229784 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00377459 (* 1 = 0.00377459 loss)
I0302 02:51:09.229792 29253 sgd_solver.cpp:106] Iteration 3460, lr = 0.01
I0302 02:51:37.664345 29253 solver.cpp:237] Iteration 3480, loss = 0.00332858
I0302 02:51:37.664377 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00332858 (* 1 = 0.00332858 loss)
I0302 02:51:37.664386 29253 sgd_solver.cpp:106] Iteration 3480, lr = 0.01
I0302 02:52:06.508733 29253 solver.cpp:237] Iteration 3500, loss = 0.00390374
I0302 02:52:06.508764 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00390374 (* 1 = 0.00390374 loss)
I0302 02:52:06.508771 29253 sgd_solver.cpp:106] Iteration 3500, lr = 0.01
I0302 02:52:35.610875 29253 solver.cpp:237] Iteration 3520, loss = 0.00425945
I0302 02:52:35.610906 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00425946 (* 1 = 0.00425946 loss)
I0302 02:52:35.610914 29253 sgd_solver.cpp:106] Iteration 3520, lr = 0.01
I0302 02:53:04.394531 29253 solver.cpp:237] Iteration 3540, loss = 0.00378026
I0302 02:53:04.394563 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00378027 (* 1 = 0.00378027 loss)
I0302 02:53:04.394572 29253 sgd_solver.cpp:106] Iteration 3540, lr = 0.01
I0302 02:53:33.154567 29253 solver.cpp:237] Iteration 3560, loss = 0.00341691
I0302 02:53:33.154598 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00341692 (* 1 = 0.00341692 loss)
I0302 02:53:33.154608 29253 sgd_solver.cpp:106] Iteration 3560, lr = 0.01
I0302 02:54:02.190991 29253 solver.cpp:237] Iteration 3580, loss = 0.00336633
I0302 02:54:02.191023 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00336633 (* 1 = 0.00336633 loss)
I0302 02:54:02.191032 29253 sgd_solver.cpp:106] Iteration 3580, lr = 0.01
I0302 02:54:31.021399 29253 solver.cpp:237] Iteration 3600, loss = 0.00345549
I0302 02:54:31.021431 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00345549 (* 1 = 0.00345549 loss)
I0302 02:54:31.021440 29253 sgd_solver.cpp:106] Iteration 3600, lr = 0.01
I0302 02:55:00.132781 29253 solver.cpp:237] Iteration 3620, loss = 0.00359385
I0302 02:55:00.132812 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00359385 (* 1 = 0.00359385 loss)
I0302 02:55:00.132820 29253 sgd_solver.cpp:106] Iteration 3620, lr = 0.01
I0302 02:55:29.061722 29253 solver.cpp:237] Iteration 3640, loss = 0.00388298
I0302 02:55:29.061754 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00388298 (* 1 = 0.00388298 loss)
I0302 02:55:29.061763 29253 sgd_solver.cpp:106] Iteration 3640, lr = 0.01
I0302 02:55:57.956296 29253 solver.cpp:237] Iteration 3660, loss = 0.00282247
I0302 02:55:57.956328 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00282247 (* 1 = 0.00282247 loss)
I0302 02:55:57.956337 29253 sgd_solver.cpp:106] Iteration 3660, lr = 0.01
I0302 02:56:26.771157 29253 solver.cpp:237] Iteration 3680, loss = 0.00410653
I0302 02:56:26.771190 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00410653 (* 1 = 0.00410653 loss)
I0302 02:56:26.771199 29253 sgd_solver.cpp:106] Iteration 3680, lr = 0.01
I0302 02:56:55.686705 29253 solver.cpp:237] Iteration 3700, loss = 0.00469066
I0302 02:56:55.686738 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00469067 (* 1 = 0.00469067 loss)
I0302 02:56:55.686745 29253 sgd_solver.cpp:106] Iteration 3700, lr = 0.01
I0302 02:57:24.697854 29253 solver.cpp:237] Iteration 3720, loss = 0.00344558
I0302 02:57:24.697885 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00344559 (* 1 = 0.00344559 loss)
I0302 02:57:24.697893 29253 sgd_solver.cpp:106] Iteration 3720, lr = 0.01
I0302 02:57:53.639188 29253 solver.cpp:237] Iteration 3740, loss = 0.0031867
I0302 02:57:53.639219 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00318671 (* 1 = 0.00318671 loss)
I0302 02:57:53.639227 29253 sgd_solver.cpp:106] Iteration 3740, lr = 0.01
I0302 02:58:22.575419 29253 solver.cpp:237] Iteration 3760, loss = 0.00345191
I0302 02:58:22.575450 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00345191 (* 1 = 0.00345191 loss)
I0302 02:58:22.575459 29253 sgd_solver.cpp:106] Iteration 3760, lr = 0.01
I0302 02:58:51.315739 29253 solver.cpp:237] Iteration 3780, loss = 0.00301329
I0302 02:58:51.315771 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00301329 (* 1 = 0.00301329 loss)
I0302 02:58:51.315780 29253 sgd_solver.cpp:106] Iteration 3780, lr = 0.01
I0302 02:59:20.161285 29253 solver.cpp:237] Iteration 3800, loss = 0.00460639
I0302 02:59:20.161319 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0046064 (* 1 = 0.0046064 loss)
I0302 02:59:20.161326 29253 sgd_solver.cpp:106] Iteration 3800, lr = 0.01
I0302 02:59:48.913645 29253 solver.cpp:237] Iteration 3820, loss = 0.00342564
I0302 02:59:48.913676 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00342565 (* 1 = 0.00342565 loss)
I0302 02:59:48.913684 29253 sgd_solver.cpp:106] Iteration 3820, lr = 0.01
I0302 03:00:17.873289 29253 solver.cpp:237] Iteration 3840, loss = 0.0031745
I0302 03:00:17.873322 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00317451 (* 1 = 0.00317451 loss)
I0302 03:00:17.873332 29253 sgd_solver.cpp:106] Iteration 3840, lr = 0.01
I0302 03:00:46.803381 29253 solver.cpp:237] Iteration 3860, loss = 0.00377213
I0302 03:00:46.803412 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00377213 (* 1 = 0.00377213 loss)
I0302 03:00:46.803421 29253 sgd_solver.cpp:106] Iteration 3860, lr = 0.01
I0302 03:01:15.806097 29253 solver.cpp:237] Iteration 3880, loss = 0.00342446
I0302 03:01:15.806129 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00342446 (* 1 = 0.00342446 loss)
I0302 03:01:15.806138 29253 sgd_solver.cpp:106] Iteration 3880, lr = 0.01
I0302 03:01:44.803208 29253 solver.cpp:237] Iteration 3900, loss = 0.00364633
I0302 03:01:44.803238 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00364633 (* 1 = 0.00364633 loss)
I0302 03:01:44.803247 29253 sgd_solver.cpp:106] Iteration 3900, lr = 0.01
I0302 03:02:13.954074 29253 solver.cpp:237] Iteration 3920, loss = 0.00375869
I0302 03:02:13.954105 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0037587 (* 1 = 0.0037587 loss)
I0302 03:02:13.954114 29253 sgd_solver.cpp:106] Iteration 3920, lr = 0.01
I0302 03:02:42.821707 29253 solver.cpp:237] Iteration 3940, loss = 0.00351254
I0302 03:02:42.821738 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00351255 (* 1 = 0.00351255 loss)
I0302 03:02:42.821748 29253 sgd_solver.cpp:106] Iteration 3940, lr = 0.01
I0302 03:03:11.620733 29253 solver.cpp:237] Iteration 3960, loss = 0.00331829
I0302 03:03:11.620764 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00331829 (* 1 = 0.00331829 loss)
I0302 03:03:11.620771 29253 sgd_solver.cpp:106] Iteration 3960, lr = 0.01
I0302 03:03:40.486313 29253 solver.cpp:237] Iteration 3980, loss = 0.00433639
I0302 03:03:40.486345 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0043364 (* 1 = 0.0043364 loss)
I0302 03:03:40.486353 29253 sgd_solver.cpp:106] Iteration 3980, lr = 0.01
I0302 03:04:09.530222 29253 solver.cpp:237] Iteration 4000, loss = 0.00277238
I0302 03:04:09.530257 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00277238 (* 1 = 0.00277238 loss)
I0302 03:04:09.530266 29253 sgd_solver.cpp:106] Iteration 4000, lr = 0.01
I0302 03:04:09.531338 29253 blocking_queue.cpp:50] Data layer prefetch queue empty
I0302 03:04:38.371862 29253 solver.cpp:237] Iteration 4020, loss = 0.00644553
I0302 03:04:38.371896 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00644553 (* 1 = 0.00644553 loss)
I0302 03:04:38.371903 29253 sgd_solver.cpp:106] Iteration 4020, lr = 0.01
I0302 03:05:07.023998 29253 solver.cpp:237] Iteration 4040, loss = 0.00308143
I0302 03:05:07.024029 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00308143 (* 1 = 0.00308143 loss)
I0302 03:05:07.024039 29253 sgd_solver.cpp:106] Iteration 4040, lr = 0.01
I0302 03:05:36.034518 29253 solver.cpp:237] Iteration 4060, loss = 0.00290431
I0302 03:05:36.034550 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00290432 (* 1 = 0.00290432 loss)
I0302 03:05:36.034559 29253 sgd_solver.cpp:106] Iteration 4060, lr = 0.01
I0302 03:06:05.119351 29253 solver.cpp:237] Iteration 4080, loss = 0.00363875
I0302 03:06:05.119382 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00363875 (* 1 = 0.00363875 loss)
I0302 03:06:05.119391 29253 sgd_solver.cpp:106] Iteration 4080, lr = 0.01
I0302 03:06:33.896105 29253 solver.cpp:237] Iteration 4100, loss = 0.00361257
I0302 03:06:33.896134 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00361257 (* 1 = 0.00361257 loss)
I0302 03:06:33.896143 29253 sgd_solver.cpp:106] Iteration 4100, lr = 0.01
I0302 03:07:02.820623 29253 solver.cpp:237] Iteration 4120, loss = 0.00308072
I0302 03:07:02.820657 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00308072 (* 1 = 0.00308072 loss)
I0302 03:07:02.820665 29253 sgd_solver.cpp:106] Iteration 4120, lr = 0.01
I0302 03:07:31.944958 29253 solver.cpp:237] Iteration 4140, loss = 0.00346307
I0302 03:07:31.944990 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00346308 (* 1 = 0.00346308 loss)
I0302 03:07:31.944999 29253 sgd_solver.cpp:106] Iteration 4140, lr = 0.01
I0302 03:08:00.723242 29253 solver.cpp:237] Iteration 4160, loss = 0.00334041
I0302 03:08:00.723271 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00334042 (* 1 = 0.00334042 loss)
I0302 03:08:00.723279 29253 sgd_solver.cpp:106] Iteration 4160, lr = 0.01
I0302 03:08:29.512511 29253 solver.cpp:237] Iteration 4180, loss = 0.00359259
I0302 03:08:29.512544 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0035926 (* 1 = 0.0035926 loss)
I0302 03:08:29.512553 29253 sgd_solver.cpp:106] Iteration 4180, lr = 0.01
I0302 03:08:58.414716 29253 solver.cpp:237] Iteration 4200, loss = 0.00363205
I0302 03:08:58.414746 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00363206 (* 1 = 0.00363206 loss)
I0302 03:08:58.414754 29253 sgd_solver.cpp:106] Iteration 4200, lr = 0.01
I0302 03:09:27.304772 29253 solver.cpp:237] Iteration 4220, loss = 0.00411726
I0302 03:09:27.304807 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00411727 (* 1 = 0.00411727 loss)
I0302 03:09:27.304816 29253 sgd_solver.cpp:106] Iteration 4220, lr = 0.01
I0302 03:09:56.162680 29253 solver.cpp:237] Iteration 4240, loss = 0.00324795
I0302 03:09:56.162713 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00324796 (* 1 = 0.00324796 loss)
I0302 03:09:56.162720 29253 sgd_solver.cpp:106] Iteration 4240, lr = 0.01
I0302 03:10:25.135771 29253 solver.cpp:237] Iteration 4260, loss = 0.00279161
I0302 03:10:25.135803 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00279162 (* 1 = 0.00279162 loss)
I0302 03:10:25.135812 29253 sgd_solver.cpp:106] Iteration 4260, lr = 0.01
I0302 03:10:54.163331 29253 solver.cpp:237] Iteration 4280, loss = 0.00367345
I0302 03:10:54.163363 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00367345 (* 1 = 0.00367345 loss)
I0302 03:10:54.163372 29253 sgd_solver.cpp:106] Iteration 4280, lr = 0.01
I0302 03:11:22.869539 29253 solver.cpp:237] Iteration 4300, loss = 0.00357239
I0302 03:11:22.869571 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00357239 (* 1 = 0.00357239 loss)
I0302 03:11:22.869580 29253 sgd_solver.cpp:106] Iteration 4300, lr = 0.01
I0302 03:11:51.750777 29253 solver.cpp:237] Iteration 4320, loss = 0.00380209
I0302 03:11:51.750808 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00380209 (* 1 = 0.00380209 loss)
I0302 03:11:51.750818 29253 sgd_solver.cpp:106] Iteration 4320, lr = 0.01
I0302 03:12:20.681921 29253 solver.cpp:237] Iteration 4340, loss = 0.00322592
I0302 03:12:20.681948 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00322592 (* 1 = 0.00322592 loss)
I0302 03:12:20.681957 29253 sgd_solver.cpp:106] Iteration 4340, lr = 0.01
I0302 03:12:49.558576 29253 solver.cpp:237] Iteration 4360, loss = 0.00333747
I0302 03:12:49.558609 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00333747 (* 1 = 0.00333747 loss)
I0302 03:12:49.558617 29253 sgd_solver.cpp:106] Iteration 4360, lr = 0.01
I0302 03:13:18.555042 29253 solver.cpp:237] Iteration 4380, loss = 0.00345443
I0302 03:13:18.555073 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00345443 (* 1 = 0.00345443 loss)
I0302 03:13:18.555081 29253 sgd_solver.cpp:106] Iteration 4380, lr = 0.01
I0302 03:13:47.567078 29253 solver.cpp:237] Iteration 4400, loss = 0.00326447
I0302 03:13:47.567108 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00326447 (* 1 = 0.00326447 loss)
I0302 03:13:47.567117 29253 sgd_solver.cpp:106] Iteration 4400, lr = 0.01
I0302 03:14:16.306812 29253 solver.cpp:237] Iteration 4420, loss = 0.00298937
I0302 03:14:16.306843 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00298937 (* 1 = 0.00298937 loss)
I0302 03:14:16.306852 29253 sgd_solver.cpp:106] Iteration 4420, lr = 0.01
I0302 03:14:45.113402 29253 solver.cpp:237] Iteration 4440, loss = 0.00394399
I0302 03:14:45.113433 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00394399 (* 1 = 0.00394399 loss)
I0302 03:14:45.113442 29253 sgd_solver.cpp:106] Iteration 4440, lr = 0.01
I0302 03:15:14.182824 29253 solver.cpp:237] Iteration 4460, loss = 0.00259627
I0302 03:15:14.182857 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00259628 (* 1 = 0.00259628 loss)
I0302 03:15:14.182864 29253 sgd_solver.cpp:106] Iteration 4460, lr = 0.01
I0302 03:15:43.111438 29253 solver.cpp:237] Iteration 4480, loss = 0.00301185
I0302 03:15:43.111469 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00301186 (* 1 = 0.00301186 loss)
I0302 03:15:43.111477 29253 sgd_solver.cpp:106] Iteration 4480, lr = 0.01
I0302 03:16:11.986891 29253 solver.cpp:237] Iteration 4500, loss = 0.00314522
I0302 03:16:11.986922 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00314523 (* 1 = 0.00314523 loss)
I0302 03:16:11.986932 29253 sgd_solver.cpp:106] Iteration 4500, lr = 0.01
I0302 03:16:41.057693 29253 solver.cpp:237] Iteration 4520, loss = 0.00230954
I0302 03:16:41.057725 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00230955 (* 1 = 0.00230955 loss)
I0302 03:16:41.057734 29253 sgd_solver.cpp:106] Iteration 4520, lr = 0.01
I0302 03:17:09.854467 29253 solver.cpp:237] Iteration 4540, loss = 0.00334617
I0302 03:17:09.854497 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00334617 (* 1 = 0.00334617 loss)
I0302 03:17:09.854506 29253 sgd_solver.cpp:106] Iteration 4540, lr = 0.01
I0302 03:17:38.752722 29253 solver.cpp:237] Iteration 4560, loss = 0.00245775
I0302 03:17:38.752755 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00245775 (* 1 = 0.00245775 loss)
I0302 03:17:38.752763 29253 sgd_solver.cpp:106] Iteration 4560, lr = 0.01
I0302 03:18:07.641341 29253 solver.cpp:237] Iteration 4580, loss = 0.00346488
I0302 03:18:07.641366 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00346488 (* 1 = 0.00346488 loss)
I0302 03:18:07.641373 29253 sgd_solver.cpp:106] Iteration 4580, lr = 0.01
I0302 03:18:36.386284 29253 solver.cpp:237] Iteration 4600, loss = 0.00217714
I0302 03:18:36.386315 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00217714 (* 1 = 0.00217714 loss)
I0302 03:18:36.386324 29253 sgd_solver.cpp:106] Iteration 4600, lr = 0.01
I0302 03:19:05.531741 29253 solver.cpp:237] Iteration 4620, loss = 0.00391884
I0302 03:19:05.531774 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00391884 (* 1 = 0.00391884 loss)
I0302 03:19:05.531781 29253 sgd_solver.cpp:106] Iteration 4620, lr = 0.01
I0302 03:19:34.430346 29253 solver.cpp:237] Iteration 4640, loss = 0.00257962
I0302 03:19:34.430377 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00257962 (* 1 = 0.00257962 loss)
I0302 03:19:34.430384 29253 sgd_solver.cpp:106] Iteration 4640, lr = 0.01
I0302 03:20:02.985347 29253 solver.cpp:237] Iteration 4660, loss = 0.00252722
I0302 03:20:02.985379 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00252722 (* 1 = 0.00252722 loss)
I0302 03:20:02.985388 29253 sgd_solver.cpp:106] Iteration 4660, lr = 0.01
I0302 03:20:31.677088 29253 solver.cpp:237] Iteration 4680, loss = 0.00287558
I0302 03:20:31.677119 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00287558 (* 1 = 0.00287558 loss)
I0302 03:20:31.677129 29253 sgd_solver.cpp:106] Iteration 4680, lr = 0.01
I0302 03:21:00.758543 29253 solver.cpp:237] Iteration 4700, loss = 0.00299061
I0302 03:21:00.758575 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00299062 (* 1 = 0.00299062 loss)
I0302 03:21:00.758586 29253 sgd_solver.cpp:106] Iteration 4700, lr = 0.01
I0302 03:21:29.668424 29253 solver.cpp:237] Iteration 4720, loss = 0.00277726
I0302 03:21:29.668458 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00277726 (* 1 = 0.00277726 loss)
I0302 03:21:29.668467 29253 sgd_solver.cpp:106] Iteration 4720, lr = 0.01
I0302 03:21:58.688047 29253 solver.cpp:237] Iteration 4740, loss = 0.00285265
I0302 03:21:58.688079 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00285265 (* 1 = 0.00285265 loss)
I0302 03:21:58.688087 29253 sgd_solver.cpp:106] Iteration 4740, lr = 0.01
I0302 03:22:27.626874 29253 solver.cpp:237] Iteration 4760, loss = 0.0025963
I0302 03:22:27.626907 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0025963 (* 1 = 0.0025963 loss)
I0302 03:22:27.626915 29253 sgd_solver.cpp:106] Iteration 4760, lr = 0.01
I0302 03:22:56.317821 29253 solver.cpp:237] Iteration 4780, loss = 0.00299025
I0302 03:22:56.317854 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00299026 (* 1 = 0.00299026 loss)
I0302 03:22:56.317863 29253 sgd_solver.cpp:106] Iteration 4780, lr = 0.01
I0302 03:23:25.396875 29253 solver.cpp:237] Iteration 4800, loss = 0.00255769
I0302 03:23:25.396908 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00255769 (* 1 = 0.00255769 loss)
I0302 03:23:25.396916 29253 sgd_solver.cpp:106] Iteration 4800, lr = 0.01
I0302 03:23:54.217612 29253 solver.cpp:237] Iteration 4820, loss = 0.00247013
I0302 03:23:54.217645 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00247013 (* 1 = 0.00247013 loss)
I0302 03:23:54.217654 29253 sgd_solver.cpp:106] Iteration 4820, lr = 0.01
I0302 03:24:23.204174 29253 solver.cpp:237] Iteration 4840, loss = 0.0026061
I0302 03:24:23.204205 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0026061 (* 1 = 0.0026061 loss)
I0302 03:24:23.204213 29253 sgd_solver.cpp:106] Iteration 4840, lr = 0.01
I0302 03:24:51.974205 29253 solver.cpp:237] Iteration 4860, loss = 0.00342121
I0302 03:24:51.974236 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00342122 (* 1 = 0.00342122 loss)
I0302 03:24:51.974244 29253 sgd_solver.cpp:106] Iteration 4860, lr = 0.01
I0302 03:25:20.630533 29253 solver.cpp:237] Iteration 4880, loss = 0.00276659
I0302 03:25:20.630568 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0027666 (* 1 = 0.0027666 loss)
I0302 03:25:20.630576 29253 sgd_solver.cpp:106] Iteration 4880, lr = 0.01
I0302 03:25:49.510843 29253 solver.cpp:237] Iteration 4900, loss = 0.00285346
I0302 03:25:49.510875 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00285346 (* 1 = 0.00285346 loss)
I0302 03:25:49.510884 29253 sgd_solver.cpp:106] Iteration 4900, lr = 0.01
I0302 03:26:18.480917 29253 solver.cpp:237] Iteration 4920, loss = 0.00303197
I0302 03:26:18.480948 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00303198 (* 1 = 0.00303198 loss)
I0302 03:26:18.480957 29253 sgd_solver.cpp:106] Iteration 4920, lr = 0.01
I0302 03:26:47.377257 29253 solver.cpp:237] Iteration 4940, loss = 0.0033452
I0302 03:26:47.377290 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0033452 (* 1 = 0.0033452 loss)
I0302 03:26:47.377300 29253 sgd_solver.cpp:106] Iteration 4940, lr = 0.01
I0302 03:27:16.228581 29253 solver.cpp:237] Iteration 4960, loss = 0.00270995
I0302 03:27:16.228612 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00270995 (* 1 = 0.00270995 loss)
I0302 03:27:16.228621 29253 sgd_solver.cpp:106] Iteration 4960, lr = 0.01
I0302 03:27:45.195332 29253 solver.cpp:237] Iteration 4980, loss = 0.00230198
I0302 03:27:45.195365 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00230198 (* 1 = 0.00230198 loss)
I0302 03:27:45.195374 29253 sgd_solver.cpp:106] Iteration 4980, lr = 0.01
I0302 03:28:12.669188 29253 solver.cpp:459] Snapshotting to binary proto file /nfs.yoda/xiaolonw/fast_rcnn/models_sunrgbd/pre_cls_1fc_scratch/model__iter_5000.caffemodel
I0302 03:28:13.869200 29253 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /nfs.yoda/xiaolonw/fast_rcnn/models_sunrgbd/pre_cls_1fc_scratch/model__iter_5000.solverstate
I0302 03:28:14.348693 29253 solver.cpp:237] Iteration 5000, loss = 0.0030571
I0302 03:28:14.348726 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0030571 (* 1 = 0.0030571 loss)
I0302 03:28:14.348734 29253 sgd_solver.cpp:106] Iteration 5000, lr = 0.01
I0302 03:28:15.556385 29253 blocking_queue.cpp:50] Data layer prefetch queue empty
I0302 03:28:42.838924 29253 solver.cpp:237] Iteration 5020, loss = 0.00264163
I0302 03:28:42.838956 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00264163 (* 1 = 0.00264163 loss)
I0302 03:28:42.838965 29253 sgd_solver.cpp:106] Iteration 5020, lr = 0.01
I0302 03:29:11.694067 29253 solver.cpp:237] Iteration 5040, loss = 0.00232671
I0302 03:29:11.694097 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00232671 (* 1 = 0.00232671 loss)
I0302 03:29:11.694105 29253 sgd_solver.cpp:106] Iteration 5040, lr = 0.01
I0302 03:29:40.645022 29253 solver.cpp:237] Iteration 5060, loss = 0.00253823
I0302 03:29:40.645054 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00253823 (* 1 = 0.00253823 loss)
I0302 03:29:40.645062 29253 sgd_solver.cpp:106] Iteration 5060, lr = 0.01
I0302 03:30:09.563215 29253 solver.cpp:237] Iteration 5080, loss = 0.00340228
I0302 03:30:09.563247 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00340228 (* 1 = 0.00340228 loss)
I0302 03:30:09.563256 29253 sgd_solver.cpp:106] Iteration 5080, lr = 0.01
I0302 03:30:38.545454 29253 solver.cpp:237] Iteration 5100, loss = 0.00230567
I0302 03:30:38.545483 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00230568 (* 1 = 0.00230568 loss)
I0302 03:30:38.545492 29253 sgd_solver.cpp:106] Iteration 5100, lr = 0.01
I0302 03:31:07.311738 29253 solver.cpp:237] Iteration 5120, loss = 0.00283573
I0302 03:31:07.311770 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00283574 (* 1 = 0.00283574 loss)
I0302 03:31:07.311779 29253 sgd_solver.cpp:106] Iteration 5120, lr = 0.01
I0302 03:31:36.231673 29253 solver.cpp:237] Iteration 5140, loss = 0.00248715
I0302 03:31:36.231703 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00248715 (* 1 = 0.00248715 loss)
I0302 03:31:36.231712 29253 sgd_solver.cpp:106] Iteration 5140, lr = 0.01
I0302 03:32:04.998438 29253 solver.cpp:237] Iteration 5160, loss = 0.00278194
I0302 03:32:04.998471 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00278194 (* 1 = 0.00278194 loss)
I0302 03:32:04.998479 29253 sgd_solver.cpp:106] Iteration 5160, lr = 0.01
I0302 03:32:33.935690 29253 solver.cpp:237] Iteration 5180, loss = 0.0034304
I0302 03:32:33.935724 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0034304 (* 1 = 0.0034304 loss)
I0302 03:32:33.935732 29253 sgd_solver.cpp:106] Iteration 5180, lr = 0.01
I0302 03:33:02.827512 29253 solver.cpp:237] Iteration 5200, loss = 0.0025123
I0302 03:33:02.827544 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0025123 (* 1 = 0.0025123 loss)
I0302 03:33:02.827553 29253 sgd_solver.cpp:106] Iteration 5200, lr = 0.01
I0302 03:33:31.515038 29253 solver.cpp:237] Iteration 5220, loss = 0.00278949
I0302 03:33:31.515069 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00278949 (* 1 = 0.00278949 loss)
I0302 03:33:31.515079 29253 sgd_solver.cpp:106] Iteration 5220, lr = 0.01
I0302 03:34:00.594709 29253 solver.cpp:237] Iteration 5240, loss = 0.00282782
I0302 03:34:00.594741 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00282782 (* 1 = 0.00282782 loss)
I0302 03:34:00.594750 29253 sgd_solver.cpp:106] Iteration 5240, lr = 0.01
I0302 03:34:29.367254 29253 solver.cpp:237] Iteration 5260, loss = 0.00215548
I0302 03:34:29.367286 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00215548 (* 1 = 0.00215548 loss)
I0302 03:34:29.367295 29253 sgd_solver.cpp:106] Iteration 5260, lr = 0.01
I0302 03:34:58.188809 29253 solver.cpp:237] Iteration 5280, loss = 0.0031135
I0302 03:34:58.188843 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00311351 (* 1 = 0.00311351 loss)
I0302 03:34:58.188851 29253 sgd_solver.cpp:106] Iteration 5280, lr = 0.01
I0302 03:35:27.012693 29253 solver.cpp:237] Iteration 5300, loss = 0.00330785
I0302 03:35:27.012725 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00330786 (* 1 = 0.00330786 loss)
I0302 03:35:27.012734 29253 sgd_solver.cpp:106] Iteration 5300, lr = 0.01
I0302 03:35:55.885629 29253 solver.cpp:237] Iteration 5320, loss = 0.00252798
I0302 03:35:55.885661 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00252798 (* 1 = 0.00252798 loss)
I0302 03:35:55.885670 29253 sgd_solver.cpp:106] Iteration 5320, lr = 0.01
I0302 03:36:24.889170 29253 solver.cpp:237] Iteration 5340, loss = 0.00211218
I0302 03:36:24.889201 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00211219 (* 1 = 0.00211219 loss)
I0302 03:36:24.889210 29253 sgd_solver.cpp:106] Iteration 5340, lr = 0.01
I0302 03:36:53.355275 29253 solver.cpp:237] Iteration 5360, loss = 0.00261073
I0302 03:36:53.355307 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00261074 (* 1 = 0.00261074 loss)
I0302 03:36:53.355316 29253 sgd_solver.cpp:106] Iteration 5360, lr = 0.01
I0302 03:37:22.192436 29253 solver.cpp:237] Iteration 5380, loss = 0.00350661
I0302 03:37:22.192467 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00350661 (* 1 = 0.00350661 loss)
I0302 03:37:22.192476 29253 sgd_solver.cpp:106] Iteration 5380, lr = 0.01
I0302 03:37:51.380355 29253 solver.cpp:237] Iteration 5400, loss = 0.00279695
I0302 03:37:51.380386 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00279695 (* 1 = 0.00279695 loss)
I0302 03:37:51.380395 29253 sgd_solver.cpp:106] Iteration 5400, lr = 0.01
I0302 03:38:20.275324 29253 solver.cpp:237] Iteration 5420, loss = 0.00247135
I0302 03:38:20.275357 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00247135 (* 1 = 0.00247135 loss)
I0302 03:38:20.275367 29253 sgd_solver.cpp:106] Iteration 5420, lr = 0.01
I0302 03:38:49.369195 29253 solver.cpp:237] Iteration 5440, loss = 0.00245083
I0302 03:38:49.369226 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00245083 (* 1 = 0.00245083 loss)
I0302 03:38:49.369235 29253 sgd_solver.cpp:106] Iteration 5440, lr = 0.01
I0302 03:39:18.393350 29253 solver.cpp:237] Iteration 5460, loss = 0.00208805
I0302 03:39:18.393383 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00208805 (* 1 = 0.00208805 loss)
I0302 03:39:18.393391 29253 sgd_solver.cpp:106] Iteration 5460, lr = 0.01
I0302 03:39:47.344121 29253 solver.cpp:237] Iteration 5480, loss = 0.00215648
I0302 03:39:47.344153 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00215648 (* 1 = 0.00215648 loss)
I0302 03:39:47.344162 29253 sgd_solver.cpp:106] Iteration 5480, lr = 0.01
I0302 03:40:16.254672 29253 solver.cpp:237] Iteration 5500, loss = 0.00268247
I0302 03:40:16.254703 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00268247 (* 1 = 0.00268247 loss)
I0302 03:40:16.254711 29253 sgd_solver.cpp:106] Iteration 5500, lr = 0.01
I0302 03:40:45.262493 29253 solver.cpp:237] Iteration 5520, loss = 0.00221993
I0302 03:40:45.262526 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00221993 (* 1 = 0.00221993 loss)
I0302 03:40:45.262534 29253 sgd_solver.cpp:106] Iteration 5520, lr = 0.01
I0302 03:41:14.189015 29253 solver.cpp:237] Iteration 5540, loss = 0.00341752
I0302 03:41:14.189048 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00341752 (* 1 = 0.00341752 loss)
I0302 03:41:14.189056 29253 sgd_solver.cpp:106] Iteration 5540, lr = 0.01
I0302 03:41:43.322945 29253 solver.cpp:237] Iteration 5560, loss = 0.00272129
I0302 03:41:43.322976 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0027213 (* 1 = 0.0027213 loss)
I0302 03:41:43.322985 29253 sgd_solver.cpp:106] Iteration 5560, lr = 0.01
I0302 03:42:12.449050 29253 solver.cpp:237] Iteration 5580, loss = 0.0022264
I0302 03:42:12.449082 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00222641 (* 1 = 0.00222641 loss)
I0302 03:42:12.449090 29253 sgd_solver.cpp:106] Iteration 5580, lr = 0.01
I0302 03:42:41.392457 29253 solver.cpp:237] Iteration 5600, loss = 0.00296431
I0302 03:42:41.392488 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00296431 (* 1 = 0.00296431 loss)
I0302 03:42:41.392496 29253 sgd_solver.cpp:106] Iteration 5600, lr = 0.01
I0302 03:43:10.152132 29253 solver.cpp:237] Iteration 5620, loss = 0.00250702
I0302 03:43:10.152163 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00250703 (* 1 = 0.00250703 loss)
I0302 03:43:10.152173 29253 sgd_solver.cpp:106] Iteration 5620, lr = 0.01
I0302 03:43:39.132179 29253 solver.cpp:237] Iteration 5640, loss = 0.0026081
I0302 03:43:39.132210 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0026081 (* 1 = 0.0026081 loss)
I0302 03:43:39.132220 29253 sgd_solver.cpp:106] Iteration 5640, lr = 0.01
I0302 03:44:08.011936 29253 solver.cpp:237] Iteration 5660, loss = 0.00240131
I0302 03:44:08.011970 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00240131 (* 1 = 0.00240131 loss)
I0302 03:44:08.011977 29253 sgd_solver.cpp:106] Iteration 5660, lr = 0.01
I0302 03:44:36.879760 29253 solver.cpp:237] Iteration 5680, loss = 0.00255189
I0302 03:44:36.879791 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00255189 (* 1 = 0.00255189 loss)
I0302 03:44:36.879801 29253 sgd_solver.cpp:106] Iteration 5680, lr = 0.01
I0302 03:45:05.753926 29253 solver.cpp:237] Iteration 5700, loss = 0.00323963
I0302 03:45:05.753957 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00323963 (* 1 = 0.00323963 loss)
I0302 03:45:05.753967 29253 sgd_solver.cpp:106] Iteration 5700, lr = 0.01
I0302 03:45:34.683120 29253 solver.cpp:237] Iteration 5720, loss = 0.00347168
I0302 03:45:34.683152 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00347168 (* 1 = 0.00347168 loss)
I0302 03:45:34.683161 29253 sgd_solver.cpp:106] Iteration 5720, lr = 0.01
I0302 03:46:03.647752 29253 solver.cpp:237] Iteration 5740, loss = 0.00236936
I0302 03:46:03.647783 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00236937 (* 1 = 0.00236937 loss)
I0302 03:46:03.647792 29253 sgd_solver.cpp:106] Iteration 5740, lr = 0.01
I0302 03:46:32.415850 29253 solver.cpp:237] Iteration 5760, loss = 0.00238163
I0302 03:46:32.415884 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00238163 (* 1 = 0.00238163 loss)
I0302 03:46:32.415892 29253 sgd_solver.cpp:106] Iteration 5760, lr = 0.01
I0302 03:47:01.247575 29253 solver.cpp:237] Iteration 5780, loss = 0.00261036
I0302 03:47:01.247606 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00261037 (* 1 = 0.00261037 loss)
I0302 03:47:01.247616 29253 sgd_solver.cpp:106] Iteration 5780, lr = 0.01
I0302 03:47:30.133592 29253 solver.cpp:237] Iteration 5800, loss = 0.00222782
I0302 03:47:30.133625 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00222782 (* 1 = 0.00222782 loss)
I0302 03:47:30.133633 29253 sgd_solver.cpp:106] Iteration 5800, lr = 0.01
I0302 03:47:59.301825 29253 solver.cpp:237] Iteration 5820, loss = 0.00198774
I0302 03:47:59.301856 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00198774 (* 1 = 0.00198774 loss)
I0302 03:47:59.301865 29253 sgd_solver.cpp:106] Iteration 5820, lr = 0.01
I0302 03:48:28.225718 29253 solver.cpp:237] Iteration 5840, loss = 0.00212927
I0302 03:48:28.225749 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00212927 (* 1 = 0.00212927 loss)
I0302 03:48:28.225757 29253 sgd_solver.cpp:106] Iteration 5840, lr = 0.01
I0302 03:48:56.982101 29253 solver.cpp:237] Iteration 5860, loss = 0.00242991
I0302 03:48:56.982133 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00242991 (* 1 = 0.00242991 loss)
I0302 03:48:56.982142 29253 sgd_solver.cpp:106] Iteration 5860, lr = 0.01
I0302 03:49:25.876689 29253 solver.cpp:237] Iteration 5880, loss = 0.00306696
I0302 03:49:25.876723 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00306697 (* 1 = 0.00306697 loss)
I0302 03:49:25.876730 29253 sgd_solver.cpp:106] Iteration 5880, lr = 0.01
I0302 03:49:54.750715 29253 solver.cpp:237] Iteration 5900, loss = 0.00237328
I0302 03:49:54.750747 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00237328 (* 1 = 0.00237328 loss)
I0302 03:49:54.750756 29253 sgd_solver.cpp:106] Iteration 5900, lr = 0.01
I0302 03:50:23.732141 29253 solver.cpp:237] Iteration 5920, loss = 0.00224482
I0302 03:50:23.732172 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00224483 (* 1 = 0.00224483 loss)
I0302 03:50:23.732179 29253 sgd_solver.cpp:106] Iteration 5920, lr = 0.01
I0302 03:50:52.642616 29253 solver.cpp:237] Iteration 5940, loss = 0.00270726
I0302 03:50:52.642650 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00270727 (* 1 = 0.00270727 loss)
I0302 03:50:52.642659 29253 sgd_solver.cpp:106] Iteration 5940, lr = 0.01
I0302 03:51:21.511685 29253 solver.cpp:237] Iteration 5960, loss = 0.00238231
I0302 03:51:21.511718 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00238231 (* 1 = 0.00238231 loss)
I0302 03:51:21.511726 29253 sgd_solver.cpp:106] Iteration 5960, lr = 0.01
I0302 03:51:50.391816 29253 solver.cpp:237] Iteration 5980, loss = 0.00213627
I0302 03:51:50.391849 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00213627 (* 1 = 0.00213627 loss)
I0302 03:51:50.391856 29253 sgd_solver.cpp:106] Iteration 5980, lr = 0.01
I0302 03:52:19.125854 29253 solver.cpp:237] Iteration 6000, loss = 0.00268564
I0302 03:52:19.125885 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00268564 (* 1 = 0.00268564 loss)
I0302 03:52:19.125895 29253 sgd_solver.cpp:106] Iteration 6000, lr = 0.01
I0302 03:52:20.590615 29253 blocking_queue.cpp:50] Data layer prefetch queue empty
I0302 03:52:48.179224 29253 solver.cpp:237] Iteration 6020, loss = 0.00360098
I0302 03:52:48.179255 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00360098 (* 1 = 0.00360098 loss)
I0302 03:52:48.179263 29253 sgd_solver.cpp:106] Iteration 6020, lr = 0.01
I0302 03:53:16.971969 29253 solver.cpp:237] Iteration 6040, loss = 0.00240205
I0302 03:53:16.972002 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00240206 (* 1 = 0.00240206 loss)
I0302 03:53:16.972010 29253 sgd_solver.cpp:106] Iteration 6040, lr = 0.01
I0302 03:53:45.998399 29253 solver.cpp:237] Iteration 6060, loss = 0.00228475
I0302 03:53:45.998432 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00228476 (* 1 = 0.00228476 loss)
I0302 03:53:45.998440 29253 sgd_solver.cpp:106] Iteration 6060, lr = 0.01
I0302 03:54:14.881940 29253 solver.cpp:237] Iteration 6080, loss = 0.00288618
I0302 03:54:14.881973 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00288618 (* 1 = 0.00288618 loss)
I0302 03:54:14.881983 29253 sgd_solver.cpp:106] Iteration 6080, lr = 0.01
I0302 03:54:43.849663 29253 solver.cpp:237] Iteration 6100, loss = 0.00236316
I0302 03:54:43.849699 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00236316 (* 1 = 0.00236316 loss)
I0302 03:54:43.849707 29253 sgd_solver.cpp:106] Iteration 6100, lr = 0.01
I0302 03:55:12.731550 29253 solver.cpp:237] Iteration 6120, loss = 0.00250797
I0302 03:55:12.731582 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00250798 (* 1 = 0.00250798 loss)
I0302 03:55:12.731591 29253 sgd_solver.cpp:106] Iteration 6120, lr = 0.01
I0302 03:55:41.678817 29253 solver.cpp:237] Iteration 6140, loss = 0.00243017
I0302 03:55:41.678848 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00243018 (* 1 = 0.00243018 loss)
I0302 03:55:41.678856 29253 sgd_solver.cpp:106] Iteration 6140, lr = 0.01
I0302 03:56:10.405531 29253 solver.cpp:237] Iteration 6160, loss = 0.00177697
I0302 03:56:10.405562 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00177698 (* 1 = 0.00177698 loss)
I0302 03:56:10.405570 29253 sgd_solver.cpp:106] Iteration 6160, lr = 0.01
I0302 03:56:39.413277 29253 solver.cpp:237] Iteration 6180, loss = 0.00297865
I0302 03:56:39.413310 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00297865 (* 1 = 0.00297865 loss)
I0302 03:56:39.413317 29253 sgd_solver.cpp:106] Iteration 6180, lr = 0.01
I0302 03:57:08.321249 29253 solver.cpp:237] Iteration 6200, loss = 0.00318785
I0302 03:57:08.321282 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00318785 (* 1 = 0.00318785 loss)
I0302 03:57:08.321290 29253 sgd_solver.cpp:106] Iteration 6200, lr = 0.01
I0302 03:57:37.429453 29253 solver.cpp:237] Iteration 6220, loss = 0.00262951
I0302 03:57:37.429486 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00262951 (* 1 = 0.00262951 loss)
I0302 03:57:37.429494 29253 sgd_solver.cpp:106] Iteration 6220, lr = 0.01
I0302 03:58:06.391296 29253 solver.cpp:237] Iteration 6240, loss = 0.00201973
I0302 03:58:06.391329 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00201974 (* 1 = 0.00201974 loss)
I0302 03:58:06.391336 29253 sgd_solver.cpp:106] Iteration 6240, lr = 0.01
I0302 03:58:35.343271 29253 solver.cpp:237] Iteration 6260, loss = 0.00215815
I0302 03:58:35.343304 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00215815 (* 1 = 0.00215815 loss)
I0302 03:58:35.343312 29253 sgd_solver.cpp:106] Iteration 6260, lr = 0.01
I0302 03:59:04.244256 29253 solver.cpp:237] Iteration 6280, loss = 0.00266912
I0302 03:59:04.244292 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00266912 (* 1 = 0.00266912 loss)
I0302 03:59:04.244299 29253 sgd_solver.cpp:106] Iteration 6280, lr = 0.01
I0302 03:59:33.150887 29253 solver.cpp:237] Iteration 6300, loss = 0.00253897
I0302 03:59:33.150919 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00253898 (* 1 = 0.00253898 loss)
I0302 03:59:33.150928 29253 sgd_solver.cpp:106] Iteration 6300, lr = 0.01
I0302 04:00:02.087121 29253 solver.cpp:237] Iteration 6320, loss = 0.00188797
I0302 04:00:02.087146 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00188797 (* 1 = 0.00188797 loss)
I0302 04:00:02.087154 29253 sgd_solver.cpp:106] Iteration 6320, lr = 0.01
I0302 04:00:31.148216 29253 solver.cpp:237] Iteration 6340, loss = 0.00214555
I0302 04:00:31.148248 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00214555 (* 1 = 0.00214555 loss)
I0302 04:00:31.148257 29253 sgd_solver.cpp:106] Iteration 6340, lr = 0.01
I0302 04:01:00.110127 29253 solver.cpp:237] Iteration 6360, loss = 0.00234249
I0302 04:01:00.110158 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0023425 (* 1 = 0.0023425 loss)
I0302 04:01:00.110167 29253 sgd_solver.cpp:106] Iteration 6360, lr = 0.01
I0302 04:01:28.811439 29253 solver.cpp:237] Iteration 6380, loss = 0.00219932
I0302 04:01:28.811471 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00219932 (* 1 = 0.00219932 loss)
I0302 04:01:28.811480 29253 sgd_solver.cpp:106] Iteration 6380, lr = 0.01
I0302 04:01:57.696645 29253 solver.cpp:237] Iteration 6400, loss = 0.00190791
I0302 04:01:57.696678 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00190791 (* 1 = 0.00190791 loss)
I0302 04:01:57.696687 29253 sgd_solver.cpp:106] Iteration 6400, lr = 0.01
I0302 04:02:26.656524 29253 solver.cpp:237] Iteration 6420, loss = 0.00324996
I0302 04:02:26.656558 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00324996 (* 1 = 0.00324996 loss)
I0302 04:02:26.656568 29253 sgd_solver.cpp:106] Iteration 6420, lr = 0.01
I0302 04:02:55.693819 29253 solver.cpp:237] Iteration 6440, loss = 0.00211083
I0302 04:02:55.693850 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00211083 (* 1 = 0.00211083 loss)
I0302 04:02:55.693859 29253 sgd_solver.cpp:106] Iteration 6440, lr = 0.01
I0302 04:03:24.554352 29253 solver.cpp:237] Iteration 6460, loss = 0.00251865
I0302 04:03:24.554383 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00251866 (* 1 = 0.00251866 loss)
I0302 04:03:24.554393 29253 sgd_solver.cpp:106] Iteration 6460, lr = 0.01
I0302 04:03:53.406373 29253 solver.cpp:237] Iteration 6480, loss = 0.00251576
I0302 04:03:53.406404 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00251576 (* 1 = 0.00251576 loss)
I0302 04:03:53.406412 29253 sgd_solver.cpp:106] Iteration 6480, lr = 0.01
I0302 04:04:22.447063 29253 solver.cpp:237] Iteration 6500, loss = 0.00267572
I0302 04:04:22.447095 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00267572 (* 1 = 0.00267572 loss)
I0302 04:04:22.447104 29253 sgd_solver.cpp:106] Iteration 6500, lr = 0.01
I0302 04:04:51.377550 29253 solver.cpp:237] Iteration 6520, loss = 0.00334041
I0302 04:04:51.377583 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00334041 (* 1 = 0.00334041 loss)
I0302 04:04:51.377591 29253 sgd_solver.cpp:106] Iteration 6520, lr = 0.01
I0302 04:05:20.508569 29253 solver.cpp:237] Iteration 6540, loss = 0.00234809
I0302 04:05:20.508600 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0023481 (* 1 = 0.0023481 loss)
I0302 04:05:20.508610 29253 sgd_solver.cpp:106] Iteration 6540, lr = 0.01
I0302 04:05:49.182801 29253 solver.cpp:237] Iteration 6560, loss = 0.00216728
I0302 04:05:49.182833 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00216729 (* 1 = 0.00216729 loss)
I0302 04:05:49.182842 29253 sgd_solver.cpp:106] Iteration 6560, lr = 0.01
I0302 04:06:18.593261 29253 solver.cpp:237] Iteration 6580, loss = 0.00293119
I0302 04:06:18.593293 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00293119 (* 1 = 0.00293119 loss)
I0302 04:06:18.593302 29253 sgd_solver.cpp:106] Iteration 6580, lr = 0.01
I0302 04:06:47.169883 29253 solver.cpp:237] Iteration 6600, loss = 0.00253633
I0302 04:06:47.169914 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00253634 (* 1 = 0.00253634 loss)
I0302 04:06:47.169922 29253 sgd_solver.cpp:106] Iteration 6600, lr = 0.01
I0302 04:07:16.357264 29253 solver.cpp:237] Iteration 6620, loss = 0.00205186
I0302 04:07:16.357297 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00205186 (* 1 = 0.00205186 loss)
I0302 04:07:16.357306 29253 sgd_solver.cpp:106] Iteration 6620, lr = 0.01
I0302 04:07:45.016427 29253 solver.cpp:237] Iteration 6640, loss = 0.00258107
I0302 04:07:45.016458 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00258108 (* 1 = 0.00258108 loss)
I0302 04:07:45.016468 29253 sgd_solver.cpp:106] Iteration 6640, lr = 0.01
I0302 04:08:13.892647 29253 solver.cpp:237] Iteration 6660, loss = 0.00162437
I0302 04:08:13.892678 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00162438 (* 1 = 0.00162438 loss)
I0302 04:08:13.892688 29253 sgd_solver.cpp:106] Iteration 6660, lr = 0.01
I0302 04:08:42.717833 29253 solver.cpp:237] Iteration 6680, loss = 0.00281132
I0302 04:08:42.717864 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00281133 (* 1 = 0.00281133 loss)
I0302 04:08:42.717874 29253 sgd_solver.cpp:106] Iteration 6680, lr = 0.01
I0302 04:09:11.634122 29253 solver.cpp:237] Iteration 6700, loss = 0.00213163
I0302 04:09:11.634153 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00213163 (* 1 = 0.00213163 loss)
I0302 04:09:11.634162 29253 sgd_solver.cpp:106] Iteration 6700, lr = 0.01
I0302 04:09:40.496177 29253 solver.cpp:237] Iteration 6720, loss = 0.00208132
I0302 04:09:40.496208 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00208133 (* 1 = 0.00208133 loss)
I0302 04:09:40.496218 29253 sgd_solver.cpp:106] Iteration 6720, lr = 0.01
I0302 04:10:09.359254 29253 solver.cpp:237] Iteration 6740, loss = 0.00328727
I0302 04:10:09.359285 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00328727 (* 1 = 0.00328727 loss)
I0302 04:10:09.359294 29253 sgd_solver.cpp:106] Iteration 6740, lr = 0.01
I0302 04:10:38.331076 29253 solver.cpp:237] Iteration 6760, loss = 0.00223241
I0302 04:10:38.331107 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00223242 (* 1 = 0.00223242 loss)
I0302 04:10:38.331115 29253 sgd_solver.cpp:106] Iteration 6760, lr = 0.01
I0302 04:11:07.116994 29253 solver.cpp:237] Iteration 6780, loss = 0.00239753
I0302 04:11:07.117027 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00239754 (* 1 = 0.00239754 loss)
I0302 04:11:07.117035 29253 sgd_solver.cpp:106] Iteration 6780, lr = 0.01
I0302 04:11:36.228602 29253 solver.cpp:237] Iteration 6800, loss = 0.00324862
I0302 04:11:36.228633 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00324863 (* 1 = 0.00324863 loss)
I0302 04:11:36.228642 29253 sgd_solver.cpp:106] Iteration 6800, lr = 0.01
I0302 04:12:04.968103 29253 solver.cpp:237] Iteration 6820, loss = 0.00216368
I0302 04:12:04.968135 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00216368 (* 1 = 0.00216368 loss)
I0302 04:12:04.968144 29253 sgd_solver.cpp:106] Iteration 6820, lr = 0.01
I0302 04:12:33.908814 29253 solver.cpp:237] Iteration 6840, loss = 0.0024597
I0302 04:12:33.908846 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00245971 (* 1 = 0.00245971 loss)
I0302 04:12:33.908855 29253 sgd_solver.cpp:106] Iteration 6840, lr = 0.01
I0302 04:13:02.876591 29253 solver.cpp:237] Iteration 6860, loss = 0.00226357
I0302 04:13:02.876624 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00226357 (* 1 = 0.00226357 loss)
I0302 04:13:02.876633 29253 sgd_solver.cpp:106] Iteration 6860, lr = 0.01
I0302 04:13:31.643975 29253 solver.cpp:237] Iteration 6880, loss = 0.00217594
I0302 04:13:31.644006 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00217594 (* 1 = 0.00217594 loss)
I0302 04:13:31.644016 29253 sgd_solver.cpp:106] Iteration 6880, lr = 0.01
I0302 04:14:00.697929 29253 solver.cpp:237] Iteration 6900, loss = 0.00305026
I0302 04:14:00.697962 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00305026 (* 1 = 0.00305026 loss)
I0302 04:14:00.697970 29253 sgd_solver.cpp:106] Iteration 6900, lr = 0.01
I0302 04:14:29.689321 29253 solver.cpp:237] Iteration 6920, loss = 0.00216984
I0302 04:14:29.689352 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00216985 (* 1 = 0.00216985 loss)
I0302 04:14:29.689360 29253 sgd_solver.cpp:106] Iteration 6920, lr = 0.01
I0302 04:14:58.626935 29253 solver.cpp:237] Iteration 6940, loss = 0.00164244
I0302 04:14:58.626967 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00164245 (* 1 = 0.00164245 loss)
I0302 04:14:58.626976 29253 sgd_solver.cpp:106] Iteration 6940, lr = 0.01
I0302 04:15:27.550389 29253 solver.cpp:237] Iteration 6960, loss = 0.00211424
I0302 04:15:27.550420 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00211424 (* 1 = 0.00211424 loss)
I0302 04:15:27.550428 29253 sgd_solver.cpp:106] Iteration 6960, lr = 0.01
I0302 04:15:56.495760 29253 solver.cpp:237] Iteration 6980, loss = 0.00222568
I0302 04:15:56.495795 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00222568 (* 1 = 0.00222568 loss)
I0302 04:15:56.495805 29253 sgd_solver.cpp:106] Iteration 6980, lr = 0.01
I0302 04:16:25.383913 29253 solver.cpp:237] Iteration 7000, loss = 0.00259193
I0302 04:16:25.383945 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00259193 (* 1 = 0.00259193 loss)
I0302 04:16:25.383955 29253 sgd_solver.cpp:106] Iteration 7000, lr = 0.01
I0302 04:16:26.803321 29253 blocking_queue.cpp:50] Data layer prefetch queue empty
I0302 04:16:54.236315 29253 solver.cpp:237] Iteration 7020, loss = 0.00259925
I0302 04:16:54.236347 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00259925 (* 1 = 0.00259925 loss)
I0302 04:16:54.236356 29253 sgd_solver.cpp:106] Iteration 7020, lr = 0.01
I0302 04:17:23.207043 29253 solver.cpp:237] Iteration 7040, loss = 0.00188352
I0302 04:17:23.207077 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00188352 (* 1 = 0.00188352 loss)
I0302 04:17:23.207084 29253 sgd_solver.cpp:106] Iteration 7040, lr = 0.01
I0302 04:17:52.094864 29253 solver.cpp:237] Iteration 7060, loss = 0.00191986
I0302 04:17:52.094897 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00191987 (* 1 = 0.00191987 loss)
I0302 04:17:52.094904 29253 sgd_solver.cpp:106] Iteration 7060, lr = 0.01
I0302 04:18:21.071864 29253 solver.cpp:237] Iteration 7080, loss = 0.00225271
I0302 04:18:21.071897 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00225272 (* 1 = 0.00225272 loss)
I0302 04:18:21.071904 29253 sgd_solver.cpp:106] Iteration 7080, lr = 0.01
I0302 04:18:50.095136 29253 solver.cpp:237] Iteration 7100, loss = 0.00198959
I0302 04:18:50.095168 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0019896 (* 1 = 0.0019896 loss)
I0302 04:18:50.095177 29253 sgd_solver.cpp:106] Iteration 7100, lr = 0.01
I0302 04:19:18.930760 29253 solver.cpp:237] Iteration 7120, loss = 0.0017339
I0302 04:19:18.930791 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0017339 (* 1 = 0.0017339 loss)
I0302 04:19:18.930800 29253 sgd_solver.cpp:106] Iteration 7120, lr = 0.01
I0302 04:19:47.729373 29253 solver.cpp:237] Iteration 7140, loss = 0.00256565
I0302 04:19:47.729408 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00256566 (* 1 = 0.00256566 loss)
I0302 04:19:47.729416 29253 sgd_solver.cpp:106] Iteration 7140, lr = 0.01
I0302 04:20:16.613625 29253 solver.cpp:237] Iteration 7160, loss = 0.00256558
I0302 04:20:16.613656 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00256558 (* 1 = 0.00256558 loss)
I0302 04:20:16.613665 29253 sgd_solver.cpp:106] Iteration 7160, lr = 0.01
I0302 04:20:45.642930 29253 solver.cpp:237] Iteration 7180, loss = 0.00292085
I0302 04:20:45.642961 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00292086 (* 1 = 0.00292086 loss)
I0302 04:20:45.642969 29253 sgd_solver.cpp:106] Iteration 7180, lr = 0.01
I0302 04:21:14.538031 29253 solver.cpp:237] Iteration 7200, loss = 0.00203982
I0302 04:21:14.538064 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00203982 (* 1 = 0.00203982 loss)
I0302 04:21:14.538072 29253 sgd_solver.cpp:106] Iteration 7200, lr = 0.01
I0302 04:21:43.485893 29253 solver.cpp:237] Iteration 7220, loss = 0.00220078
I0302 04:21:43.485924 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00220078 (* 1 = 0.00220078 loss)
I0302 04:21:43.485932 29253 sgd_solver.cpp:106] Iteration 7220, lr = 0.01
I0302 04:22:12.405211 29253 solver.cpp:237] Iteration 7240, loss = 0.00192208
I0302 04:22:12.405244 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00192208 (* 1 = 0.00192208 loss)
I0302 04:22:12.405252 29253 sgd_solver.cpp:106] Iteration 7240, lr = 0.01
I0302 04:22:41.116060 29253 solver.cpp:237] Iteration 7260, loss = 0.00171901
I0302 04:22:41.116091 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00171901 (* 1 = 0.00171901 loss)
I0302 04:22:41.116101 29253 sgd_solver.cpp:106] Iteration 7260, lr = 0.01
I0302 04:23:10.294323 29253 solver.cpp:237] Iteration 7280, loss = 0.00203338
I0302 04:23:10.294355 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00203338 (* 1 = 0.00203338 loss)
I0302 04:23:10.294364 29253 sgd_solver.cpp:106] Iteration 7280, lr = 0.01
I0302 04:23:39.351727 29253 solver.cpp:237] Iteration 7300, loss = 0.00200845
I0302 04:23:39.351758 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00200845 (* 1 = 0.00200845 loss)
I0302 04:23:39.351766 29253 sgd_solver.cpp:106] Iteration 7300, lr = 0.01
I0302 04:24:08.120069 29253 solver.cpp:237] Iteration 7320, loss = 0.00177042
I0302 04:24:08.120100 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00177042 (* 1 = 0.00177042 loss)
I0302 04:24:08.120107 29253 sgd_solver.cpp:106] Iteration 7320, lr = 0.01
I0302 04:24:37.078920 29253 solver.cpp:237] Iteration 7340, loss = 0.00178322
I0302 04:24:37.078953 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00178322 (* 1 = 0.00178322 loss)
I0302 04:24:37.078961 29253 sgd_solver.cpp:106] Iteration 7340, lr = 0.01
I0302 04:25:05.968744 29253 solver.cpp:237] Iteration 7360, loss = 0.00225083
I0302 04:25:05.968776 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00225083 (* 1 = 0.00225083 loss)
I0302 04:25:05.968786 29253 sgd_solver.cpp:106] Iteration 7360, lr = 0.01
I0302 04:25:34.742040 29253 solver.cpp:237] Iteration 7380, loss = 0.00242886
I0302 04:25:34.742072 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00242887 (* 1 = 0.00242887 loss)
I0302 04:25:34.742081 29253 sgd_solver.cpp:106] Iteration 7380, lr = 0.01
I0302 04:26:03.897946 29253 solver.cpp:237] Iteration 7400, loss = 0.00206723
I0302 04:26:03.897979 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00206723 (* 1 = 0.00206723 loss)
I0302 04:26:03.897987 29253 sgd_solver.cpp:106] Iteration 7400, lr = 0.01
I0302 04:26:32.813752 29253 solver.cpp:237] Iteration 7420, loss = 0.00184139
I0302 04:26:32.813784 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00184139 (* 1 = 0.00184139 loss)
I0302 04:26:32.813792 29253 sgd_solver.cpp:106] Iteration 7420, lr = 0.01
I0302 04:27:01.488957 29253 solver.cpp:237] Iteration 7440, loss = 0.00189486
I0302 04:27:01.488989 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00189486 (* 1 = 0.00189486 loss)
I0302 04:27:01.488998 29253 sgd_solver.cpp:106] Iteration 7440, lr = 0.01
I0302 04:27:30.580451 29253 solver.cpp:237] Iteration 7460, loss = 0.00229891
I0302 04:27:30.580482 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00229892 (* 1 = 0.00229892 loss)
I0302 04:27:30.580492 29253 sgd_solver.cpp:106] Iteration 7460, lr = 0.01
I0302 04:27:59.544340 29253 solver.cpp:237] Iteration 7480, loss = 0.00250431
I0302 04:27:59.544373 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00250431 (* 1 = 0.00250431 loss)
I0302 04:27:59.544386 29253 sgd_solver.cpp:106] Iteration 7480, lr = 0.01
I0302 04:28:28.158795 29253 solver.cpp:237] Iteration 7500, loss = 0.00177858
I0302 04:28:28.158828 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00177859 (* 1 = 0.00177859 loss)
I0302 04:28:28.158836 29253 sgd_solver.cpp:106] Iteration 7500, lr = 0.01
I0302 04:28:56.989147 29253 solver.cpp:237] Iteration 7520, loss = 0.00265801
I0302 04:28:56.989181 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00265802 (* 1 = 0.00265802 loss)
I0302 04:28:56.989189 29253 sgd_solver.cpp:106] Iteration 7520, lr = 0.01
I0302 04:29:25.925583 29253 solver.cpp:237] Iteration 7540, loss = 0.00237429
I0302 04:29:25.925616 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00237429 (* 1 = 0.00237429 loss)
I0302 04:29:25.925624 29253 sgd_solver.cpp:106] Iteration 7540, lr = 0.01
I0302 04:29:54.760591 29253 solver.cpp:237] Iteration 7560, loss = 0.00210448
I0302 04:29:54.760622 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00210448 (* 1 = 0.00210448 loss)
I0302 04:29:54.760630 29253 sgd_solver.cpp:106] Iteration 7560, lr = 0.01
I0302 04:30:23.813681 29253 solver.cpp:237] Iteration 7580, loss = 0.00235754
I0302 04:30:23.813714 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00235754 (* 1 = 0.00235754 loss)
I0302 04:30:23.813721 29253 sgd_solver.cpp:106] Iteration 7580, lr = 0.01
I0302 04:30:52.710563 29253 solver.cpp:237] Iteration 7600, loss = 0.00194149
I0302 04:30:52.710597 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00194149 (* 1 = 0.00194149 loss)
I0302 04:30:52.710605 29253 sgd_solver.cpp:106] Iteration 7600, lr = 0.01
I0302 04:31:21.715960 29253 solver.cpp:237] Iteration 7620, loss = 0.00208054
I0302 04:31:21.715991 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00208055 (* 1 = 0.00208055 loss)
I0302 04:31:21.715999 29253 sgd_solver.cpp:106] Iteration 7620, lr = 0.01
I0302 04:31:50.676549 29253 solver.cpp:237] Iteration 7640, loss = 0.00220253
I0302 04:31:50.676583 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00220253 (* 1 = 0.00220253 loss)
I0302 04:31:50.676591 29253 sgd_solver.cpp:106] Iteration 7640, lr = 0.01
I0302 04:32:19.544734 29253 solver.cpp:237] Iteration 7660, loss = 0.00223022
I0302 04:32:19.544766 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00223023 (* 1 = 0.00223023 loss)
I0302 04:32:19.544775 29253 sgd_solver.cpp:106] Iteration 7660, lr = 0.01
I0302 04:32:48.726048 29253 solver.cpp:237] Iteration 7680, loss = 0.00295705
I0302 04:32:48.726080 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00295705 (* 1 = 0.00295705 loss)
I0302 04:32:48.726089 29253 sgd_solver.cpp:106] Iteration 7680, lr = 0.01
I0302 04:33:17.363071 29253 solver.cpp:237] Iteration 7700, loss = 0.0019192
I0302 04:33:17.363103 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0019192 (* 1 = 0.0019192 loss)
I0302 04:33:17.363112 29253 sgd_solver.cpp:106] Iteration 7700, lr = 0.01
I0302 04:33:46.387174 29253 solver.cpp:237] Iteration 7720, loss = 0.0026218
I0302 04:33:46.387207 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0026218 (* 1 = 0.0026218 loss)
I0302 04:33:46.387215 29253 sgd_solver.cpp:106] Iteration 7720, lr = 0.01
I0302 04:34:15.230016 29253 solver.cpp:237] Iteration 7740, loss = 0.00212614
I0302 04:34:15.230049 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00212614 (* 1 = 0.00212614 loss)
I0302 04:34:15.230058 29253 sgd_solver.cpp:106] Iteration 7740, lr = 0.01
I0302 04:34:44.165163 29253 solver.cpp:237] Iteration 7760, loss = 0.00256316
I0302 04:34:44.165196 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00256316 (* 1 = 0.00256316 loss)
I0302 04:34:44.165205 29253 sgd_solver.cpp:106] Iteration 7760, lr = 0.01
I0302 04:35:13.122100 29253 solver.cpp:237] Iteration 7780, loss = 0.00195844
I0302 04:35:13.122131 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00195844 (* 1 = 0.00195844 loss)
I0302 04:35:13.122139 29253 sgd_solver.cpp:106] Iteration 7780, lr = 0.01
I0302 04:35:41.866683 29253 solver.cpp:237] Iteration 7800, loss = 0.00223625
I0302 04:35:41.866715 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00223625 (* 1 = 0.00223625 loss)
I0302 04:35:41.866724 29253 sgd_solver.cpp:106] Iteration 7800, lr = 0.01
I0302 04:36:10.721196 29253 solver.cpp:237] Iteration 7820, loss = 0.00210967
I0302 04:36:10.721228 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00210967 (* 1 = 0.00210967 loss)
I0302 04:36:10.721237 29253 sgd_solver.cpp:106] Iteration 7820, lr = 0.01
I0302 04:36:39.698168 29253 solver.cpp:237] Iteration 7840, loss = 0.00270781
I0302 04:36:39.698199 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00270781 (* 1 = 0.00270781 loss)
I0302 04:36:39.698207 29253 sgd_solver.cpp:106] Iteration 7840, lr = 0.01
I0302 04:37:08.948832 29253 solver.cpp:237] Iteration 7860, loss = 0.00166895
I0302 04:37:08.948863 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00166895 (* 1 = 0.00166895 loss)
I0302 04:37:08.948873 29253 sgd_solver.cpp:106] Iteration 7860, lr = 0.01
I0302 04:37:37.879045 29253 solver.cpp:237] Iteration 7880, loss = 0.00224303
I0302 04:37:37.879078 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00224303 (* 1 = 0.00224303 loss)
I0302 04:37:37.879086 29253 sgd_solver.cpp:106] Iteration 7880, lr = 0.01
I0302 04:38:06.760440 29253 solver.cpp:237] Iteration 7900, loss = 0.002131
I0302 04:38:06.760473 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.002131 (* 1 = 0.002131 loss)
I0302 04:38:06.760481 29253 sgd_solver.cpp:106] Iteration 7900, lr = 0.01
I0302 04:38:35.733219 29253 solver.cpp:237] Iteration 7920, loss = 0.00205686
I0302 04:38:35.733253 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00205686 (* 1 = 0.00205686 loss)
I0302 04:38:35.733260 29253 sgd_solver.cpp:106] Iteration 7920, lr = 0.01
I0302 04:39:04.783475 29253 solver.cpp:237] Iteration 7940, loss = 0.00220233
I0302 04:39:04.783509 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00220233 (* 1 = 0.00220233 loss)
I0302 04:39:04.783516 29253 sgd_solver.cpp:106] Iteration 7940, lr = 0.01
I0302 04:39:33.525184 29253 solver.cpp:237] Iteration 7960, loss = 0.00195312
I0302 04:39:33.525218 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00195312 (* 1 = 0.00195312 loss)
I0302 04:39:33.525226 29253 sgd_solver.cpp:106] Iteration 7960, lr = 0.01
I0302 04:40:02.018452 29253 solver.cpp:237] Iteration 7980, loss = 0.00202987
I0302 04:40:02.018484 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00202988 (* 1 = 0.00202988 loss)
I0302 04:40:02.018493 29253 sgd_solver.cpp:106] Iteration 7980, lr = 0.01
I0302 04:40:31.064854 29253 solver.cpp:237] Iteration 8000, loss = 0.00206543
I0302 04:40:31.064887 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00206543 (* 1 = 0.00206543 loss)
I0302 04:40:31.064895 29253 sgd_solver.cpp:106] Iteration 8000, lr = 0.01
I0302 04:40:32.634112 29253 blocking_queue.cpp:50] Data layer prefetch queue empty
I0302 04:40:59.784379 29253 solver.cpp:237] Iteration 8020, loss = 0.00214246
I0302 04:40:59.784410 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00214246 (* 1 = 0.00214246 loss)
I0302 04:40:59.784420 29253 sgd_solver.cpp:106] Iteration 8020, lr = 0.01
I0302 04:41:29.251983 29253 solver.cpp:237] Iteration 8040, loss = 0.00233981
I0302 04:41:29.252017 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00233982 (* 1 = 0.00233982 loss)
I0302 04:41:29.252024 29253 sgd_solver.cpp:106] Iteration 8040, lr = 0.01
I0302 04:41:58.459951 29253 solver.cpp:237] Iteration 8060, loss = 0.00164515
I0302 04:41:58.459985 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00164515 (* 1 = 0.00164515 loss)
I0302 04:41:58.459992 29253 sgd_solver.cpp:106] Iteration 8060, lr = 0.01
I0302 04:42:27.353610 29253 solver.cpp:237] Iteration 8080, loss = 0.00230427
I0302 04:42:27.353642 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00230427 (* 1 = 0.00230427 loss)
I0302 04:42:27.353652 29253 sgd_solver.cpp:106] Iteration 8080, lr = 0.01
I0302 04:42:56.377647 29253 solver.cpp:237] Iteration 8100, loss = 0.00179681
I0302 04:42:56.377681 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00179681 (* 1 = 0.00179681 loss)
I0302 04:42:56.377691 29253 sgd_solver.cpp:106] Iteration 8100, lr = 0.01
I0302 04:43:25.850625 29253 solver.cpp:237] Iteration 8120, loss = 0.0019034
I0302 04:43:25.850658 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0019034 (* 1 = 0.0019034 loss)
I0302 04:43:25.850666 29253 sgd_solver.cpp:106] Iteration 8120, lr = 0.01
I0302 04:43:54.767562 29253 solver.cpp:237] Iteration 8140, loss = 0.00222979
I0302 04:43:54.767593 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0022298 (* 1 = 0.0022298 loss)
I0302 04:43:54.767601 29253 sgd_solver.cpp:106] Iteration 8140, lr = 0.01
I0302 04:44:23.449241 29253 solver.cpp:237] Iteration 8160, loss = 0.00217297
I0302 04:44:23.449275 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00217298 (* 1 = 0.00217298 loss)
I0302 04:44:23.449282 29253 sgd_solver.cpp:106] Iteration 8160, lr = 0.01
I0302 04:44:52.264163 29253 solver.cpp:237] Iteration 8180, loss = 0.00187483
I0302 04:44:52.264196 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00187483 (* 1 = 0.00187483 loss)
I0302 04:44:52.264204 29253 sgd_solver.cpp:106] Iteration 8180, lr = 0.01
I0302 04:45:21.029170 29253 solver.cpp:237] Iteration 8200, loss = 0.00184318
I0302 04:45:21.029201 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00184319 (* 1 = 0.00184319 loss)
I0302 04:45:21.029211 29253 sgd_solver.cpp:106] Iteration 8200, lr = 0.01
I0302 04:45:49.783478 29253 solver.cpp:237] Iteration 8220, loss = 0.00190254
I0302 04:45:49.783510 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00190254 (* 1 = 0.00190254 loss)
I0302 04:45:49.783519 29253 sgd_solver.cpp:106] Iteration 8220, lr = 0.01
I0302 04:46:18.882592 29253 solver.cpp:237] Iteration 8240, loss = 0.00192609
I0302 04:46:18.882624 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00192609 (* 1 = 0.00192609 loss)
I0302 04:46:18.882632 29253 sgd_solver.cpp:106] Iteration 8240, lr = 0.01
I0302 04:46:47.262382 29253 solver.cpp:237] Iteration 8260, loss = 0.0020804
I0302 04:46:47.262413 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0020804 (* 1 = 0.0020804 loss)
I0302 04:46:47.262421 29253 sgd_solver.cpp:106] Iteration 8260, lr = 0.01
I0302 04:47:16.577121 29253 solver.cpp:237] Iteration 8280, loss = 0.00164551
I0302 04:47:16.577153 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00164551 (* 1 = 0.00164551 loss)
I0302 04:47:16.577162 29253 sgd_solver.cpp:106] Iteration 8280, lr = 0.01
I0302 04:47:45.570102 29253 solver.cpp:237] Iteration 8300, loss = 0.00223396
I0302 04:47:45.570134 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00223396 (* 1 = 0.00223396 loss)
I0302 04:47:45.570142 29253 sgd_solver.cpp:106] Iteration 8300, lr = 0.01
I0302 04:48:14.276671 29253 solver.cpp:237] Iteration 8320, loss = 0.00239955
I0302 04:48:14.276702 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00239955 (* 1 = 0.00239955 loss)
I0302 04:48:14.276710 29253 sgd_solver.cpp:106] Iteration 8320, lr = 0.01
I0302 04:48:43.205616 29253 solver.cpp:237] Iteration 8340, loss = 0.0019504
I0302 04:48:43.205649 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0019504 (* 1 = 0.0019504 loss)
I0302 04:48:43.205658 29253 sgd_solver.cpp:106] Iteration 8340, lr = 0.01
I0302 04:49:12.246242 29253 solver.cpp:237] Iteration 8360, loss = 0.00218425
I0302 04:49:12.246274 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00218425 (* 1 = 0.00218425 loss)
I0302 04:49:12.246284 29253 sgd_solver.cpp:106] Iteration 8360, lr = 0.01
I0302 04:49:41.173127 29253 solver.cpp:237] Iteration 8380, loss = 0.00200274
I0302 04:49:41.173159 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00200274 (* 1 = 0.00200274 loss)
I0302 04:49:41.173167 29253 sgd_solver.cpp:106] Iteration 8380, lr = 0.01
I0302 04:50:10.113709 29253 solver.cpp:237] Iteration 8400, loss = 0.00202301
I0302 04:50:10.113741 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00202302 (* 1 = 0.00202302 loss)
I0302 04:50:10.113750 29253 sgd_solver.cpp:106] Iteration 8400, lr = 0.01
I0302 04:50:39.457294 29253 solver.cpp:237] Iteration 8420, loss = 0.00241585
I0302 04:50:39.457326 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00241586 (* 1 = 0.00241586 loss)
I0302 04:50:39.457335 29253 sgd_solver.cpp:106] Iteration 8420, lr = 0.01
I0302 04:51:08.406478 29253 solver.cpp:237] Iteration 8440, loss = 0.00252864
I0302 04:51:08.406512 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00252865 (* 1 = 0.00252865 loss)
I0302 04:51:08.406520 29253 sgd_solver.cpp:106] Iteration 8440, lr = 0.01
I0302 04:51:37.037677 29253 solver.cpp:237] Iteration 8460, loss = 0.00238135
I0302 04:51:37.037708 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00238135 (* 1 = 0.00238135 loss)
I0302 04:51:37.037716 29253 sgd_solver.cpp:106] Iteration 8460, lr = 0.01
I0302 04:52:06.308193 29253 solver.cpp:237] Iteration 8480, loss = 0.00200182
I0302 04:52:06.308225 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00200183 (* 1 = 0.00200183 loss)
I0302 04:52:06.308234 29253 sgd_solver.cpp:106] Iteration 8480, lr = 0.01
I0302 04:52:35.176282 29253 solver.cpp:237] Iteration 8500, loss = 0.00176283
I0302 04:52:35.176314 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00176284 (* 1 = 0.00176284 loss)
I0302 04:52:35.176323 29253 sgd_solver.cpp:106] Iteration 8500, lr = 0.01
I0302 04:53:04.124960 29253 solver.cpp:237] Iteration 8520, loss = 0.00239972
I0302 04:53:04.124992 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00239973 (* 1 = 0.00239973 loss)
I0302 04:53:04.125001 29253 sgd_solver.cpp:106] Iteration 8520, lr = 0.01
I0302 04:53:33.052278 29253 solver.cpp:237] Iteration 8540, loss = 0.0030299
I0302 04:53:33.052309 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0030299 (* 1 = 0.0030299 loss)
I0302 04:53:33.052319 29253 sgd_solver.cpp:106] Iteration 8540, lr = 0.01
I0302 04:54:01.866848 29253 solver.cpp:237] Iteration 8560, loss = 0.00177397
I0302 04:54:01.866881 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00177398 (* 1 = 0.00177398 loss)
I0302 04:54:01.866889 29253 sgd_solver.cpp:106] Iteration 8560, lr = 0.01
I0302 04:54:30.628190 29253 solver.cpp:237] Iteration 8580, loss = 0.00226055
I0302 04:54:30.628221 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00226055 (* 1 = 0.00226055 loss)
I0302 04:54:30.628231 29253 sgd_solver.cpp:106] Iteration 8580, lr = 0.01
I0302 04:54:59.781730 29253 solver.cpp:237] Iteration 8600, loss = 0.00172654
I0302 04:54:59.781762 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00172654 (* 1 = 0.00172654 loss)
I0302 04:54:59.781771 29253 sgd_solver.cpp:106] Iteration 8600, lr = 0.01
I0302 04:55:28.757565 29253 solver.cpp:237] Iteration 8620, loss = 0.00156899
I0302 04:55:28.757599 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00156899 (* 1 = 0.00156899 loss)
I0302 04:55:28.757608 29253 sgd_solver.cpp:106] Iteration 8620, lr = 0.01
I0302 04:55:57.828233 29253 solver.cpp:237] Iteration 8640, loss = 0.00206343
I0302 04:55:57.828265 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00206343 (* 1 = 0.00206343 loss)
I0302 04:55:57.828274 29253 sgd_solver.cpp:106] Iteration 8640, lr = 0.01
I0302 04:56:26.679779 29253 solver.cpp:237] Iteration 8660, loss = 0.00195737
I0302 04:56:26.679810 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00195737 (* 1 = 0.00195737 loss)
I0302 04:56:26.679818 29253 sgd_solver.cpp:106] Iteration 8660, lr = 0.01
I0302 04:56:55.631647 29253 solver.cpp:237] Iteration 8680, loss = 0.00250939
I0302 04:56:55.631680 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00250939 (* 1 = 0.00250939 loss)
I0302 04:56:55.631688 29253 sgd_solver.cpp:106] Iteration 8680, lr = 0.01
I0302 04:57:24.445030 29253 solver.cpp:237] Iteration 8700, loss = 0.00297044
I0302 04:57:24.445062 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00297044 (* 1 = 0.00297044 loss)
I0302 04:57:24.445071 29253 sgd_solver.cpp:106] Iteration 8700, lr = 0.01
I0302 04:57:53.239624 29253 solver.cpp:237] Iteration 8720, loss = 0.00188571
I0302 04:57:53.239655 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00188571 (* 1 = 0.00188571 loss)
I0302 04:57:53.239665 29253 sgd_solver.cpp:106] Iteration 8720, lr = 0.01
I0302 04:58:22.252511 29253 solver.cpp:237] Iteration 8740, loss = 0.00219794
I0302 04:58:22.252544 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00219795 (* 1 = 0.00219795 loss)
I0302 04:58:22.252553 29253 sgd_solver.cpp:106] Iteration 8740, lr = 0.01
I0302 04:58:51.227768 29253 solver.cpp:237] Iteration 8760, loss = 0.00193708
I0302 04:58:51.227802 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00193709 (* 1 = 0.00193709 loss)
I0302 04:58:51.227810 29253 sgd_solver.cpp:106] Iteration 8760, lr = 0.01
I0302 04:59:20.104763 29253 solver.cpp:237] Iteration 8780, loss = 0.00208391
I0302 04:59:20.104795 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00208391 (* 1 = 0.00208391 loss)
I0302 04:59:20.104804 29253 sgd_solver.cpp:106] Iteration 8780, lr = 0.01
I0302 04:59:49.018793 29253 solver.cpp:237] Iteration 8800, loss = 0.00231621
I0302 04:59:49.018824 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00231621 (* 1 = 0.00231621 loss)
I0302 04:59:49.018833 29253 sgd_solver.cpp:106] Iteration 8800, lr = 0.01
I0302 05:00:17.808050 29253 solver.cpp:237] Iteration 8820, loss = 0.00213692
I0302 05:00:17.808084 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00213692 (* 1 = 0.00213692 loss)
I0302 05:00:17.808092 29253 sgd_solver.cpp:106] Iteration 8820, lr = 0.01
I0302 05:00:46.931663 29253 solver.cpp:237] Iteration 8840, loss = 0.00211876
I0302 05:00:46.931694 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00211877 (* 1 = 0.00211877 loss)
I0302 05:00:46.931704 29253 sgd_solver.cpp:106] Iteration 8840, lr = 0.01
I0302 05:01:16.134416 29253 solver.cpp:237] Iteration 8860, loss = 0.00193696
I0302 05:01:16.134449 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00193697 (* 1 = 0.00193697 loss)
I0302 05:01:16.134457 29253 sgd_solver.cpp:106] Iteration 8860, lr = 0.01
I0302 05:01:44.615221 29253 solver.cpp:237] Iteration 8880, loss = 0.00205854
I0302 05:01:44.615254 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00205854 (* 1 = 0.00205854 loss)
I0302 05:01:44.615263 29253 sgd_solver.cpp:106] Iteration 8880, lr = 0.01
I0302 05:02:13.469213 29253 solver.cpp:237] Iteration 8900, loss = 0.00187546
I0302 05:02:13.469245 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00187546 (* 1 = 0.00187546 loss)
I0302 05:02:13.469254 29253 sgd_solver.cpp:106] Iteration 8900, lr = 0.01
I0302 05:02:42.433282 29253 solver.cpp:237] Iteration 8920, loss = 0.00160377
I0302 05:02:42.433313 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00160378 (* 1 = 0.00160378 loss)
I0302 05:02:42.433322 29253 sgd_solver.cpp:106] Iteration 8920, lr = 0.01
I0302 05:03:11.261467 29253 solver.cpp:237] Iteration 8940, loss = 0.00239735
I0302 05:03:11.261499 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00239736 (* 1 = 0.00239736 loss)
I0302 05:03:11.261508 29253 sgd_solver.cpp:106] Iteration 8940, lr = 0.01
I0302 05:03:40.238530 29253 solver.cpp:237] Iteration 8960, loss = 0.00189618
I0302 05:03:40.238561 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00189619 (* 1 = 0.00189619 loss)
I0302 05:03:40.238570 29253 sgd_solver.cpp:106] Iteration 8960, lr = 0.01
I0302 05:04:09.342269 29253 solver.cpp:237] Iteration 8980, loss = 0.00306039
I0302 05:04:09.342301 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00306039 (* 1 = 0.00306039 loss)
I0302 05:04:09.342310 29253 sgd_solver.cpp:106] Iteration 8980, lr = 0.01
I0302 05:04:38.394037 29253 solver.cpp:237] Iteration 9000, loss = 0.0019321
I0302 05:04:38.394068 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00193211 (* 1 = 0.00193211 loss)
I0302 05:04:38.394078 29253 sgd_solver.cpp:106] Iteration 9000, lr = 0.01
I0302 05:04:39.984412 29253 blocking_queue.cpp:50] Data layer prefetch queue empty
I0302 05:05:07.030552 29253 solver.cpp:237] Iteration 9020, loss = 0.0022202
I0302 05:05:07.030586 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0022202 (* 1 = 0.0022202 loss)
I0302 05:05:07.030596 29253 sgd_solver.cpp:106] Iteration 9020, lr = 0.01
I0302 05:05:36.279723 29253 solver.cpp:237] Iteration 9040, loss = 0.00238872
I0302 05:05:36.279755 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00238872 (* 1 = 0.00238872 loss)
I0302 05:05:36.279764 29253 sgd_solver.cpp:106] Iteration 9040, lr = 0.01
I0302 05:06:05.241171 29253 solver.cpp:237] Iteration 9060, loss = 0.00148887
I0302 05:06:05.241204 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00148887 (* 1 = 0.00148887 loss)
I0302 05:06:05.241212 29253 sgd_solver.cpp:106] Iteration 9060, lr = 0.01
I0302 05:06:33.806660 29253 solver.cpp:237] Iteration 9080, loss = 0.00171041
I0302 05:06:33.806694 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00171041 (* 1 = 0.00171041 loss)
I0302 05:06:33.806702 29253 sgd_solver.cpp:106] Iteration 9080, lr = 0.01
I0302 05:07:03.070140 29253 solver.cpp:237] Iteration 9100, loss = 0.0022557
I0302 05:07:03.070173 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0022557 (* 1 = 0.0022557 loss)
I0302 05:07:03.070181 29253 sgd_solver.cpp:106] Iteration 9100, lr = 0.01
I0302 05:07:32.004962 29253 solver.cpp:237] Iteration 9120, loss = 0.00219933
I0302 05:07:32.004994 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00219934 (* 1 = 0.00219934 loss)
I0302 05:07:32.005003 29253 sgd_solver.cpp:106] Iteration 9120, lr = 0.01
I0302 05:08:01.094729 29253 solver.cpp:237] Iteration 9140, loss = 0.00183444
I0302 05:08:01.094761 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00183445 (* 1 = 0.00183445 loss)
I0302 05:08:01.094770 29253 sgd_solver.cpp:106] Iteration 9140, lr = 0.01
I0302 05:08:30.097719 29253 solver.cpp:237] Iteration 9160, loss = 0.00205388
I0302 05:08:30.097750 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00205388 (* 1 = 0.00205388 loss)
I0302 05:08:30.097759 29253 sgd_solver.cpp:106] Iteration 9160, lr = 0.01
I0302 05:08:58.679780 29253 solver.cpp:237] Iteration 9180, loss = 0.00184313
I0302 05:08:58.679811 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00184314 (* 1 = 0.00184314 loss)
I0302 05:08:58.679819 29253 sgd_solver.cpp:106] Iteration 9180, lr = 0.01
I0302 05:09:27.610098 29253 solver.cpp:237] Iteration 9200, loss = 0.00172632
I0302 05:09:27.610132 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00172632 (* 1 = 0.00172632 loss)
I0302 05:09:27.610141 29253 sgd_solver.cpp:106] Iteration 9200, lr = 0.01
I0302 05:09:56.024246 29253 solver.cpp:237] Iteration 9220, loss = 0.00175262
I0302 05:09:56.024278 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00175262 (* 1 = 0.00175262 loss)
I0302 05:09:56.024287 29253 sgd_solver.cpp:106] Iteration 9220, lr = 0.01
I0302 05:10:24.867352 29253 solver.cpp:237] Iteration 9240, loss = 0.00183953
I0302 05:10:24.867383 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00183953 (* 1 = 0.00183953 loss)
I0302 05:10:24.867391 29253 sgd_solver.cpp:106] Iteration 9240, lr = 0.01
I0302 05:10:53.953775 29253 solver.cpp:237] Iteration 9260, loss = 0.00150968
I0302 05:10:53.953807 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00150968 (* 1 = 0.00150968 loss)
I0302 05:10:53.953816 29253 sgd_solver.cpp:106] Iteration 9260, lr = 0.01
I0302 05:11:23.399016 29253 solver.cpp:237] Iteration 9280, loss = 0.00170891
I0302 05:11:23.399049 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00170892 (* 1 = 0.00170892 loss)
I0302 05:11:23.399058 29253 sgd_solver.cpp:106] Iteration 9280, lr = 0.01
I0302 05:11:52.232033 29253 solver.cpp:237] Iteration 9300, loss = 0.00270876
I0302 05:11:52.232065 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00270876 (* 1 = 0.00270876 loss)
I0302 05:11:52.232074 29253 sgd_solver.cpp:106] Iteration 9300, lr = 0.01
I0302 05:12:20.808209 29253 solver.cpp:237] Iteration 9320, loss = 0.00235267
I0302 05:12:20.808241 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00235268 (* 1 = 0.00235268 loss)
I0302 05:12:20.808249 29253 sgd_solver.cpp:106] Iteration 9320, lr = 0.01
I0302 05:12:50.073041 29253 solver.cpp:237] Iteration 9340, loss = 0.00213895
I0302 05:12:50.073076 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00213895 (* 1 = 0.00213895 loss)
I0302 05:12:50.073084 29253 sgd_solver.cpp:106] Iteration 9340, lr = 0.01
I0302 05:13:18.567046 29253 solver.cpp:237] Iteration 9360, loss = 0.00180468
I0302 05:13:18.567078 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00180469 (* 1 = 0.00180469 loss)
I0302 05:13:18.567087 29253 sgd_solver.cpp:106] Iteration 9360, lr = 0.01
I0302 05:13:47.663552 29253 solver.cpp:237] Iteration 9380, loss = 0.00152488
I0302 05:13:47.663585 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00152488 (* 1 = 0.00152488 loss)
I0302 05:13:47.663594 29253 sgd_solver.cpp:106] Iteration 9380, lr = 0.01
I0302 05:14:16.798310 29253 solver.cpp:237] Iteration 9400, loss = 0.00176839
I0302 05:14:16.798341 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00176839 (* 1 = 0.00176839 loss)
I0302 05:14:16.798349 29253 sgd_solver.cpp:106] Iteration 9400, lr = 0.01
I0302 05:14:46.303606 29253 solver.cpp:237] Iteration 9420, loss = 0.00169991
I0302 05:14:46.303638 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00169991 (* 1 = 0.00169991 loss)
I0302 05:14:46.303647 29253 sgd_solver.cpp:106] Iteration 9420, lr = 0.01
I0302 05:15:14.912840 29253 solver.cpp:237] Iteration 9440, loss = 0.00177351
I0302 05:15:14.912870 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00177352 (* 1 = 0.00177352 loss)
I0302 05:15:14.912878 29253 sgd_solver.cpp:106] Iteration 9440, lr = 0.01
I0302 05:15:44.252940 29253 solver.cpp:237] Iteration 9460, loss = 0.00168622
I0302 05:15:44.252974 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00168622 (* 1 = 0.00168622 loss)
I0302 05:15:44.252982 29253 sgd_solver.cpp:106] Iteration 9460, lr = 0.01
I0302 05:16:13.190146 29253 solver.cpp:237] Iteration 9480, loss = 0.00162974
I0302 05:16:13.190179 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00162974 (* 1 = 0.00162974 loss)
I0302 05:16:13.190187 29253 sgd_solver.cpp:106] Iteration 9480, lr = 0.01
I0302 05:16:42.381213 29253 solver.cpp:237] Iteration 9500, loss = 0.00157895
I0302 05:16:42.381247 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00157896 (* 1 = 0.00157896 loss)
I0302 05:16:42.381255 29253 sgd_solver.cpp:106] Iteration 9500, lr = 0.01
I0302 05:17:11.123270 29253 solver.cpp:237] Iteration 9520, loss = 0.00156807
I0302 05:17:11.123303 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00156807 (* 1 = 0.00156807 loss)
I0302 05:17:11.123312 29253 sgd_solver.cpp:106] Iteration 9520, lr = 0.01
I0302 05:17:40.060690 29253 solver.cpp:237] Iteration 9540, loss = 0.00179764
I0302 05:17:40.060722 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00179765 (* 1 = 0.00179765 loss)
I0302 05:17:40.060730 29253 sgd_solver.cpp:106] Iteration 9540, lr = 0.01
I0302 05:18:08.948843 29253 solver.cpp:237] Iteration 9560, loss = 0.00184322
I0302 05:18:08.948876 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00184322 (* 1 = 0.00184322 loss)
I0302 05:18:08.948884 29253 sgd_solver.cpp:106] Iteration 9560, lr = 0.01
I0302 05:18:37.754120 29253 solver.cpp:237] Iteration 9580, loss = 0.00193095
I0302 05:18:37.754153 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00193095 (* 1 = 0.00193095 loss)
I0302 05:18:37.754161 29253 sgd_solver.cpp:106] Iteration 9580, lr = 0.01
I0302 05:19:06.795503 29253 solver.cpp:237] Iteration 9600, loss = 0.00187119
I0302 05:19:06.795534 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00187119 (* 1 = 0.00187119 loss)
I0302 05:19:06.795542 29253 sgd_solver.cpp:106] Iteration 9600, lr = 0.01
I0302 05:19:35.602542 29253 solver.cpp:237] Iteration 9620, loss = 0.00190073
I0302 05:19:35.602573 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00190073 (* 1 = 0.00190073 loss)
I0302 05:19:35.602582 29253 sgd_solver.cpp:106] Iteration 9620, lr = 0.01
I0302 05:20:04.547281 29253 solver.cpp:237] Iteration 9640, loss = 0.00183915
I0302 05:20:04.547315 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00183915 (* 1 = 0.00183915 loss)
I0302 05:20:04.547323 29253 sgd_solver.cpp:106] Iteration 9640, lr = 0.01
I0302 05:20:33.649648 29253 solver.cpp:237] Iteration 9660, loss = 0.00222058
I0302 05:20:33.649679 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00222058 (* 1 = 0.00222058 loss)
I0302 05:20:33.649688 29253 sgd_solver.cpp:106] Iteration 9660, lr = 0.01
I0302 05:21:02.496848 29253 solver.cpp:237] Iteration 9680, loss = 0.00183652
I0302 05:21:02.496881 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00183652 (* 1 = 0.00183652 loss)
I0302 05:21:02.496889 29253 sgd_solver.cpp:106] Iteration 9680, lr = 0.01
I0302 05:21:31.320688 29253 solver.cpp:237] Iteration 9700, loss = 0.00275409
I0302 05:21:31.320720 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00275409 (* 1 = 0.00275409 loss)
I0302 05:21:31.320729 29253 sgd_solver.cpp:106] Iteration 9700, lr = 0.01
I0302 05:22:00.414374 29253 solver.cpp:237] Iteration 9720, loss = 0.0018128
I0302 05:22:00.414405 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0018128 (* 1 = 0.0018128 loss)
I0302 05:22:00.414414 29253 sgd_solver.cpp:106] Iteration 9720, lr = 0.01
I0302 05:22:29.266492 29253 solver.cpp:237] Iteration 9740, loss = 0.00158426
I0302 05:22:29.266522 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00158426 (* 1 = 0.00158426 loss)
I0302 05:22:29.266531 29253 sgd_solver.cpp:106] Iteration 9740, lr = 0.01
I0302 05:22:58.362221 29253 solver.cpp:237] Iteration 9760, loss = 0.0015392
I0302 05:22:58.362253 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0015392 (* 1 = 0.0015392 loss)
I0302 05:22:58.362262 29253 sgd_solver.cpp:106] Iteration 9760, lr = 0.01
I0302 05:23:27.069279 29253 solver.cpp:237] Iteration 9780, loss = 0.00186944
I0302 05:23:27.069311 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00186944 (* 1 = 0.00186944 loss)
I0302 05:23:27.069320 29253 sgd_solver.cpp:106] Iteration 9780, lr = 0.01
I0302 05:23:55.792569 29253 solver.cpp:237] Iteration 9800, loss = 0.00159043
I0302 05:23:55.792600 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00159043 (* 1 = 0.00159043 loss)
I0302 05:23:55.792609 29253 sgd_solver.cpp:106] Iteration 9800, lr = 0.01
I0302 05:24:24.622222 29253 solver.cpp:237] Iteration 9820, loss = 0.00196006
I0302 05:24:24.622254 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00196007 (* 1 = 0.00196007 loss)
I0302 05:24:24.622262 29253 sgd_solver.cpp:106] Iteration 9820, lr = 0.01
I0302 05:24:53.704246 29253 solver.cpp:237] Iteration 9840, loss = 0.00182165
I0302 05:24:53.704279 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00182166 (* 1 = 0.00182166 loss)
I0302 05:24:53.704288 29253 sgd_solver.cpp:106] Iteration 9840, lr = 0.01
I0302 05:25:22.742687 29253 solver.cpp:237] Iteration 9860, loss = 0.001949
I0302 05:25:22.742719 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.001949 (* 1 = 0.001949 loss)
I0302 05:25:22.742728 29253 sgd_solver.cpp:106] Iteration 9860, lr = 0.01
I0302 05:25:51.972771 29253 solver.cpp:237] Iteration 9880, loss = 0.00223611
I0302 05:25:51.972805 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00223612 (* 1 = 0.00223612 loss)
I0302 05:25:51.972812 29253 sgd_solver.cpp:106] Iteration 9880, lr = 0.01
I0302 05:26:20.823282 29253 solver.cpp:237] Iteration 9900, loss = 0.0014015
I0302 05:26:20.823313 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0014015 (* 1 = 0.0014015 loss)
I0302 05:26:20.823323 29253 sgd_solver.cpp:106] Iteration 9900, lr = 0.01
I0302 05:26:49.906131 29253 solver.cpp:237] Iteration 9920, loss = 0.00186482
I0302 05:26:49.906163 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00186482 (* 1 = 0.00186482 loss)
I0302 05:26:49.906172 29253 sgd_solver.cpp:106] Iteration 9920, lr = 0.01
I0302 05:27:19.197280 29253 solver.cpp:237] Iteration 9940, loss = 0.00188425
I0302 05:27:19.197311 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00188425 (* 1 = 0.00188425 loss)
I0302 05:27:19.197319 29253 sgd_solver.cpp:106] Iteration 9940, lr = 0.01
I0302 05:27:48.058166 29253 solver.cpp:237] Iteration 9960, loss = 0.00178421
I0302 05:27:48.058197 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00178421 (* 1 = 0.00178421 loss)
I0302 05:27:48.058207 29253 sgd_solver.cpp:106] Iteration 9960, lr = 0.01
I0302 05:28:17.417881 29253 solver.cpp:237] Iteration 9980, loss = 0.00237824
I0302 05:28:17.417912 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00237825 (* 1 = 0.00237825 loss)
I0302 05:28:17.417920 29253 sgd_solver.cpp:106] Iteration 9980, lr = 0.01
I0302 05:28:44.881090 29253 solver.cpp:459] Snapshotting to binary proto file /nfs.yoda/xiaolonw/fast_rcnn/models_sunrgbd/pre_cls_1fc_scratch/model__iter_10000.caffemodel
I0302 05:29:20.061216 29253 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /nfs.yoda/xiaolonw/fast_rcnn/models_sunrgbd/pre_cls_1fc_scratch/model__iter_10000.solverstate
I0302 05:29:20.451310 29253 solver.cpp:237] Iteration 10000, loss = 0.00192573
I0302 05:29:20.451340 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00192574 (* 1 = 0.00192574 loss)
I0302 05:29:20.451349 29253 sgd_solver.cpp:106] Iteration 10000, lr = 0.001
I0302 05:29:23.298399 29253 blocking_queue.cpp:50] Data layer prefetch queue empty
I0302 05:29:46.693917 29253 solver.cpp:237] Iteration 10020, loss = 0.00156741
I0302 05:29:46.693950 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00156741 (* 1 = 0.00156741 loss)
I0302 05:29:46.693959 29253 sgd_solver.cpp:106] Iteration 10020, lr = 0.001
I0302 05:30:15.540232 29253 solver.cpp:237] Iteration 10040, loss = 0.00174003
I0302 05:30:15.540266 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00174004 (* 1 = 0.00174004 loss)
I0302 05:30:15.540274 29253 sgd_solver.cpp:106] Iteration 10040, lr = 0.001
I0302 05:30:44.384433 29253 solver.cpp:237] Iteration 10060, loss = 0.00208513
I0302 05:30:44.384462 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00208514 (* 1 = 0.00208514 loss)
I0302 05:30:44.384471 29253 sgd_solver.cpp:106] Iteration 10060, lr = 0.001
I0302 05:31:13.362166 29253 solver.cpp:237] Iteration 10080, loss = 0.00163637
I0302 05:31:13.362198 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00163638 (* 1 = 0.00163638 loss)
I0302 05:31:13.362207 29253 sgd_solver.cpp:106] Iteration 10080, lr = 0.001
I0302 05:31:42.380638 29253 solver.cpp:237] Iteration 10100, loss = 0.00183392
I0302 05:31:42.380671 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00183392 (* 1 = 0.00183392 loss)
I0302 05:31:42.380681 29253 sgd_solver.cpp:106] Iteration 10100, lr = 0.001
I0302 05:32:11.614375 29253 solver.cpp:237] Iteration 10120, loss = 0.00186399
I0302 05:32:11.614409 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00186399 (* 1 = 0.00186399 loss)
I0302 05:32:11.614418 29253 sgd_solver.cpp:106] Iteration 10120, lr = 0.001
I0302 05:32:40.793733 29253 solver.cpp:237] Iteration 10140, loss = 0.00191984
I0302 05:32:40.793766 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00191984 (* 1 = 0.00191984 loss)
I0302 05:32:40.793774 29253 sgd_solver.cpp:106] Iteration 10140, lr = 0.001
I0302 05:33:09.453925 29253 solver.cpp:237] Iteration 10160, loss = 0.00185374
I0302 05:33:09.453958 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00185375 (* 1 = 0.00185375 loss)
I0302 05:33:09.453968 29253 sgd_solver.cpp:106] Iteration 10160, lr = 0.001
I0302 05:33:38.275403 29253 solver.cpp:237] Iteration 10180, loss = 0.00134844
I0302 05:33:38.275435 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00134844 (* 1 = 0.00134844 loss)
I0302 05:33:38.275444 29253 sgd_solver.cpp:106] Iteration 10180, lr = 0.001
I0302 05:34:07.128681 29253 solver.cpp:237] Iteration 10200, loss = 0.00127983
I0302 05:34:07.128715 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00127983 (* 1 = 0.00127983 loss)
I0302 05:34:07.128723 29253 sgd_solver.cpp:106] Iteration 10200, lr = 0.001
I0302 05:34:36.200484 29253 solver.cpp:237] Iteration 10220, loss = 0.00191371
I0302 05:34:36.200516 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00191372 (* 1 = 0.00191372 loss)
I0302 05:34:36.200525 29253 sgd_solver.cpp:106] Iteration 10220, lr = 0.001
I0302 05:35:04.970260 29253 solver.cpp:237] Iteration 10240, loss = 0.00141347
I0302 05:35:04.970293 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00141348 (* 1 = 0.00141348 loss)
I0302 05:35:04.970302 29253 sgd_solver.cpp:106] Iteration 10240, lr = 0.001
I0302 05:35:33.995782 29253 solver.cpp:237] Iteration 10260, loss = 0.00210394
I0302 05:35:33.995813 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00210394 (* 1 = 0.00210394 loss)
I0302 05:35:33.995821 29253 sgd_solver.cpp:106] Iteration 10260, lr = 0.001
I0302 05:36:02.992326 29253 solver.cpp:237] Iteration 10280, loss = 0.00150161
I0302 05:36:02.992358 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00150161 (* 1 = 0.00150161 loss)
I0302 05:36:02.992367 29253 sgd_solver.cpp:106] Iteration 10280, lr = 0.001
I0302 05:36:32.507964 29253 solver.cpp:237] Iteration 10300, loss = 0.00140352
I0302 05:36:32.507997 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00140352 (* 1 = 0.00140352 loss)
I0302 05:36:32.508004 29253 sgd_solver.cpp:106] Iteration 10300, lr = 0.001
I0302 05:37:01.024757 29253 solver.cpp:237] Iteration 10320, loss = 0.00167728
I0302 05:37:01.024791 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00167729 (* 1 = 0.00167729 loss)
I0302 05:37:01.024799 29253 sgd_solver.cpp:106] Iteration 10320, lr = 0.001
I0302 05:37:29.694932 29253 solver.cpp:237] Iteration 10340, loss = 0.00155692
I0302 05:37:29.694964 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00155692 (* 1 = 0.00155692 loss)
I0302 05:37:29.694972 29253 sgd_solver.cpp:106] Iteration 10340, lr = 0.001
I0302 05:37:58.685251 29253 solver.cpp:237] Iteration 10360, loss = 0.00148079
I0302 05:37:58.685283 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00148079 (* 1 = 0.00148079 loss)
I0302 05:37:58.685292 29253 sgd_solver.cpp:106] Iteration 10360, lr = 0.001
I0302 05:38:27.617817 29253 solver.cpp:237] Iteration 10380, loss = 0.00195203
I0302 05:38:27.617848 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00195203 (* 1 = 0.00195203 loss)
I0302 05:38:27.617857 29253 sgd_solver.cpp:106] Iteration 10380, lr = 0.001
I0302 05:38:56.631960 29253 solver.cpp:237] Iteration 10400, loss = 0.00167808
I0302 05:38:56.631992 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00167808 (* 1 = 0.00167808 loss)
I0302 05:38:56.632001 29253 sgd_solver.cpp:106] Iteration 10400, lr = 0.001
I0302 05:39:25.320293 29253 solver.cpp:237] Iteration 10420, loss = 0.00190849
I0302 05:39:25.320325 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00190849 (* 1 = 0.00190849 loss)
I0302 05:39:25.320334 29253 sgd_solver.cpp:106] Iteration 10420, lr = 0.001
I0302 05:39:54.340035 29253 solver.cpp:237] Iteration 10440, loss = 0.00178092
I0302 05:39:54.340067 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00178092 (* 1 = 0.00178092 loss)
I0302 05:39:54.340075 29253 sgd_solver.cpp:106] Iteration 10440, lr = 0.001
I0302 05:40:23.220104 29253 solver.cpp:237] Iteration 10460, loss = 0.00155495
I0302 05:40:23.220135 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00155495 (* 1 = 0.00155495 loss)
I0302 05:40:23.220144 29253 sgd_solver.cpp:106] Iteration 10460, lr = 0.001
I0302 05:40:51.710238 29253 solver.cpp:237] Iteration 10480, loss = 0.0013368
I0302 05:40:51.710270 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0013368 (* 1 = 0.0013368 loss)
I0302 05:40:51.710279 29253 sgd_solver.cpp:106] Iteration 10480, lr = 0.001
I0302 05:41:20.910163 29253 solver.cpp:237] Iteration 10500, loss = 0.00172886
I0302 05:41:20.910193 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00172887 (* 1 = 0.00172887 loss)
I0302 05:41:20.910202 29253 sgd_solver.cpp:106] Iteration 10500, lr = 0.001
I0302 05:41:49.827817 29253 solver.cpp:237] Iteration 10520, loss = 0.00167025
I0302 05:41:49.827850 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00167025 (* 1 = 0.00167025 loss)
I0302 05:41:49.827858 29253 sgd_solver.cpp:106] Iteration 10520, lr = 0.001
I0302 05:42:18.691733 29253 solver.cpp:237] Iteration 10540, loss = 0.00136774
I0302 05:42:18.691766 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00136774 (* 1 = 0.00136774 loss)
I0302 05:42:18.691773 29253 sgd_solver.cpp:106] Iteration 10540, lr = 0.001
I0302 05:42:47.632809 29253 solver.cpp:237] Iteration 10560, loss = 0.00220141
I0302 05:42:47.632841 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00220141 (* 1 = 0.00220141 loss)
I0302 05:42:47.632850 29253 sgd_solver.cpp:106] Iteration 10560, lr = 0.001
I0302 05:43:16.403318 29253 solver.cpp:237] Iteration 10580, loss = 0.00193759
I0302 05:43:16.403350 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00193759 (* 1 = 0.00193759 loss)
I0302 05:43:16.403358 29253 sgd_solver.cpp:106] Iteration 10580, lr = 0.001
I0302 05:43:45.299022 29253 solver.cpp:237] Iteration 10600, loss = 0.00179417
I0302 05:43:45.299052 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00179417 (* 1 = 0.00179417 loss)
I0302 05:43:45.299060 29253 sgd_solver.cpp:106] Iteration 10600, lr = 0.001
I0302 05:44:14.187363 29253 solver.cpp:237] Iteration 10620, loss = 0.00162324
I0302 05:44:14.187398 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00162324 (* 1 = 0.00162324 loss)
I0302 05:44:14.187407 29253 sgd_solver.cpp:106] Iteration 10620, lr = 0.001
I0302 05:44:43.195910 29253 solver.cpp:237] Iteration 10640, loss = 0.0020566
I0302 05:44:43.195941 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0020566 (* 1 = 0.0020566 loss)
I0302 05:44:43.195950 29253 sgd_solver.cpp:106] Iteration 10640, lr = 0.001
I0302 05:45:12.084648 29253 solver.cpp:237] Iteration 10660, loss = 0.00212813
I0302 05:45:12.084681 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00212813 (* 1 = 0.00212813 loss)
I0302 05:45:12.084691 29253 sgd_solver.cpp:106] Iteration 10660, lr = 0.001
I0302 05:45:41.047575 29253 solver.cpp:237] Iteration 10680, loss = 0.00137305
I0302 05:45:41.047605 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00137305 (* 1 = 0.00137305 loss)
I0302 05:45:41.047613 29253 sgd_solver.cpp:106] Iteration 10680, lr = 0.001
I0302 05:46:09.890223 29253 solver.cpp:237] Iteration 10700, loss = 0.00151447
I0302 05:46:09.890249 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00151447 (* 1 = 0.00151447 loss)
I0302 05:46:09.890257 29253 sgd_solver.cpp:106] Iteration 10700, lr = 0.001
I0302 05:46:38.789240 29253 solver.cpp:237] Iteration 10720, loss = 0.00186666
I0302 05:46:38.789273 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00186666 (* 1 = 0.00186666 loss)
I0302 05:46:38.789281 29253 sgd_solver.cpp:106] Iteration 10720, lr = 0.001
I0302 05:47:07.817734 29253 solver.cpp:237] Iteration 10740, loss = 0.00239448
I0302 05:47:07.817764 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00239448 (* 1 = 0.00239448 loss)
I0302 05:47:07.817773 29253 sgd_solver.cpp:106] Iteration 10740, lr = 0.001
I0302 05:47:36.569977 29253 solver.cpp:237] Iteration 10760, loss = 0.00145106
I0302 05:47:36.570005 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00145107 (* 1 = 0.00145107 loss)
I0302 05:47:36.570014 29253 sgd_solver.cpp:106] Iteration 10760, lr = 0.001
I0302 05:48:05.508194 29253 solver.cpp:237] Iteration 10780, loss = 0.00155089
I0302 05:48:05.508222 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0015509 (* 1 = 0.0015509 loss)
I0302 05:48:05.508231 29253 sgd_solver.cpp:106] Iteration 10780, lr = 0.001
I0302 05:48:34.431017 29253 solver.cpp:237] Iteration 10800, loss = 0.00207754
I0302 05:48:34.431044 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00207755 (* 1 = 0.00207755 loss)
I0302 05:48:34.431052 29253 sgd_solver.cpp:106] Iteration 10800, lr = 0.001
I0302 05:49:03.324017 29253 solver.cpp:237] Iteration 10820, loss = 0.00161646
I0302 05:49:03.324046 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00161646 (* 1 = 0.00161646 loss)
I0302 05:49:03.324055 29253 sgd_solver.cpp:106] Iteration 10820, lr = 0.001
I0302 05:49:32.286766 29253 solver.cpp:237] Iteration 10840, loss = 0.0016307
I0302 05:49:32.286798 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00163071 (* 1 = 0.00163071 loss)
I0302 05:49:32.286806 29253 sgd_solver.cpp:106] Iteration 10840, lr = 0.001
I0302 05:50:01.279760 29253 solver.cpp:237] Iteration 10860, loss = 0.00154568
I0302 05:50:01.279794 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00154568 (* 1 = 0.00154568 loss)
I0302 05:50:01.279803 29253 sgd_solver.cpp:106] Iteration 10860, lr = 0.001
I0302 05:50:30.264638 29253 solver.cpp:237] Iteration 10880, loss = 0.00144397
I0302 05:50:30.264662 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00144397 (* 1 = 0.00144397 loss)
I0302 05:50:30.264670 29253 sgd_solver.cpp:106] Iteration 10880, lr = 0.001
I0302 05:50:59.032176 29253 solver.cpp:237] Iteration 10900, loss = 0.00171547
I0302 05:50:59.032208 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00171547 (* 1 = 0.00171547 loss)
I0302 05:50:59.032217 29253 sgd_solver.cpp:106] Iteration 10900, lr = 0.001
I0302 05:51:27.928928 29253 solver.cpp:237] Iteration 10920, loss = 0.00162104
I0302 05:51:27.928961 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00162105 (* 1 = 0.00162105 loss)
I0302 05:51:27.928969 29253 sgd_solver.cpp:106] Iteration 10920, lr = 0.001
I0302 05:51:56.855700 29253 solver.cpp:237] Iteration 10940, loss = 0.00150855
I0302 05:51:56.855733 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00150855 (* 1 = 0.00150855 loss)
I0302 05:51:56.855742 29253 sgd_solver.cpp:106] Iteration 10940, lr = 0.001
I0302 05:52:25.845235 29253 solver.cpp:237] Iteration 10960, loss = 0.00132389
I0302 05:52:25.845268 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00132389 (* 1 = 0.00132389 loss)
I0302 05:52:25.845278 29253 sgd_solver.cpp:106] Iteration 10960, lr = 0.001
I0302 05:52:54.779814 29253 solver.cpp:237] Iteration 10980, loss = 0.00150733
I0302 05:52:54.779839 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00150733 (* 1 = 0.00150733 loss)
I0302 05:52:54.779846 29253 sgd_solver.cpp:106] Iteration 10980, lr = 0.001
I0302 05:53:23.934087 29253 solver.cpp:237] Iteration 11000, loss = 0.00150211
I0302 05:53:23.934120 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00150211 (* 1 = 0.00150211 loss)
I0302 05:53:23.934128 29253 sgd_solver.cpp:106] Iteration 11000, lr = 0.001
I0302 05:53:29.640725 29253 blocking_queue.cpp:50] Data layer prefetch queue empty
I0302 05:53:52.877249 29253 solver.cpp:237] Iteration 11020, loss = 0.00175051
I0302 05:53:52.877282 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00175052 (* 1 = 0.00175052 loss)
I0302 05:53:52.877290 29253 sgd_solver.cpp:106] Iteration 11020, lr = 0.001
I0302 05:54:21.876466 29253 solver.cpp:237] Iteration 11040, loss = 0.0017471
I0302 05:54:21.876499 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0017471 (* 1 = 0.0017471 loss)
I0302 05:54:21.876507 29253 sgd_solver.cpp:106] Iteration 11040, lr = 0.001
I0302 05:54:50.629925 29253 solver.cpp:237] Iteration 11060, loss = 0.00177401
I0302 05:54:50.629957 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00177401 (* 1 = 0.00177401 loss)
I0302 05:54:50.629966 29253 sgd_solver.cpp:106] Iteration 11060, lr = 0.001
I0302 05:55:19.770833 29253 solver.cpp:237] Iteration 11080, loss = 0.00157767
I0302 05:55:19.770865 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00157767 (* 1 = 0.00157767 loss)
I0302 05:55:19.770874 29253 sgd_solver.cpp:106] Iteration 11080, lr = 0.001
I0302 05:55:48.712050 29253 solver.cpp:237] Iteration 11100, loss = 0.00174366
I0302 05:55:48.712082 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00174366 (* 1 = 0.00174366 loss)
I0302 05:55:48.712090 29253 sgd_solver.cpp:106] Iteration 11100, lr = 0.001
I0302 05:56:17.531617 29253 solver.cpp:237] Iteration 11120, loss = 0.00168994
I0302 05:56:17.531649 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00168994 (* 1 = 0.00168994 loss)
I0302 05:56:17.531658 29253 sgd_solver.cpp:106] Iteration 11120, lr = 0.001
I0302 05:56:46.639261 29253 solver.cpp:237] Iteration 11140, loss = 0.0017138
I0302 05:56:46.639293 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0017138 (* 1 = 0.0017138 loss)
I0302 05:56:46.639302 29253 sgd_solver.cpp:106] Iteration 11140, lr = 0.001
I0302 05:57:15.624531 29253 solver.cpp:237] Iteration 11160, loss = 0.00171982
I0302 05:57:15.624563 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00171982 (* 1 = 0.00171982 loss)
I0302 05:57:15.624572 29253 sgd_solver.cpp:106] Iteration 11160, lr = 0.001
I0302 05:57:44.577953 29253 solver.cpp:237] Iteration 11180, loss = 0.00205288
I0302 05:57:44.577986 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00205289 (* 1 = 0.00205289 loss)
I0302 05:57:44.577996 29253 sgd_solver.cpp:106] Iteration 11180, lr = 0.001
I0302 05:58:13.346356 29253 solver.cpp:237] Iteration 11200, loss = 0.00146629
I0302 05:58:13.346391 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0014663 (* 1 = 0.0014663 loss)
I0302 05:58:13.346400 29253 sgd_solver.cpp:106] Iteration 11200, lr = 0.001
I0302 05:58:42.267370 29253 solver.cpp:237] Iteration 11220, loss = 0.00146929
I0302 05:58:42.267402 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00146929 (* 1 = 0.00146929 loss)
I0302 05:58:42.267411 29253 sgd_solver.cpp:106] Iteration 11220, lr = 0.001
I0302 05:59:11.220319 29253 solver.cpp:237] Iteration 11240, loss = 0.00165357
I0302 05:59:11.220351 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00165357 (* 1 = 0.00165357 loss)
I0302 05:59:11.220360 29253 sgd_solver.cpp:106] Iteration 11240, lr = 0.001
I0302 05:59:40.063856 29253 solver.cpp:237] Iteration 11260, loss = 0.00166183
I0302 05:59:40.063889 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00166183 (* 1 = 0.00166183 loss)
I0302 05:59:40.063899 29253 sgd_solver.cpp:106] Iteration 11260, lr = 0.001
I0302 06:00:09.202035 29253 solver.cpp:237] Iteration 11280, loss = 0.00210099
I0302 06:00:09.202069 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00210099 (* 1 = 0.00210099 loss)
I0302 06:00:09.202080 29253 sgd_solver.cpp:106] Iteration 11280, lr = 0.001
I0302 06:00:38.257540 29253 solver.cpp:237] Iteration 11300, loss = 0.00196804
I0302 06:00:38.257571 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00196804 (* 1 = 0.00196804 loss)
I0302 06:00:38.257580 29253 sgd_solver.cpp:106] Iteration 11300, lr = 0.001
I0302 06:01:07.091246 29253 solver.cpp:237] Iteration 11320, loss = 0.0016761
I0302 06:01:07.091279 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00167611 (* 1 = 0.00167611 loss)
I0302 06:01:07.091286 29253 sgd_solver.cpp:106] Iteration 11320, lr = 0.001
I0302 06:01:36.096580 29253 solver.cpp:237] Iteration 11340, loss = 0.00166906
I0302 06:01:36.096611 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00166906 (* 1 = 0.00166906 loss)
I0302 06:01:36.096621 29253 sgd_solver.cpp:106] Iteration 11340, lr = 0.001
I0302 06:02:04.985311 29253 solver.cpp:237] Iteration 11360, loss = 0.00188335
I0302 06:02:04.985344 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00188335 (* 1 = 0.00188335 loss)
I0302 06:02:04.985353 29253 sgd_solver.cpp:106] Iteration 11360, lr = 0.001
I0302 06:02:33.888020 29253 solver.cpp:237] Iteration 11380, loss = 0.00193505
I0302 06:02:33.888051 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00193505 (* 1 = 0.00193505 loss)
I0302 06:02:33.888059 29253 sgd_solver.cpp:106] Iteration 11380, lr = 0.001
I0302 06:03:02.740321 29253 solver.cpp:237] Iteration 11400, loss = 0.00195528
I0302 06:03:02.740353 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00195528 (* 1 = 0.00195528 loss)
I0302 06:03:02.740362 29253 sgd_solver.cpp:106] Iteration 11400, lr = 0.001
I0302 06:03:31.771515 29253 solver.cpp:237] Iteration 11420, loss = 0.00154394
I0302 06:03:31.771548 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00154394 (* 1 = 0.00154394 loss)
I0302 06:03:31.771555 29253 sgd_solver.cpp:106] Iteration 11420, lr = 0.001
I0302 06:04:00.707310 29253 solver.cpp:237] Iteration 11440, loss = 0.00183165
I0302 06:04:00.707343 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00183165 (* 1 = 0.00183165 loss)
I0302 06:04:00.707351 29253 sgd_solver.cpp:106] Iteration 11440, lr = 0.001
I0302 06:04:29.707268 29253 solver.cpp:237] Iteration 11460, loss = 0.00181915
I0302 06:04:29.707301 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00181915 (* 1 = 0.00181915 loss)
I0302 06:04:29.707311 29253 sgd_solver.cpp:106] Iteration 11460, lr = 0.001
I0302 06:04:58.631445 29253 solver.cpp:237] Iteration 11480, loss = 0.00144877
I0302 06:04:58.631479 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00144878 (* 1 = 0.00144878 loss)
I0302 06:04:58.631487 29253 sgd_solver.cpp:106] Iteration 11480, lr = 0.001
I0302 06:05:27.292328 29253 solver.cpp:237] Iteration 11500, loss = 0.00160845
I0302 06:05:27.292361 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00160845 (* 1 = 0.00160845 loss)
I0302 06:05:27.292371 29253 sgd_solver.cpp:106] Iteration 11500, lr = 0.001
I0302 06:05:56.122192 29253 solver.cpp:237] Iteration 11520, loss = 0.0015865
I0302 06:05:56.122226 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0015865 (* 1 = 0.0015865 loss)
I0302 06:05:56.122236 29253 sgd_solver.cpp:106] Iteration 11520, lr = 0.001
I0302 06:06:25.152079 29253 solver.cpp:237] Iteration 11540, loss = 0.00180575
I0302 06:06:25.152112 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00180575 (* 1 = 0.00180575 loss)
I0302 06:06:25.152119 29253 sgd_solver.cpp:106] Iteration 11540, lr = 0.001
I0302 06:06:53.955015 29253 solver.cpp:237] Iteration 11560, loss = 0.00189719
I0302 06:06:53.955047 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0018972 (* 1 = 0.0018972 loss)
I0302 06:06:53.955056 29253 sgd_solver.cpp:106] Iteration 11560, lr = 0.001
I0302 06:07:22.910378 29253 solver.cpp:237] Iteration 11580, loss = 0.0017828
I0302 06:07:22.910413 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00178281 (* 1 = 0.00178281 loss)
I0302 06:07:22.910423 29253 sgd_solver.cpp:106] Iteration 11580, lr = 0.001
I0302 06:07:51.980322 29253 solver.cpp:237] Iteration 11600, loss = 0.0015677
I0302 06:07:51.980355 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00156771 (* 1 = 0.00156771 loss)
I0302 06:07:51.980365 29253 sgd_solver.cpp:106] Iteration 11600, lr = 0.001
I0302 06:08:20.961555 29253 solver.cpp:237] Iteration 11620, loss = 0.00149582
I0302 06:08:20.961588 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00149582 (* 1 = 0.00149582 loss)
I0302 06:08:20.961596 29253 sgd_solver.cpp:106] Iteration 11620, lr = 0.001
I0302 06:08:49.799679 29253 solver.cpp:237] Iteration 11640, loss = 0.00181036
I0302 06:08:49.799711 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00181037 (* 1 = 0.00181037 loss)
I0302 06:08:49.799721 29253 sgd_solver.cpp:106] Iteration 11640, lr = 0.001
I0302 06:09:18.597511 29253 solver.cpp:237] Iteration 11660, loss = 0.00148449
I0302 06:09:18.597543 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0014845 (* 1 = 0.0014845 loss)
I0302 06:09:18.597551 29253 sgd_solver.cpp:106] Iteration 11660, lr = 0.001
I0302 06:09:47.635529 29253 solver.cpp:237] Iteration 11680, loss = 0.00151178
I0302 06:09:47.635561 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00151178 (* 1 = 0.00151178 loss)
I0302 06:09:47.635571 29253 sgd_solver.cpp:106] Iteration 11680, lr = 0.001
I0302 06:10:16.124641 29253 solver.cpp:237] Iteration 11700, loss = 0.00163301
I0302 06:10:16.124673 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00163301 (* 1 = 0.00163301 loss)
I0302 06:10:16.124682 29253 sgd_solver.cpp:106] Iteration 11700, lr = 0.001
I0302 06:10:45.365555 29253 solver.cpp:237] Iteration 11720, loss = 0.00184074
I0302 06:10:45.365584 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00184075 (* 1 = 0.00184075 loss)
I0302 06:10:45.365593 29253 sgd_solver.cpp:106] Iteration 11720, lr = 0.001
I0302 06:11:14.210178 29253 solver.cpp:237] Iteration 11740, loss = 0.00153261
I0302 06:11:14.210212 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00153262 (* 1 = 0.00153262 loss)
I0302 06:11:14.210221 29253 sgd_solver.cpp:106] Iteration 11740, lr = 0.001
I0302 06:11:42.886173 29253 solver.cpp:237] Iteration 11760, loss = 0.00175853
I0302 06:11:42.886204 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00175853 (* 1 = 0.00175853 loss)
I0302 06:11:42.886212 29253 sgd_solver.cpp:106] Iteration 11760, lr = 0.001
I0302 06:12:11.706703 29253 solver.cpp:237] Iteration 11780, loss = 0.0020152
I0302 06:12:11.706734 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0020152 (* 1 = 0.0020152 loss)
I0302 06:12:11.706743 29253 sgd_solver.cpp:106] Iteration 11780, lr = 0.001
I0302 06:12:40.572636 29253 solver.cpp:237] Iteration 11800, loss = 0.00153786
I0302 06:12:40.572669 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00153786 (* 1 = 0.00153786 loss)
I0302 06:12:40.572677 29253 sgd_solver.cpp:106] Iteration 11800, lr = 0.001
I0302 06:13:09.741091 29253 solver.cpp:237] Iteration 11820, loss = 0.00174473
I0302 06:13:09.741122 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00174473 (* 1 = 0.00174473 loss)
I0302 06:13:09.741132 29253 sgd_solver.cpp:106] Iteration 11820, lr = 0.001
I0302 06:13:38.453708 29253 solver.cpp:237] Iteration 11840, loss = 0.00136432
I0302 06:13:38.453742 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00136432 (* 1 = 0.00136432 loss)
I0302 06:13:38.453749 29253 sgd_solver.cpp:106] Iteration 11840, lr = 0.001
I0302 06:14:08.015944 29253 solver.cpp:237] Iteration 11860, loss = 0.00167098
I0302 06:14:08.015975 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00167099 (* 1 = 0.00167099 loss)
I0302 06:14:08.015983 29253 sgd_solver.cpp:106] Iteration 11860, lr = 0.001
I0302 06:14:36.571593 29253 solver.cpp:237] Iteration 11880, loss = 0.00175398
I0302 06:14:36.571624 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00175398 (* 1 = 0.00175398 loss)
I0302 06:14:36.571633 29253 sgd_solver.cpp:106] Iteration 11880, lr = 0.001
I0302 06:15:05.303804 29253 solver.cpp:237] Iteration 11900, loss = 0.00167536
I0302 06:15:05.303836 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00167536 (* 1 = 0.00167536 loss)
I0302 06:15:05.303846 29253 sgd_solver.cpp:106] Iteration 11900, lr = 0.001
I0302 06:15:34.273216 29253 solver.cpp:237] Iteration 11920, loss = 0.0019485
I0302 06:15:34.273248 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0019485 (* 1 = 0.0019485 loss)
I0302 06:15:34.273257 29253 sgd_solver.cpp:106] Iteration 11920, lr = 0.001
I0302 06:16:03.173897 29253 solver.cpp:237] Iteration 11940, loss = 0.00177443
I0302 06:16:03.173928 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00177443 (* 1 = 0.00177443 loss)
I0302 06:16:03.173938 29253 sgd_solver.cpp:106] Iteration 11940, lr = 0.001
I0302 06:16:32.055681 29253 solver.cpp:237] Iteration 11960, loss = 0.00189942
I0302 06:16:32.055714 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00189942 (* 1 = 0.00189942 loss)
I0302 06:16:32.055723 29253 sgd_solver.cpp:106] Iteration 11960, lr = 0.001
I0302 06:17:00.988015 29253 solver.cpp:237] Iteration 11980, loss = 0.00174404
I0302 06:17:00.988049 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00174404 (* 1 = 0.00174404 loss)
I0302 06:17:00.988057 29253 sgd_solver.cpp:106] Iteration 11980, lr = 0.001
I0302 06:17:29.919446 29253 solver.cpp:237] Iteration 12000, loss = 0.00156832
I0302 06:17:29.919479 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00156833 (* 1 = 0.00156833 loss)
I0302 06:17:29.919488 29253 sgd_solver.cpp:106] Iteration 12000, lr = 0.001
I0302 06:17:35.769261 29253 blocking_queue.cpp:50] Data layer prefetch queue empty
I0302 06:17:58.876088 29253 solver.cpp:237] Iteration 12020, loss = 0.00186304
I0302 06:17:58.876121 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00186304 (* 1 = 0.00186304 loss)
I0302 06:17:58.876130 29253 sgd_solver.cpp:106] Iteration 12020, lr = 0.001
I0302 06:18:28.185987 29253 solver.cpp:237] Iteration 12040, loss = 0.00182555
I0302 06:18:28.186020 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00182556 (* 1 = 0.00182556 loss)
I0302 06:18:28.186028 29253 sgd_solver.cpp:106] Iteration 12040, lr = 0.001
I0302 06:18:56.897924 29253 solver.cpp:237] Iteration 12060, loss = 0.00167828
I0302 06:18:56.897956 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00167828 (* 1 = 0.00167828 loss)
I0302 06:18:56.897964 29253 sgd_solver.cpp:106] Iteration 12060, lr = 0.001
I0302 06:19:25.874977 29253 solver.cpp:237] Iteration 12080, loss = 0.00193419
I0302 06:19:25.875010 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00193419 (* 1 = 0.00193419 loss)
I0302 06:19:25.875018 29253 sgd_solver.cpp:106] Iteration 12080, lr = 0.001
I0302 06:19:54.813493 29253 solver.cpp:237] Iteration 12100, loss = 0.00166034
I0302 06:19:54.813524 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00166035 (* 1 = 0.00166035 loss)
I0302 06:19:54.813534 29253 sgd_solver.cpp:106] Iteration 12100, lr = 0.001
I0302 06:20:23.677590 29253 solver.cpp:237] Iteration 12120, loss = 0.00177423
I0302 06:20:23.677621 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00177424 (* 1 = 0.00177424 loss)
I0302 06:20:23.677629 29253 sgd_solver.cpp:106] Iteration 12120, lr = 0.001
I0302 06:20:52.688181 29253 solver.cpp:237] Iteration 12140, loss = 0.00166593
I0302 06:20:52.688213 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00166593 (* 1 = 0.00166593 loss)
I0302 06:20:52.688222 29253 sgd_solver.cpp:106] Iteration 12140, lr = 0.001
I0302 06:21:21.478708 29253 solver.cpp:237] Iteration 12160, loss = 0.00167917
I0302 06:21:21.478739 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00167918 (* 1 = 0.00167918 loss)
I0302 06:21:21.478747 29253 sgd_solver.cpp:106] Iteration 12160, lr = 0.001
I0302 06:21:50.435822 29253 solver.cpp:237] Iteration 12180, loss = 0.00197389
I0302 06:21:50.435853 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00197389 (* 1 = 0.00197389 loss)
I0302 06:21:50.435863 29253 sgd_solver.cpp:106] Iteration 12180, lr = 0.001
I0302 06:22:19.846076 29253 solver.cpp:237] Iteration 12200, loss = 0.00169374
I0302 06:22:19.846108 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00169374 (* 1 = 0.00169374 loss)
I0302 06:22:19.846117 29253 sgd_solver.cpp:106] Iteration 12200, lr = 0.001
I0302 06:22:48.891540 29253 solver.cpp:237] Iteration 12220, loss = 0.00173892
I0302 06:22:48.891571 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00173893 (* 1 = 0.00173893 loss)
I0302 06:22:48.891582 29253 sgd_solver.cpp:106] Iteration 12220, lr = 0.001
I0302 06:23:18.251049 29253 solver.cpp:237] Iteration 12240, loss = 0.00141996
I0302 06:23:18.251081 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00141996 (* 1 = 0.00141996 loss)
I0302 06:23:18.251091 29253 sgd_solver.cpp:106] Iteration 12240, lr = 0.001
I0302 06:23:46.658843 29253 solver.cpp:237] Iteration 12260, loss = 0.00141919
I0302 06:23:46.658874 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00141919 (* 1 = 0.00141919 loss)
I0302 06:23:46.658884 29253 sgd_solver.cpp:106] Iteration 12260, lr = 0.001
I0302 06:24:15.637923 29253 solver.cpp:237] Iteration 12280, loss = 0.00126381
I0302 06:24:15.637953 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00126381 (* 1 = 0.00126381 loss)
I0302 06:24:15.637961 29253 sgd_solver.cpp:106] Iteration 12280, lr = 0.001
I0302 06:24:44.562871 29253 solver.cpp:237] Iteration 12300, loss = 0.001928
I0302 06:24:44.562903 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.001928 (* 1 = 0.001928 loss)
I0302 06:24:44.562911 29253 sgd_solver.cpp:106] Iteration 12300, lr = 0.001
I0302 06:25:13.563473 29253 solver.cpp:237] Iteration 12320, loss = 0.00159298
I0302 06:25:13.563506 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00159299 (* 1 = 0.00159299 loss)
I0302 06:25:13.563515 29253 sgd_solver.cpp:106] Iteration 12320, lr = 0.001
I0302 06:25:42.409274 29253 solver.cpp:237] Iteration 12340, loss = 0.00161158
I0302 06:25:42.409304 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00161158 (* 1 = 0.00161158 loss)
I0302 06:25:42.409313 29253 sgd_solver.cpp:106] Iteration 12340, lr = 0.001
I0302 06:26:11.210155 29253 solver.cpp:237] Iteration 12360, loss = 0.00211187
I0302 06:26:11.210187 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00211187 (* 1 = 0.00211187 loss)
I0302 06:26:11.210196 29253 sgd_solver.cpp:106] Iteration 12360, lr = 0.001
I0302 06:26:40.250792 29253 solver.cpp:237] Iteration 12380, loss = 0.00170868
I0302 06:26:40.250823 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00170868 (* 1 = 0.00170868 loss)
I0302 06:26:40.250833 29253 sgd_solver.cpp:106] Iteration 12380, lr = 0.001
I0302 06:27:09.050762 29253 solver.cpp:237] Iteration 12400, loss = 0.00189701
I0302 06:27:09.050798 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00189701 (* 1 = 0.00189701 loss)
I0302 06:27:09.050807 29253 sgd_solver.cpp:106] Iteration 12400, lr = 0.001
I0302 06:27:37.973143 29253 solver.cpp:237] Iteration 12420, loss = 0.00153467
I0302 06:27:37.973176 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00153467 (* 1 = 0.00153467 loss)
I0302 06:27:37.973184 29253 sgd_solver.cpp:106] Iteration 12420, lr = 0.001
I0302 06:28:06.901203 29253 solver.cpp:237] Iteration 12440, loss = 0.00173551
I0302 06:28:06.901237 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00173551 (* 1 = 0.00173551 loss)
I0302 06:28:06.901245 29253 sgd_solver.cpp:106] Iteration 12440, lr = 0.001
I0302 06:28:35.770799 29253 solver.cpp:237] Iteration 12460, loss = 0.00146688
I0302 06:28:35.770831 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00146689 (* 1 = 0.00146689 loss)
I0302 06:28:35.770840 29253 sgd_solver.cpp:106] Iteration 12460, lr = 0.001
I0302 06:29:04.236244 29253 solver.cpp:237] Iteration 12480, loss = 0.00169923
I0302 06:29:04.236277 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00169923 (* 1 = 0.00169923 loss)
I0302 06:29:04.236286 29253 sgd_solver.cpp:106] Iteration 12480, lr = 0.001
I0302 06:29:33.266335 29253 solver.cpp:237] Iteration 12500, loss = 0.00144619
I0302 06:29:33.266368 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00144619 (* 1 = 0.00144619 loss)
I0302 06:29:33.266377 29253 sgd_solver.cpp:106] Iteration 12500, lr = 0.001
I0302 06:30:02.110242 29253 solver.cpp:237] Iteration 12520, loss = 0.00167917
I0302 06:30:02.110273 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00167918 (* 1 = 0.00167918 loss)
I0302 06:30:02.110282 29253 sgd_solver.cpp:106] Iteration 12520, lr = 0.001
I0302 06:30:31.134879 29253 solver.cpp:237] Iteration 12540, loss = 0.00198394
I0302 06:30:31.134912 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00198394 (* 1 = 0.00198394 loss)
I0302 06:30:31.134920 29253 sgd_solver.cpp:106] Iteration 12540, lr = 0.001
I0302 06:30:59.865478 29253 solver.cpp:237] Iteration 12560, loss = 0.00168965
I0302 06:30:59.865507 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00168966 (* 1 = 0.00168966 loss)
I0302 06:30:59.865515 29253 sgd_solver.cpp:106] Iteration 12560, lr = 0.001
I0302 06:31:28.752377 29253 solver.cpp:237] Iteration 12580, loss = 0.0015956
I0302 06:31:28.752408 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0015956 (* 1 = 0.0015956 loss)
I0302 06:31:28.752418 29253 sgd_solver.cpp:106] Iteration 12580, lr = 0.001
I0302 06:31:57.750478 29253 solver.cpp:237] Iteration 12600, loss = 0.00161996
I0302 06:31:57.750507 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00161996 (* 1 = 0.00161996 loss)
I0302 06:31:57.750516 29253 sgd_solver.cpp:106] Iteration 12600, lr = 0.001
I0302 06:32:26.670236 29253 solver.cpp:237] Iteration 12620, loss = 0.00157957
I0302 06:32:26.670267 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00157957 (* 1 = 0.00157957 loss)
I0302 06:32:26.670276 29253 sgd_solver.cpp:106] Iteration 12620, lr = 0.001
I0302 06:32:55.445168 29253 solver.cpp:237] Iteration 12640, loss = 0.00169175
I0302 06:32:55.445201 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00169175 (* 1 = 0.00169175 loss)
I0302 06:32:55.445210 29253 sgd_solver.cpp:106] Iteration 12640, lr = 0.001
I0302 06:33:24.384311 29253 solver.cpp:237] Iteration 12660, loss = 0.0015833
I0302 06:33:24.384343 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0015833 (* 1 = 0.0015833 loss)
I0302 06:33:24.384352 29253 sgd_solver.cpp:106] Iteration 12660, lr = 0.001
I0302 06:33:53.163251 29253 solver.cpp:237] Iteration 12680, loss = 0.001493
I0302 06:33:53.163285 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00149301 (* 1 = 0.00149301 loss)
I0302 06:33:53.163292 29253 sgd_solver.cpp:106] Iteration 12680, lr = 0.001
I0302 06:34:22.115171 29253 solver.cpp:237] Iteration 12700, loss = 0.00150837
I0302 06:34:22.115203 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00150837 (* 1 = 0.00150837 loss)
I0302 06:34:22.115212 29253 sgd_solver.cpp:106] Iteration 12700, lr = 0.001
I0302 06:34:51.032513 29253 solver.cpp:237] Iteration 12720, loss = 0.00129479
I0302 06:34:51.032548 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00129479 (* 1 = 0.00129479 loss)
I0302 06:34:51.032557 29253 sgd_solver.cpp:106] Iteration 12720, lr = 0.001
I0302 06:35:19.983510 29253 solver.cpp:237] Iteration 12740, loss = 0.00171483
I0302 06:35:19.983541 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00171483 (* 1 = 0.00171483 loss)
I0302 06:35:19.983549 29253 sgd_solver.cpp:106] Iteration 12740, lr = 0.001
I0302 06:35:48.908154 29253 solver.cpp:237] Iteration 12760, loss = 0.00159267
I0302 06:35:48.908186 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00159268 (* 1 = 0.00159268 loss)
I0302 06:35:48.908196 29253 sgd_solver.cpp:106] Iteration 12760, lr = 0.001
I0302 06:36:17.618866 29253 solver.cpp:237] Iteration 12780, loss = 0.00199432
I0302 06:36:17.618899 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00199433 (* 1 = 0.00199433 loss)
I0302 06:36:17.618907 29253 sgd_solver.cpp:106] Iteration 12780, lr = 0.001
I0302 06:36:46.665078 29253 solver.cpp:237] Iteration 12800, loss = 0.00168733
I0302 06:36:46.665110 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00168734 (* 1 = 0.00168734 loss)
I0302 06:36:46.665119 29253 sgd_solver.cpp:106] Iteration 12800, lr = 0.001
I0302 06:37:15.606417 29253 solver.cpp:237] Iteration 12820, loss = 0.00135488
I0302 06:37:15.606448 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00135488 (* 1 = 0.00135488 loss)
I0302 06:37:15.606456 29253 sgd_solver.cpp:106] Iteration 12820, lr = 0.001
I0302 06:37:44.224951 29253 solver.cpp:237] Iteration 12840, loss = 0.00168325
I0302 06:37:44.224982 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00168325 (* 1 = 0.00168325 loss)
I0302 06:37:44.224992 29253 sgd_solver.cpp:106] Iteration 12840, lr = 0.001
I0302 06:38:13.403105 29253 solver.cpp:237] Iteration 12860, loss = 0.00160682
I0302 06:38:13.403134 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00160682 (* 1 = 0.00160682 loss)
I0302 06:38:13.403142 29253 sgd_solver.cpp:106] Iteration 12860, lr = 0.001
I0302 06:38:42.215641 29253 solver.cpp:237] Iteration 12880, loss = 0.00169018
I0302 06:38:42.215673 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00169018 (* 1 = 0.00169018 loss)
I0302 06:38:42.215682 29253 sgd_solver.cpp:106] Iteration 12880, lr = 0.001
I0302 06:39:11.212978 29253 solver.cpp:237] Iteration 12900, loss = 0.00181518
I0302 06:39:11.213011 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00181518 (* 1 = 0.00181518 loss)
I0302 06:39:11.213018 29253 sgd_solver.cpp:106] Iteration 12900, lr = 0.001
I0302 06:39:39.792217 29253 solver.cpp:237] Iteration 12920, loss = 0.00168596
I0302 06:39:39.792248 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00168596 (* 1 = 0.00168596 loss)
I0302 06:39:39.792256 29253 sgd_solver.cpp:106] Iteration 12920, lr = 0.001
I0302 06:40:08.798434 29253 solver.cpp:237] Iteration 12940, loss = 0.00156695
I0302 06:40:08.798466 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00156695 (* 1 = 0.00156695 loss)
I0302 06:40:08.798502 29253 sgd_solver.cpp:106] Iteration 12940, lr = 0.001
I0302 06:40:38.066215 29253 solver.cpp:237] Iteration 12960, loss = 0.00171738
I0302 06:40:38.066248 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00171739 (* 1 = 0.00171739 loss)
I0302 06:40:38.066256 29253 sgd_solver.cpp:106] Iteration 12960, lr = 0.001
I0302 06:41:06.943228 29253 solver.cpp:237] Iteration 12980, loss = 0.00143799
I0302 06:41:06.943260 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.001438 (* 1 = 0.001438 loss)
I0302 06:41:06.943269 29253 sgd_solver.cpp:106] Iteration 12980, lr = 0.001
I0302 06:41:35.547917 29253 solver.cpp:237] Iteration 13000, loss = 0.00155098
I0302 06:41:35.547948 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00155099 (* 1 = 0.00155099 loss)
I0302 06:41:35.547957 29253 sgd_solver.cpp:106] Iteration 13000, lr = 0.001
I0302 06:41:41.334048 29253 blocking_queue.cpp:50] Data layer prefetch queue empty
I0302 06:42:04.579028 29253 solver.cpp:237] Iteration 13020, loss = 0.00145796
I0302 06:42:04.579059 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00145796 (* 1 = 0.00145796 loss)
I0302 06:42:04.579067 29253 sgd_solver.cpp:106] Iteration 13020, lr = 0.001
I0302 06:42:33.388870 29253 solver.cpp:237] Iteration 13040, loss = 0.00128616
I0302 06:42:33.388900 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00128616 (* 1 = 0.00128616 loss)
I0302 06:42:33.388908 29253 sgd_solver.cpp:106] Iteration 13040, lr = 0.001
I0302 06:43:02.358515 29253 solver.cpp:237] Iteration 13060, loss = 0.00167077
I0302 06:43:02.358548 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00167077 (* 1 = 0.00167077 loss)
I0302 06:43:02.358557 29253 sgd_solver.cpp:106] Iteration 13060, lr = 0.001
I0302 06:43:31.123044 29253 solver.cpp:237] Iteration 13080, loss = 0.00163335
I0302 06:43:31.123076 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00163335 (* 1 = 0.00163335 loss)
I0302 06:43:31.123085 29253 sgd_solver.cpp:106] Iteration 13080, lr = 0.001
I0302 06:44:00.239063 29253 solver.cpp:237] Iteration 13100, loss = 0.00154104
I0302 06:44:00.239095 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00154104 (* 1 = 0.00154104 loss)
I0302 06:44:00.239104 29253 sgd_solver.cpp:106] Iteration 13100, lr = 0.001
I0302 06:44:28.899317 29253 solver.cpp:237] Iteration 13120, loss = 0.00169681
I0302 06:44:28.899348 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00169681 (* 1 = 0.00169681 loss)
I0302 06:44:28.899356 29253 sgd_solver.cpp:106] Iteration 13120, lr = 0.001
I0302 06:44:57.693275 29253 solver.cpp:237] Iteration 13140, loss = 0.00187234
I0302 06:44:57.693307 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00187235 (* 1 = 0.00187235 loss)
I0302 06:44:57.693316 29253 sgd_solver.cpp:106] Iteration 13140, lr = 0.001
I0302 06:45:26.620580 29253 solver.cpp:237] Iteration 13160, loss = 0.0019513
I0302 06:45:26.620612 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0019513 (* 1 = 0.0019513 loss)
I0302 06:45:26.620621 29253 sgd_solver.cpp:106] Iteration 13160, lr = 0.001
I0302 06:45:55.510208 29253 solver.cpp:237] Iteration 13180, loss = 0.00156161
I0302 06:45:55.510239 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00156161 (* 1 = 0.00156161 loss)
I0302 06:45:55.510248 29253 sgd_solver.cpp:106] Iteration 13180, lr = 0.001
I0302 06:46:24.496247 29253 solver.cpp:237] Iteration 13200, loss = 0.00157312
I0302 06:46:24.496279 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00157312 (* 1 = 0.00157312 loss)
I0302 06:46:24.496289 29253 sgd_solver.cpp:106] Iteration 13200, lr = 0.001
I0302 06:46:53.217362 29253 solver.cpp:237] Iteration 13220, loss = 0.00155252
I0302 06:46:53.217396 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00155252 (* 1 = 0.00155252 loss)
I0302 06:46:53.217403 29253 sgd_solver.cpp:106] Iteration 13220, lr = 0.001
I0302 06:47:22.188083 29253 solver.cpp:237] Iteration 13240, loss = 0.00172592
I0302 06:47:22.188115 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00172593 (* 1 = 0.00172593 loss)
I0302 06:47:22.188124 29253 sgd_solver.cpp:106] Iteration 13240, lr = 0.001
I0302 06:47:51.448942 29253 solver.cpp:237] Iteration 13260, loss = 0.00285874
I0302 06:47:51.448971 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00285874 (* 1 = 0.00285874 loss)
I0302 06:47:51.448978 29253 sgd_solver.cpp:106] Iteration 13260, lr = 0.001
I0302 06:48:20.385993 29253 solver.cpp:237] Iteration 13280, loss = 0.0016988
I0302 06:48:20.386025 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00169881 (* 1 = 0.00169881 loss)
I0302 06:48:20.386034 29253 sgd_solver.cpp:106] Iteration 13280, lr = 0.001
I0302 06:48:49.299371 29253 solver.cpp:237] Iteration 13300, loss = 0.0016917
I0302 06:48:49.299402 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00169171 (* 1 = 0.00169171 loss)
I0302 06:48:49.299412 29253 sgd_solver.cpp:106] Iteration 13300, lr = 0.001
I0302 06:49:18.222961 29253 solver.cpp:237] Iteration 13320, loss = 0.00200286
I0302 06:49:18.222995 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00200287 (* 1 = 0.00200287 loss)
I0302 06:49:18.223002 29253 sgd_solver.cpp:106] Iteration 13320, lr = 0.001
I0302 06:49:47.100778 29253 solver.cpp:237] Iteration 13340, loss = 0.00178298
I0302 06:49:47.100811 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00178298 (* 1 = 0.00178298 loss)
I0302 06:49:47.100821 29253 sgd_solver.cpp:106] Iteration 13340, lr = 0.001
I0302 06:50:15.862810 29253 solver.cpp:237] Iteration 13360, loss = 0.00177729
I0302 06:50:15.862843 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00177729 (* 1 = 0.00177729 loss)
I0302 06:50:15.862851 29253 sgd_solver.cpp:106] Iteration 13360, lr = 0.001
I0302 06:50:45.134919 29253 solver.cpp:237] Iteration 13380, loss = 0.00147577
I0302 06:50:45.134950 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00147578 (* 1 = 0.00147578 loss)
I0302 06:50:45.134959 29253 sgd_solver.cpp:106] Iteration 13380, lr = 0.001
I0302 06:51:14.138056 29253 solver.cpp:237] Iteration 13400, loss = 0.00193212
I0302 06:51:14.138087 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00193213 (* 1 = 0.00193213 loss)
I0302 06:51:14.138095 29253 sgd_solver.cpp:106] Iteration 13400, lr = 0.001
I0302 06:51:43.033278 29253 solver.cpp:237] Iteration 13420, loss = 0.00191997
I0302 06:51:43.033310 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00191998 (* 1 = 0.00191998 loss)
I0302 06:51:43.033319 29253 sgd_solver.cpp:106] Iteration 13420, lr = 0.001
I0302 06:52:11.989096 29253 solver.cpp:237] Iteration 13440, loss = 0.00185109
I0302 06:52:11.989130 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00185109 (* 1 = 0.00185109 loss)
I0302 06:52:11.989138 29253 sgd_solver.cpp:106] Iteration 13440, lr = 0.001
I0302 06:52:41.109014 29253 solver.cpp:237] Iteration 13460, loss = 0.00144166
I0302 06:52:41.109046 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00144166 (* 1 = 0.00144166 loss)
I0302 06:52:41.109055 29253 sgd_solver.cpp:106] Iteration 13460, lr = 0.001
I0302 06:53:10.094884 29253 solver.cpp:237] Iteration 13480, loss = 0.00154616
I0302 06:53:10.094915 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00154616 (* 1 = 0.00154616 loss)
I0302 06:53:10.094923 29253 sgd_solver.cpp:106] Iteration 13480, lr = 0.001
I0302 06:53:38.931787 29253 solver.cpp:237] Iteration 13500, loss = 0.00236549
I0302 06:53:38.931820 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00236549 (* 1 = 0.00236549 loss)
I0302 06:53:38.931829 29253 sgd_solver.cpp:106] Iteration 13500, lr = 0.001
I0302 06:54:07.859390 29253 solver.cpp:237] Iteration 13520, loss = 0.00222018
I0302 06:54:07.859422 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00222019 (* 1 = 0.00222019 loss)
I0302 06:54:07.859431 29253 sgd_solver.cpp:106] Iteration 13520, lr = 0.001
I0302 06:54:36.831034 29253 solver.cpp:237] Iteration 13540, loss = 0.00165815
I0302 06:54:36.831065 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00165815 (* 1 = 0.00165815 loss)
I0302 06:54:36.831074 29253 sgd_solver.cpp:106] Iteration 13540, lr = 0.001
I0302 06:55:05.676928 29253 solver.cpp:237] Iteration 13560, loss = 0.00137319
I0302 06:55:05.676959 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00137319 (* 1 = 0.00137319 loss)
I0302 06:55:05.676967 29253 sgd_solver.cpp:106] Iteration 13560, lr = 0.001
I0302 06:55:34.578579 29253 solver.cpp:237] Iteration 13580, loss = 0.00167798
I0302 06:55:34.578613 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00167798 (* 1 = 0.00167798 loss)
I0302 06:55:34.578620 29253 sgd_solver.cpp:106] Iteration 13580, lr = 0.001
I0302 06:56:03.584339 29253 solver.cpp:237] Iteration 13600, loss = 0.00190896
I0302 06:56:03.584369 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00190897 (* 1 = 0.00190897 loss)
I0302 06:56:03.584378 29253 sgd_solver.cpp:106] Iteration 13600, lr = 0.001
I0302 06:56:32.591008 29253 solver.cpp:237] Iteration 13620, loss = 0.00183639
I0302 06:56:32.591040 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00183639 (* 1 = 0.00183639 loss)
I0302 06:56:32.591048 29253 sgd_solver.cpp:106] Iteration 13620, lr = 0.001
I0302 06:57:01.226878 29253 solver.cpp:237] Iteration 13640, loss = 0.00172128
I0302 06:57:01.226910 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00172128 (* 1 = 0.00172128 loss)
I0302 06:57:01.226919 29253 sgd_solver.cpp:106] Iteration 13640, lr = 0.001
I0302 06:57:30.057587 29253 solver.cpp:237] Iteration 13660, loss = 0.00189719
I0302 06:57:30.057621 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00189719 (* 1 = 0.00189719 loss)
I0302 06:57:30.057629 29253 sgd_solver.cpp:106] Iteration 13660, lr = 0.001
I0302 06:57:58.889770 29253 solver.cpp:237] Iteration 13680, loss = 0.00176534
I0302 06:57:58.889803 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00176534 (* 1 = 0.00176534 loss)
I0302 06:57:58.889813 29253 sgd_solver.cpp:106] Iteration 13680, lr = 0.001
I0302 06:58:27.618173 29253 solver.cpp:237] Iteration 13700, loss = 0.0019302
I0302 06:58:27.618206 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00193021 (* 1 = 0.00193021 loss)
I0302 06:58:27.618214 29253 sgd_solver.cpp:106] Iteration 13700, lr = 0.001
I0302 06:58:56.842216 29253 solver.cpp:237] Iteration 13720, loss = 0.00161746
I0302 06:58:56.842247 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00161746 (* 1 = 0.00161746 loss)
I0302 06:58:56.842255 29253 sgd_solver.cpp:106] Iteration 13720, lr = 0.001
I0302 06:59:25.802814 29253 solver.cpp:237] Iteration 13740, loss = 0.00221418
I0302 06:59:25.802846 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00221419 (* 1 = 0.00221419 loss)
I0302 06:59:25.802855 29253 sgd_solver.cpp:106] Iteration 13740, lr = 0.001
I0302 06:59:54.632057 29253 solver.cpp:237] Iteration 13760, loss = 0.00165523
I0302 06:59:54.632089 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00165523 (* 1 = 0.00165523 loss)
I0302 06:59:54.632098 29253 sgd_solver.cpp:106] Iteration 13760, lr = 0.001
I0302 07:00:23.574640 29253 solver.cpp:237] Iteration 13780, loss = 0.00212696
I0302 07:00:23.574671 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00212696 (* 1 = 0.00212696 loss)
I0302 07:00:23.574681 29253 sgd_solver.cpp:106] Iteration 13780, lr = 0.001
I0302 07:00:52.514962 29253 solver.cpp:237] Iteration 13800, loss = 0.0014859
I0302 07:00:52.514996 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00148591 (* 1 = 0.00148591 loss)
I0302 07:00:52.515003 29253 sgd_solver.cpp:106] Iteration 13800, lr = 0.001
I0302 07:01:21.320690 29253 solver.cpp:237] Iteration 13820, loss = 0.00158333
I0302 07:01:21.320722 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00158333 (* 1 = 0.00158333 loss)
I0302 07:01:21.320731 29253 sgd_solver.cpp:106] Iteration 13820, lr = 0.001
I0302 07:01:50.378000 29253 solver.cpp:237] Iteration 13840, loss = 0.00142488
I0302 07:01:50.378031 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00142489 (* 1 = 0.00142489 loss)
I0302 07:01:50.378041 29253 sgd_solver.cpp:106] Iteration 13840, lr = 0.001
I0302 07:02:19.509315 29253 solver.cpp:237] Iteration 13860, loss = 0.0018684
I0302 07:02:19.509344 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00186841 (* 1 = 0.00186841 loss)
I0302 07:02:19.509353 29253 sgd_solver.cpp:106] Iteration 13860, lr = 0.001
I0302 07:02:48.518160 29253 solver.cpp:237] Iteration 13880, loss = 0.00154554
I0302 07:02:48.518192 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00154555 (* 1 = 0.00154555 loss)
I0302 07:02:48.518200 29253 sgd_solver.cpp:106] Iteration 13880, lr = 0.001
I0302 07:03:17.482055 29253 solver.cpp:237] Iteration 13900, loss = 0.0018448
I0302 07:03:17.482086 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00184481 (* 1 = 0.00184481 loss)
I0302 07:03:17.482095 29253 sgd_solver.cpp:106] Iteration 13900, lr = 0.001
I0302 07:03:46.724313 29253 solver.cpp:237] Iteration 13920, loss = 0.00162984
I0302 07:03:46.724344 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00162985 (* 1 = 0.00162985 loss)
I0302 07:03:46.724352 29253 sgd_solver.cpp:106] Iteration 13920, lr = 0.001
I0302 07:04:15.788990 29253 solver.cpp:237] Iteration 13940, loss = 0.00190946
I0302 07:04:15.789021 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00190946 (* 1 = 0.00190946 loss)
I0302 07:04:15.789029 29253 sgd_solver.cpp:106] Iteration 13940, lr = 0.001
I0302 07:04:44.631319 29253 solver.cpp:237] Iteration 13960, loss = 0.00177411
I0302 07:04:44.631350 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00177412 (* 1 = 0.00177412 loss)
I0302 07:04:44.631357 29253 sgd_solver.cpp:106] Iteration 13960, lr = 0.001
I0302 07:05:13.522399 29253 solver.cpp:237] Iteration 13980, loss = 0.00170428
I0302 07:05:13.522430 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00170428 (* 1 = 0.00170428 loss)
I0302 07:05:13.522439 29253 sgd_solver.cpp:106] Iteration 13980, lr = 0.001
I0302 07:05:42.332623 29253 solver.cpp:237] Iteration 14000, loss = 0.00163889
I0302 07:05:42.332655 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00163889 (* 1 = 0.00163889 loss)
I0302 07:05:42.332664 29253 sgd_solver.cpp:106] Iteration 14000, lr = 0.001
I0302 07:05:48.064795 29253 blocking_queue.cpp:50] Data layer prefetch queue empty
I0302 07:06:11.133510 29253 solver.cpp:237] Iteration 14020, loss = 0.00147313
I0302 07:06:11.133543 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00147313 (* 1 = 0.00147313 loss)
I0302 07:06:11.133551 29253 sgd_solver.cpp:106] Iteration 14020, lr = 0.001
I0302 07:06:40.115109 29253 solver.cpp:237] Iteration 14040, loss = 0.00224757
I0302 07:06:40.115142 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00224757 (* 1 = 0.00224757 loss)
I0302 07:06:40.115151 29253 sgd_solver.cpp:106] Iteration 14040, lr = 0.001
I0302 07:07:09.044036 29253 solver.cpp:237] Iteration 14060, loss = 0.00166678
I0302 07:07:09.044069 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00166679 (* 1 = 0.00166679 loss)
I0302 07:07:09.044077 29253 sgd_solver.cpp:106] Iteration 14060, lr = 0.001
I0302 07:07:37.895540 29253 solver.cpp:237] Iteration 14080, loss = 0.00192237
I0302 07:07:37.895573 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00192237 (* 1 = 0.00192237 loss)
I0302 07:07:37.895582 29253 sgd_solver.cpp:106] Iteration 14080, lr = 0.001
I0302 07:08:06.776006 29253 solver.cpp:237] Iteration 14100, loss = 0.00192987
I0302 07:08:06.776037 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00192988 (* 1 = 0.00192988 loss)
I0302 07:08:06.776046 29253 sgd_solver.cpp:106] Iteration 14100, lr = 0.001
I0302 07:08:35.776087 29253 solver.cpp:237] Iteration 14120, loss = 0.00166692
I0302 07:08:35.776119 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00166692 (* 1 = 0.00166692 loss)
I0302 07:08:35.776127 29253 sgd_solver.cpp:106] Iteration 14120, lr = 0.001
I0302 07:09:04.718369 29253 solver.cpp:237] Iteration 14140, loss = 0.00180778
I0302 07:09:04.718400 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00180778 (* 1 = 0.00180778 loss)
I0302 07:09:04.718410 29253 sgd_solver.cpp:106] Iteration 14140, lr = 0.001
I0302 07:09:33.921630 29253 solver.cpp:237] Iteration 14160, loss = 0.0016167
I0302 07:09:33.921663 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00161671 (* 1 = 0.00161671 loss)
I0302 07:09:33.921670 29253 sgd_solver.cpp:106] Iteration 14160, lr = 0.001
I0302 07:10:02.856343 29253 solver.cpp:237] Iteration 14180, loss = 0.00146632
I0302 07:10:02.856374 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00146633 (* 1 = 0.00146633 loss)
I0302 07:10:02.856384 29253 sgd_solver.cpp:106] Iteration 14180, lr = 0.001
I0302 07:10:31.724594 29253 solver.cpp:237] Iteration 14200, loss = 0.00167211
I0302 07:10:31.724627 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00167212 (* 1 = 0.00167212 loss)
I0302 07:10:31.724635 29253 sgd_solver.cpp:106] Iteration 14200, lr = 0.001
I0302 07:11:00.748539 29253 solver.cpp:237] Iteration 14220, loss = 0.00129999
I0302 07:11:00.748572 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0013 (* 1 = 0.0013 loss)
I0302 07:11:00.748581 29253 sgd_solver.cpp:106] Iteration 14220, lr = 0.001
I0302 07:11:29.736588 29253 solver.cpp:237] Iteration 14240, loss = 0.00163471
I0302 07:11:29.736620 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00163471 (* 1 = 0.00163471 loss)
I0302 07:11:29.736629 29253 sgd_solver.cpp:106] Iteration 14240, lr = 0.001
I0302 07:11:58.635490 29253 solver.cpp:237] Iteration 14260, loss = 0.00180332
I0302 07:11:58.635522 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00180333 (* 1 = 0.00180333 loss)
I0302 07:11:58.635535 29253 sgd_solver.cpp:106] Iteration 14260, lr = 0.001
I0302 07:12:27.540485 29253 solver.cpp:237] Iteration 14280, loss = 0.00180761
I0302 07:12:27.540515 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00180762 (* 1 = 0.00180762 loss)
I0302 07:12:27.540524 29253 sgd_solver.cpp:106] Iteration 14280, lr = 0.001
I0302 07:12:56.561089 29253 solver.cpp:237] Iteration 14300, loss = 0.00163881
I0302 07:12:56.561120 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00163881 (* 1 = 0.00163881 loss)
I0302 07:12:56.561127 29253 sgd_solver.cpp:106] Iteration 14300, lr = 0.001
I0302 07:13:25.350323 29253 solver.cpp:237] Iteration 14320, loss = 0.00188221
I0302 07:13:25.350358 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00188221 (* 1 = 0.00188221 loss)
I0302 07:13:25.350366 29253 sgd_solver.cpp:106] Iteration 14320, lr = 0.001
I0302 07:13:54.270978 29253 solver.cpp:237] Iteration 14340, loss = 0.00192544
I0302 07:13:54.271011 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00192545 (* 1 = 0.00192545 loss)
I0302 07:13:54.271020 29253 sgd_solver.cpp:106] Iteration 14340, lr = 0.001
I0302 07:14:23.298995 29253 solver.cpp:237] Iteration 14360, loss = 0.00159839
I0302 07:14:23.299027 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00159839 (* 1 = 0.00159839 loss)
I0302 07:14:23.299036 29253 sgd_solver.cpp:106] Iteration 14360, lr = 0.001
I0302 07:14:52.266589 29253 solver.cpp:237] Iteration 14380, loss = 0.00161181
I0302 07:14:52.266621 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00161182 (* 1 = 0.00161182 loss)
I0302 07:14:52.266633 29253 sgd_solver.cpp:106] Iteration 14380, lr = 0.001
I0302 07:15:21.173679 29253 solver.cpp:237] Iteration 14400, loss = 0.00160531
I0302 07:15:21.173712 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00160532 (* 1 = 0.00160532 loss)
I0302 07:15:21.173720 29253 sgd_solver.cpp:106] Iteration 14400, lr = 0.001
I0302 07:15:49.929787 29253 solver.cpp:237] Iteration 14420, loss = 0.00198669
I0302 07:15:49.929819 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00198669 (* 1 = 0.00198669 loss)
I0302 07:15:49.929857 29253 sgd_solver.cpp:106] Iteration 14420, lr = 0.001
I0302 07:16:19.128947 29253 solver.cpp:237] Iteration 14440, loss = 0.00194473
I0302 07:16:19.128981 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00194474 (* 1 = 0.00194474 loss)
I0302 07:16:19.128989 29253 sgd_solver.cpp:106] Iteration 14440, lr = 0.001
I0302 07:16:48.030278 29253 solver.cpp:237] Iteration 14460, loss = 0.00217468
I0302 07:16:48.030309 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00217469 (* 1 = 0.00217469 loss)
I0302 07:16:48.030318 29253 sgd_solver.cpp:106] Iteration 14460, lr = 0.001
I0302 07:17:16.994410 29253 solver.cpp:237] Iteration 14480, loss = 0.00172352
I0302 07:17:16.994441 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00172352 (* 1 = 0.00172352 loss)
I0302 07:17:16.994451 29253 sgd_solver.cpp:106] Iteration 14480, lr = 0.001
I0302 07:17:45.906548 29253 solver.cpp:237] Iteration 14500, loss = 0.00156058
I0302 07:17:45.906579 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00156058 (* 1 = 0.00156058 loss)
I0302 07:17:45.906589 29253 sgd_solver.cpp:106] Iteration 14500, lr = 0.001
I0302 07:18:14.856909 29253 solver.cpp:237] Iteration 14520, loss = 0.00171874
I0302 07:18:14.856940 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00171874 (* 1 = 0.00171874 loss)
I0302 07:18:14.856950 29253 sgd_solver.cpp:106] Iteration 14520, lr = 0.001
I0302 07:18:43.976125 29253 solver.cpp:237] Iteration 14540, loss = 0.00154198
I0302 07:18:43.976156 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00154198 (* 1 = 0.00154198 loss)
I0302 07:18:43.976164 29253 sgd_solver.cpp:106] Iteration 14540, lr = 0.001
I0302 07:19:12.899092 29253 solver.cpp:237] Iteration 14560, loss = 0.00188275
I0302 07:19:12.899124 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00188275 (* 1 = 0.00188275 loss)
I0302 07:19:12.899133 29253 sgd_solver.cpp:106] Iteration 14560, lr = 0.001
I0302 07:19:41.841975 29253 solver.cpp:237] Iteration 14580, loss = 0.00144488
I0302 07:19:41.842007 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00144488 (* 1 = 0.00144488 loss)
I0302 07:19:41.842016 29253 sgd_solver.cpp:106] Iteration 14580, lr = 0.001
I0302 07:20:10.717234 29253 solver.cpp:237] Iteration 14600, loss = 0.00223387
I0302 07:20:10.717265 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00223387 (* 1 = 0.00223387 loss)
I0302 07:20:10.717273 29253 sgd_solver.cpp:106] Iteration 14600, lr = 0.001
I0302 07:20:39.663213 29253 solver.cpp:237] Iteration 14620, loss = 0.00236668
I0302 07:20:39.663245 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00236668 (* 1 = 0.00236668 loss)
I0302 07:20:39.663254 29253 sgd_solver.cpp:106] Iteration 14620, lr = 0.001
I0302 07:21:08.598685 29253 solver.cpp:237] Iteration 14640, loss = 0.00171338
I0302 07:21:08.598718 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00171338 (* 1 = 0.00171338 loss)
I0302 07:21:08.598727 29253 sgd_solver.cpp:106] Iteration 14640, lr = 0.001
I0302 07:21:37.609231 29253 solver.cpp:237] Iteration 14660, loss = 0.0022257
I0302 07:21:37.609263 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00222571 (* 1 = 0.00222571 loss)
I0302 07:21:37.609272 29253 sgd_solver.cpp:106] Iteration 14660, lr = 0.001
I0302 07:22:06.513329 29253 solver.cpp:237] Iteration 14680, loss = 0.00167627
I0302 07:22:06.513361 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00167627 (* 1 = 0.00167627 loss)
I0302 07:22:06.513370 29253 sgd_solver.cpp:106] Iteration 14680, lr = 0.001
I0302 07:22:35.488319 29253 solver.cpp:237] Iteration 14700, loss = 0.00173046
I0302 07:22:35.488351 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00173046 (* 1 = 0.00173046 loss)
I0302 07:22:35.488359 29253 sgd_solver.cpp:106] Iteration 14700, lr = 0.001
I0302 07:23:04.346657 29253 solver.cpp:237] Iteration 14720, loss = 0.00198375
I0302 07:23:04.346689 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00198375 (* 1 = 0.00198375 loss)
I0302 07:23:04.346698 29253 sgd_solver.cpp:106] Iteration 14720, lr = 0.001
I0302 07:23:33.130700 29253 solver.cpp:237] Iteration 14740, loss = 0.00170296
I0302 07:23:33.130734 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00170296 (* 1 = 0.00170296 loss)
I0302 07:23:33.130743 29253 sgd_solver.cpp:106] Iteration 14740, lr = 0.001
I0302 07:24:02.160850 29253 solver.cpp:237] Iteration 14760, loss = 0.00190179
I0302 07:24:02.160881 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00190179 (* 1 = 0.00190179 loss)
I0302 07:24:02.160889 29253 sgd_solver.cpp:106] Iteration 14760, lr = 0.001
I0302 07:24:31.115633 29253 solver.cpp:237] Iteration 14780, loss = 0.00199827
I0302 07:24:31.115664 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00199827 (* 1 = 0.00199827 loss)
I0302 07:24:31.115674 29253 sgd_solver.cpp:106] Iteration 14780, lr = 0.001
I0302 07:25:00.000084 29253 solver.cpp:237] Iteration 14800, loss = 0.00167505
I0302 07:25:00.000118 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00167505 (* 1 = 0.00167505 loss)
I0302 07:25:00.000126 29253 sgd_solver.cpp:106] Iteration 14800, lr = 0.001
I0302 07:25:28.874569 29253 solver.cpp:237] Iteration 14820, loss = 0.00192775
I0302 07:25:28.874603 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00192776 (* 1 = 0.00192776 loss)
I0302 07:25:28.874611 29253 sgd_solver.cpp:106] Iteration 14820, lr = 0.001
I0302 07:25:57.841845 29253 solver.cpp:237] Iteration 14840, loss = 0.00170627
I0302 07:25:57.841877 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00170627 (* 1 = 0.00170627 loss)
I0302 07:25:57.841886 29253 sgd_solver.cpp:106] Iteration 14840, lr = 0.001
I0302 07:26:26.708467 29253 solver.cpp:237] Iteration 14860, loss = 0.0026678
I0302 07:26:26.708501 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0026678 (* 1 = 0.0026678 loss)
I0302 07:26:26.708510 29253 sgd_solver.cpp:106] Iteration 14860, lr = 0.001
I0302 07:26:55.701926 29253 solver.cpp:237] Iteration 14880, loss = 0.0017262
I0302 07:26:55.701959 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0017262 (* 1 = 0.0017262 loss)
I0302 07:26:55.701968 29253 sgd_solver.cpp:106] Iteration 14880, lr = 0.001
I0302 07:27:24.418278 29253 solver.cpp:237] Iteration 14900, loss = 0.00146306
I0302 07:27:24.418310 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00146306 (* 1 = 0.00146306 loss)
I0302 07:27:24.418319 29253 sgd_solver.cpp:106] Iteration 14900, lr = 0.001
I0302 07:27:53.353577 29253 solver.cpp:237] Iteration 14920, loss = 0.00158694
I0302 07:27:53.353610 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00158694 (* 1 = 0.00158694 loss)
I0302 07:27:53.353618 29253 sgd_solver.cpp:106] Iteration 14920, lr = 0.001
I0302 07:28:22.263950 29253 solver.cpp:237] Iteration 14940, loss = 0.0015279
I0302 07:28:22.263983 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0015279 (* 1 = 0.0015279 loss)
I0302 07:28:22.263990 29253 sgd_solver.cpp:106] Iteration 14940, lr = 0.001
I0302 07:28:51.236238 29253 solver.cpp:237] Iteration 14960, loss = 0.00158433
I0302 07:28:51.236269 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00158433 (* 1 = 0.00158433 loss)
I0302 07:28:51.236279 29253 sgd_solver.cpp:106] Iteration 14960, lr = 0.001
I0302 07:29:19.993247 29253 solver.cpp:237] Iteration 14980, loss = 0.00140361
I0302 07:29:19.993275 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00140361 (* 1 = 0.00140361 loss)
I0302 07:29:19.993283 29253 sgd_solver.cpp:106] Iteration 14980, lr = 0.001
I0302 07:29:47.480000 29253 solver.cpp:459] Snapshotting to binary proto file /nfs.yoda/xiaolonw/fast_rcnn/models_sunrgbd/pre_cls_1fc_scratch/model__iter_15000.caffemodel
I0302 07:31:12.282984 29253 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /nfs.yoda/xiaolonw/fast_rcnn/models_sunrgbd/pre_cls_1fc_scratch/model__iter_15000.solverstate
I0302 07:31:12.804996 29253 solver.cpp:237] Iteration 15000, loss = 0.00133655
I0302 07:31:12.805027 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00133656 (* 1 = 0.00133656 loss)
I0302 07:31:12.805037 29253 sgd_solver.cpp:106] Iteration 15000, lr = 0.001
I0302 07:31:20.000988 29253 blocking_queue.cpp:50] Data layer prefetch queue empty
I0302 07:31:38.730816 29253 solver.cpp:237] Iteration 15020, loss = 0.00262067
I0302 07:31:38.730850 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00262067 (* 1 = 0.00262067 loss)
I0302 07:31:38.730859 29253 sgd_solver.cpp:106] Iteration 15020, lr = 0.001
I0302 07:32:07.713340 29253 solver.cpp:237] Iteration 15040, loss = 0.00155517
I0302 07:32:07.713371 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00155517 (* 1 = 0.00155517 loss)
I0302 07:32:07.713379 29253 sgd_solver.cpp:106] Iteration 15040, lr = 0.001
I0302 07:32:36.712262 29253 solver.cpp:237] Iteration 15060, loss = 0.00162072
I0302 07:32:36.712294 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00162072 (* 1 = 0.00162072 loss)
I0302 07:32:36.712303 29253 sgd_solver.cpp:106] Iteration 15060, lr = 0.001
I0302 07:33:05.598167 29253 solver.cpp:237] Iteration 15080, loss = 0.00166244
I0302 07:33:05.598201 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00166245 (* 1 = 0.00166245 loss)
I0302 07:33:05.598209 29253 sgd_solver.cpp:106] Iteration 15080, lr = 0.001
I0302 07:33:34.569098 29253 solver.cpp:237] Iteration 15100, loss = 0.00167519
I0302 07:33:34.569128 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00167519 (* 1 = 0.00167519 loss)
I0302 07:33:34.569138 29253 sgd_solver.cpp:106] Iteration 15100, lr = 0.001
I0302 07:34:03.663296 29253 solver.cpp:237] Iteration 15120, loss = 0.00169863
I0302 07:34:03.663329 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00169863 (* 1 = 0.00169863 loss)
I0302 07:34:03.663338 29253 sgd_solver.cpp:106] Iteration 15120, lr = 0.001
I0302 07:34:32.562538 29253 solver.cpp:237] Iteration 15140, loss = 0.00160775
I0302 07:34:32.562572 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00160776 (* 1 = 0.00160776 loss)
I0302 07:34:32.562607 29253 sgd_solver.cpp:106] Iteration 15140, lr = 0.001
I0302 07:35:01.531687 29253 solver.cpp:237] Iteration 15160, loss = 0.00143902
I0302 07:35:01.531718 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00143903 (* 1 = 0.00143903 loss)
I0302 07:35:01.531726 29253 sgd_solver.cpp:106] Iteration 15160, lr = 0.001
I0302 07:35:30.261972 29253 solver.cpp:237] Iteration 15180, loss = 0.00127637
I0302 07:35:30.262004 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00127637 (* 1 = 0.00127637 loss)
I0302 07:35:30.262013 29253 sgd_solver.cpp:106] Iteration 15180, lr = 0.001
I0302 07:35:59.266728 29253 solver.cpp:237] Iteration 15200, loss = 0.00175979
I0302 07:35:59.266760 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00175979 (* 1 = 0.00175979 loss)
I0302 07:35:59.266769 29253 sgd_solver.cpp:106] Iteration 15200, lr = 0.001
I0302 07:36:28.175158 29253 solver.cpp:237] Iteration 15220, loss = 0.00134097
I0302 07:36:28.175191 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00134097 (* 1 = 0.00134097 loss)
I0302 07:36:28.175200 29253 sgd_solver.cpp:106] Iteration 15220, lr = 0.001
I0302 07:36:56.991034 29253 solver.cpp:237] Iteration 15240, loss = 0.00316347
I0302 07:36:56.991066 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00316347 (* 1 = 0.00316347 loss)
I0302 07:36:56.991075 29253 sgd_solver.cpp:106] Iteration 15240, lr = 0.001
I0302 07:37:26.034574 29253 solver.cpp:237] Iteration 15260, loss = 0.00169354
I0302 07:37:26.034607 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00169354 (* 1 = 0.00169354 loss)
I0302 07:37:26.034615 29253 sgd_solver.cpp:106] Iteration 15260, lr = 0.001
I0302 07:37:55.334573 29253 solver.cpp:237] Iteration 15280, loss = 0.00157711
I0302 07:37:55.334605 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00157711 (* 1 = 0.00157711 loss)
I0302 07:37:55.334614 29253 sgd_solver.cpp:106] Iteration 15280, lr = 0.001
I0302 07:38:24.418118 29253 solver.cpp:237] Iteration 15300, loss = 0.00174118
I0302 07:38:24.418149 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00174119 (* 1 = 0.00174119 loss)
I0302 07:38:24.418159 29253 sgd_solver.cpp:106] Iteration 15300, lr = 0.001
I0302 07:38:53.233594 29253 solver.cpp:237] Iteration 15320, loss = 0.00190496
I0302 07:38:53.233726 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00190497 (* 1 = 0.00190497 loss)
I0302 07:38:53.233734 29253 sgd_solver.cpp:106] Iteration 15320, lr = 0.001
I0302 07:39:22.325578 29253 solver.cpp:237] Iteration 15340, loss = 0.00157386
I0302 07:39:22.325610 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00157387 (* 1 = 0.00157387 loss)
I0302 07:39:22.325619 29253 sgd_solver.cpp:106] Iteration 15340, lr = 0.001
I0302 07:39:50.972605 29253 solver.cpp:237] Iteration 15360, loss = 0.00195719
I0302 07:39:50.972638 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00195719 (* 1 = 0.00195719 loss)
I0302 07:39:50.972647 29253 sgd_solver.cpp:106] Iteration 15360, lr = 0.001
I0302 07:40:19.711011 29253 solver.cpp:237] Iteration 15380, loss = 0.00139774
I0302 07:40:19.711045 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00139775 (* 1 = 0.00139775 loss)
I0302 07:40:19.711052 29253 sgd_solver.cpp:106] Iteration 15380, lr = 0.001
I0302 07:40:48.628558 29253 solver.cpp:237] Iteration 15400, loss = 0.00132805
I0302 07:40:48.628592 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00132806 (* 1 = 0.00132806 loss)
I0302 07:40:48.628600 29253 sgd_solver.cpp:106] Iteration 15400, lr = 0.001
I0302 07:41:17.541082 29253 solver.cpp:237] Iteration 15420, loss = 0.00159357
I0302 07:41:17.541115 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00159358 (* 1 = 0.00159358 loss)
I0302 07:41:17.541123 29253 sgd_solver.cpp:106] Iteration 15420, lr = 0.001
I0302 07:41:46.513103 29253 solver.cpp:237] Iteration 15440, loss = 0.00257509
I0302 07:41:46.513134 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0025751 (* 1 = 0.0025751 loss)
I0302 07:41:46.513144 29253 sgd_solver.cpp:106] Iteration 15440, lr = 0.001
I0302 07:42:15.303462 29253 solver.cpp:237] Iteration 15460, loss = 0.00178455
I0302 07:42:15.303493 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00178455 (* 1 = 0.00178455 loss)
I0302 07:42:15.303501 29253 sgd_solver.cpp:106] Iteration 15460, lr = 0.001
I0302 07:42:44.239661 29253 solver.cpp:237] Iteration 15480, loss = 0.00143747
I0302 07:42:44.239692 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00143747 (* 1 = 0.00143747 loss)
I0302 07:42:44.239701 29253 sgd_solver.cpp:106] Iteration 15480, lr = 0.001
I0302 07:43:13.593466 29253 solver.cpp:237] Iteration 15500, loss = 0.001673
I0302 07:43:13.593499 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00167301 (* 1 = 0.00167301 loss)
I0302 07:43:13.593508 29253 sgd_solver.cpp:106] Iteration 15500, lr = 0.001
I0302 07:43:42.158252 29253 solver.cpp:237] Iteration 15520, loss = 0.00142359
I0302 07:43:42.158284 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00142359 (* 1 = 0.00142359 loss)
I0302 07:43:42.158293 29253 sgd_solver.cpp:106] Iteration 15520, lr = 0.001
I0302 07:44:11.216487 29253 solver.cpp:237] Iteration 15540, loss = 0.00161604
I0302 07:44:11.216521 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00161605 (* 1 = 0.00161605 loss)
I0302 07:44:11.216531 29253 sgd_solver.cpp:106] Iteration 15540, lr = 0.001
I0302 07:44:39.845155 29253 solver.cpp:237] Iteration 15560, loss = 0.00140732
I0302 07:44:39.845188 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00140732 (* 1 = 0.00140732 loss)
I0302 07:44:39.845196 29253 sgd_solver.cpp:106] Iteration 15560, lr = 0.001
I0302 07:45:09.093332 29253 solver.cpp:237] Iteration 15580, loss = 0.00161463
I0302 07:45:09.093363 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00161464 (* 1 = 0.00161464 loss)
I0302 07:45:09.093372 29253 sgd_solver.cpp:106] Iteration 15580, lr = 0.001
I0302 07:45:38.236182 29253 solver.cpp:237] Iteration 15600, loss = 0.00217452
I0302 07:45:38.236215 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00217452 (* 1 = 0.00217452 loss)
I0302 07:45:38.236224 29253 sgd_solver.cpp:106] Iteration 15600, lr = 0.001
I0302 07:46:07.873962 29253 solver.cpp:237] Iteration 15620, loss = 0.00165841
I0302 07:46:07.873994 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00165842 (* 1 = 0.00165842 loss)
I0302 07:46:07.874002 29253 sgd_solver.cpp:106] Iteration 15620, lr = 0.001
I0302 07:46:37.070899 29253 solver.cpp:237] Iteration 15640, loss = 0.00171583
I0302 07:46:37.070933 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00171584 (* 1 = 0.00171584 loss)
I0302 07:46:37.070942 29253 sgd_solver.cpp:106] Iteration 15640, lr = 0.001
I0302 07:47:05.934958 29253 solver.cpp:237] Iteration 15660, loss = 0.001699
I0302 07:47:05.934991 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.001699 (* 1 = 0.001699 loss)
I0302 07:47:05.935000 29253 sgd_solver.cpp:106] Iteration 15660, lr = 0.001
I0302 07:47:34.833344 29253 solver.cpp:237] Iteration 15680, loss = 0.00145964
I0302 07:47:34.833377 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00145964 (* 1 = 0.00145964 loss)
I0302 07:47:34.833386 29253 sgd_solver.cpp:106] Iteration 15680, lr = 0.001
I0302 07:48:03.549157 29253 solver.cpp:237] Iteration 15700, loss = 0.00169412
I0302 07:48:03.549190 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00169412 (* 1 = 0.00169412 loss)
I0302 07:48:03.549199 29253 sgd_solver.cpp:106] Iteration 15700, lr = 0.001
I0302 07:48:32.558831 29253 solver.cpp:237] Iteration 15720, loss = 0.0015531
I0302 07:48:32.558864 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0015531 (* 1 = 0.0015531 loss)
I0302 07:48:32.558874 29253 sgd_solver.cpp:106] Iteration 15720, lr = 0.001
I0302 07:49:01.975682 29253 solver.cpp:237] Iteration 15740, loss = 0.00177056
I0302 07:49:01.975713 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00177057 (* 1 = 0.00177057 loss)
I0302 07:49:01.975721 29253 sgd_solver.cpp:106] Iteration 15740, lr = 0.001
I0302 07:49:30.774696 29253 solver.cpp:237] Iteration 15760, loss = 0.001532
I0302 07:49:30.774729 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.001532 (* 1 = 0.001532 loss)
I0302 07:49:30.774737 29253 sgd_solver.cpp:106] Iteration 15760, lr = 0.001
I0302 07:49:59.744410 29253 solver.cpp:237] Iteration 15780, loss = 0.00151197
I0302 07:49:59.744441 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00151198 (* 1 = 0.00151198 loss)
I0302 07:49:59.744451 29253 sgd_solver.cpp:106] Iteration 15780, lr = 0.001
I0302 07:50:28.659420 29253 solver.cpp:237] Iteration 15800, loss = 0.00174291
I0302 07:50:28.659453 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00174292 (* 1 = 0.00174292 loss)
I0302 07:50:28.659462 29253 sgd_solver.cpp:106] Iteration 15800, lr = 0.001
I0302 07:50:57.967562 29253 solver.cpp:237] Iteration 15820, loss = 0.00168794
I0302 07:50:57.967597 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00168794 (* 1 = 0.00168794 loss)
I0302 07:50:57.967605 29253 sgd_solver.cpp:106] Iteration 15820, lr = 0.001
I0302 07:51:26.678711 29253 solver.cpp:237] Iteration 15840, loss = 0.00172496
I0302 07:51:26.678745 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00172496 (* 1 = 0.00172496 loss)
I0302 07:51:26.678752 29253 sgd_solver.cpp:106] Iteration 15840, lr = 0.001
I0302 07:51:55.405177 29253 solver.cpp:237] Iteration 15860, loss = 0.00125797
I0302 07:51:55.405210 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00125797 (* 1 = 0.00125797 loss)
I0302 07:51:55.405220 29253 sgd_solver.cpp:106] Iteration 15860, lr = 0.001
I0302 07:52:24.078096 29253 solver.cpp:237] Iteration 15880, loss = 0.0020418
I0302 07:52:24.078129 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00204181 (* 1 = 0.00204181 loss)
I0302 07:52:24.078138 29253 sgd_solver.cpp:106] Iteration 15880, lr = 0.001
I0302 07:52:52.981909 29253 solver.cpp:237] Iteration 15900, loss = 0.00160562
I0302 07:52:52.981942 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00160562 (* 1 = 0.00160562 loss)
I0302 07:52:52.981951 29253 sgd_solver.cpp:106] Iteration 15900, lr = 0.001
I0302 07:53:21.880673 29253 solver.cpp:237] Iteration 15920, loss = 0.00176412
I0302 07:53:21.880704 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00176412 (* 1 = 0.00176412 loss)
I0302 07:53:21.880712 29253 sgd_solver.cpp:106] Iteration 15920, lr = 0.001
I0302 07:53:50.858683 29253 solver.cpp:237] Iteration 15940, loss = 0.00159213
I0302 07:53:50.858717 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00159214 (* 1 = 0.00159214 loss)
I0302 07:53:50.858726 29253 sgd_solver.cpp:106] Iteration 15940, lr = 0.001
I0302 07:54:19.555763 29253 solver.cpp:237] Iteration 15960, loss = 0.00154301
I0302 07:54:19.555796 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00154301 (* 1 = 0.00154301 loss)
I0302 07:54:19.555804 29253 sgd_solver.cpp:106] Iteration 15960, lr = 0.001
I0302 07:54:48.625421 29253 solver.cpp:237] Iteration 15980, loss = 0.00211292
I0302 07:54:48.625453 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00211292 (* 1 = 0.00211292 loss)
I0302 07:54:48.625463 29253 sgd_solver.cpp:106] Iteration 15980, lr = 0.001
I0302 07:55:17.783339 29253 solver.cpp:237] Iteration 16000, loss = 0.00128204
I0302 07:55:17.783371 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00128204 (* 1 = 0.00128204 loss)
I0302 07:55:17.783380 29253 sgd_solver.cpp:106] Iteration 16000, lr = 0.001
I0302 07:55:27.587214 29253 blocking_queue.cpp:50] Data layer prefetch queue empty
I0302 07:55:46.433873 29253 solver.cpp:237] Iteration 16020, loss = 0.00152507
I0302 07:55:46.433905 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00152507 (* 1 = 0.00152507 loss)
I0302 07:55:46.433914 29253 sgd_solver.cpp:106] Iteration 16020, lr = 0.001
I0302 07:56:15.410936 29253 solver.cpp:237] Iteration 16040, loss = 0.00138804
I0302 07:56:15.410969 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00138805 (* 1 = 0.00138805 loss)
I0302 07:56:15.410977 29253 sgd_solver.cpp:106] Iteration 16040, lr = 0.001
I0302 07:56:44.366760 29253 solver.cpp:237] Iteration 16060, loss = 0.00142807
I0302 07:56:44.366793 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00142807 (* 1 = 0.00142807 loss)
I0302 07:56:44.366801 29253 sgd_solver.cpp:106] Iteration 16060, lr = 0.001
I0302 07:57:13.530299 29253 solver.cpp:237] Iteration 16080, loss = 0.00200577
I0302 07:57:13.530330 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00200578 (* 1 = 0.00200578 loss)
I0302 07:57:13.530339 29253 sgd_solver.cpp:106] Iteration 16080, lr = 0.001
I0302 07:57:42.495605 29253 solver.cpp:237] Iteration 16100, loss = 0.00178878
I0302 07:57:42.495636 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00178878 (* 1 = 0.00178878 loss)
I0302 07:57:42.495645 29253 sgd_solver.cpp:106] Iteration 16100, lr = 0.001
I0302 07:58:11.511981 29253 solver.cpp:237] Iteration 16120, loss = 0.00185388
I0302 07:58:11.512012 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00185389 (* 1 = 0.00185389 loss)
I0302 07:58:11.512022 29253 sgd_solver.cpp:106] Iteration 16120, lr = 0.001
I0302 07:58:40.338206 29253 solver.cpp:237] Iteration 16140, loss = 0.00191404
I0302 07:58:40.338238 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00191404 (* 1 = 0.00191404 loss)
I0302 07:58:40.338248 29253 sgd_solver.cpp:106] Iteration 16140, lr = 0.001
I0302 07:59:09.401885 29253 solver.cpp:237] Iteration 16160, loss = 0.00132117
I0302 07:59:09.401918 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00132117 (* 1 = 0.00132117 loss)
I0302 07:59:09.401926 29253 sgd_solver.cpp:106] Iteration 16160, lr = 0.001
I0302 07:59:38.225965 29253 solver.cpp:237] Iteration 16180, loss = 0.00150344
I0302 07:59:38.225997 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00150344 (* 1 = 0.00150344 loss)
I0302 07:59:38.226006 29253 sgd_solver.cpp:106] Iteration 16180, lr = 0.001
I0302 08:00:07.157826 29253 solver.cpp:237] Iteration 16200, loss = 0.00175972
I0302 08:00:07.157858 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00175972 (* 1 = 0.00175972 loss)
I0302 08:00:07.157868 29253 sgd_solver.cpp:106] Iteration 16200, lr = 0.001
I0302 08:00:36.161576 29253 solver.cpp:237] Iteration 16220, loss = 0.00179443
I0302 08:00:36.161607 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00179443 (* 1 = 0.00179443 loss)
I0302 08:00:36.161617 29253 sgd_solver.cpp:106] Iteration 16220, lr = 0.001
I0302 08:01:04.806463 29253 solver.cpp:237] Iteration 16240, loss = 0.00173542
I0302 08:01:04.806495 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00173542 (* 1 = 0.00173542 loss)
I0302 08:01:04.806505 29253 sgd_solver.cpp:106] Iteration 16240, lr = 0.001
I0302 08:01:33.712494 29253 solver.cpp:237] Iteration 16260, loss = 0.00169548
I0302 08:01:33.712527 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00169548 (* 1 = 0.00169548 loss)
I0302 08:01:33.712538 29253 sgd_solver.cpp:106] Iteration 16260, lr = 0.001
I0302 08:02:02.590221 29253 solver.cpp:237] Iteration 16280, loss = 0.00154488
I0302 08:02:02.590253 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00154489 (* 1 = 0.00154489 loss)
I0302 08:02:02.590262 29253 sgd_solver.cpp:106] Iteration 16280, lr = 0.001
I0302 08:02:31.450809 29253 solver.cpp:237] Iteration 16300, loss = 0.001564
I0302 08:02:31.450842 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00156401 (* 1 = 0.00156401 loss)
I0302 08:02:31.450851 29253 sgd_solver.cpp:106] Iteration 16300, lr = 0.001
I0302 08:03:00.220618 29253 solver.cpp:237] Iteration 16320, loss = 0.00136352
I0302 08:03:00.220650 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00136352 (* 1 = 0.00136352 loss)
I0302 08:03:00.220659 29253 sgd_solver.cpp:106] Iteration 16320, lr = 0.001
I0302 08:03:29.256676 29253 solver.cpp:237] Iteration 16340, loss = 0.00196714
I0302 08:03:29.256710 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00196715 (* 1 = 0.00196715 loss)
I0302 08:03:29.256718 29253 sgd_solver.cpp:106] Iteration 16340, lr = 0.001
I0302 08:03:58.201010 29253 solver.cpp:237] Iteration 16360, loss = 0.00170606
I0302 08:03:58.201042 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00170606 (* 1 = 0.00170606 loss)
I0302 08:03:58.201051 29253 sgd_solver.cpp:106] Iteration 16360, lr = 0.001
I0302 08:04:26.954553 29253 solver.cpp:237] Iteration 16380, loss = 0.00149456
I0302 08:04:26.954586 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00149457 (* 1 = 0.00149457 loss)
I0302 08:04:26.954596 29253 sgd_solver.cpp:106] Iteration 16380, lr = 0.001
I0302 08:04:55.840397 29253 solver.cpp:237] Iteration 16400, loss = 0.0013677
I0302 08:04:55.840431 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0013677 (* 1 = 0.0013677 loss)
I0302 08:04:55.840441 29253 sgd_solver.cpp:106] Iteration 16400, lr = 0.001
I0302 08:05:24.615053 29253 solver.cpp:237] Iteration 16420, loss = 0.00190911
I0302 08:05:24.615087 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00190912 (* 1 = 0.00190912 loss)
I0302 08:05:24.615097 29253 sgd_solver.cpp:106] Iteration 16420, lr = 0.001
I0302 08:05:53.676386 29253 solver.cpp:237] Iteration 16440, loss = 0.00196937
I0302 08:05:53.676419 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00196938 (* 1 = 0.00196938 loss)
I0302 08:05:53.676429 29253 sgd_solver.cpp:106] Iteration 16440, lr = 0.001
I0302 08:06:22.667140 29253 solver.cpp:237] Iteration 16460, loss = 0.00196513
I0302 08:06:22.667173 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00196513 (* 1 = 0.00196513 loss)
I0302 08:06:22.667183 29253 sgd_solver.cpp:106] Iteration 16460, lr = 0.001
I0302 08:06:51.691231 29253 solver.cpp:237] Iteration 16480, loss = 0.00177308
I0302 08:06:51.691262 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00177308 (* 1 = 0.00177308 loss)
I0302 08:06:51.691272 29253 sgd_solver.cpp:106] Iteration 16480, lr = 0.001
I0302 08:07:20.524525 29253 solver.cpp:237] Iteration 16500, loss = 0.00197188
I0302 08:07:20.524556 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00197189 (* 1 = 0.00197189 loss)
I0302 08:07:20.524565 29253 sgd_solver.cpp:106] Iteration 16500, lr = 0.001
I0302 08:07:49.440065 29253 solver.cpp:237] Iteration 16520, loss = 0.00130119
I0302 08:07:49.440098 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00130119 (* 1 = 0.00130119 loss)
I0302 08:07:49.440106 29253 sgd_solver.cpp:106] Iteration 16520, lr = 0.001
I0302 08:08:18.397086 29253 solver.cpp:237] Iteration 16540, loss = 0.00173073
I0302 08:08:18.397119 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00173074 (* 1 = 0.00173074 loss)
I0302 08:08:18.397128 29253 sgd_solver.cpp:106] Iteration 16540, lr = 0.001
I0302 08:08:47.883898 29253 solver.cpp:237] Iteration 16560, loss = 0.00186685
I0302 08:08:47.883929 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00186685 (* 1 = 0.00186685 loss)
I0302 08:08:47.883939 29253 sgd_solver.cpp:106] Iteration 16560, lr = 0.001
I0302 08:09:16.611956 29253 solver.cpp:237] Iteration 16580, loss = 0.0014967
I0302 08:09:16.611989 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0014967 (* 1 = 0.0014967 loss)
I0302 08:09:16.611999 29253 sgd_solver.cpp:106] Iteration 16580, lr = 0.001
I0302 08:09:45.264551 29253 solver.cpp:237] Iteration 16600, loss = 0.00175004
I0302 08:09:45.264585 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00175004 (* 1 = 0.00175004 loss)
I0302 08:09:45.264593 29253 sgd_solver.cpp:106] Iteration 16600, lr = 0.001
I0302 08:10:14.250134 29253 solver.cpp:237] Iteration 16620, loss = 0.00126431
I0302 08:10:14.250169 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00126431 (* 1 = 0.00126431 loss)
I0302 08:10:14.250177 29253 sgd_solver.cpp:106] Iteration 16620, lr = 0.001
I0302 08:10:43.545398 29253 solver.cpp:237] Iteration 16640, loss = 0.00164695
I0302 08:10:43.545428 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00164696 (* 1 = 0.00164696 loss)
I0302 08:10:43.545438 29253 sgd_solver.cpp:106] Iteration 16640, lr = 0.001
I0302 08:11:12.620538 29253 solver.cpp:237] Iteration 16660, loss = 0.00249174
I0302 08:11:12.620570 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00249175 (* 1 = 0.00249175 loss)
I0302 08:11:12.620579 29253 sgd_solver.cpp:106] Iteration 16660, lr = 0.001
I0302 08:11:41.459930 29253 solver.cpp:237] Iteration 16680, loss = 0.00159935
I0302 08:11:41.459964 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00159936 (* 1 = 0.00159936 loss)
I0302 08:11:41.459972 29253 sgd_solver.cpp:106] Iteration 16680, lr = 0.001
I0302 08:12:10.411790 29253 solver.cpp:237] Iteration 16700, loss = 0.00190788
I0302 08:12:10.411824 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00190788 (* 1 = 0.00190788 loss)
I0302 08:12:10.411834 29253 sgd_solver.cpp:106] Iteration 16700, lr = 0.001
I0302 08:12:38.986261 29253 solver.cpp:237] Iteration 16720, loss = 0.00186131
I0302 08:12:38.986294 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00186131 (* 1 = 0.00186131 loss)
I0302 08:12:38.986302 29253 sgd_solver.cpp:106] Iteration 16720, lr = 0.001
I0302 08:13:07.991228 29253 solver.cpp:237] Iteration 16740, loss = 0.00176891
I0302 08:13:07.991261 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00176892 (* 1 = 0.00176892 loss)
I0302 08:13:07.991271 29253 sgd_solver.cpp:106] Iteration 16740, lr = 0.001
I0302 08:13:36.735855 29253 solver.cpp:237] Iteration 16760, loss = 0.00225746
I0302 08:13:36.735887 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00225747 (* 1 = 0.00225747 loss)
I0302 08:13:36.735895 29253 sgd_solver.cpp:106] Iteration 16760, lr = 0.001
I0302 08:14:05.781688 29253 solver.cpp:237] Iteration 16780, loss = 0.00170595
I0302 08:14:05.781720 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00170595 (* 1 = 0.00170595 loss)
I0302 08:14:05.781729 29253 sgd_solver.cpp:106] Iteration 16780, lr = 0.001
I0302 08:14:34.685318 29253 solver.cpp:237] Iteration 16800, loss = 0.0016348
I0302 08:14:34.685350 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0016348 (* 1 = 0.0016348 loss)
I0302 08:14:34.685359 29253 sgd_solver.cpp:106] Iteration 16800, lr = 0.001
I0302 08:15:03.532032 29253 solver.cpp:237] Iteration 16820, loss = 0.00173104
I0302 08:15:03.532063 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00173104 (* 1 = 0.00173104 loss)
I0302 08:15:03.532073 29253 sgd_solver.cpp:106] Iteration 16820, lr = 0.001
I0302 08:15:32.929242 29253 solver.cpp:237] Iteration 16840, loss = 0.00141186
I0302 08:15:32.929275 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00141187 (* 1 = 0.00141187 loss)
I0302 08:15:32.929283 29253 sgd_solver.cpp:106] Iteration 16840, lr = 0.001
I0302 08:16:01.726339 29253 solver.cpp:237] Iteration 16860, loss = 0.00134798
I0302 08:16:01.726373 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00134799 (* 1 = 0.00134799 loss)
I0302 08:16:01.726382 29253 sgd_solver.cpp:106] Iteration 16860, lr = 0.001
I0302 08:16:30.546421 29253 solver.cpp:237] Iteration 16880, loss = 0.00168235
I0302 08:16:30.546452 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00168235 (* 1 = 0.00168235 loss)
I0302 08:16:30.546461 29253 sgd_solver.cpp:106] Iteration 16880, lr = 0.001
I0302 08:16:59.403086 29253 solver.cpp:237] Iteration 16900, loss = 0.00165339
I0302 08:16:59.403120 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0016534 (* 1 = 0.0016534 loss)
I0302 08:16:59.403128 29253 sgd_solver.cpp:106] Iteration 16900, lr = 0.001
I0302 08:17:28.302000 29253 solver.cpp:237] Iteration 16920, loss = 0.00165574
I0302 08:17:28.302033 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00165574 (* 1 = 0.00165574 loss)
I0302 08:17:28.302042 29253 sgd_solver.cpp:106] Iteration 16920, lr = 0.001
I0302 08:17:57.244089 29253 solver.cpp:237] Iteration 16940, loss = 0.00168714
I0302 08:17:57.244120 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00168715 (* 1 = 0.00168715 loss)
I0302 08:17:57.244129 29253 sgd_solver.cpp:106] Iteration 16940, lr = 0.001
I0302 08:18:26.137689 29253 solver.cpp:237] Iteration 16960, loss = 0.0016072
I0302 08:18:26.137722 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00160721 (* 1 = 0.00160721 loss)
I0302 08:18:26.137729 29253 sgd_solver.cpp:106] Iteration 16960, lr = 0.001
I0302 08:18:55.051690 29253 solver.cpp:237] Iteration 16980, loss = 0.00178723
I0302 08:18:55.051723 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00178724 (* 1 = 0.00178724 loss)
I0302 08:18:55.051731 29253 sgd_solver.cpp:106] Iteration 16980, lr = 0.001
I0302 08:19:23.918545 29253 solver.cpp:237] Iteration 17000, loss = 0.00180467
I0302 08:19:23.918578 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00180467 (* 1 = 0.00180467 loss)
I0302 08:19:23.918586 29253 sgd_solver.cpp:106] Iteration 17000, lr = 0.001
I0302 08:19:33.905551 29253 blocking_queue.cpp:50] Data layer prefetch queue empty
I0302 08:19:52.676901 29253 solver.cpp:237] Iteration 17020, loss = 0.00143453
I0302 08:19:52.676933 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00143454 (* 1 = 0.00143454 loss)
I0302 08:19:52.676941 29253 sgd_solver.cpp:106] Iteration 17020, lr = 0.001
I0302 08:20:21.755563 29253 solver.cpp:237] Iteration 17040, loss = 0.00131333
I0302 08:20:21.755594 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00131334 (* 1 = 0.00131334 loss)
I0302 08:20:21.755602 29253 sgd_solver.cpp:106] Iteration 17040, lr = 0.001
I0302 08:20:50.653821 29253 solver.cpp:237] Iteration 17060, loss = 0.00155271
I0302 08:20:50.653856 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00155272 (* 1 = 0.00155272 loss)
I0302 08:20:50.653863 29253 sgd_solver.cpp:106] Iteration 17060, lr = 0.001
I0302 08:21:19.595875 29253 solver.cpp:237] Iteration 17080, loss = 0.00172485
I0302 08:21:19.595906 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00172485 (* 1 = 0.00172485 loss)
I0302 08:21:19.595914 29253 sgd_solver.cpp:106] Iteration 17080, lr = 0.001
I0302 08:21:48.319376 29253 solver.cpp:237] Iteration 17100, loss = 0.00172183
I0302 08:21:48.319407 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00172183 (* 1 = 0.00172183 loss)
I0302 08:21:48.319416 29253 sgd_solver.cpp:106] Iteration 17100, lr = 0.001
I0302 08:22:17.276144 29253 solver.cpp:237] Iteration 17120, loss = 0.0015016
I0302 08:22:17.276175 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0015016 (* 1 = 0.0015016 loss)
I0302 08:22:17.276183 29253 sgd_solver.cpp:106] Iteration 17120, lr = 0.001
I0302 08:22:46.262353 29253 solver.cpp:237] Iteration 17140, loss = 0.00135027
I0302 08:22:46.262389 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00135027 (* 1 = 0.00135027 loss)
I0302 08:22:46.262398 29253 sgd_solver.cpp:106] Iteration 17140, lr = 0.001
I0302 08:23:15.170955 29253 solver.cpp:237] Iteration 17160, loss = 0.0016376
I0302 08:23:15.170989 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0016376 (* 1 = 0.0016376 loss)
I0302 08:23:15.170999 29253 sgd_solver.cpp:106] Iteration 17160, lr = 0.001
I0302 08:23:43.986984 29253 solver.cpp:237] Iteration 17180, loss = 0.00158129
I0302 08:23:43.987015 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00158129 (* 1 = 0.00158129 loss)
I0302 08:23:43.987023 29253 sgd_solver.cpp:106] Iteration 17180, lr = 0.001
I0302 08:24:12.918123 29253 solver.cpp:237] Iteration 17200, loss = 0.00187287
I0302 08:24:12.918154 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00187287 (* 1 = 0.00187287 loss)
I0302 08:24:12.918164 29253 sgd_solver.cpp:106] Iteration 17200, lr = 0.001
I0302 08:24:41.875072 29253 solver.cpp:237] Iteration 17220, loss = 0.00169677
I0302 08:24:41.875105 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00169677 (* 1 = 0.00169677 loss)
I0302 08:24:41.875114 29253 sgd_solver.cpp:106] Iteration 17220, lr = 0.001
I0302 08:25:10.886373 29253 solver.cpp:237] Iteration 17240, loss = 0.00135288
I0302 08:25:10.886404 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00135288 (* 1 = 0.00135288 loss)
I0302 08:25:10.886412 29253 sgd_solver.cpp:106] Iteration 17240, lr = 0.001
I0302 08:25:39.693608 29253 solver.cpp:237] Iteration 17260, loss = 0.00163834
I0302 08:25:39.693640 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00163834 (* 1 = 0.00163834 loss)
I0302 08:25:39.693650 29253 sgd_solver.cpp:106] Iteration 17260, lr = 0.001
I0302 08:26:08.668743 29253 solver.cpp:237] Iteration 17280, loss = 0.00162978
I0302 08:26:08.668774 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00162979 (* 1 = 0.00162979 loss)
I0302 08:26:08.668783 29253 sgd_solver.cpp:106] Iteration 17280, lr = 0.001
I0302 08:26:37.373072 29253 solver.cpp:237] Iteration 17300, loss = 0.00181891
I0302 08:26:37.373106 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00181892 (* 1 = 0.00181892 loss)
I0302 08:26:37.373113 29253 sgd_solver.cpp:106] Iteration 17300, lr = 0.001
I0302 08:27:06.454152 29253 solver.cpp:237] Iteration 17320, loss = 0.0018411
I0302 08:27:06.454185 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00184111 (* 1 = 0.00184111 loss)
I0302 08:27:06.454193 29253 sgd_solver.cpp:106] Iteration 17320, lr = 0.001
I0302 08:27:35.259882 29253 solver.cpp:237] Iteration 17340, loss = 0.001697
I0302 08:27:35.259914 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00169701 (* 1 = 0.00169701 loss)
I0302 08:27:35.259923 29253 sgd_solver.cpp:106] Iteration 17340, lr = 0.001
I0302 08:28:04.252655 29253 solver.cpp:237] Iteration 17360, loss = 0.00121661
I0302 08:28:04.252687 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00121661 (* 1 = 0.00121661 loss)
I0302 08:28:04.252696 29253 sgd_solver.cpp:106] Iteration 17360, lr = 0.001
I0302 08:28:33.303256 29253 solver.cpp:237] Iteration 17380, loss = 0.0016809
I0302 08:28:33.303289 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0016809 (* 1 = 0.0016809 loss)
I0302 08:28:33.303297 29253 sgd_solver.cpp:106] Iteration 17380, lr = 0.001
I0302 08:29:02.213495 29253 solver.cpp:237] Iteration 17400, loss = 0.00218026
I0302 08:29:02.213527 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00218027 (* 1 = 0.00218027 loss)
I0302 08:29:02.213536 29253 sgd_solver.cpp:106] Iteration 17400, lr = 0.001
I0302 08:29:31.332168 29253 solver.cpp:237] Iteration 17420, loss = 0.00186187
I0302 08:29:31.332201 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00186187 (* 1 = 0.00186187 loss)
I0302 08:29:31.332211 29253 sgd_solver.cpp:106] Iteration 17420, lr = 0.001
I0302 08:30:00.254142 29253 solver.cpp:237] Iteration 17440, loss = 0.00160849
I0302 08:30:00.254174 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00160849 (* 1 = 0.00160849 loss)
I0302 08:30:00.254184 29253 sgd_solver.cpp:106] Iteration 17440, lr = 0.001
I0302 08:30:29.218310 29253 solver.cpp:237] Iteration 17460, loss = 0.00178163
I0302 08:30:29.218341 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00178163 (* 1 = 0.00178163 loss)
I0302 08:30:29.218351 29253 sgd_solver.cpp:106] Iteration 17460, lr = 0.001
I0302 08:30:58.001245 29253 solver.cpp:237] Iteration 17480, loss = 0.00171035
I0302 08:30:58.001276 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00171036 (* 1 = 0.00171036 loss)
I0302 08:30:58.001284 29253 sgd_solver.cpp:106] Iteration 17480, lr = 0.001
I0302 08:31:26.886091 29253 solver.cpp:237] Iteration 17500, loss = 0.00158712
I0302 08:31:26.886122 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00158713 (* 1 = 0.00158713 loss)
I0302 08:31:26.886132 29253 sgd_solver.cpp:106] Iteration 17500, lr = 0.001
I0302 08:31:55.840668 29253 solver.cpp:237] Iteration 17520, loss = 0.00180997
I0302 08:31:55.840700 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00180997 (* 1 = 0.00180997 loss)
I0302 08:31:55.840709 29253 sgd_solver.cpp:106] Iteration 17520, lr = 0.001
I0302 08:32:24.732266 29253 solver.cpp:237] Iteration 17540, loss = 0.00159875
I0302 08:32:24.732297 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00159875 (* 1 = 0.00159875 loss)
I0302 08:32:24.732306 29253 sgd_solver.cpp:106] Iteration 17540, lr = 0.001
I0302 08:32:53.609797 29253 solver.cpp:237] Iteration 17560, loss = 0.00153009
I0302 08:32:53.609827 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00153009 (* 1 = 0.00153009 loss)
I0302 08:32:53.609838 29253 sgd_solver.cpp:106] Iteration 17560, lr = 0.001
I0302 08:33:22.524538 29253 solver.cpp:237] Iteration 17580, loss = 0.00179002
I0302 08:33:22.524569 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00179003 (* 1 = 0.00179003 loss)
I0302 08:33:22.524577 29253 sgd_solver.cpp:106] Iteration 17580, lr = 0.001
I0302 08:33:51.573982 29253 solver.cpp:237] Iteration 17600, loss = 0.00151444
I0302 08:33:51.574015 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00151444 (* 1 = 0.00151444 loss)
I0302 08:33:51.574024 29253 sgd_solver.cpp:106] Iteration 17600, lr = 0.001
I0302 08:34:20.902143 29253 solver.cpp:237] Iteration 17620, loss = 0.00157501
I0302 08:34:20.902175 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00157502 (* 1 = 0.00157502 loss)
I0302 08:34:20.902184 29253 sgd_solver.cpp:106] Iteration 17620, lr = 0.001
I0302 08:34:49.361749 29253 solver.cpp:237] Iteration 17640, loss = 0.0013643
I0302 08:34:49.361781 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0013643 (* 1 = 0.0013643 loss)
I0302 08:34:49.361791 29253 sgd_solver.cpp:106] Iteration 17640, lr = 0.001
I0302 08:35:18.465446 29253 solver.cpp:237] Iteration 17660, loss = 0.00163829
I0302 08:35:18.465478 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00163829 (* 1 = 0.00163829 loss)
I0302 08:35:18.465487 29253 sgd_solver.cpp:106] Iteration 17660, lr = 0.001
I0302 08:35:47.426570 29253 solver.cpp:237] Iteration 17680, loss = 0.00208541
I0302 08:35:47.426601 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00208541 (* 1 = 0.00208541 loss)
I0302 08:35:47.426610 29253 sgd_solver.cpp:106] Iteration 17680, lr = 0.001
I0302 08:36:16.522048 29253 solver.cpp:237] Iteration 17700, loss = 0.00159136
I0302 08:36:16.522079 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00159137 (* 1 = 0.00159137 loss)
I0302 08:36:16.522088 29253 sgd_solver.cpp:106] Iteration 17700, lr = 0.001
I0302 08:36:45.307919 29253 solver.cpp:237] Iteration 17720, loss = 0.00172637
I0302 08:36:45.307951 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00172638 (* 1 = 0.00172638 loss)
I0302 08:36:45.307960 29253 sgd_solver.cpp:106] Iteration 17720, lr = 0.001
I0302 08:37:14.264299 29253 solver.cpp:237] Iteration 17740, loss = 0.00173615
I0302 08:37:14.264329 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00173615 (* 1 = 0.00173615 loss)
I0302 08:37:14.264338 29253 sgd_solver.cpp:106] Iteration 17740, lr = 0.001
I0302 08:37:43.085243 29253 solver.cpp:237] Iteration 17760, loss = 0.00156278
I0302 08:37:43.085275 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00156278 (* 1 = 0.00156278 loss)
I0302 08:37:43.085284 29253 sgd_solver.cpp:106] Iteration 17760, lr = 0.001
I0302 08:38:12.029928 29253 solver.cpp:237] Iteration 17780, loss = 0.00159464
I0302 08:38:12.029959 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00159465 (* 1 = 0.00159465 loss)
I0302 08:38:12.029968 29253 sgd_solver.cpp:106] Iteration 17780, lr = 0.001
I0302 08:38:41.240878 29253 solver.cpp:237] Iteration 17800, loss = 0.0023071
I0302 08:38:41.240911 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00230711 (* 1 = 0.00230711 loss)
I0302 08:38:41.240921 29253 sgd_solver.cpp:106] Iteration 17800, lr = 0.001
I0302 08:39:09.972158 29253 solver.cpp:237] Iteration 17820, loss = 0.00157805
I0302 08:39:09.972192 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00157805 (* 1 = 0.00157805 loss)
I0302 08:39:09.972200 29253 sgd_solver.cpp:106] Iteration 17820, lr = 0.001
I0302 08:39:38.498926 29253 solver.cpp:237] Iteration 17840, loss = 0.0022513
I0302 08:39:38.498958 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00225131 (* 1 = 0.00225131 loss)
I0302 08:39:38.498967 29253 sgd_solver.cpp:106] Iteration 17840, lr = 0.001
I0302 08:40:07.459337 29253 solver.cpp:237] Iteration 17860, loss = 0.0014929
I0302 08:40:07.459368 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00149291 (* 1 = 0.00149291 loss)
I0302 08:40:07.459378 29253 sgd_solver.cpp:106] Iteration 17860, lr = 0.001
I0302 08:40:36.370009 29253 solver.cpp:237] Iteration 17880, loss = 0.00143267
I0302 08:40:36.370043 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00143268 (* 1 = 0.00143268 loss)
I0302 08:40:36.370051 29253 sgd_solver.cpp:106] Iteration 17880, lr = 0.001
I0302 08:41:05.536944 29253 solver.cpp:237] Iteration 17900, loss = 0.00176597
I0302 08:41:05.536978 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00176598 (* 1 = 0.00176598 loss)
I0302 08:41:05.536985 29253 sgd_solver.cpp:106] Iteration 17900, lr = 0.001
I0302 08:41:34.359864 29253 solver.cpp:237] Iteration 17920, loss = 0.00196559
I0302 08:41:34.359897 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0019656 (* 1 = 0.0019656 loss)
I0302 08:41:34.359906 29253 sgd_solver.cpp:106] Iteration 17920, lr = 0.001
I0302 08:42:03.235473 29253 solver.cpp:237] Iteration 17940, loss = 0.00151722
I0302 08:42:03.235504 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00151722 (* 1 = 0.00151722 loss)
I0302 08:42:03.235513 29253 sgd_solver.cpp:106] Iteration 17940, lr = 0.001
I0302 08:42:32.193408 29253 solver.cpp:237] Iteration 17960, loss = 0.00134428
I0302 08:42:32.193442 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00134428 (* 1 = 0.00134428 loss)
I0302 08:42:32.193451 29253 sgd_solver.cpp:106] Iteration 17960, lr = 0.001
I0302 08:43:00.792814 29253 solver.cpp:237] Iteration 17980, loss = 0.00146551
I0302 08:43:00.792845 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00146552 (* 1 = 0.00146552 loss)
I0302 08:43:00.792855 29253 sgd_solver.cpp:106] Iteration 17980, lr = 0.001
I0302 08:43:29.681627 29253 solver.cpp:237] Iteration 18000, loss = 0.00183943
I0302 08:43:29.681660 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00183944 (* 1 = 0.00183944 loss)
I0302 08:43:29.681669 29253 sgd_solver.cpp:106] Iteration 18000, lr = 0.001
I0302 08:43:39.847204 29253 blocking_queue.cpp:50] Data layer prefetch queue empty
I0302 08:43:58.829442 29253 solver.cpp:237] Iteration 18020, loss = 0.00180507
I0302 08:43:58.829478 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00180508 (* 1 = 0.00180508 loss)
I0302 08:43:58.829488 29253 sgd_solver.cpp:106] Iteration 18020, lr = 0.001
I0302 08:44:27.703251 29253 solver.cpp:237] Iteration 18040, loss = 0.0014596
I0302 08:44:27.703284 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00145961 (* 1 = 0.00145961 loss)
I0302 08:44:27.703294 29253 sgd_solver.cpp:106] Iteration 18040, lr = 0.001
I0302 08:44:56.671699 29253 solver.cpp:237] Iteration 18060, loss = 0.0013381
I0302 08:44:56.671731 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00133811 (* 1 = 0.00133811 loss)
I0302 08:44:56.671741 29253 sgd_solver.cpp:106] Iteration 18060, lr = 0.001
I0302 08:45:25.663918 29253 solver.cpp:237] Iteration 18080, loss = 0.00225553
I0302 08:45:25.663949 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00225553 (* 1 = 0.00225553 loss)
I0302 08:45:25.663959 29253 sgd_solver.cpp:106] Iteration 18080, lr = 0.001
I0302 08:45:54.308156 29253 solver.cpp:237] Iteration 18100, loss = 0.00155996
I0302 08:45:54.308187 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00155997 (* 1 = 0.00155997 loss)
I0302 08:45:54.308197 29253 sgd_solver.cpp:106] Iteration 18100, lr = 0.001
I0302 08:46:23.127854 29253 solver.cpp:237] Iteration 18120, loss = 0.00153283
I0302 08:46:23.127887 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00153283 (* 1 = 0.00153283 loss)
I0302 08:46:23.127897 29253 sgd_solver.cpp:106] Iteration 18120, lr = 0.001
I0302 08:46:52.018010 29253 solver.cpp:237] Iteration 18140, loss = 0.00155879
I0302 08:46:52.018043 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00155879 (* 1 = 0.00155879 loss)
I0302 08:46:52.018051 29253 sgd_solver.cpp:106] Iteration 18140, lr = 0.001
I0302 08:47:20.746247 29253 solver.cpp:237] Iteration 18160, loss = 0.0015891
I0302 08:47:20.746279 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0015891 (* 1 = 0.0015891 loss)
I0302 08:47:20.746289 29253 sgd_solver.cpp:106] Iteration 18160, lr = 0.001
I0302 08:47:49.720607 29253 solver.cpp:237] Iteration 18180, loss = 0.00178865
I0302 08:47:49.720638 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00178865 (* 1 = 0.00178865 loss)
I0302 08:47:49.720646 29253 sgd_solver.cpp:106] Iteration 18180, lr = 0.001
I0302 08:48:18.469338 29253 solver.cpp:237] Iteration 18200, loss = 0.00169241
I0302 08:48:18.469372 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00169241 (* 1 = 0.00169241 loss)
I0302 08:48:18.469380 29253 sgd_solver.cpp:106] Iteration 18200, lr = 0.001
I0302 08:48:47.309650 29253 solver.cpp:237] Iteration 18220, loss = 0.00145668
I0302 08:48:47.309684 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00145668 (* 1 = 0.00145668 loss)
I0302 08:48:47.309692 29253 sgd_solver.cpp:106] Iteration 18220, lr = 0.001
I0302 08:49:16.287750 29253 solver.cpp:237] Iteration 18240, loss = 0.00166231
I0302 08:49:16.287782 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00166231 (* 1 = 0.00166231 loss)
I0302 08:49:16.287792 29253 sgd_solver.cpp:106] Iteration 18240, lr = 0.001
I0302 08:49:45.137020 29253 solver.cpp:237] Iteration 18260, loss = 0.00163309
I0302 08:49:45.137053 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00163309 (* 1 = 0.00163309 loss)
I0302 08:49:45.137063 29253 sgd_solver.cpp:106] Iteration 18260, lr = 0.001
I0302 08:50:14.029508 29253 solver.cpp:237] Iteration 18280, loss = 0.00175292
I0302 08:50:14.029542 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00175292 (* 1 = 0.00175292 loss)
I0302 08:50:14.029551 29253 sgd_solver.cpp:106] Iteration 18280, lr = 0.001
I0302 08:50:43.141226 29253 solver.cpp:237] Iteration 18300, loss = 0.00187946
I0302 08:50:43.141258 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00187946 (* 1 = 0.00187946 loss)
I0302 08:50:43.141266 29253 sgd_solver.cpp:106] Iteration 18300, lr = 0.001
I0302 08:51:12.126513 29253 solver.cpp:237] Iteration 18320, loss = 0.00155729
I0302 08:51:12.126544 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0015573 (* 1 = 0.0015573 loss)
I0302 08:51:12.126554 29253 sgd_solver.cpp:106] Iteration 18320, lr = 0.001
I0302 08:51:41.009037 29253 solver.cpp:237] Iteration 18340, loss = 0.00162402
I0302 08:51:41.009068 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00162403 (* 1 = 0.00162403 loss)
I0302 08:51:41.009078 29253 sgd_solver.cpp:106] Iteration 18340, lr = 0.001
I0302 08:52:10.018961 29253 solver.cpp:237] Iteration 18360, loss = 0.00141018
I0302 08:52:10.018995 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00141019 (* 1 = 0.00141019 loss)
I0302 08:52:10.019003 29253 sgd_solver.cpp:106] Iteration 18360, lr = 0.001
I0302 08:52:38.756573 29253 solver.cpp:237] Iteration 18380, loss = 0.00150659
I0302 08:52:38.756606 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00150659 (* 1 = 0.00150659 loss)
I0302 08:52:38.756614 29253 sgd_solver.cpp:106] Iteration 18380, lr = 0.001
I0302 08:53:07.639415 29253 solver.cpp:237] Iteration 18400, loss = 0.00167861
I0302 08:53:07.639448 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00167861 (* 1 = 0.00167861 loss)
I0302 08:53:07.639456 29253 sgd_solver.cpp:106] Iteration 18400, lr = 0.001
I0302 08:53:36.650578 29253 solver.cpp:237] Iteration 18420, loss = 0.00148314
I0302 08:53:36.650610 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00148314 (* 1 = 0.00148314 loss)
I0302 08:53:36.650619 29253 sgd_solver.cpp:106] Iteration 18420, lr = 0.001
I0302 08:54:05.652004 29253 solver.cpp:237] Iteration 18440, loss = 0.00142458
I0302 08:54:05.652036 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00142458 (* 1 = 0.00142458 loss)
I0302 08:54:05.652045 29253 sgd_solver.cpp:106] Iteration 18440, lr = 0.001
I0302 08:54:34.506984 29253 solver.cpp:237] Iteration 18460, loss = 0.0014989
I0302 08:54:34.507016 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0014989 (* 1 = 0.0014989 loss)
I0302 08:54:34.507025 29253 sgd_solver.cpp:106] Iteration 18460, lr = 0.001
I0302 08:55:03.359037 29253 solver.cpp:237] Iteration 18480, loss = 0.00229775
I0302 08:55:03.359068 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00229776 (* 1 = 0.00229776 loss)
I0302 08:55:03.359077 29253 sgd_solver.cpp:106] Iteration 18480, lr = 0.001
I0302 08:55:32.280822 29253 solver.cpp:237] Iteration 18500, loss = 0.00171239
I0302 08:55:32.280854 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00171239 (* 1 = 0.00171239 loss)
I0302 08:55:32.280864 29253 sgd_solver.cpp:106] Iteration 18500, lr = 0.001
I0302 08:56:01.259644 29253 solver.cpp:237] Iteration 18520, loss = 0.00155288
I0302 08:56:01.259676 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00155289 (* 1 = 0.00155289 loss)
I0302 08:56:01.259685 29253 sgd_solver.cpp:106] Iteration 18520, lr = 0.001
I0302 08:56:30.023560 29253 solver.cpp:237] Iteration 18540, loss = 0.00155981
I0302 08:56:30.023591 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00155981 (* 1 = 0.00155981 loss)
I0302 08:56:30.023599 29253 sgd_solver.cpp:106] Iteration 18540, lr = 0.001
I0302 08:56:59.014842 29253 solver.cpp:237] Iteration 18560, loss = 0.00160633
I0302 08:56:59.014873 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00160633 (* 1 = 0.00160633 loss)
I0302 08:56:59.014883 29253 sgd_solver.cpp:106] Iteration 18560, lr = 0.001
I0302 08:57:27.938024 29253 solver.cpp:237] Iteration 18580, loss = 0.00154074
I0302 08:57:27.938057 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00154074 (* 1 = 0.00154074 loss)
I0302 08:57:27.938066 29253 sgd_solver.cpp:106] Iteration 18580, lr = 0.001
I0302 08:57:56.551965 29253 solver.cpp:237] Iteration 18600, loss = 0.00217712
I0302 08:57:56.551997 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00217712 (* 1 = 0.00217712 loss)
I0302 08:57:56.552006 29253 sgd_solver.cpp:106] Iteration 18600, lr = 0.001
I0302 08:58:25.463291 29253 solver.cpp:237] Iteration 18620, loss = 0.00182832
I0302 08:58:25.463322 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00182832 (* 1 = 0.00182832 loss)
I0302 08:58:25.463331 29253 sgd_solver.cpp:106] Iteration 18620, lr = 0.001
I0302 08:58:54.448720 29253 solver.cpp:237] Iteration 18640, loss = 0.00162921
I0302 08:58:54.448751 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00162921 (* 1 = 0.00162921 loss)
I0302 08:58:54.448760 29253 sgd_solver.cpp:106] Iteration 18640, lr = 0.001
I0302 08:59:23.226701 29253 solver.cpp:237] Iteration 18660, loss = 0.00138193
I0302 08:59:23.226732 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00138193 (* 1 = 0.00138193 loss)
I0302 08:59:23.226742 29253 sgd_solver.cpp:106] Iteration 18660, lr = 0.001
I0302 08:59:52.071882 29253 solver.cpp:237] Iteration 18680, loss = 0.00153928
I0302 08:59:52.071915 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00153929 (* 1 = 0.00153929 loss)
I0302 08:59:52.071924 29253 sgd_solver.cpp:106] Iteration 18680, lr = 0.001
I0302 09:00:21.104001 29253 solver.cpp:237] Iteration 18700, loss = 0.00182124
I0302 09:00:21.104033 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00182124 (* 1 = 0.00182124 loss)
I0302 09:00:21.104043 29253 sgd_solver.cpp:106] Iteration 18700, lr = 0.001
I0302 09:00:49.834785 29253 solver.cpp:237] Iteration 18720, loss = 0.00144276
I0302 09:00:49.834815 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00144276 (* 1 = 0.00144276 loss)
I0302 09:00:49.834825 29253 sgd_solver.cpp:106] Iteration 18720, lr = 0.001
I0302 09:01:18.887014 29253 solver.cpp:237] Iteration 18740, loss = 0.00191531
I0302 09:01:18.887045 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00191531 (* 1 = 0.00191531 loss)
I0302 09:01:18.887054 29253 sgd_solver.cpp:106] Iteration 18740, lr = 0.001
I0302 09:01:47.975661 29253 solver.cpp:237] Iteration 18760, loss = 0.00140661
I0302 09:01:47.975693 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00140661 (* 1 = 0.00140661 loss)
I0302 09:01:47.975703 29253 sgd_solver.cpp:106] Iteration 18760, lr = 0.001
I0302 09:02:16.635447 29253 solver.cpp:237] Iteration 18780, loss = 0.00148476
I0302 09:02:16.635478 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00148476 (* 1 = 0.00148476 loss)
I0302 09:02:16.635488 29253 sgd_solver.cpp:106] Iteration 18780, lr = 0.001
I0302 09:02:45.469027 29253 solver.cpp:237] Iteration 18800, loss = 0.00260169
I0302 09:02:45.469059 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00260169 (* 1 = 0.00260169 loss)
I0302 09:02:45.469068 29253 sgd_solver.cpp:106] Iteration 18800, lr = 0.001
I0302 09:03:14.869191 29253 solver.cpp:237] Iteration 18820, loss = 0.00151654
I0302 09:03:14.869222 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00151654 (* 1 = 0.00151654 loss)
I0302 09:03:14.869231 29253 sgd_solver.cpp:106] Iteration 18820, lr = 0.001
I0302 09:03:43.379854 29253 solver.cpp:237] Iteration 18840, loss = 0.00189074
I0302 09:03:43.379886 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00189074 (* 1 = 0.00189074 loss)
I0302 09:03:43.379895 29253 sgd_solver.cpp:106] Iteration 18840, lr = 0.001
I0302 09:04:11.898803 29253 solver.cpp:237] Iteration 18860, loss = 0.00143845
I0302 09:04:11.898839 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00143845 (* 1 = 0.00143845 loss)
I0302 09:04:11.898849 29253 sgd_solver.cpp:106] Iteration 18860, lr = 0.001
I0302 09:04:40.910372 29253 solver.cpp:237] Iteration 18880, loss = 0.00182783
I0302 09:04:40.910404 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00182784 (* 1 = 0.00182784 loss)
I0302 09:04:40.910414 29253 sgd_solver.cpp:106] Iteration 18880, lr = 0.001
I0302 09:05:09.796340 29253 solver.cpp:237] Iteration 18900, loss = 0.00137785
I0302 09:05:09.796372 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00137785 (* 1 = 0.00137785 loss)
I0302 09:05:09.796381 29253 sgd_solver.cpp:106] Iteration 18900, lr = 0.001
I0302 09:05:38.614562 29253 solver.cpp:237] Iteration 18920, loss = 0.0017795
I0302 09:05:38.614593 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0017795 (* 1 = 0.0017795 loss)
I0302 09:05:38.614603 29253 sgd_solver.cpp:106] Iteration 18920, lr = 0.001
I0302 09:06:07.632585 29253 solver.cpp:237] Iteration 18940, loss = 0.00162407
I0302 09:06:07.632617 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00162407 (* 1 = 0.00162407 loss)
I0302 09:06:07.632625 29253 sgd_solver.cpp:106] Iteration 18940, lr = 0.001
I0302 09:06:36.332643 29253 solver.cpp:237] Iteration 18960, loss = 0.00160227
I0302 09:06:36.332675 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00160228 (* 1 = 0.00160228 loss)
I0302 09:06:36.332684 29253 sgd_solver.cpp:106] Iteration 18960, lr = 0.001
I0302 09:07:05.307458 29253 solver.cpp:237] Iteration 18980, loss = 0.00160945
I0302 09:07:05.307490 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00160946 (* 1 = 0.00160946 loss)
I0302 09:07:05.307499 29253 sgd_solver.cpp:106] Iteration 18980, lr = 0.001
I0302 09:07:34.193123 29253 solver.cpp:237] Iteration 19000, loss = 0.00158919
I0302 09:07:34.193156 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0015892 (* 1 = 0.0015892 loss)
I0302 09:07:34.193166 29253 sgd_solver.cpp:106] Iteration 19000, lr = 0.001
I0302 09:07:44.293957 29253 blocking_queue.cpp:50] Data layer prefetch queue empty
I0302 09:08:03.290524 29253 solver.cpp:237] Iteration 19020, loss = 0.00132683
I0302 09:08:03.290558 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00132683 (* 1 = 0.00132683 loss)
I0302 09:08:03.290568 29253 sgd_solver.cpp:106] Iteration 19020, lr = 0.001
I0302 09:08:32.111218 29253 solver.cpp:237] Iteration 19040, loss = 0.00167092
I0302 09:08:32.111249 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00167092 (* 1 = 0.00167092 loss)
I0302 09:08:32.111258 29253 sgd_solver.cpp:106] Iteration 19040, lr = 0.001
I0302 09:09:00.929808 29253 solver.cpp:237] Iteration 19060, loss = 0.00159923
I0302 09:09:00.929841 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00159924 (* 1 = 0.00159924 loss)
I0302 09:09:00.929850 29253 sgd_solver.cpp:106] Iteration 19060, lr = 0.001
I0302 09:09:29.871332 29253 solver.cpp:237] Iteration 19080, loss = 0.00153691
I0302 09:09:29.871366 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00153692 (* 1 = 0.00153692 loss)
I0302 09:09:29.871374 29253 sgd_solver.cpp:106] Iteration 19080, lr = 0.001
I0302 09:09:58.982868 29253 solver.cpp:237] Iteration 19100, loss = 0.00207169
I0302 09:09:58.982899 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00207169 (* 1 = 0.00207169 loss)
I0302 09:09:58.982908 29253 sgd_solver.cpp:106] Iteration 19100, lr = 0.001
I0302 09:10:27.741907 29253 solver.cpp:237] Iteration 19120, loss = 0.00185467
I0302 09:10:27.741940 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00185468 (* 1 = 0.00185468 loss)
I0302 09:10:27.741948 29253 sgd_solver.cpp:106] Iteration 19120, lr = 0.001
I0302 09:10:56.654902 29253 solver.cpp:237] Iteration 19140, loss = 0.00166614
I0302 09:10:56.654933 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00166614 (* 1 = 0.00166614 loss)
I0302 09:10:56.654942 29253 sgd_solver.cpp:106] Iteration 19140, lr = 0.001
I0302 09:11:25.548634 29253 solver.cpp:237] Iteration 19160, loss = 0.00128235
I0302 09:11:25.548666 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00128236 (* 1 = 0.00128236 loss)
I0302 09:11:25.548674 29253 sgd_solver.cpp:106] Iteration 19160, lr = 0.001
I0302 09:11:54.484813 29253 solver.cpp:237] Iteration 19180, loss = 0.00180908
I0302 09:11:54.484848 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00180909 (* 1 = 0.00180909 loss)
I0302 09:11:54.484856 29253 sgd_solver.cpp:106] Iteration 19180, lr = 0.001
I0302 09:12:23.891973 29253 solver.cpp:237] Iteration 19200, loss = 0.00177643
I0302 09:12:23.892005 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00177644 (* 1 = 0.00177644 loss)
I0302 09:12:23.892014 29253 sgd_solver.cpp:106] Iteration 19200, lr = 0.001
I0302 09:12:52.628649 29253 solver.cpp:237] Iteration 19220, loss = 0.00242856
I0302 09:12:52.628682 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00242856 (* 1 = 0.00242856 loss)
I0302 09:12:52.628690 29253 sgd_solver.cpp:106] Iteration 19220, lr = 0.001
I0302 09:13:22.016176 29253 solver.cpp:237] Iteration 19240, loss = 0.00168574
I0302 09:13:22.016208 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00168574 (* 1 = 0.00168574 loss)
I0302 09:13:22.016217 29253 sgd_solver.cpp:106] Iteration 19240, lr = 0.001
I0302 09:13:50.506032 29253 solver.cpp:237] Iteration 19260, loss = 0.00183207
I0302 09:13:50.506063 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00183208 (* 1 = 0.00183208 loss)
I0302 09:13:50.506072 29253 sgd_solver.cpp:106] Iteration 19260, lr = 0.001
I0302 09:14:19.693693 29253 solver.cpp:237] Iteration 19280, loss = 0.00183357
I0302 09:14:19.693727 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00183358 (* 1 = 0.00183358 loss)
I0302 09:14:19.693735 29253 sgd_solver.cpp:106] Iteration 19280, lr = 0.001
I0302 09:14:48.343260 29253 solver.cpp:237] Iteration 19300, loss = 0.00147181
I0302 09:14:48.343292 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00147182 (* 1 = 0.00147182 loss)
I0302 09:14:48.343302 29253 sgd_solver.cpp:106] Iteration 19300, lr = 0.001
I0302 09:15:17.156678 29253 solver.cpp:237] Iteration 19320, loss = 0.00157088
I0302 09:15:17.156710 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00157088 (* 1 = 0.00157088 loss)
I0302 09:15:17.156719 29253 sgd_solver.cpp:106] Iteration 19320, lr = 0.001
I0302 09:15:46.204677 29253 solver.cpp:237] Iteration 19340, loss = 0.00154898
I0302 09:15:46.204710 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00154899 (* 1 = 0.00154899 loss)
I0302 09:15:46.204720 29253 sgd_solver.cpp:106] Iteration 19340, lr = 0.001
I0302 09:16:15.187265 29253 solver.cpp:237] Iteration 19360, loss = 0.00173657
I0302 09:16:15.187299 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00173657 (* 1 = 0.00173657 loss)
I0302 09:16:15.187307 29253 sgd_solver.cpp:106] Iteration 19360, lr = 0.001
I0302 09:16:43.864717 29253 solver.cpp:237] Iteration 19380, loss = 0.00177375
I0302 09:16:43.864749 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00177375 (* 1 = 0.00177375 loss)
I0302 09:16:43.864758 29253 sgd_solver.cpp:106] Iteration 19380, lr = 0.001
I0302 09:17:12.927678 29253 solver.cpp:237] Iteration 19400, loss = 0.00178974
I0302 09:17:12.927711 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00178974 (* 1 = 0.00178974 loss)
I0302 09:17:12.927721 29253 sgd_solver.cpp:106] Iteration 19400, lr = 0.001
I0302 09:17:41.594288 29253 solver.cpp:237] Iteration 19420, loss = 0.00156764
I0302 09:17:41.594321 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00156764 (* 1 = 0.00156764 loss)
I0302 09:17:41.594329 29253 sgd_solver.cpp:106] Iteration 19420, lr = 0.001
I0302 09:18:10.576581 29253 solver.cpp:237] Iteration 19440, loss = 0.00177601
I0302 09:18:10.576614 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00177601 (* 1 = 0.00177601 loss)
I0302 09:18:10.576623 29253 sgd_solver.cpp:106] Iteration 19440, lr = 0.001
I0302 09:18:39.328858 29253 solver.cpp:237] Iteration 19460, loss = 0.0012319
I0302 09:18:39.328889 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00123191 (* 1 = 0.00123191 loss)
I0302 09:18:39.328898 29253 sgd_solver.cpp:106] Iteration 19460, lr = 0.001
I0302 09:19:08.549782 29253 solver.cpp:237] Iteration 19480, loss = 0.00149677
I0302 09:19:08.549814 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00149677 (* 1 = 0.00149677 loss)
I0302 09:19:08.549823 29253 sgd_solver.cpp:106] Iteration 19480, lr = 0.001
I0302 09:19:37.301372 29253 solver.cpp:237] Iteration 19500, loss = 0.00157779
I0302 09:19:37.301405 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00157779 (* 1 = 0.00157779 loss)
I0302 09:19:37.301414 29253 sgd_solver.cpp:106] Iteration 19500, lr = 0.001
I0302 09:20:06.077126 29253 solver.cpp:237] Iteration 19520, loss = 0.00124547
I0302 09:20:06.077158 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00124547 (* 1 = 0.00124547 loss)
I0302 09:20:06.077167 29253 sgd_solver.cpp:106] Iteration 19520, lr = 0.001
I0302 09:20:35.072656 29253 solver.cpp:237] Iteration 19540, loss = 0.00129492
I0302 09:20:35.072690 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00129493 (* 1 = 0.00129493 loss)
I0302 09:20:35.072700 29253 sgd_solver.cpp:106] Iteration 19540, lr = 0.001
I0302 09:21:03.805887 29253 solver.cpp:237] Iteration 19560, loss = 0.00191993
I0302 09:21:03.805920 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00191993 (* 1 = 0.00191993 loss)
I0302 09:21:03.805929 29253 sgd_solver.cpp:106] Iteration 19560, lr = 0.001
I0302 09:21:32.581785 29253 solver.cpp:237] Iteration 19580, loss = 0.00156008
I0302 09:21:32.581817 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00156008 (* 1 = 0.00156008 loss)
I0302 09:21:32.581825 29253 sgd_solver.cpp:106] Iteration 19580, lr = 0.001
I0302 09:22:01.488380 29253 solver.cpp:237] Iteration 19600, loss = 0.00174321
I0302 09:22:01.488412 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00174322 (* 1 = 0.00174322 loss)
I0302 09:22:01.488422 29253 sgd_solver.cpp:106] Iteration 19600, lr = 0.001
I0302 09:22:30.527794 29253 solver.cpp:237] Iteration 19620, loss = 0.00180607
I0302 09:22:30.527827 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00180607 (* 1 = 0.00180607 loss)
I0302 09:22:30.527835 29253 sgd_solver.cpp:106] Iteration 19620, lr = 0.001
I0302 09:22:59.579383 29253 solver.cpp:237] Iteration 19640, loss = 0.00231399
I0302 09:22:59.579416 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.002314 (* 1 = 0.002314 loss)
I0302 09:22:59.579423 29253 sgd_solver.cpp:106] Iteration 19640, lr = 0.001
I0302 09:23:28.602565 29253 solver.cpp:237] Iteration 19660, loss = 0.00142371
I0302 09:23:28.602596 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00142371 (* 1 = 0.00142371 loss)
I0302 09:23:28.602604 29253 sgd_solver.cpp:106] Iteration 19660, lr = 0.001
I0302 09:23:57.418995 29253 solver.cpp:237] Iteration 19680, loss = 0.00155797
I0302 09:23:57.419028 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00155798 (* 1 = 0.00155798 loss)
I0302 09:23:57.419037 29253 sgd_solver.cpp:106] Iteration 19680, lr = 0.001
I0302 09:24:26.424654 29253 solver.cpp:237] Iteration 19700, loss = 0.00153828
I0302 09:24:26.424688 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00153828 (* 1 = 0.00153828 loss)
I0302 09:24:26.424697 29253 sgd_solver.cpp:106] Iteration 19700, lr = 0.001
I0302 09:24:55.012564 29253 solver.cpp:237] Iteration 19720, loss = 0.0019001
I0302 09:24:55.012596 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00190011 (* 1 = 0.00190011 loss)
I0302 09:24:55.012604 29253 sgd_solver.cpp:106] Iteration 19720, lr = 0.001
I0302 09:25:24.283529 29253 solver.cpp:237] Iteration 19740, loss = 0.00138336
I0302 09:25:24.283560 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00138337 (* 1 = 0.00138337 loss)
I0302 09:25:24.283568 29253 sgd_solver.cpp:106] Iteration 19740, lr = 0.001
I0302 09:25:53.151444 29253 solver.cpp:237] Iteration 19760, loss = 0.00140723
I0302 09:25:53.151474 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00140723 (* 1 = 0.00140723 loss)
I0302 09:25:53.151484 29253 sgd_solver.cpp:106] Iteration 19760, lr = 0.001
I0302 09:26:22.114229 29253 solver.cpp:237] Iteration 19780, loss = 0.00159028
I0302 09:26:22.114262 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00159029 (* 1 = 0.00159029 loss)
I0302 09:26:22.114271 29253 sgd_solver.cpp:106] Iteration 19780, lr = 0.001
I0302 09:26:51.073185 29253 solver.cpp:237] Iteration 19800, loss = 0.00153086
I0302 09:26:51.073218 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00153087 (* 1 = 0.00153087 loss)
I0302 09:26:51.073227 29253 sgd_solver.cpp:106] Iteration 19800, lr = 0.001
I0302 09:27:20.000113 29253 solver.cpp:237] Iteration 19820, loss = 0.00179983
I0302 09:27:20.000145 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00179984 (* 1 = 0.00179984 loss)
I0302 09:27:20.000154 29253 sgd_solver.cpp:106] Iteration 19820, lr = 0.001
I0302 09:27:48.479884 29253 solver.cpp:237] Iteration 19840, loss = 0.00136482
I0302 09:27:48.479918 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00136483 (* 1 = 0.00136483 loss)
I0302 09:27:48.479925 29253 sgd_solver.cpp:106] Iteration 19840, lr = 0.001
I0302 09:28:17.641491 29253 solver.cpp:237] Iteration 19860, loss = 0.00131046
I0302 09:28:17.641525 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00131046 (* 1 = 0.00131046 loss)
I0302 09:28:17.641533 29253 sgd_solver.cpp:106] Iteration 19860, lr = 0.001
I0302 09:28:46.498875 29253 solver.cpp:237] Iteration 19880, loss = 0.00143535
I0302 09:28:46.498908 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00143536 (* 1 = 0.00143536 loss)
I0302 09:28:46.498917 29253 sgd_solver.cpp:106] Iteration 19880, lr = 0.001
I0302 09:29:15.631441 29253 solver.cpp:237] Iteration 19900, loss = 0.00175494
I0302 09:29:15.631474 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00175494 (* 1 = 0.00175494 loss)
I0302 09:29:15.631486 29253 sgd_solver.cpp:106] Iteration 19900, lr = 0.001
I0302 09:29:44.540309 29253 solver.cpp:237] Iteration 19920, loss = 0.00140614
I0302 09:29:44.540341 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00140614 (* 1 = 0.00140614 loss)
I0302 09:29:44.540350 29253 sgd_solver.cpp:106] Iteration 19920, lr = 0.001
I0302 09:30:13.280589 29253 solver.cpp:237] Iteration 19940, loss = 0.00149517
I0302 09:30:13.280622 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00149517 (* 1 = 0.00149517 loss)
I0302 09:30:13.280632 29253 sgd_solver.cpp:106] Iteration 19940, lr = 0.001
I0302 09:30:42.044050 29253 solver.cpp:237] Iteration 19960, loss = 0.00188714
I0302 09:30:42.044083 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00188714 (* 1 = 0.00188714 loss)
I0302 09:30:42.044091 29253 sgd_solver.cpp:106] Iteration 19960, lr = 0.001
I0302 09:31:11.055373 29253 solver.cpp:237] Iteration 19980, loss = 0.00171163
I0302 09:31:11.055408 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00171164 (* 1 = 0.00171164 loss)
I0302 09:31:11.055418 29253 sgd_solver.cpp:106] Iteration 19980, lr = 0.001
I0302 09:31:38.407582 29253 solver.cpp:459] Snapshotting to binary proto file /nfs.yoda/xiaolonw/fast_rcnn/models_sunrgbd/pre_cls_1fc_scratch/model__iter_20000.caffemodel
I0302 09:31:58.678766 29253 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /nfs.yoda/xiaolonw/fast_rcnn/models_sunrgbd/pre_cls_1fc_scratch/model__iter_20000.solverstate
I0302 09:31:59.057767 29253 solver.cpp:237] Iteration 20000, loss = 0.001551
I0302 09:31:59.057799 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00155101 (* 1 = 0.00155101 loss)
I0302 09:31:59.057808 29253 sgd_solver.cpp:106] Iteration 20000, lr = 0.0001
I0302 09:32:10.724550 29253 blocking_queue.cpp:50] Data layer prefetch queue empty
I0302 09:32:25.109073 29253 solver.cpp:237] Iteration 20020, loss = 0.00162993
I0302 09:32:25.109107 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00162993 (* 1 = 0.00162993 loss)
I0302 09:32:25.109117 29253 sgd_solver.cpp:106] Iteration 20020, lr = 0.0001
I0302 09:32:54.154183 29253 solver.cpp:237] Iteration 20040, loss = 0.00128494
I0302 09:32:54.154217 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00128494 (* 1 = 0.00128494 loss)
I0302 09:32:54.154224 29253 sgd_solver.cpp:106] Iteration 20040, lr = 0.0001
I0302 09:33:23.207806 29253 solver.cpp:237] Iteration 20060, loss = 0.00161203
I0302 09:33:23.207840 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00161203 (* 1 = 0.00161203 loss)
I0302 09:33:23.207849 29253 sgd_solver.cpp:106] Iteration 20060, lr = 0.0001
I0302 09:33:52.039577 29253 solver.cpp:237] Iteration 20080, loss = 0.00161653
I0302 09:33:52.039608 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00161653 (* 1 = 0.00161653 loss)
I0302 09:33:52.039615 29253 sgd_solver.cpp:106] Iteration 20080, lr = 0.0001
I0302 09:34:20.880156 29253 solver.cpp:237] Iteration 20100, loss = 0.00152714
I0302 09:34:20.880189 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00152714 (* 1 = 0.00152714 loss)
I0302 09:34:20.880198 29253 sgd_solver.cpp:106] Iteration 20100, lr = 0.0001
I0302 09:34:49.817431 29253 solver.cpp:237] Iteration 20120, loss = 0.0014063
I0302 09:34:49.817463 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0014063 (* 1 = 0.0014063 loss)
I0302 09:34:49.817472 29253 sgd_solver.cpp:106] Iteration 20120, lr = 0.0001
I0302 09:35:18.472718 29253 solver.cpp:237] Iteration 20140, loss = 0.00140486
I0302 09:35:18.472749 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00140486 (* 1 = 0.00140486 loss)
I0302 09:35:18.472759 29253 sgd_solver.cpp:106] Iteration 20140, lr = 0.0001
I0302 09:35:47.594152 29253 solver.cpp:237] Iteration 20160, loss = 0.001621
I0302 09:35:47.594185 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00162101 (* 1 = 0.00162101 loss)
I0302 09:35:47.594194 29253 sgd_solver.cpp:106] Iteration 20160, lr = 0.0001
I0302 09:36:16.342393 29253 solver.cpp:237] Iteration 20180, loss = 0.00209839
I0302 09:36:16.342427 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0020984 (* 1 = 0.0020984 loss)
I0302 09:36:16.342435 29253 sgd_solver.cpp:106] Iteration 20180, lr = 0.0001
I0302 09:36:45.076551 29253 solver.cpp:237] Iteration 20200, loss = 0.00187214
I0302 09:36:45.076583 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00187214 (* 1 = 0.00187214 loss)
I0302 09:36:45.076592 29253 sgd_solver.cpp:106] Iteration 20200, lr = 0.0001
I0302 09:37:14.147683 29253 solver.cpp:237] Iteration 20220, loss = 0.00161359
I0302 09:37:14.147714 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0016136 (* 1 = 0.0016136 loss)
I0302 09:37:14.147723 29253 sgd_solver.cpp:106] Iteration 20220, lr = 0.0001
I0302 09:37:42.824988 29253 solver.cpp:237] Iteration 20240, loss = 0.00189181
I0302 09:37:42.825021 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00189181 (* 1 = 0.00189181 loss)
I0302 09:37:42.825031 29253 sgd_solver.cpp:106] Iteration 20240, lr = 0.0001
I0302 09:38:11.818217 29253 solver.cpp:237] Iteration 20260, loss = 0.00151977
I0302 09:38:11.818246 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00151977 (* 1 = 0.00151977 loss)
I0302 09:38:11.818255 29253 sgd_solver.cpp:106] Iteration 20260, lr = 0.0001
I0302 09:38:40.985957 29253 solver.cpp:237] Iteration 20280, loss = 0.00168109
I0302 09:38:40.985991 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0016811 (* 1 = 0.0016811 loss)
I0302 09:38:40.985999 29253 sgd_solver.cpp:106] Iteration 20280, lr = 0.0001
I0302 09:39:09.870403 29253 solver.cpp:237] Iteration 20300, loss = 0.00227606
I0302 09:39:09.870434 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00227606 (* 1 = 0.00227606 loss)
I0302 09:39:09.870442 29253 sgd_solver.cpp:106] Iteration 20300, lr = 0.0001
I0302 09:39:38.688815 29253 solver.cpp:237] Iteration 20320, loss = 0.00164794
I0302 09:39:38.688848 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00164794 (* 1 = 0.00164794 loss)
I0302 09:39:38.688858 29253 sgd_solver.cpp:106] Iteration 20320, lr = 0.0001
I0302 09:40:07.793284 29253 solver.cpp:237] Iteration 20340, loss = 0.00165683
I0302 09:40:07.793315 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00165683 (* 1 = 0.00165683 loss)
I0302 09:40:07.793324 29253 sgd_solver.cpp:106] Iteration 20340, lr = 0.0001
I0302 09:40:36.690038 29253 solver.cpp:237] Iteration 20360, loss = 0.00166736
I0302 09:40:36.690071 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00166736 (* 1 = 0.00166736 loss)
I0302 09:40:36.690080 29253 sgd_solver.cpp:106] Iteration 20360, lr = 0.0001
I0302 09:41:05.809142 29253 solver.cpp:237] Iteration 20380, loss = 0.00144412
I0302 09:41:05.809175 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00144412 (* 1 = 0.00144412 loss)
I0302 09:41:05.809183 29253 sgd_solver.cpp:106] Iteration 20380, lr = 0.0001
I0302 09:41:34.580981 29253 solver.cpp:237] Iteration 20400, loss = 0.0016697
I0302 09:41:34.581013 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00166971 (* 1 = 0.00166971 loss)
I0302 09:41:34.581023 29253 sgd_solver.cpp:106] Iteration 20400, lr = 0.0001
I0302 09:42:03.210495 29253 solver.cpp:237] Iteration 20420, loss = 0.00152766
I0302 09:42:03.210527 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00152767 (* 1 = 0.00152767 loss)
I0302 09:42:03.210536 29253 sgd_solver.cpp:106] Iteration 20420, lr = 0.0001
I0302 09:42:31.965981 29253 solver.cpp:237] Iteration 20440, loss = 0.00148341
I0302 09:42:31.966012 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00148342 (* 1 = 0.00148342 loss)
I0302 09:42:31.966022 29253 sgd_solver.cpp:106] Iteration 20440, lr = 0.0001
I0302 09:43:01.101542 29253 solver.cpp:237] Iteration 20460, loss = 0.0013328
I0302 09:43:01.101574 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0013328 (* 1 = 0.0013328 loss)
I0302 09:43:01.101583 29253 sgd_solver.cpp:106] Iteration 20460, lr = 0.0001
I0302 09:43:30.044212 29253 solver.cpp:237] Iteration 20480, loss = 0.00141919
I0302 09:43:30.044245 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00141919 (* 1 = 0.00141919 loss)
I0302 09:43:30.044255 29253 sgd_solver.cpp:106] Iteration 20480, lr = 0.0001
I0302 09:43:58.739455 29253 solver.cpp:237] Iteration 20500, loss = 0.00223112
I0302 09:43:58.739488 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00223112 (* 1 = 0.00223112 loss)
I0302 09:43:58.739497 29253 sgd_solver.cpp:106] Iteration 20500, lr = 0.0001
I0302 09:44:27.813302 29253 solver.cpp:237] Iteration 20520, loss = 0.00131959
I0302 09:44:27.813334 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0013196 (* 1 = 0.0013196 loss)
I0302 09:44:27.813344 29253 sgd_solver.cpp:106] Iteration 20520, lr = 0.0001
I0302 09:44:56.710294 29253 solver.cpp:237] Iteration 20540, loss = 0.00194542
I0302 09:44:56.710325 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00194542 (* 1 = 0.00194542 loss)
I0302 09:44:56.710335 29253 sgd_solver.cpp:106] Iteration 20540, lr = 0.0001
I0302 09:45:25.586493 29253 solver.cpp:237] Iteration 20560, loss = 0.00164454
I0302 09:45:25.586526 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00164454 (* 1 = 0.00164454 loss)
I0302 09:45:25.586535 29253 sgd_solver.cpp:106] Iteration 20560, lr = 0.0001
I0302 09:45:54.546952 29253 solver.cpp:237] Iteration 20580, loss = 0.00135048
I0302 09:45:54.546984 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00135049 (* 1 = 0.00135049 loss)
I0302 09:45:54.546993 29253 sgd_solver.cpp:106] Iteration 20580, lr = 0.0001
I0302 09:46:23.392798 29253 solver.cpp:237] Iteration 20600, loss = 0.00146611
I0302 09:46:23.392830 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00146611 (* 1 = 0.00146611 loss)
I0302 09:46:23.392839 29253 sgd_solver.cpp:106] Iteration 20600, lr = 0.0001
I0302 09:46:52.184028 29253 solver.cpp:237] Iteration 20620, loss = 0.00150983
I0302 09:46:52.184061 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00150983 (* 1 = 0.00150983 loss)
I0302 09:46:52.184068 29253 sgd_solver.cpp:106] Iteration 20620, lr = 0.0001
I0302 09:47:21.110313 29253 solver.cpp:237] Iteration 20640, loss = 0.00174216
I0302 09:47:21.110344 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00174217 (* 1 = 0.00174217 loss)
I0302 09:47:21.110353 29253 sgd_solver.cpp:106] Iteration 20640, lr = 0.0001
I0302 09:47:50.083596 29253 solver.cpp:237] Iteration 20660, loss = 0.0015857
I0302 09:47:50.083627 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00158571 (* 1 = 0.00158571 loss)
I0302 09:47:50.083636 29253 sgd_solver.cpp:106] Iteration 20660, lr = 0.0001
I0302 09:48:18.758608 29253 solver.cpp:237] Iteration 20680, loss = 0.00145033
I0302 09:48:18.758641 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00145033 (* 1 = 0.00145033 loss)
I0302 09:48:18.758649 29253 sgd_solver.cpp:106] Iteration 20680, lr = 0.0001
I0302 09:48:47.590107 29253 solver.cpp:237] Iteration 20700, loss = 0.00167087
I0302 09:48:47.590139 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00167088 (* 1 = 0.00167088 loss)
I0302 09:48:47.590148 29253 sgd_solver.cpp:106] Iteration 20700, lr = 0.0001
I0302 09:49:16.434295 29253 solver.cpp:237] Iteration 20720, loss = 0.00159629
I0302 09:49:16.434326 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00159629 (* 1 = 0.00159629 loss)
I0302 09:49:16.434335 29253 sgd_solver.cpp:106] Iteration 20720, lr = 0.0001
I0302 09:49:45.586282 29253 solver.cpp:237] Iteration 20740, loss = 0.00159493
I0302 09:49:45.586313 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00159493 (* 1 = 0.00159493 loss)
I0302 09:49:45.586323 29253 sgd_solver.cpp:106] Iteration 20740, lr = 0.0001
I0302 09:50:14.301403 29253 solver.cpp:237] Iteration 20760, loss = 0.00141721
I0302 09:50:14.301434 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00141722 (* 1 = 0.00141722 loss)
I0302 09:50:14.301443 29253 sgd_solver.cpp:106] Iteration 20760, lr = 0.0001
I0302 09:50:43.275427 29253 solver.cpp:237] Iteration 20780, loss = 0.00143277
I0302 09:50:43.275460 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00143277 (* 1 = 0.00143277 loss)
I0302 09:50:43.275470 29253 sgd_solver.cpp:106] Iteration 20780, lr = 0.0001
I0302 09:51:12.070333 29253 solver.cpp:237] Iteration 20800, loss = 0.00166096
I0302 09:51:12.070364 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00166096 (* 1 = 0.00166096 loss)
I0302 09:51:12.070374 29253 sgd_solver.cpp:106] Iteration 20800, lr = 0.0001
I0302 09:51:41.023671 29253 solver.cpp:237] Iteration 20820, loss = 0.00184938
I0302 09:51:41.023705 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00184938 (* 1 = 0.00184938 loss)
I0302 09:51:41.023713 29253 sgd_solver.cpp:106] Iteration 20820, lr = 0.0001
I0302 09:52:09.843144 29253 solver.cpp:237] Iteration 20840, loss = 0.00161222
I0302 09:52:09.843176 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00161222 (* 1 = 0.00161222 loss)
I0302 09:52:09.843185 29253 sgd_solver.cpp:106] Iteration 20840, lr = 0.0001
I0302 09:52:38.692790 29253 solver.cpp:237] Iteration 20860, loss = 0.00161621
I0302 09:52:38.692821 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00161621 (* 1 = 0.00161621 loss)
I0302 09:52:38.692829 29253 sgd_solver.cpp:106] Iteration 20860, lr = 0.0001
I0302 09:53:07.670003 29253 solver.cpp:237] Iteration 20880, loss = 0.00166531
I0302 09:53:07.670035 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00166532 (* 1 = 0.00166532 loss)
I0302 09:53:07.670044 29253 sgd_solver.cpp:106] Iteration 20880, lr = 0.0001
I0302 09:53:36.756834 29253 solver.cpp:237] Iteration 20900, loss = 0.00178963
I0302 09:53:36.756865 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00178963 (* 1 = 0.00178963 loss)
I0302 09:53:36.756873 29253 sgd_solver.cpp:106] Iteration 20900, lr = 0.0001
I0302 09:54:05.590922 29253 solver.cpp:237] Iteration 20920, loss = 0.00172172
I0302 09:54:05.590955 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00172172 (* 1 = 0.00172172 loss)
I0302 09:54:05.590963 29253 sgd_solver.cpp:106] Iteration 20920, lr = 0.0001
I0302 09:54:34.657646 29253 solver.cpp:237] Iteration 20940, loss = 0.0014317
I0302 09:54:34.657678 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0014317 (* 1 = 0.0014317 loss)
I0302 09:54:34.657687 29253 sgd_solver.cpp:106] Iteration 20940, lr = 0.0001
I0302 09:55:03.339421 29253 solver.cpp:237] Iteration 20960, loss = 0.00131807
I0302 09:55:03.339452 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00131807 (* 1 = 0.00131807 loss)
I0302 09:55:03.339462 29253 sgd_solver.cpp:106] Iteration 20960, lr = 0.0001
I0302 09:55:32.323400 29253 solver.cpp:237] Iteration 20980, loss = 0.00133919
I0302 09:55:32.323432 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00133919 (* 1 = 0.00133919 loss)
I0302 09:55:32.323441 29253 sgd_solver.cpp:106] Iteration 20980, lr = 0.0001
I0302 09:56:01.116600 29253 solver.cpp:237] Iteration 21000, loss = 0.0012551
I0302 09:56:01.116632 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0012551 (* 1 = 0.0012551 loss)
I0302 09:56:01.116641 29253 sgd_solver.cpp:106] Iteration 21000, lr = 0.0001
I0302 09:56:15.556323 29253 blocking_queue.cpp:50] Data layer prefetch queue empty
I0302 09:56:29.907922 29253 solver.cpp:237] Iteration 21020, loss = 0.00196285
I0302 09:56:29.907953 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00196285 (* 1 = 0.00196285 loss)
I0302 09:56:29.907963 29253 sgd_solver.cpp:106] Iteration 21020, lr = 0.0001
I0302 09:56:58.834350 29253 solver.cpp:237] Iteration 21040, loss = 0.0012949
I0302 09:56:58.834384 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0012949 (* 1 = 0.0012949 loss)
I0302 09:56:58.834393 29253 sgd_solver.cpp:106] Iteration 21040, lr = 0.0001
I0302 09:57:27.778847 29253 solver.cpp:237] Iteration 21060, loss = 0.00212107
I0302 09:57:27.778880 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00212107 (* 1 = 0.00212107 loss)
I0302 09:57:27.778889 29253 sgd_solver.cpp:106] Iteration 21060, lr = 0.0001
I0302 09:57:56.770705 29253 solver.cpp:237] Iteration 21080, loss = 0.00162266
I0302 09:57:56.770737 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00162267 (* 1 = 0.00162267 loss)
I0302 09:57:56.770746 29253 sgd_solver.cpp:106] Iteration 21080, lr = 0.0001
I0302 09:58:25.616065 29253 solver.cpp:237] Iteration 21100, loss = 0.00231989
I0302 09:58:25.616097 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00231989 (* 1 = 0.00231989 loss)
I0302 09:58:25.616106 29253 sgd_solver.cpp:106] Iteration 21100, lr = 0.0001
I0302 09:58:54.535274 29253 solver.cpp:237] Iteration 21120, loss = 0.00163597
I0302 09:58:54.535305 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00163598 (* 1 = 0.00163598 loss)
I0302 09:58:54.535313 29253 sgd_solver.cpp:106] Iteration 21120, lr = 0.0001
I0302 09:59:23.386998 29253 solver.cpp:237] Iteration 21140, loss = 0.0019938
I0302 09:59:23.387032 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00199381 (* 1 = 0.00199381 loss)
I0302 09:59:23.387040 29253 sgd_solver.cpp:106] Iteration 21140, lr = 0.0001
I0302 09:59:52.429405 29253 solver.cpp:237] Iteration 21160, loss = 0.00157773
I0302 09:59:52.429438 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00157773 (* 1 = 0.00157773 loss)
I0302 09:59:52.429446 29253 sgd_solver.cpp:106] Iteration 21160, lr = 0.0001
I0302 10:00:21.357630 29253 solver.cpp:237] Iteration 21180, loss = 0.00185047
I0302 10:00:21.357663 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00185048 (* 1 = 0.00185048 loss)
I0302 10:00:21.357672 29253 sgd_solver.cpp:106] Iteration 21180, lr = 0.0001
I0302 10:00:50.321406 29253 solver.cpp:237] Iteration 21200, loss = 0.00142026
I0302 10:00:50.321440 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00142026 (* 1 = 0.00142026 loss)
I0302 10:00:50.321449 29253 sgd_solver.cpp:106] Iteration 21200, lr = 0.0001
I0302 10:01:19.318253 29253 solver.cpp:237] Iteration 21220, loss = 0.00209803
I0302 10:01:19.318284 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00209803 (* 1 = 0.00209803 loss)
I0302 10:01:19.318292 29253 sgd_solver.cpp:106] Iteration 21220, lr = 0.0001
I0302 10:01:48.167371 29253 solver.cpp:237] Iteration 21240, loss = 0.00179092
I0302 10:01:48.167402 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00179092 (* 1 = 0.00179092 loss)
I0302 10:01:48.167410 29253 sgd_solver.cpp:106] Iteration 21240, lr = 0.0001
I0302 10:02:17.091150 29253 solver.cpp:237] Iteration 21260, loss = 0.00122053
I0302 10:02:17.091183 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00122053 (* 1 = 0.00122053 loss)
I0302 10:02:17.091192 29253 sgd_solver.cpp:106] Iteration 21260, lr = 0.0001
I0302 10:02:46.053720 29253 solver.cpp:237] Iteration 21280, loss = 0.00155419
I0302 10:02:46.053752 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0015542 (* 1 = 0.0015542 loss)
I0302 10:02:46.053761 29253 sgd_solver.cpp:106] Iteration 21280, lr = 0.0001
I0302 10:03:14.907486 29253 solver.cpp:237] Iteration 21300, loss = 0.00140345
I0302 10:03:14.907517 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00140346 (* 1 = 0.00140346 loss)
I0302 10:03:14.907526 29253 sgd_solver.cpp:106] Iteration 21300, lr = 0.0001
I0302 10:03:43.604527 29253 solver.cpp:237] Iteration 21320, loss = 0.00224752
I0302 10:03:43.604560 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00224753 (* 1 = 0.00224753 loss)
I0302 10:03:43.604568 29253 sgd_solver.cpp:106] Iteration 21320, lr = 0.0001
I0302 10:04:12.500179 29253 solver.cpp:237] Iteration 21340, loss = 0.00185097
I0302 10:04:12.500211 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00185097 (* 1 = 0.00185097 loss)
I0302 10:04:12.500219 29253 sgd_solver.cpp:106] Iteration 21340, lr = 0.0001
I0302 10:04:41.369983 29253 solver.cpp:237] Iteration 21360, loss = 0.00151956
I0302 10:04:41.370015 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00151956 (* 1 = 0.00151956 loss)
I0302 10:04:41.370024 29253 sgd_solver.cpp:106] Iteration 21360, lr = 0.0001
I0302 10:05:10.370584 29253 solver.cpp:237] Iteration 21380, loss = 0.00177747
I0302 10:05:10.370615 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00177748 (* 1 = 0.00177748 loss)
I0302 10:05:10.370623 29253 sgd_solver.cpp:106] Iteration 21380, lr = 0.0001
I0302 10:05:39.578811 29253 solver.cpp:237] Iteration 21400, loss = 0.00140117
I0302 10:05:39.578843 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00140117 (* 1 = 0.00140117 loss)
I0302 10:05:39.578852 29253 sgd_solver.cpp:106] Iteration 21400, lr = 0.0001
I0302 10:06:08.453701 29253 solver.cpp:237] Iteration 21420, loss = 0.00147353
I0302 10:06:08.453734 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00147353 (* 1 = 0.00147353 loss)
I0302 10:06:08.453743 29253 sgd_solver.cpp:106] Iteration 21420, lr = 0.0001
I0302 10:06:37.191375 29253 solver.cpp:237] Iteration 21440, loss = 0.00210355
I0302 10:06:37.191406 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00210355 (* 1 = 0.00210355 loss)
I0302 10:06:37.191413 29253 sgd_solver.cpp:106] Iteration 21440, lr = 0.0001
I0302 10:07:06.206918 29253 solver.cpp:237] Iteration 21460, loss = 0.00173975
I0302 10:07:06.206950 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00173975 (* 1 = 0.00173975 loss)
I0302 10:07:06.206959 29253 sgd_solver.cpp:106] Iteration 21460, lr = 0.0001
I0302 10:07:35.159164 29253 solver.cpp:237] Iteration 21480, loss = 0.00176882
I0302 10:07:35.159196 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00176882 (* 1 = 0.00176882 loss)
I0302 10:07:35.159204 29253 sgd_solver.cpp:106] Iteration 21480, lr = 0.0001
I0302 10:08:04.021349 29253 solver.cpp:237] Iteration 21500, loss = 0.00174545
I0302 10:08:04.021380 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00174545 (* 1 = 0.00174545 loss)
I0302 10:08:04.021389 29253 sgd_solver.cpp:106] Iteration 21500, lr = 0.0001
I0302 10:08:32.843612 29253 solver.cpp:237] Iteration 21520, loss = 0.00236569
I0302 10:08:32.843646 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0023657 (* 1 = 0.0023657 loss)
I0302 10:08:32.843654 29253 sgd_solver.cpp:106] Iteration 21520, lr = 0.0001
I0302 10:09:01.768888 29253 solver.cpp:237] Iteration 21540, loss = 0.00146415
I0302 10:09:01.768920 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00146415 (* 1 = 0.00146415 loss)
I0302 10:09:01.768929 29253 sgd_solver.cpp:106] Iteration 21540, lr = 0.0001
I0302 10:09:30.843381 29253 solver.cpp:237] Iteration 21560, loss = 0.00159159
I0302 10:09:30.843413 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0015916 (* 1 = 0.0015916 loss)
I0302 10:09:30.843422 29253 sgd_solver.cpp:106] Iteration 21560, lr = 0.0001
I0302 10:09:59.893887 29253 solver.cpp:237] Iteration 21580, loss = 0.00164757
I0302 10:09:59.893918 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00164758 (* 1 = 0.00164758 loss)
I0302 10:09:59.893926 29253 sgd_solver.cpp:106] Iteration 21580, lr = 0.0001
I0302 10:10:28.744484 29253 solver.cpp:237] Iteration 21600, loss = 0.00129436
I0302 10:10:28.744518 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00129436 (* 1 = 0.00129436 loss)
I0302 10:10:28.744527 29253 sgd_solver.cpp:106] Iteration 21600, lr = 0.0001
I0302 10:10:57.708943 29253 solver.cpp:237] Iteration 21620, loss = 0.00184453
I0302 10:10:57.708976 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00184453 (* 1 = 0.00184453 loss)
I0302 10:10:57.708984 29253 sgd_solver.cpp:106] Iteration 21620, lr = 0.0001
I0302 10:11:27.083600 29253 solver.cpp:237] Iteration 21640, loss = 0.00189916
I0302 10:11:27.083632 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00189916 (* 1 = 0.00189916 loss)
I0302 10:11:27.083642 29253 sgd_solver.cpp:106] Iteration 21640, lr = 0.0001
I0302 10:11:55.850502 29253 solver.cpp:237] Iteration 21660, loss = 0.00211752
I0302 10:11:55.850538 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00211753 (* 1 = 0.00211753 loss)
I0302 10:11:55.850548 29253 sgd_solver.cpp:106] Iteration 21660, lr = 0.0001
I0302 10:12:24.801102 29253 solver.cpp:237] Iteration 21680, loss = 0.00164138
I0302 10:12:24.801136 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00164139 (* 1 = 0.00164139 loss)
I0302 10:12:24.801144 29253 sgd_solver.cpp:106] Iteration 21680, lr = 0.0001
I0302 10:12:53.669831 29253 solver.cpp:237] Iteration 21700, loss = 0.0020547
I0302 10:12:53.669862 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00205471 (* 1 = 0.00205471 loss)
I0302 10:12:53.669869 29253 sgd_solver.cpp:106] Iteration 21700, lr = 0.0001
I0302 10:13:22.698813 29253 solver.cpp:237] Iteration 21720, loss = 0.00170955
I0302 10:13:22.698848 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00170955 (* 1 = 0.00170955 loss)
I0302 10:13:22.698855 29253 sgd_solver.cpp:106] Iteration 21720, lr = 0.0001
I0302 10:13:51.829429 29253 solver.cpp:237] Iteration 21740, loss = 0.00148757
I0302 10:13:51.829463 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00148757 (* 1 = 0.00148757 loss)
I0302 10:13:51.829473 29253 sgd_solver.cpp:106] Iteration 21740, lr = 0.0001
I0302 10:14:20.519266 29253 solver.cpp:237] Iteration 21760, loss = 0.00167977
I0302 10:14:20.519299 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00167977 (* 1 = 0.00167977 loss)
I0302 10:14:20.519307 29253 sgd_solver.cpp:106] Iteration 21760, lr = 0.0001
I0302 10:14:49.541267 29253 solver.cpp:237] Iteration 21780, loss = 0.00142084
I0302 10:14:49.541301 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00142085 (* 1 = 0.00142085 loss)
I0302 10:14:49.541309 29253 sgd_solver.cpp:106] Iteration 21780, lr = 0.0001
I0302 10:15:18.379194 29253 solver.cpp:237] Iteration 21800, loss = 0.00168902
I0302 10:15:18.379226 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00168902 (* 1 = 0.00168902 loss)
I0302 10:15:18.379235 29253 sgd_solver.cpp:106] Iteration 21800, lr = 0.0001
I0302 10:15:47.455600 29253 solver.cpp:237] Iteration 21820, loss = 0.00174335
I0302 10:15:47.455634 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00174335 (* 1 = 0.00174335 loss)
I0302 10:15:47.455643 29253 sgd_solver.cpp:106] Iteration 21820, lr = 0.0001
I0302 10:16:16.367878 29253 solver.cpp:237] Iteration 21840, loss = 0.00157416
I0302 10:16:16.367911 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00157416 (* 1 = 0.00157416 loss)
I0302 10:16:16.367920 29253 sgd_solver.cpp:106] Iteration 21840, lr = 0.0001
I0302 10:16:45.231431 29253 solver.cpp:237] Iteration 21860, loss = 0.0018866
I0302 10:16:45.231463 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00188661 (* 1 = 0.00188661 loss)
I0302 10:16:45.231472 29253 sgd_solver.cpp:106] Iteration 21860, lr = 0.0001
I0302 10:17:14.060612 29253 solver.cpp:237] Iteration 21880, loss = 0.00162878
I0302 10:17:14.060645 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00162879 (* 1 = 0.00162879 loss)
I0302 10:17:14.060654 29253 sgd_solver.cpp:106] Iteration 21880, lr = 0.0001
I0302 10:17:42.915257 29253 solver.cpp:237] Iteration 21900, loss = 0.00136335
I0302 10:17:42.915289 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00136335 (* 1 = 0.00136335 loss)
I0302 10:17:42.915298 29253 sgd_solver.cpp:106] Iteration 21900, lr = 0.0001
I0302 10:18:11.870535 29253 solver.cpp:237] Iteration 21920, loss = 0.00164777
I0302 10:18:11.870566 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00164778 (* 1 = 0.00164778 loss)
I0302 10:18:11.870574 29253 sgd_solver.cpp:106] Iteration 21920, lr = 0.0001
I0302 10:18:40.831135 29253 solver.cpp:237] Iteration 21940, loss = 0.00160369
I0302 10:18:40.831168 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0016037 (* 1 = 0.0016037 loss)
I0302 10:18:40.831178 29253 sgd_solver.cpp:106] Iteration 21940, lr = 0.0001
I0302 10:19:09.826750 29253 solver.cpp:237] Iteration 21960, loss = 0.00190679
I0302 10:19:09.826782 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00190679 (* 1 = 0.00190679 loss)
I0302 10:19:09.826792 29253 sgd_solver.cpp:106] Iteration 21960, lr = 0.0001
I0302 10:19:38.877836 29253 solver.cpp:237] Iteration 21980, loss = 0.002686
I0302 10:19:38.877869 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.002686 (* 1 = 0.002686 loss)
I0302 10:19:38.877877 29253 sgd_solver.cpp:106] Iteration 21980, lr = 0.0001
I0302 10:20:07.972579 29253 solver.cpp:237] Iteration 22000, loss = 0.00176581
I0302 10:20:07.972612 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00176581 (* 1 = 0.00176581 loss)
I0302 10:20:07.972620 29253 sgd_solver.cpp:106] Iteration 22000, lr = 0.0001
I0302 10:20:22.431633 29253 blocking_queue.cpp:50] Data layer prefetch queue empty
I0302 10:20:36.859814 29253 solver.cpp:237] Iteration 22020, loss = 0.00209891
I0302 10:20:36.859849 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00209891 (* 1 = 0.00209891 loss)
I0302 10:20:36.859858 29253 sgd_solver.cpp:106] Iteration 22020, lr = 0.0001
I0302 10:21:05.866233 29253 solver.cpp:237] Iteration 22040, loss = 0.001571
I0302 10:21:05.866263 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.001571 (* 1 = 0.001571 loss)
I0302 10:21:05.866272 29253 sgd_solver.cpp:106] Iteration 22040, lr = 0.0001
I0302 10:21:34.708228 29253 solver.cpp:237] Iteration 22060, loss = 0.00157404
I0302 10:21:34.708261 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00157405 (* 1 = 0.00157405 loss)
I0302 10:21:34.708268 29253 sgd_solver.cpp:106] Iteration 22060, lr = 0.0001
I0302 10:22:03.733815 29253 solver.cpp:237] Iteration 22080, loss = 0.00179349
I0302 10:22:03.733847 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00179349 (* 1 = 0.00179349 loss)
I0302 10:22:03.733856 29253 sgd_solver.cpp:106] Iteration 22080, lr = 0.0001
I0302 10:22:32.266525 29253 solver.cpp:237] Iteration 22100, loss = 0.00161799
I0302 10:22:32.266558 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00161799 (* 1 = 0.00161799 loss)
I0302 10:22:32.266567 29253 sgd_solver.cpp:106] Iteration 22100, lr = 0.0001
I0302 10:23:01.478791 29253 solver.cpp:237] Iteration 22120, loss = 0.00135774
I0302 10:23:01.478823 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00135774 (* 1 = 0.00135774 loss)
I0302 10:23:01.478832 29253 sgd_solver.cpp:106] Iteration 22120, lr = 0.0001
I0302 10:23:30.147454 29253 solver.cpp:237] Iteration 22140, loss = 0.00147704
I0302 10:23:30.147487 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00147704 (* 1 = 0.00147704 loss)
I0302 10:23:30.147496 29253 sgd_solver.cpp:106] Iteration 22140, lr = 0.0001
I0302 10:23:59.135738 29253 solver.cpp:237] Iteration 22160, loss = 0.00144302
I0302 10:23:59.135771 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00144302 (* 1 = 0.00144302 loss)
I0302 10:23:59.135779 29253 sgd_solver.cpp:106] Iteration 22160, lr = 0.0001
I0302 10:24:28.093904 29253 solver.cpp:237] Iteration 22180, loss = 0.00161214
I0302 10:24:28.093933 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00161215 (* 1 = 0.00161215 loss)
I0302 10:24:28.093942 29253 sgd_solver.cpp:106] Iteration 22180, lr = 0.0001
I0302 10:24:57.032155 29253 solver.cpp:237] Iteration 22200, loss = 0.00208052
I0302 10:24:57.032186 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00208052 (* 1 = 0.00208052 loss)
I0302 10:24:57.032194 29253 sgd_solver.cpp:106] Iteration 22200, lr = 0.0001
I0302 10:25:26.023186 29253 solver.cpp:237] Iteration 22220, loss = 0.00186849
I0302 10:25:26.023217 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00186849 (* 1 = 0.00186849 loss)
I0302 10:25:26.023226 29253 sgd_solver.cpp:106] Iteration 22220, lr = 0.0001
I0302 10:25:54.830824 29253 solver.cpp:237] Iteration 22240, loss = 0.00175729
I0302 10:25:54.830859 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00175729 (* 1 = 0.00175729 loss)
I0302 10:25:54.830868 29253 sgd_solver.cpp:106] Iteration 22240, lr = 0.0001
I0302 10:26:23.822860 29253 solver.cpp:237] Iteration 22260, loss = 0.00142499
I0302 10:26:23.822892 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.001425 (* 1 = 0.001425 loss)
I0302 10:26:23.822901 29253 sgd_solver.cpp:106] Iteration 22260, lr = 0.0001
I0302 10:26:52.784037 29253 solver.cpp:237] Iteration 22280, loss = 0.00151574
I0302 10:26:52.784070 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00151575 (* 1 = 0.00151575 loss)
I0302 10:26:52.784078 29253 sgd_solver.cpp:106] Iteration 22280, lr = 0.0001
I0302 10:27:21.728801 29253 solver.cpp:237] Iteration 22300, loss = 0.00171635
I0302 10:27:21.728834 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00171635 (* 1 = 0.00171635 loss)
I0302 10:27:21.728843 29253 sgd_solver.cpp:106] Iteration 22300, lr = 0.0001
I0302 10:27:50.733238 29253 solver.cpp:237] Iteration 22320, loss = 0.00152048
I0302 10:27:50.733268 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00152048 (* 1 = 0.00152048 loss)
I0302 10:27:50.733276 29253 sgd_solver.cpp:106] Iteration 22320, lr = 0.0001
I0302 10:28:19.565161 29253 solver.cpp:237] Iteration 22340, loss = 0.00150388
I0302 10:28:19.565192 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00150388 (* 1 = 0.00150388 loss)
I0302 10:28:19.565201 29253 sgd_solver.cpp:106] Iteration 22340, lr = 0.0001
I0302 10:28:48.525822 29253 solver.cpp:237] Iteration 22360, loss = 0.0018979
I0302 10:28:48.525856 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00189791 (* 1 = 0.00189791 loss)
I0302 10:28:48.525864 29253 sgd_solver.cpp:106] Iteration 22360, lr = 0.0001
I0302 10:29:17.665556 29253 solver.cpp:237] Iteration 22380, loss = 0.00147343
I0302 10:29:17.665587 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00147343 (* 1 = 0.00147343 loss)
I0302 10:29:17.665596 29253 sgd_solver.cpp:106] Iteration 22380, lr = 0.0001
I0302 10:29:46.375241 29253 solver.cpp:237] Iteration 22400, loss = 0.00166159
I0302 10:29:46.375273 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00166159 (* 1 = 0.00166159 loss)
I0302 10:29:46.375283 29253 sgd_solver.cpp:106] Iteration 22400, lr = 0.0001
I0302 10:30:15.399056 29253 solver.cpp:237] Iteration 22420, loss = 0.00175223
I0302 10:30:15.399087 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00175224 (* 1 = 0.00175224 loss)
I0302 10:30:15.399096 29253 sgd_solver.cpp:106] Iteration 22420, lr = 0.0001
I0302 10:30:44.103754 29253 solver.cpp:237] Iteration 22440, loss = 0.00156047
I0302 10:30:44.103786 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00156047 (* 1 = 0.00156047 loss)
I0302 10:30:44.103796 29253 sgd_solver.cpp:106] Iteration 22440, lr = 0.0001
I0302 10:31:12.797922 29253 solver.cpp:237] Iteration 22460, loss = 0.00170372
I0302 10:31:12.797955 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00170372 (* 1 = 0.00170372 loss)
I0302 10:31:12.797963 29253 sgd_solver.cpp:106] Iteration 22460, lr = 0.0001
I0302 10:31:41.935947 29253 solver.cpp:237] Iteration 22480, loss = 0.00176575
I0302 10:31:41.935979 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00176575 (* 1 = 0.00176575 loss)
I0302 10:31:41.935989 29253 sgd_solver.cpp:106] Iteration 22480, lr = 0.0001
I0302 10:32:10.873909 29253 solver.cpp:237] Iteration 22500, loss = 0.00192716
I0302 10:32:10.873940 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00192717 (* 1 = 0.00192717 loss)
I0302 10:32:10.873950 29253 sgd_solver.cpp:106] Iteration 22500, lr = 0.0001
I0302 10:32:39.732758 29253 solver.cpp:237] Iteration 22520, loss = 0.00177327
I0302 10:32:39.732789 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00177327 (* 1 = 0.00177327 loss)
I0302 10:32:39.732797 29253 sgd_solver.cpp:106] Iteration 22520, lr = 0.0001
I0302 10:33:08.654578 29253 solver.cpp:237] Iteration 22540, loss = 0.00188186
I0302 10:33:08.654610 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00188186 (* 1 = 0.00188186 loss)
I0302 10:33:08.654619 29253 sgd_solver.cpp:106] Iteration 22540, lr = 0.0001
I0302 10:33:37.576905 29253 solver.cpp:237] Iteration 22560, loss = 0.00207544
I0302 10:33:37.576936 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00207545 (* 1 = 0.00207545 loss)
I0302 10:33:37.576946 29253 sgd_solver.cpp:106] Iteration 22560, lr = 0.0001
I0302 10:34:06.499766 29253 solver.cpp:237] Iteration 22580, loss = 0.0016354
I0302 10:34:06.499800 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0016354 (* 1 = 0.0016354 loss)
I0302 10:34:06.499809 29253 sgd_solver.cpp:106] Iteration 22580, lr = 0.0001
I0302 10:34:35.299914 29253 solver.cpp:237] Iteration 22600, loss = 0.00143384
I0302 10:34:35.299947 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00143384 (* 1 = 0.00143384 loss)
I0302 10:34:35.299955 29253 sgd_solver.cpp:106] Iteration 22600, lr = 0.0001
I0302 10:35:04.409471 29253 solver.cpp:237] Iteration 22620, loss = 0.00145976
I0302 10:35:04.409500 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00145976 (* 1 = 0.00145976 loss)
I0302 10:35:04.409509 29253 sgd_solver.cpp:106] Iteration 22620, lr = 0.0001
I0302 10:35:33.110827 29253 solver.cpp:237] Iteration 22640, loss = 0.00230247
I0302 10:35:33.110859 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00230247 (* 1 = 0.00230247 loss)
I0302 10:35:33.110868 29253 sgd_solver.cpp:106] Iteration 22640, lr = 0.0001
I0302 10:36:01.962437 29253 solver.cpp:237] Iteration 22660, loss = 0.0016808
I0302 10:36:01.962469 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00168081 (* 1 = 0.00168081 loss)
I0302 10:36:01.962478 29253 sgd_solver.cpp:106] Iteration 22660, lr = 0.0001
I0302 10:36:30.715827 29253 solver.cpp:237] Iteration 22680, loss = 0.00172885
I0302 10:36:30.715858 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00172885 (* 1 = 0.00172885 loss)
I0302 10:36:30.715867 29253 sgd_solver.cpp:106] Iteration 22680, lr = 0.0001
I0302 10:36:59.730449 29253 solver.cpp:237] Iteration 22700, loss = 0.00147269
I0302 10:36:59.730481 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0014727 (* 1 = 0.0014727 loss)
I0302 10:36:59.730490 29253 sgd_solver.cpp:106] Iteration 22700, lr = 0.0001
I0302 10:37:28.740483 29253 solver.cpp:237] Iteration 22720, loss = 0.00161393
I0302 10:37:28.740514 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00161393 (* 1 = 0.00161393 loss)
I0302 10:37:28.740522 29253 sgd_solver.cpp:106] Iteration 22720, lr = 0.0001
I0302 10:37:57.637234 29253 solver.cpp:237] Iteration 22740, loss = 0.00179182
I0302 10:37:57.637266 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00179182 (* 1 = 0.00179182 loss)
I0302 10:37:57.637275 29253 sgd_solver.cpp:106] Iteration 22740, lr = 0.0001
I0302 10:38:26.668236 29253 solver.cpp:237] Iteration 22760, loss = 0.00200029
I0302 10:38:26.668267 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00200029 (* 1 = 0.00200029 loss)
I0302 10:38:26.668274 29253 sgd_solver.cpp:106] Iteration 22760, lr = 0.0001
I0302 10:38:55.373078 29253 solver.cpp:237] Iteration 22780, loss = 0.0014377
I0302 10:38:55.373111 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0014377 (* 1 = 0.0014377 loss)
I0302 10:38:55.373119 29253 sgd_solver.cpp:106] Iteration 22780, lr = 0.0001
I0302 10:39:24.311425 29253 solver.cpp:237] Iteration 22800, loss = 0.00168074
I0302 10:39:24.311456 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00168074 (* 1 = 0.00168074 loss)
I0302 10:39:24.311465 29253 sgd_solver.cpp:106] Iteration 22800, lr = 0.0001
I0302 10:39:53.339962 29253 solver.cpp:237] Iteration 22820, loss = 0.00157795
I0302 10:39:53.339993 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00157795 (* 1 = 0.00157795 loss)
I0302 10:39:53.340003 29253 sgd_solver.cpp:106] Iteration 22820, lr = 0.0001
I0302 10:40:22.365321 29253 solver.cpp:237] Iteration 22840, loss = 0.0015909
I0302 10:40:22.365355 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0015909 (* 1 = 0.0015909 loss)
I0302 10:40:22.365362 29253 sgd_solver.cpp:106] Iteration 22840, lr = 0.0001
I0302 10:40:51.370081 29253 solver.cpp:237] Iteration 22860, loss = 0.00140557
I0302 10:40:51.370112 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00140557 (* 1 = 0.00140557 loss)
I0302 10:40:51.370121 29253 sgd_solver.cpp:106] Iteration 22860, lr = 0.0001
I0302 10:41:20.341624 29253 solver.cpp:237] Iteration 22880, loss = 0.00176335
I0302 10:41:20.341655 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00176335 (* 1 = 0.00176335 loss)
I0302 10:41:20.341665 29253 sgd_solver.cpp:106] Iteration 22880, lr = 0.0001
I0302 10:41:49.256366 29253 solver.cpp:237] Iteration 22900, loss = 0.00134546
I0302 10:41:49.256398 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00134546 (* 1 = 0.00134546 loss)
I0302 10:41:49.256407 29253 sgd_solver.cpp:106] Iteration 22900, lr = 0.0001
I0302 10:42:18.009603 29253 solver.cpp:237] Iteration 22920, loss = 0.00152913
I0302 10:42:18.009634 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00152913 (* 1 = 0.00152913 loss)
I0302 10:42:18.009642 29253 sgd_solver.cpp:106] Iteration 22920, lr = 0.0001
I0302 10:42:47.053980 29253 solver.cpp:237] Iteration 22940, loss = 0.00133823
I0302 10:42:47.054013 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00133823 (* 1 = 0.00133823 loss)
I0302 10:42:47.054020 29253 sgd_solver.cpp:106] Iteration 22940, lr = 0.0001
I0302 10:43:15.798244 29253 solver.cpp:237] Iteration 22960, loss = 0.00187939
I0302 10:43:15.798277 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0018794 (* 1 = 0.0018794 loss)
I0302 10:43:15.798286 29253 sgd_solver.cpp:106] Iteration 22960, lr = 0.0001
I0302 10:43:44.741350 29253 solver.cpp:237] Iteration 22980, loss = 0.0015839
I0302 10:43:44.741384 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00158391 (* 1 = 0.00158391 loss)
I0302 10:43:44.741392 29253 sgd_solver.cpp:106] Iteration 22980, lr = 0.0001
I0302 10:44:13.593703 29253 solver.cpp:237] Iteration 23000, loss = 0.00163815
I0302 10:44:13.593735 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00163816 (* 1 = 0.00163816 loss)
I0302 10:44:13.593745 29253 sgd_solver.cpp:106] Iteration 23000, lr = 0.0001
I0302 10:44:27.806535 29253 blocking_queue.cpp:50] Data layer prefetch queue empty
I0302 10:44:42.258469 29253 solver.cpp:237] Iteration 23020, loss = 0.00177797
I0302 10:44:42.258501 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00177798 (* 1 = 0.00177798 loss)
I0302 10:44:42.258508 29253 sgd_solver.cpp:106] Iteration 23020, lr = 0.0001
I0302 10:45:11.255928 29253 solver.cpp:237] Iteration 23040, loss = 0.00132845
I0302 10:45:11.255959 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00132845 (* 1 = 0.00132845 loss)
I0302 10:45:11.255967 29253 sgd_solver.cpp:106] Iteration 23040, lr = 0.0001
I0302 10:45:40.011059 29253 solver.cpp:237] Iteration 23060, loss = 0.00170996
I0302 10:45:40.011091 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00170997 (* 1 = 0.00170997 loss)
I0302 10:45:40.011099 29253 sgd_solver.cpp:106] Iteration 23060, lr = 0.0001
I0302 10:46:08.902282 29253 solver.cpp:237] Iteration 23080, loss = 0.00167923
I0302 10:46:08.902312 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00167923 (* 1 = 0.00167923 loss)
I0302 10:46:08.902323 29253 sgd_solver.cpp:106] Iteration 23080, lr = 0.0001
I0302 10:46:37.653218 29253 solver.cpp:237] Iteration 23100, loss = 0.00146684
I0302 10:46:37.653249 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00146684 (* 1 = 0.00146684 loss)
I0302 10:46:37.653259 29253 sgd_solver.cpp:106] Iteration 23100, lr = 0.0001
I0302 10:47:06.656342 29253 solver.cpp:237] Iteration 23120, loss = 0.00135273
I0302 10:47:06.656373 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00135273 (* 1 = 0.00135273 loss)
I0302 10:47:06.656383 29253 sgd_solver.cpp:106] Iteration 23120, lr = 0.0001
I0302 10:47:35.421794 29253 solver.cpp:237] Iteration 23140, loss = 0.00131962
I0302 10:47:35.421825 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00131963 (* 1 = 0.00131963 loss)
I0302 10:47:35.421833 29253 sgd_solver.cpp:106] Iteration 23140, lr = 0.0001
I0302 10:48:04.374594 29253 solver.cpp:237] Iteration 23160, loss = 0.00285463
I0302 10:48:04.374629 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00285464 (* 1 = 0.00285464 loss)
I0302 10:48:04.374639 29253 sgd_solver.cpp:106] Iteration 23160, lr = 0.0001
I0302 10:48:33.041195 29253 solver.cpp:237] Iteration 23180, loss = 0.0013731
I0302 10:48:33.041226 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0013731 (* 1 = 0.0013731 loss)
I0302 10:48:33.041235 29253 sgd_solver.cpp:106] Iteration 23180, lr = 0.0001
I0302 10:49:01.776314 29253 solver.cpp:237] Iteration 23200, loss = 0.00171856
I0302 10:49:01.776346 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00171857 (* 1 = 0.00171857 loss)
I0302 10:49:01.776355 29253 sgd_solver.cpp:106] Iteration 23200, lr = 0.0001
I0302 10:49:30.657961 29253 solver.cpp:237] Iteration 23220, loss = 0.00178486
I0302 10:49:30.657992 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00178486 (* 1 = 0.00178486 loss)
I0302 10:49:30.658001 29253 sgd_solver.cpp:106] Iteration 23220, lr = 0.0001
I0302 10:49:59.769300 29253 solver.cpp:237] Iteration 23240, loss = 0.00125721
I0302 10:49:59.769337 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00125722 (* 1 = 0.00125722 loss)
I0302 10:49:59.769347 29253 sgd_solver.cpp:106] Iteration 23240, lr = 0.0001
I0302 10:50:28.783553 29253 solver.cpp:237] Iteration 23260, loss = 0.00154376
I0302 10:50:28.783584 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00154377 (* 1 = 0.00154377 loss)
I0302 10:50:28.783592 29253 sgd_solver.cpp:106] Iteration 23260, lr = 0.0001
I0302 10:50:57.588726 29253 solver.cpp:237] Iteration 23280, loss = 0.00141488
I0302 10:50:57.588758 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00141488 (* 1 = 0.00141488 loss)
I0302 10:50:57.588767 29253 sgd_solver.cpp:106] Iteration 23280, lr = 0.0001
I0302 10:51:26.540532 29253 solver.cpp:237] Iteration 23300, loss = 0.00150967
I0302 10:51:26.540563 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00150968 (* 1 = 0.00150968 loss)
I0302 10:51:26.540572 29253 sgd_solver.cpp:106] Iteration 23300, lr = 0.0001
I0302 10:51:55.590134 29253 solver.cpp:237] Iteration 23320, loss = 0.00146622
I0302 10:51:55.590167 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00146622 (* 1 = 0.00146622 loss)
I0302 10:51:55.590175 29253 sgd_solver.cpp:106] Iteration 23320, lr = 0.0001
I0302 10:52:24.283949 29253 solver.cpp:237] Iteration 23340, loss = 0.00173505
I0302 10:52:24.283982 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00173506 (* 1 = 0.00173506 loss)
I0302 10:52:24.283990 29253 sgd_solver.cpp:106] Iteration 23340, lr = 0.0001
I0302 10:52:53.251919 29253 solver.cpp:237] Iteration 23360, loss = 0.00229571
I0302 10:52:53.251952 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00229572 (* 1 = 0.00229572 loss)
I0302 10:52:53.251960 29253 sgd_solver.cpp:106] Iteration 23360, lr = 0.0001
I0302 10:53:22.353119 29253 solver.cpp:237] Iteration 23380, loss = 0.00158705
I0302 10:53:22.353153 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00158706 (* 1 = 0.00158706 loss)
I0302 10:53:22.353163 29253 sgd_solver.cpp:106] Iteration 23380, lr = 0.0001
I0302 10:53:51.151165 29253 solver.cpp:237] Iteration 23400, loss = 0.0015074
I0302 10:53:51.151197 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00150741 (* 1 = 0.00150741 loss)
I0302 10:53:51.151206 29253 sgd_solver.cpp:106] Iteration 23400, lr = 0.0001
I0302 10:54:19.969846 29253 solver.cpp:237] Iteration 23420, loss = 0.00170241
I0302 10:54:19.969877 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00170241 (* 1 = 0.00170241 loss)
I0302 10:54:19.969885 29253 sgd_solver.cpp:106] Iteration 23420, lr = 0.0001
I0302 10:54:48.809928 29253 solver.cpp:237] Iteration 23440, loss = 0.00151039
I0302 10:54:48.809962 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00151039 (* 1 = 0.00151039 loss)
I0302 10:54:48.809972 29253 sgd_solver.cpp:106] Iteration 23440, lr = 0.0001
I0302 10:55:17.869736 29253 solver.cpp:237] Iteration 23460, loss = 0.00118056
I0302 10:55:17.869771 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00118056 (* 1 = 0.00118056 loss)
I0302 10:55:17.869781 29253 sgd_solver.cpp:106] Iteration 23460, lr = 0.0001
I0302 10:55:49.941949 29253 solver.cpp:237] Iteration 23480, loss = 0.00154454
I0302 10:55:49.941980 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00154454 (* 1 = 0.00154454 loss)
I0302 10:55:49.941990 29253 sgd_solver.cpp:106] Iteration 23480, lr = 0.0001
I0302 10:56:18.674948 29253 solver.cpp:237] Iteration 23500, loss = 0.00141864
I0302 10:56:18.674981 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00141865 (* 1 = 0.00141865 loss)
I0302 10:56:18.674989 29253 sgd_solver.cpp:106] Iteration 23500, lr = 0.0001
I0302 10:56:47.692073 29253 solver.cpp:237] Iteration 23520, loss = 0.00129675
I0302 10:56:47.692104 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00129675 (* 1 = 0.00129675 loss)
I0302 10:56:47.692113 29253 sgd_solver.cpp:106] Iteration 23520, lr = 0.0001
I0302 10:57:16.743206 29253 solver.cpp:237] Iteration 23540, loss = 0.0017111
I0302 10:57:16.743237 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00171111 (* 1 = 0.00171111 loss)
I0302 10:57:16.743245 29253 sgd_solver.cpp:106] Iteration 23540, lr = 0.0001
I0302 10:57:45.562206 29253 solver.cpp:237] Iteration 23560, loss = 0.00158581
I0302 10:57:45.562237 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00158582 (* 1 = 0.00158582 loss)
I0302 10:57:45.562245 29253 sgd_solver.cpp:106] Iteration 23560, lr = 0.0001
I0302 10:58:14.531657 29253 solver.cpp:237] Iteration 23580, loss = 0.00138219
I0302 10:58:14.531689 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0013822 (* 1 = 0.0013822 loss)
I0302 10:58:14.531697 29253 sgd_solver.cpp:106] Iteration 23580, lr = 0.0001
I0302 10:58:43.474897 29253 solver.cpp:237] Iteration 23600, loss = 0.00187858
I0302 10:58:43.474931 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00187859 (* 1 = 0.00187859 loss)
I0302 10:58:43.474938 29253 sgd_solver.cpp:106] Iteration 23600, lr = 0.0001
I0302 10:59:12.292544 29253 solver.cpp:237] Iteration 23620, loss = 0.00171637
I0302 10:59:12.292575 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00171637 (* 1 = 0.00171637 loss)
I0302 10:59:12.292584 29253 sgd_solver.cpp:106] Iteration 23620, lr = 0.0001
I0302 10:59:41.199663 29253 solver.cpp:237] Iteration 23640, loss = 0.00147339
I0302 10:59:41.199697 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00147339 (* 1 = 0.00147339 loss)
I0302 10:59:41.199704 29253 sgd_solver.cpp:106] Iteration 23640, lr = 0.0001
I0302 11:00:10.303148 29253 solver.cpp:237] Iteration 23660, loss = 0.00143384
I0302 11:00:10.303180 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00143384 (* 1 = 0.00143384 loss)
I0302 11:00:10.303189 29253 sgd_solver.cpp:106] Iteration 23660, lr = 0.0001
I0302 11:00:39.019654 29253 solver.cpp:237] Iteration 23680, loss = 0.0014948
I0302 11:00:39.019686 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00149481 (* 1 = 0.00149481 loss)
I0302 11:00:39.019695 29253 sgd_solver.cpp:106] Iteration 23680, lr = 0.0001
I0302 11:01:08.010361 29253 solver.cpp:237] Iteration 23700, loss = 0.002086
I0302 11:01:08.010393 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.002086 (* 1 = 0.002086 loss)
I0302 11:01:08.010401 29253 sgd_solver.cpp:106] Iteration 23700, lr = 0.0001
I0302 11:01:36.792712 29253 solver.cpp:237] Iteration 23720, loss = 0.00135066
I0302 11:01:36.792744 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00135067 (* 1 = 0.00135067 loss)
I0302 11:01:36.792753 29253 sgd_solver.cpp:106] Iteration 23720, lr = 0.0001
I0302 11:02:05.801010 29253 solver.cpp:237] Iteration 23740, loss = 0.0016568
I0302 11:02:05.801043 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0016568 (* 1 = 0.0016568 loss)
I0302 11:02:05.801053 29253 sgd_solver.cpp:106] Iteration 23740, lr = 0.0001
I0302 11:02:34.754170 29253 solver.cpp:237] Iteration 23760, loss = 0.00172597
I0302 11:02:34.754204 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00172597 (* 1 = 0.00172597 loss)
I0302 11:02:34.754211 29253 sgd_solver.cpp:106] Iteration 23760, lr = 0.0001
I0302 11:03:03.484529 29253 solver.cpp:237] Iteration 23780, loss = 0.00160888
I0302 11:03:03.484560 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00160888 (* 1 = 0.00160888 loss)
I0302 11:03:03.484570 29253 sgd_solver.cpp:106] Iteration 23780, lr = 0.0001
I0302 11:03:32.290918 29253 solver.cpp:237] Iteration 23800, loss = 0.00160375
I0302 11:03:32.290951 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00160376 (* 1 = 0.00160376 loss)
I0302 11:03:32.290959 29253 sgd_solver.cpp:106] Iteration 23800, lr = 0.0001
I0302 11:04:01.155381 29253 solver.cpp:237] Iteration 23820, loss = 0.00167407
I0302 11:04:01.155412 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00167407 (* 1 = 0.00167407 loss)
I0302 11:04:01.155421 29253 sgd_solver.cpp:106] Iteration 23820, lr = 0.0001
I0302 11:04:30.164778 29253 solver.cpp:237] Iteration 23840, loss = 0.0015139
I0302 11:04:30.164813 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0015139 (* 1 = 0.0015139 loss)
I0302 11:04:30.164821 29253 sgd_solver.cpp:106] Iteration 23840, lr = 0.0001
I0302 11:04:59.125273 29253 solver.cpp:237] Iteration 23860, loss = 0.00131583
I0302 11:04:59.125306 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00131583 (* 1 = 0.00131583 loss)
I0302 11:04:59.125315 29253 sgd_solver.cpp:106] Iteration 23860, lr = 0.0001
I0302 11:05:28.139619 29253 solver.cpp:237] Iteration 23880, loss = 0.00185729
I0302 11:05:28.139652 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0018573 (* 1 = 0.0018573 loss)
I0302 11:05:28.139660 29253 sgd_solver.cpp:106] Iteration 23880, lr = 0.0001
I0302 11:05:56.953023 29253 solver.cpp:237] Iteration 23900, loss = 0.00156796
I0302 11:05:56.953058 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00156796 (* 1 = 0.00156796 loss)
I0302 11:05:56.953066 29253 sgd_solver.cpp:106] Iteration 23900, lr = 0.0001
I0302 11:06:25.819936 29253 solver.cpp:237] Iteration 23920, loss = 0.00143532
I0302 11:06:25.819968 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00143533 (* 1 = 0.00143533 loss)
I0302 11:06:25.819977 29253 sgd_solver.cpp:106] Iteration 23920, lr = 0.0001
I0302 11:06:54.847280 29253 solver.cpp:237] Iteration 23940, loss = 0.00140451
I0302 11:06:54.847314 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00140452 (* 1 = 0.00140452 loss)
I0302 11:06:54.847324 29253 sgd_solver.cpp:106] Iteration 23940, lr = 0.0001
I0302 11:07:23.933682 29253 solver.cpp:237] Iteration 23960, loss = 0.00159108
I0302 11:07:23.933715 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00159108 (* 1 = 0.00159108 loss)
I0302 11:07:23.933723 29253 sgd_solver.cpp:106] Iteration 23960, lr = 0.0001
I0302 11:07:52.842053 29253 solver.cpp:237] Iteration 23980, loss = 0.00165045
I0302 11:07:52.842085 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00165045 (* 1 = 0.00165045 loss)
I0302 11:07:52.842094 29253 sgd_solver.cpp:106] Iteration 23980, lr = 0.0001
I0302 11:08:21.520109 29253 solver.cpp:237] Iteration 24000, loss = 0.00165403
I0302 11:08:21.520143 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00165403 (* 1 = 0.00165403 loss)
I0302 11:08:21.520151 29253 sgd_solver.cpp:106] Iteration 24000, lr = 0.0001
I0302 11:08:36.045138 29253 blocking_queue.cpp:50] Data layer prefetch queue empty
I0302 11:08:50.582573 29253 solver.cpp:237] Iteration 24020, loss = 0.00146433
I0302 11:08:50.582607 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00146434 (* 1 = 0.00146434 loss)
I0302 11:08:50.582615 29253 sgd_solver.cpp:106] Iteration 24020, lr = 0.0001
I0302 11:09:19.534544 29253 solver.cpp:237] Iteration 24040, loss = 0.00122073
I0302 11:09:19.534574 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00122073 (* 1 = 0.00122073 loss)
I0302 11:09:19.534584 29253 sgd_solver.cpp:106] Iteration 24040, lr = 0.0001
I0302 11:09:48.592013 29253 solver.cpp:237] Iteration 24060, loss = 0.00178941
I0302 11:09:48.592044 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00178941 (* 1 = 0.00178941 loss)
I0302 11:09:48.592053 29253 sgd_solver.cpp:106] Iteration 24060, lr = 0.0001
I0302 11:10:17.157891 29253 solver.cpp:237] Iteration 24080, loss = 0.00156914
I0302 11:10:17.157924 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00156914 (* 1 = 0.00156914 loss)
I0302 11:10:17.157933 29253 sgd_solver.cpp:106] Iteration 24080, lr = 0.0001
I0302 11:10:46.184425 29253 solver.cpp:237] Iteration 24100, loss = 0.00164185
I0302 11:10:46.184459 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00164185 (* 1 = 0.00164185 loss)
I0302 11:10:46.184468 29253 sgd_solver.cpp:106] Iteration 24100, lr = 0.0001
I0302 11:11:14.881873 29253 solver.cpp:237] Iteration 24120, loss = 0.00156571
I0302 11:11:14.881907 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00156571 (* 1 = 0.00156571 loss)
I0302 11:11:14.881916 29253 sgd_solver.cpp:106] Iteration 24120, lr = 0.0001
I0302 11:11:43.766674 29253 solver.cpp:237] Iteration 24140, loss = 0.00172597
I0302 11:11:43.766706 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00172597 (* 1 = 0.00172597 loss)
I0302 11:11:43.766716 29253 sgd_solver.cpp:106] Iteration 24140, lr = 0.0001
I0302 11:12:12.651062 29253 solver.cpp:237] Iteration 24160, loss = 0.00160452
I0302 11:12:12.651095 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00160452 (* 1 = 0.00160452 loss)
I0302 11:12:12.651105 29253 sgd_solver.cpp:106] Iteration 24160, lr = 0.0001
I0302 11:12:41.675011 29253 solver.cpp:237] Iteration 24180, loss = 0.00124864
I0302 11:12:41.675047 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00124864 (* 1 = 0.00124864 loss)
I0302 11:12:41.675057 29253 sgd_solver.cpp:106] Iteration 24180, lr = 0.0001
I0302 11:13:10.262890 29253 solver.cpp:237] Iteration 24200, loss = 0.00157427
I0302 11:13:10.262923 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00157427 (* 1 = 0.00157427 loss)
I0302 11:13:10.262931 29253 sgd_solver.cpp:106] Iteration 24200, lr = 0.0001
I0302 11:13:39.234921 29253 solver.cpp:237] Iteration 24220, loss = 0.00183347
I0302 11:13:39.234954 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00183347 (* 1 = 0.00183347 loss)
I0302 11:13:39.234964 29253 sgd_solver.cpp:106] Iteration 24220, lr = 0.0001
I0302 11:14:08.231984 29253 solver.cpp:237] Iteration 24240, loss = 0.00158445
I0302 11:14:08.232019 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00158446 (* 1 = 0.00158446 loss)
I0302 11:14:08.232028 29253 sgd_solver.cpp:106] Iteration 24240, lr = 0.0001
I0302 11:14:37.096848 29253 solver.cpp:237] Iteration 24260, loss = 0.0017383
I0302 11:14:37.096881 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0017383 (* 1 = 0.0017383 loss)
I0302 11:14:37.096890 29253 sgd_solver.cpp:106] Iteration 24260, lr = 0.0001
I0302 11:15:05.887780 29253 solver.cpp:237] Iteration 24280, loss = 0.00150848
I0302 11:15:05.887811 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00150848 (* 1 = 0.00150848 loss)
I0302 11:15:05.887820 29253 sgd_solver.cpp:106] Iteration 24280, lr = 0.0001
I0302 11:15:35.000474 29253 solver.cpp:237] Iteration 24300, loss = 0.00168733
I0302 11:15:35.000506 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00168733 (* 1 = 0.00168733 loss)
I0302 11:15:35.000515 29253 sgd_solver.cpp:106] Iteration 24300, lr = 0.0001
I0302 11:16:03.871737 29253 solver.cpp:237] Iteration 24320, loss = 0.00185989
I0302 11:16:03.871768 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00185989 (* 1 = 0.00185989 loss)
I0302 11:16:03.871778 29253 sgd_solver.cpp:106] Iteration 24320, lr = 0.0001
I0302 11:16:32.764277 29253 solver.cpp:237] Iteration 24340, loss = 0.00190113
I0302 11:16:32.764309 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00190113 (* 1 = 0.00190113 loss)
I0302 11:16:32.764317 29253 sgd_solver.cpp:106] Iteration 24340, lr = 0.0001
I0302 11:17:01.615891 29253 solver.cpp:237] Iteration 24360, loss = 0.00153136
I0302 11:17:01.615923 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00153136 (* 1 = 0.00153136 loss)
I0302 11:17:01.615931 29253 sgd_solver.cpp:106] Iteration 24360, lr = 0.0001
I0302 11:17:31.003793 29253 solver.cpp:237] Iteration 24380, loss = 0.00172554
I0302 11:17:31.003826 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00172555 (* 1 = 0.00172555 loss)
I0302 11:17:31.003835 29253 sgd_solver.cpp:106] Iteration 24380, lr = 0.0001
I0302 11:18:00.005419 29253 solver.cpp:237] Iteration 24400, loss = 0.00176446
I0302 11:18:00.005452 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00176446 (* 1 = 0.00176446 loss)
I0302 11:18:00.005462 29253 sgd_solver.cpp:106] Iteration 24400, lr = 0.0001
I0302 11:18:29.092605 29253 solver.cpp:237] Iteration 24420, loss = 0.00141369
I0302 11:18:29.092638 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0014137 (* 1 = 0.0014137 loss)
I0302 11:18:29.092646 29253 sgd_solver.cpp:106] Iteration 24420, lr = 0.0001
I0302 11:18:58.065377 29253 solver.cpp:237] Iteration 24440, loss = 0.00168669
I0302 11:18:58.065409 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00168669 (* 1 = 0.00168669 loss)
I0302 11:18:58.065418 29253 sgd_solver.cpp:106] Iteration 24440, lr = 0.0001
I0302 11:19:26.820837 29253 solver.cpp:237] Iteration 24460, loss = 0.00140238
I0302 11:19:26.820869 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00140238 (* 1 = 0.00140238 loss)
I0302 11:19:26.820878 29253 sgd_solver.cpp:106] Iteration 24460, lr = 0.0001
I0302 11:19:56.094537 29253 solver.cpp:237] Iteration 24480, loss = 0.00147703
I0302 11:19:56.094570 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00147703 (* 1 = 0.00147703 loss)
I0302 11:19:56.094579 29253 sgd_solver.cpp:106] Iteration 24480, lr = 0.0001
I0302 11:20:25.169948 29253 solver.cpp:237] Iteration 24500, loss = 0.00121682
I0302 11:20:25.169981 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00121683 (* 1 = 0.00121683 loss)
I0302 11:20:25.169989 29253 sgd_solver.cpp:106] Iteration 24500, lr = 0.0001
I0302 11:20:54.023825 29253 solver.cpp:237] Iteration 24520, loss = 0.00152689
I0302 11:20:54.023859 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00152689 (* 1 = 0.00152689 loss)
I0302 11:20:54.023869 29253 sgd_solver.cpp:106] Iteration 24520, lr = 0.0001
I0302 11:21:22.994411 29253 solver.cpp:237] Iteration 24540, loss = 0.00147798
I0302 11:21:22.994443 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00147798 (* 1 = 0.00147798 loss)
I0302 11:21:22.994452 29253 sgd_solver.cpp:106] Iteration 24540, lr = 0.0001
I0302 11:21:51.775526 29253 solver.cpp:237] Iteration 24560, loss = 0.00184898
I0302 11:21:51.775557 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00184898 (* 1 = 0.00184898 loss)
I0302 11:21:51.775566 29253 sgd_solver.cpp:106] Iteration 24560, lr = 0.0001
I0302 11:22:20.671177 29253 solver.cpp:237] Iteration 24580, loss = 0.00161437
I0302 11:22:20.671210 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00161438 (* 1 = 0.00161438 loss)
I0302 11:22:20.671218 29253 sgd_solver.cpp:106] Iteration 24580, lr = 0.0001
I0302 11:22:49.603209 29253 solver.cpp:237] Iteration 24600, loss = 0.00221913
I0302 11:22:49.603240 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00221913 (* 1 = 0.00221913 loss)
I0302 11:22:49.603247 29253 sgd_solver.cpp:106] Iteration 24600, lr = 0.0001
I0302 11:23:18.522683 29253 solver.cpp:237] Iteration 24620, loss = 0.00176286
I0302 11:23:18.522716 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00176287 (* 1 = 0.00176287 loss)
I0302 11:23:18.522723 29253 sgd_solver.cpp:106] Iteration 24620, lr = 0.0001
I0302 11:23:47.554359 29253 solver.cpp:237] Iteration 24640, loss = 0.00140886
I0302 11:23:47.554399 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00140886 (* 1 = 0.00140886 loss)
I0302 11:23:47.554409 29253 sgd_solver.cpp:106] Iteration 24640, lr = 0.0001
I0302 11:24:16.517596 29253 solver.cpp:237] Iteration 24660, loss = 0.00225072
I0302 11:24:16.517627 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00225072 (* 1 = 0.00225072 loss)
I0302 11:24:16.517635 29253 sgd_solver.cpp:106] Iteration 24660, lr = 0.0001
I0302 11:24:45.328407 29253 solver.cpp:237] Iteration 24680, loss = 0.00182174
I0302 11:24:45.328439 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00182174 (* 1 = 0.00182174 loss)
I0302 11:24:45.328449 29253 sgd_solver.cpp:106] Iteration 24680, lr = 0.0001
I0302 11:25:14.257392 29253 solver.cpp:237] Iteration 24700, loss = 0.00132446
I0302 11:25:14.257424 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00132447 (* 1 = 0.00132447 loss)
I0302 11:25:14.257437 29253 sgd_solver.cpp:106] Iteration 24700, lr = 0.0001
I0302 11:25:43.109966 29253 solver.cpp:237] Iteration 24720, loss = 0.00123519
I0302 11:25:43.109998 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00123519 (* 1 = 0.00123519 loss)
I0302 11:25:43.110007 29253 sgd_solver.cpp:106] Iteration 24720, lr = 0.0001
I0302 11:26:12.045536 29253 solver.cpp:237] Iteration 24740, loss = 0.00227121
I0302 11:26:12.045569 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00227121 (* 1 = 0.00227121 loss)
I0302 11:26:12.045578 29253 sgd_solver.cpp:106] Iteration 24740, lr = 0.0001
I0302 11:26:40.930212 29253 solver.cpp:237] Iteration 24760, loss = 0.00195662
I0302 11:26:40.930246 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00195663 (* 1 = 0.00195663 loss)
I0302 11:26:40.930255 29253 sgd_solver.cpp:106] Iteration 24760, lr = 0.0001
I0302 11:27:09.769130 29253 solver.cpp:237] Iteration 24780, loss = 0.00141552
I0302 11:27:09.769162 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00141552 (* 1 = 0.00141552 loss)
I0302 11:27:09.769171 29253 sgd_solver.cpp:106] Iteration 24780, lr = 0.0001
I0302 11:27:38.523653 29253 solver.cpp:237] Iteration 24800, loss = 0.00139094
I0302 11:27:38.523686 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00139094 (* 1 = 0.00139094 loss)
I0302 11:27:38.523695 29253 sgd_solver.cpp:106] Iteration 24800, lr = 0.0001
I0302 11:28:07.274792 29253 solver.cpp:237] Iteration 24820, loss = 0.00173601
I0302 11:28:07.274824 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00173601 (* 1 = 0.00173601 loss)
I0302 11:28:07.274833 29253 sgd_solver.cpp:106] Iteration 24820, lr = 0.0001
I0302 11:28:36.412947 29253 solver.cpp:237] Iteration 24840, loss = 0.00193083
I0302 11:28:36.412979 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00193083 (* 1 = 0.00193083 loss)
I0302 11:28:36.412988 29253 sgd_solver.cpp:106] Iteration 24840, lr = 0.0001
I0302 11:29:05.397833 29253 solver.cpp:237] Iteration 24860, loss = 0.00175445
I0302 11:29:05.397866 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00175445 (* 1 = 0.00175445 loss)
I0302 11:29:05.397876 29253 sgd_solver.cpp:106] Iteration 24860, lr = 0.0001
I0302 11:29:34.462889 29253 solver.cpp:237] Iteration 24880, loss = 0.00118006
I0302 11:29:34.462923 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00118006 (* 1 = 0.00118006 loss)
I0302 11:29:34.462931 29253 sgd_solver.cpp:106] Iteration 24880, lr = 0.0001
I0302 11:30:03.372459 29253 solver.cpp:237] Iteration 24900, loss = 0.00153686
I0302 11:30:03.372490 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00153686 (* 1 = 0.00153686 loss)
I0302 11:30:03.372499 29253 sgd_solver.cpp:106] Iteration 24900, lr = 0.0001
I0302 11:30:32.222334 29253 solver.cpp:237] Iteration 24920, loss = 0.00189156
I0302 11:30:32.222365 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00189156 (* 1 = 0.00189156 loss)
I0302 11:30:32.222373 29253 sgd_solver.cpp:106] Iteration 24920, lr = 0.0001
I0302 11:31:01.147634 29253 solver.cpp:237] Iteration 24940, loss = 0.00154987
I0302 11:31:01.147665 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00154987 (* 1 = 0.00154987 loss)
I0302 11:31:01.147675 29253 sgd_solver.cpp:106] Iteration 24940, lr = 0.0001
I0302 11:31:30.063338 29253 solver.cpp:237] Iteration 24960, loss = 0.00145351
I0302 11:31:30.063370 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00145351 (* 1 = 0.00145351 loss)
I0302 11:31:30.063380 29253 sgd_solver.cpp:106] Iteration 24960, lr = 0.0001
I0302 11:31:58.974362 29253 solver.cpp:237] Iteration 24980, loss = 0.00150958
I0302 11:31:58.974397 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00150959 (* 1 = 0.00150959 loss)
I0302 11:31:58.974407 29253 sgd_solver.cpp:106] Iteration 24980, lr = 0.0001
I0302 11:32:26.424825 29253 solver.cpp:459] Snapshotting to binary proto file /nfs.yoda/xiaolonw/fast_rcnn/models_sunrgbd/pre_cls_1fc_scratch/model__iter_25000.caffemodel
I0302 11:32:27.046185 29253 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /nfs.yoda/xiaolonw/fast_rcnn/models_sunrgbd/pre_cls_1fc_scratch/model__iter_25000.solverstate
I0302 11:32:27.935662 29253 solver.cpp:237] Iteration 25000, loss = 0.00156281
I0302 11:32:27.935694 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00156281 (* 1 = 0.00156281 loss)
I0302 11:32:27.935703 29253 sgd_solver.cpp:106] Iteration 25000, lr = 0.0001
I0302 11:32:42.450207 29253 blocking_queue.cpp:50] Data layer prefetch queue empty
I0302 11:32:57.062984 29253 solver.cpp:237] Iteration 25020, loss = 0.00199571
I0302 11:32:57.063020 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00199571 (* 1 = 0.00199571 loss)
I0302 11:32:57.063030 29253 sgd_solver.cpp:106] Iteration 25020, lr = 0.0001
I0302 11:33:25.886960 29253 solver.cpp:237] Iteration 25040, loss = 0.00138137
I0302 11:33:25.886997 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00138138 (* 1 = 0.00138138 loss)
I0302 11:33:25.887006 29253 sgd_solver.cpp:106] Iteration 25040, lr = 0.0001
I0302 11:33:54.721514 29253 solver.cpp:237] Iteration 25060, loss = 0.00119116
I0302 11:33:54.721546 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00119116 (* 1 = 0.00119116 loss)
I0302 11:33:54.721554 29253 sgd_solver.cpp:106] Iteration 25060, lr = 0.0001
I0302 11:34:23.526463 29253 solver.cpp:237] Iteration 25080, loss = 0.00157227
I0302 11:34:23.526495 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00157227 (* 1 = 0.00157227 loss)
I0302 11:34:23.526504 29253 sgd_solver.cpp:106] Iteration 25080, lr = 0.0001
I0302 11:34:52.554082 29253 solver.cpp:237] Iteration 25100, loss = 0.00178505
I0302 11:34:52.554114 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00178506 (* 1 = 0.00178506 loss)
I0302 11:34:52.554123 29253 sgd_solver.cpp:106] Iteration 25100, lr = 0.0001
I0302 11:35:21.604934 29253 solver.cpp:237] Iteration 25120, loss = 0.001466
I0302 11:35:21.604969 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.001466 (* 1 = 0.001466 loss)
I0302 11:35:21.604976 29253 sgd_solver.cpp:106] Iteration 25120, lr = 0.0001
I0302 11:35:50.669945 29253 solver.cpp:237] Iteration 25140, loss = 0.00144163
I0302 11:35:50.669978 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00144164 (* 1 = 0.00144164 loss)
I0302 11:35:50.669986 29253 sgd_solver.cpp:106] Iteration 25140, lr = 0.0001
I0302 11:36:19.681982 29253 solver.cpp:237] Iteration 25160, loss = 0.00166611
I0302 11:36:19.682013 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00166611 (* 1 = 0.00166611 loss)
I0302 11:36:19.682023 29253 sgd_solver.cpp:106] Iteration 25160, lr = 0.0001
I0302 11:36:48.368387 29253 solver.cpp:237] Iteration 25180, loss = 0.0017178
I0302 11:36:48.368420 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0017178 (* 1 = 0.0017178 loss)
I0302 11:36:48.368429 29253 sgd_solver.cpp:106] Iteration 25180, lr = 0.0001
I0302 11:37:17.497838 29253 solver.cpp:237] Iteration 25200, loss = 0.00155807
I0302 11:37:17.497869 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00155807 (* 1 = 0.00155807 loss)
I0302 11:37:17.497879 29253 sgd_solver.cpp:106] Iteration 25200, lr = 0.0001
I0302 11:37:46.488682 29253 solver.cpp:237] Iteration 25220, loss = 0.001618
I0302 11:37:46.488718 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00161801 (* 1 = 0.00161801 loss)
I0302 11:37:46.488725 29253 sgd_solver.cpp:106] Iteration 25220, lr = 0.0001
I0302 11:38:15.577419 29253 solver.cpp:237] Iteration 25240, loss = 0.00141556
I0302 11:38:15.577450 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00141556 (* 1 = 0.00141556 loss)
I0302 11:38:15.577460 29253 sgd_solver.cpp:106] Iteration 25240, lr = 0.0001
I0302 11:38:44.665088 29253 solver.cpp:237] Iteration 25260, loss = 0.00163432
I0302 11:38:44.665122 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00163433 (* 1 = 0.00163433 loss)
I0302 11:38:44.665130 29253 sgd_solver.cpp:106] Iteration 25260, lr = 0.0001
I0302 11:39:13.611331 29253 solver.cpp:237] Iteration 25280, loss = 0.00169719
I0302 11:39:13.611363 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00169719 (* 1 = 0.00169719 loss)
I0302 11:39:13.611372 29253 sgd_solver.cpp:106] Iteration 25280, lr = 0.0001
I0302 11:39:42.653410 29253 solver.cpp:237] Iteration 25300, loss = 0.00142164
I0302 11:39:42.653442 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00142165 (* 1 = 0.00142165 loss)
I0302 11:39:42.653451 29253 sgd_solver.cpp:106] Iteration 25300, lr = 0.0001
I0302 11:40:11.544059 29253 solver.cpp:237] Iteration 25320, loss = 0.00187347
I0302 11:40:11.544092 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00187348 (* 1 = 0.00187348 loss)
I0302 11:40:11.544101 29253 sgd_solver.cpp:106] Iteration 25320, lr = 0.0001
I0302 11:40:40.250360 29253 solver.cpp:237] Iteration 25340, loss = 0.00156752
I0302 11:40:40.250392 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00156752 (* 1 = 0.00156752 loss)
I0302 11:40:40.250401 29253 sgd_solver.cpp:106] Iteration 25340, lr = 0.0001
I0302 11:41:09.127573 29253 solver.cpp:237] Iteration 25360, loss = 0.00134874
I0302 11:41:09.127606 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00134874 (* 1 = 0.00134874 loss)
I0302 11:41:09.127614 29253 sgd_solver.cpp:106] Iteration 25360, lr = 0.0001
I0302 11:41:38.472807 29253 solver.cpp:237] Iteration 25380, loss = 0.00147466
I0302 11:41:38.472837 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00147466 (* 1 = 0.00147466 loss)
I0302 11:41:38.472846 29253 sgd_solver.cpp:106] Iteration 25380, lr = 0.0001
I0302 11:42:07.512501 29253 solver.cpp:237] Iteration 25400, loss = 0.00151294
I0302 11:42:07.512532 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00151294 (* 1 = 0.00151294 loss)
I0302 11:42:07.512542 29253 sgd_solver.cpp:106] Iteration 25400, lr = 0.0001
I0302 11:42:36.798540 29253 solver.cpp:237] Iteration 25420, loss = 0.00214351
I0302 11:42:36.798573 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00214352 (* 1 = 0.00214352 loss)
I0302 11:42:36.798580 29253 sgd_solver.cpp:106] Iteration 25420, lr = 0.0001
I0302 11:43:05.702806 29253 solver.cpp:237] Iteration 25440, loss = 0.00230908
I0302 11:43:05.702839 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00230908 (* 1 = 0.00230908 loss)
I0302 11:43:05.702847 29253 sgd_solver.cpp:106] Iteration 25440, lr = 0.0001
I0302 11:43:34.719171 29253 solver.cpp:237] Iteration 25460, loss = 0.00146468
I0302 11:43:34.719202 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00146468 (* 1 = 0.00146468 loss)
I0302 11:43:34.719210 29253 sgd_solver.cpp:106] Iteration 25460, lr = 0.0001
I0302 11:44:03.811710 29253 solver.cpp:237] Iteration 25480, loss = 0.00157564
I0302 11:44:03.811745 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00157564 (* 1 = 0.00157564 loss)
I0302 11:44:03.811754 29253 sgd_solver.cpp:106] Iteration 25480, lr = 0.0001
I0302 11:44:32.641857 29253 solver.cpp:237] Iteration 25500, loss = 0.0019743
I0302 11:44:32.641891 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00197431 (* 1 = 0.00197431 loss)
I0302 11:44:32.641901 29253 sgd_solver.cpp:106] Iteration 25500, lr = 0.0001
I0302 11:45:01.586545 29253 solver.cpp:237] Iteration 25520, loss = 0.00143774
I0302 11:45:01.586577 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00143774 (* 1 = 0.00143774 loss)
I0302 11:45:01.586586 29253 sgd_solver.cpp:106] Iteration 25520, lr = 0.0001
I0302 11:45:30.651021 29253 solver.cpp:237] Iteration 25540, loss = 0.0014315
I0302 11:45:30.651060 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0014315 (* 1 = 0.0014315 loss)
I0302 11:45:30.651069 29253 sgd_solver.cpp:106] Iteration 25540, lr = 0.0001
I0302 11:45:59.672430 29253 solver.cpp:237] Iteration 25560, loss = 0.00172139
I0302 11:45:59.672466 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00172139 (* 1 = 0.00172139 loss)
I0302 11:45:59.672476 29253 sgd_solver.cpp:106] Iteration 25560, lr = 0.0001
I0302 11:46:28.726167 29253 solver.cpp:237] Iteration 25580, loss = 0.00167696
I0302 11:46:28.726200 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00167696 (* 1 = 0.00167696 loss)
I0302 11:46:28.726209 29253 sgd_solver.cpp:106] Iteration 25580, lr = 0.0001
I0302 11:46:57.909782 29253 solver.cpp:237] Iteration 25600, loss = 0.00167492
I0302 11:46:57.909816 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00167492 (* 1 = 0.00167492 loss)
I0302 11:46:57.909824 29253 sgd_solver.cpp:106] Iteration 25600, lr = 0.0001
I0302 11:47:26.686194 29253 solver.cpp:237] Iteration 25620, loss = 0.00160512
I0302 11:47:26.686226 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00160513 (* 1 = 0.00160513 loss)
I0302 11:47:26.686235 29253 sgd_solver.cpp:106] Iteration 25620, lr = 0.0001
I0302 11:47:55.448462 29253 solver.cpp:237] Iteration 25640, loss = 0.0014263
I0302 11:47:55.448493 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00142631 (* 1 = 0.00142631 loss)
I0302 11:47:55.448501 29253 sgd_solver.cpp:106] Iteration 25640, lr = 0.0001
I0302 11:48:24.532877 29253 solver.cpp:237] Iteration 25660, loss = 0.00172602
I0302 11:48:24.532915 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00172603 (* 1 = 0.00172603 loss)
I0302 11:48:24.532925 29253 sgd_solver.cpp:106] Iteration 25660, lr = 0.0001
I0302 11:48:53.566550 29253 solver.cpp:237] Iteration 25680, loss = 0.00219428
I0302 11:48:53.566581 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00219428 (* 1 = 0.00219428 loss)
I0302 11:48:53.566591 29253 sgd_solver.cpp:106] Iteration 25680, lr = 0.0001
I0302 11:49:22.465138 29253 solver.cpp:237] Iteration 25700, loss = 0.00171588
I0302 11:49:22.465173 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00171589 (* 1 = 0.00171589 loss)
I0302 11:49:22.465183 29253 sgd_solver.cpp:106] Iteration 25700, lr = 0.0001
I0302 11:49:51.684448 29253 solver.cpp:237] Iteration 25720, loss = 0.00157009
I0302 11:49:51.684483 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00157009 (* 1 = 0.00157009 loss)
I0302 11:49:51.684491 29253 sgd_solver.cpp:106] Iteration 25720, lr = 0.0001
I0302 11:50:20.457000 29253 solver.cpp:237] Iteration 25740, loss = 0.00172733
I0302 11:50:20.457031 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00172733 (* 1 = 0.00172733 loss)
I0302 11:50:20.457041 29253 sgd_solver.cpp:106] Iteration 25740, lr = 0.0001
I0302 11:50:49.511960 29253 solver.cpp:237] Iteration 25760, loss = 0.00139226
I0302 11:50:49.511993 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00139226 (* 1 = 0.00139226 loss)
I0302 11:50:49.512002 29253 sgd_solver.cpp:106] Iteration 25760, lr = 0.0001
I0302 11:51:18.693032 29253 solver.cpp:237] Iteration 25780, loss = 0.00168477
I0302 11:51:18.693063 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00168477 (* 1 = 0.00168477 loss)
I0302 11:51:18.693073 29253 sgd_solver.cpp:106] Iteration 25780, lr = 0.0001
I0302 11:51:47.883005 29253 solver.cpp:237] Iteration 25800, loss = 0.00162102
I0302 11:51:47.883033 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00162102 (* 1 = 0.00162102 loss)
I0302 11:51:47.883043 29253 sgd_solver.cpp:106] Iteration 25800, lr = 0.0001
I0302 11:52:16.972265 29253 solver.cpp:237] Iteration 25820, loss = 0.00158066
I0302 11:52:16.972301 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00158066 (* 1 = 0.00158066 loss)
I0302 11:52:16.972309 29253 sgd_solver.cpp:106] Iteration 25820, lr = 0.0001
I0302 11:52:45.872264 29253 solver.cpp:237] Iteration 25840, loss = 0.00214612
I0302 11:52:45.872303 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00214612 (* 1 = 0.00214612 loss)
I0302 11:52:45.872311 29253 sgd_solver.cpp:106] Iteration 25840, lr = 0.0001
I0302 11:53:14.839485 29253 solver.cpp:237] Iteration 25860, loss = 0.0017147
I0302 11:53:14.839517 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00171471 (* 1 = 0.00171471 loss)
I0302 11:53:14.839527 29253 sgd_solver.cpp:106] Iteration 25860, lr = 0.0001
I0302 11:53:43.688632 29253 solver.cpp:237] Iteration 25880, loss = 0.00180994
I0302 11:53:43.688664 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00180994 (* 1 = 0.00180994 loss)
I0302 11:53:43.688673 29253 sgd_solver.cpp:106] Iteration 25880, lr = 0.0001
I0302 11:54:12.667462 29253 solver.cpp:237] Iteration 25900, loss = 0.0018895
I0302 11:54:12.667495 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00188951 (* 1 = 0.00188951 loss)
I0302 11:54:12.667505 29253 sgd_solver.cpp:106] Iteration 25900, lr = 0.0001
I0302 11:54:41.556798 29253 solver.cpp:237] Iteration 25920, loss = 0.0017508
I0302 11:54:41.556829 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0017508 (* 1 = 0.0017508 loss)
I0302 11:54:41.556838 29253 sgd_solver.cpp:106] Iteration 25920, lr = 0.0001
I0302 11:55:10.396297 29253 solver.cpp:237] Iteration 25940, loss = 0.00151977
I0302 11:55:10.396330 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00151977 (* 1 = 0.00151977 loss)
I0302 11:55:10.396339 29253 sgd_solver.cpp:106] Iteration 25940, lr = 0.0001
I0302 11:55:39.568910 29253 solver.cpp:237] Iteration 25960, loss = 0.00220606
I0302 11:55:39.568941 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00220607 (* 1 = 0.00220607 loss)
I0302 11:55:39.568951 29253 sgd_solver.cpp:106] Iteration 25960, lr = 0.0001
I0302 11:56:08.508283 29253 solver.cpp:237] Iteration 25980, loss = 0.00149476
I0302 11:56:08.508314 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00149477 (* 1 = 0.00149477 loss)
I0302 11:56:08.508323 29253 sgd_solver.cpp:106] Iteration 25980, lr = 0.0001
I0302 11:56:37.572682 29253 solver.cpp:237] Iteration 26000, loss = 0.00181689
I0302 11:56:37.572713 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00181689 (* 1 = 0.00181689 loss)
I0302 11:56:37.572722 29253 sgd_solver.cpp:106] Iteration 26000, lr = 0.0001
I0302 11:56:51.869287 29253 blocking_queue.cpp:50] Data layer prefetch queue empty
I0302 11:57:06.349542 29253 solver.cpp:237] Iteration 26020, loss = 0.0018375
I0302 11:57:06.349575 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0018375 (* 1 = 0.0018375 loss)
I0302 11:57:06.349583 29253 sgd_solver.cpp:106] Iteration 26020, lr = 0.0001
I0302 11:57:35.347230 29253 solver.cpp:237] Iteration 26040, loss = 0.00203778
I0302 11:57:35.347265 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00203778 (* 1 = 0.00203778 loss)
I0302 11:57:35.347272 29253 sgd_solver.cpp:106] Iteration 26040, lr = 0.0001
I0302 11:58:04.806920 29253 solver.cpp:237] Iteration 26060, loss = 0.00152788
I0302 11:58:04.806957 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00152788 (* 1 = 0.00152788 loss)
I0302 11:58:04.806965 29253 sgd_solver.cpp:106] Iteration 26060, lr = 0.0001
I0302 11:58:34.749644 29253 solver.cpp:237] Iteration 26080, loss = 0.00172612
I0302 11:58:34.749680 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00172612 (* 1 = 0.00172612 loss)
I0302 11:58:34.749691 29253 sgd_solver.cpp:106] Iteration 26080, lr = 0.0001
I0302 11:59:04.836192 29253 solver.cpp:237] Iteration 26100, loss = 0.0016341
I0302 11:59:04.836232 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0016341 (* 1 = 0.0016341 loss)
I0302 11:59:04.836241 29253 sgd_solver.cpp:106] Iteration 26100, lr = 0.0001
I0302 11:59:34.561470 29253 solver.cpp:237] Iteration 26120, loss = 0.00152122
I0302 11:59:34.561501 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00152122 (* 1 = 0.00152122 loss)
I0302 11:59:34.561511 29253 sgd_solver.cpp:106] Iteration 26120, lr = 0.0001
I0302 12:00:03.235572 29253 solver.cpp:237] Iteration 26140, loss = 0.00165795
I0302 12:00:03.235605 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00165796 (* 1 = 0.00165796 loss)
I0302 12:00:03.235613 29253 sgd_solver.cpp:106] Iteration 26140, lr = 0.0001
I0302 12:00:32.228026 29253 solver.cpp:237] Iteration 26160, loss = 0.00155934
I0302 12:00:32.228058 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00155935 (* 1 = 0.00155935 loss)
I0302 12:00:32.228067 29253 sgd_solver.cpp:106] Iteration 26160, lr = 0.0001
I0302 12:01:02.094483 29253 solver.cpp:237] Iteration 26180, loss = 0.00201879
I0302 12:01:02.094516 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0020188 (* 1 = 0.0020188 loss)
I0302 12:01:02.094526 29253 sgd_solver.cpp:106] Iteration 26180, lr = 0.0001
I0302 12:01:31.204663 29253 solver.cpp:237] Iteration 26200, loss = 0.00151092
I0302 12:01:31.204699 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00151093 (* 1 = 0.00151093 loss)
I0302 12:01:31.204706 29253 sgd_solver.cpp:106] Iteration 26200, lr = 0.0001
I0302 12:02:00.244526 29253 solver.cpp:237] Iteration 26220, loss = 0.00177194
I0302 12:02:00.244560 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00177194 (* 1 = 0.00177194 loss)
I0302 12:02:00.244567 29253 sgd_solver.cpp:106] Iteration 26220, lr = 0.0001
I0302 12:02:29.007578 29253 solver.cpp:237] Iteration 26240, loss = 0.00143138
I0302 12:02:29.007612 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00143138 (* 1 = 0.00143138 loss)
I0302 12:02:29.007621 29253 sgd_solver.cpp:106] Iteration 26240, lr = 0.0001
I0302 12:02:58.940228 29253 solver.cpp:237] Iteration 26260, loss = 0.00125521
I0302 12:02:58.940268 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00125522 (* 1 = 0.00125522 loss)
I0302 12:02:58.940277 29253 sgd_solver.cpp:106] Iteration 26260, lr = 0.0001
I0302 12:03:28.045990 29253 solver.cpp:237] Iteration 26280, loss = 0.00145219
I0302 12:03:28.046022 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0014522 (* 1 = 0.0014522 loss)
I0302 12:03:28.046031 29253 sgd_solver.cpp:106] Iteration 26280, lr = 0.0001
I0302 12:03:56.751137 29253 solver.cpp:237] Iteration 26300, loss = 0.00153552
I0302 12:03:56.751168 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00153553 (* 1 = 0.00153553 loss)
I0302 12:03:56.751178 29253 sgd_solver.cpp:106] Iteration 26300, lr = 0.0001
I0302 12:04:25.628417 29253 solver.cpp:237] Iteration 26320, loss = 0.00167314
I0302 12:04:25.628453 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00167314 (* 1 = 0.00167314 loss)
I0302 12:04:25.628463 29253 sgd_solver.cpp:106] Iteration 26320, lr = 0.0001
I0302 12:04:54.574015 29253 solver.cpp:237] Iteration 26340, loss = 0.00132426
I0302 12:04:54.574048 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00132427 (* 1 = 0.00132427 loss)
I0302 12:04:54.574056 29253 sgd_solver.cpp:106] Iteration 26340, lr = 0.0001
I0302 12:05:23.597756 29253 solver.cpp:237] Iteration 26360, loss = 0.00155218
I0302 12:05:23.597789 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00155218 (* 1 = 0.00155218 loss)
I0302 12:05:23.597797 29253 sgd_solver.cpp:106] Iteration 26360, lr = 0.0001
I0302 12:05:52.533782 29253 solver.cpp:237] Iteration 26380, loss = 0.00154305
I0302 12:05:52.533814 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00154306 (* 1 = 0.00154306 loss)
I0302 12:05:52.533823 29253 sgd_solver.cpp:106] Iteration 26380, lr = 0.0001
I0302 12:06:21.468484 29253 solver.cpp:237] Iteration 26400, loss = 0.00135014
I0302 12:06:21.468519 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00135014 (* 1 = 0.00135014 loss)
I0302 12:06:21.468528 29253 sgd_solver.cpp:106] Iteration 26400, lr = 0.0001
I0302 12:06:50.753725 29253 solver.cpp:237] Iteration 26420, loss = 0.00165044
I0302 12:06:50.753757 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00165044 (* 1 = 0.00165044 loss)
I0302 12:06:50.753767 29253 sgd_solver.cpp:106] Iteration 26420, lr = 0.0001
I0302 12:07:20.923878 29253 solver.cpp:237] Iteration 26440, loss = 0.00185477
I0302 12:07:20.923910 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00185478 (* 1 = 0.00185478 loss)
I0302 12:07:20.923919 29253 sgd_solver.cpp:106] Iteration 26440, lr = 0.0001
I0302 12:07:50.165021 29253 solver.cpp:237] Iteration 26460, loss = 0.00201692
I0302 12:07:50.165060 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00201693 (* 1 = 0.00201693 loss)
I0302 12:07:50.165069 29253 sgd_solver.cpp:106] Iteration 26460, lr = 0.0001
I0302 12:08:19.117081 29253 solver.cpp:237] Iteration 26480, loss = 0.00179454
I0302 12:08:19.117113 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00179455 (* 1 = 0.00179455 loss)
I0302 12:08:19.117121 29253 sgd_solver.cpp:106] Iteration 26480, lr = 0.0001
I0302 12:08:47.974730 29253 solver.cpp:237] Iteration 26500, loss = 0.00120283
I0302 12:08:47.974761 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00120283 (* 1 = 0.00120283 loss)
I0302 12:08:47.974769 29253 sgd_solver.cpp:106] Iteration 26500, lr = 0.0001
I0302 12:09:16.638777 29253 solver.cpp:237] Iteration 26520, loss = 0.00164384
I0302 12:09:16.638804 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00164384 (* 1 = 0.00164384 loss)
I0302 12:09:16.638814 29253 sgd_solver.cpp:106] Iteration 26520, lr = 0.0001
I0302 12:09:45.877174 29253 solver.cpp:237] Iteration 26540, loss = 0.00142467
I0302 12:09:45.877208 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00142467 (* 1 = 0.00142467 loss)
I0302 12:09:45.877218 29253 sgd_solver.cpp:106] Iteration 26540, lr = 0.0001
I0302 12:10:14.909466 29253 solver.cpp:237] Iteration 26560, loss = 0.00161161
I0302 12:10:14.909497 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00161161 (* 1 = 0.00161161 loss)
I0302 12:10:14.909507 29253 sgd_solver.cpp:106] Iteration 26560, lr = 0.0001
I0302 12:10:43.887673 29253 solver.cpp:237] Iteration 26580, loss = 0.00169836
I0302 12:10:43.887706 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00169836 (* 1 = 0.00169836 loss)
I0302 12:10:43.887713 29253 sgd_solver.cpp:106] Iteration 26580, lr = 0.0001
I0302 12:11:12.822074 29253 solver.cpp:237] Iteration 26600, loss = 0.00147833
I0302 12:11:12.822108 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00147833 (* 1 = 0.00147833 loss)
I0302 12:11:12.822115 29253 sgd_solver.cpp:106] Iteration 26600, lr = 0.0001
I0302 12:11:42.080865 29253 solver.cpp:237] Iteration 26620, loss = 0.00121898
I0302 12:11:42.080899 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00121898 (* 1 = 0.00121898 loss)
I0302 12:11:42.080907 29253 sgd_solver.cpp:106] Iteration 26620, lr = 0.0001
I0302 12:12:10.811013 29253 solver.cpp:237] Iteration 26640, loss = 0.00162687
I0302 12:12:10.811044 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00162688 (* 1 = 0.00162688 loss)
I0302 12:12:10.811053 29253 sgd_solver.cpp:106] Iteration 26640, lr = 0.0001
I0302 12:12:39.842970 29253 solver.cpp:237] Iteration 26660, loss = 0.00278512
I0302 12:12:39.843003 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00278513 (* 1 = 0.00278513 loss)
I0302 12:12:39.843011 29253 sgd_solver.cpp:106] Iteration 26660, lr = 0.0001
I0302 12:13:08.618866 29253 solver.cpp:237] Iteration 26680, loss = 0.00166805
I0302 12:13:08.618899 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00166805 (* 1 = 0.00166805 loss)
I0302 12:13:08.618908 29253 sgd_solver.cpp:106] Iteration 26680, lr = 0.0001
I0302 12:13:37.641635 29253 solver.cpp:237] Iteration 26700, loss = 0.00176206
I0302 12:13:37.641667 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00176206 (* 1 = 0.00176206 loss)
I0302 12:13:37.641677 29253 sgd_solver.cpp:106] Iteration 26700, lr = 0.0001
I0302 12:14:06.543313 29253 solver.cpp:237] Iteration 26720, loss = 0.00156558
I0302 12:14:06.543345 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00156558 (* 1 = 0.00156558 loss)
I0302 12:14:06.543354 29253 sgd_solver.cpp:106] Iteration 26720, lr = 0.0001
I0302 12:14:35.589561 29253 solver.cpp:237] Iteration 26740, loss = 0.00202714
I0302 12:14:35.589594 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00202714 (* 1 = 0.00202714 loss)
I0302 12:14:35.589603 29253 sgd_solver.cpp:106] Iteration 26740, lr = 0.0001
I0302 12:15:04.470780 29253 solver.cpp:237] Iteration 26760, loss = 0.00154694
I0302 12:15:04.470813 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00154694 (* 1 = 0.00154694 loss)
I0302 12:15:04.470821 29253 sgd_solver.cpp:106] Iteration 26760, lr = 0.0001
I0302 12:15:33.511585 29253 solver.cpp:237] Iteration 26780, loss = 0.00171801
I0302 12:15:33.511623 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00171801 (* 1 = 0.00171801 loss)
I0302 12:15:33.511633 29253 sgd_solver.cpp:106] Iteration 26780, lr = 0.0001
I0302 12:16:02.409091 29253 solver.cpp:237] Iteration 26800, loss = 0.00144615
I0302 12:16:02.409124 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00144615 (* 1 = 0.00144615 loss)
I0302 12:16:02.409132 29253 sgd_solver.cpp:106] Iteration 26800, lr = 0.0001
I0302 12:16:31.563228 29253 solver.cpp:237] Iteration 26820, loss = 0.00157668
I0302 12:16:31.563259 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00157668 (* 1 = 0.00157668 loss)
I0302 12:16:31.563267 29253 sgd_solver.cpp:106] Iteration 26820, lr = 0.0001
I0302 12:17:00.453809 29253 solver.cpp:237] Iteration 26840, loss = 0.00198709
I0302 12:17:00.453840 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0019871 (* 1 = 0.0019871 loss)
I0302 12:17:00.453850 29253 sgd_solver.cpp:106] Iteration 26840, lr = 0.0001
I0302 12:17:29.518643 29253 solver.cpp:237] Iteration 26860, loss = 0.0014986
I0302 12:17:29.518674 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0014986 (* 1 = 0.0014986 loss)
I0302 12:17:29.518683 29253 sgd_solver.cpp:106] Iteration 26860, lr = 0.0001
I0302 12:17:58.330445 29253 solver.cpp:237] Iteration 26880, loss = 0.00159512
I0302 12:17:58.330476 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00159512 (* 1 = 0.00159512 loss)
I0302 12:17:58.330485 29253 sgd_solver.cpp:106] Iteration 26880, lr = 0.0001
I0302 12:18:27.444628 29253 solver.cpp:237] Iteration 26900, loss = 0.00168541
I0302 12:18:27.444661 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00168542 (* 1 = 0.00168542 loss)
I0302 12:18:27.444669 29253 sgd_solver.cpp:106] Iteration 26900, lr = 0.0001
I0302 12:18:56.540571 29253 solver.cpp:237] Iteration 26920, loss = 0.00181457
I0302 12:18:56.540603 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00181458 (* 1 = 0.00181458 loss)
I0302 12:18:56.540612 29253 sgd_solver.cpp:106] Iteration 26920, lr = 0.0001
I0302 12:19:25.396708 29253 solver.cpp:237] Iteration 26940, loss = 0.00181823
I0302 12:19:25.396740 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00181823 (* 1 = 0.00181823 loss)
I0302 12:19:25.396749 29253 sgd_solver.cpp:106] Iteration 26940, lr = 0.0001
I0302 12:19:54.287525 29253 solver.cpp:237] Iteration 26960, loss = 0.00159611
I0302 12:19:54.287560 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00159611 (* 1 = 0.00159611 loss)
I0302 12:19:54.287569 29253 sgd_solver.cpp:106] Iteration 26960, lr = 0.0001
I0302 12:20:23.303053 29253 solver.cpp:237] Iteration 26980, loss = 0.00174971
I0302 12:20:23.303086 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00174971 (* 1 = 0.00174971 loss)
I0302 12:20:23.303094 29253 sgd_solver.cpp:106] Iteration 26980, lr = 0.0001
I0302 12:20:52.280452 29253 solver.cpp:237] Iteration 27000, loss = 0.00173568
I0302 12:20:52.280485 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00173568 (* 1 = 0.00173568 loss)
I0302 12:20:52.280494 29253 sgd_solver.cpp:106] Iteration 27000, lr = 0.0001
I0302 12:21:06.484125 29253 blocking_queue.cpp:50] Data layer prefetch queue empty
I0302 12:21:21.028461 29253 solver.cpp:237] Iteration 27020, loss = 0.00173249
I0302 12:21:21.028494 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0017325 (* 1 = 0.0017325 loss)
I0302 12:21:21.028503 29253 sgd_solver.cpp:106] Iteration 27020, lr = 0.0001
I0302 12:21:50.048138 29253 solver.cpp:237] Iteration 27040, loss = 0.00175393
I0302 12:21:50.048172 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00175394 (* 1 = 0.00175394 loss)
I0302 12:21:50.048182 29253 sgd_solver.cpp:106] Iteration 27040, lr = 0.0001
I0302 12:22:18.948657 29253 solver.cpp:237] Iteration 27060, loss = 0.00212043
I0302 12:22:18.948688 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00212044 (* 1 = 0.00212044 loss)
I0302 12:22:18.948696 29253 sgd_solver.cpp:106] Iteration 27060, lr = 0.0001
I0302 12:22:48.036023 29253 solver.cpp:237] Iteration 27080, loss = 0.00168754
I0302 12:22:48.036056 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00168755 (* 1 = 0.00168755 loss)
I0302 12:22:48.036065 29253 sgd_solver.cpp:106] Iteration 27080, lr = 0.0001
I0302 12:23:17.003325 29253 solver.cpp:237] Iteration 27100, loss = 0.00152233
I0302 12:23:17.003357 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00152233 (* 1 = 0.00152233 loss)
I0302 12:23:17.003366 29253 sgd_solver.cpp:106] Iteration 27100, lr = 0.0001
I0302 12:23:45.953080 29253 solver.cpp:237] Iteration 27120, loss = 0.0015914
I0302 12:23:45.953115 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0015914 (* 1 = 0.0015914 loss)
I0302 12:23:45.953125 29253 sgd_solver.cpp:106] Iteration 27120, lr = 0.0001
I0302 12:24:15.024936 29253 solver.cpp:237] Iteration 27140, loss = 0.0016765
I0302 12:24:15.024971 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0016765 (* 1 = 0.0016765 loss)
I0302 12:24:15.024981 29253 sgd_solver.cpp:106] Iteration 27140, lr = 0.0001
I0302 12:24:44.078842 29253 solver.cpp:237] Iteration 27160, loss = 0.00144227
I0302 12:24:44.078876 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00144228 (* 1 = 0.00144228 loss)
I0302 12:24:44.078884 29253 sgd_solver.cpp:106] Iteration 27160, lr = 0.0001
I0302 12:25:12.913893 29253 solver.cpp:237] Iteration 27180, loss = 0.00161917
I0302 12:25:12.913928 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00161917 (* 1 = 0.00161917 loss)
I0302 12:25:12.913936 29253 sgd_solver.cpp:106] Iteration 27180, lr = 0.0001
I0302 12:25:41.922551 29253 solver.cpp:237] Iteration 27200, loss = 0.00158107
I0302 12:25:41.922583 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00158108 (* 1 = 0.00158108 loss)
I0302 12:25:41.922591 29253 sgd_solver.cpp:106] Iteration 27200, lr = 0.0001
I0302 12:26:10.776625 29253 solver.cpp:237] Iteration 27220, loss = 0.00156755
I0302 12:26:10.776656 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00156756 (* 1 = 0.00156756 loss)
I0302 12:26:10.776665 29253 sgd_solver.cpp:106] Iteration 27220, lr = 0.0001
I0302 12:26:39.589967 29253 solver.cpp:237] Iteration 27240, loss = 0.00156288
I0302 12:26:39.589999 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00156288 (* 1 = 0.00156288 loss)
I0302 12:26:39.590008 29253 sgd_solver.cpp:106] Iteration 27240, lr = 0.0001
I0302 12:27:08.439122 29253 solver.cpp:237] Iteration 27260, loss = 0.0018663
I0302 12:27:08.439153 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00186631 (* 1 = 0.00186631 loss)
I0302 12:27:08.439162 29253 sgd_solver.cpp:106] Iteration 27260, lr = 0.0001
I0302 12:27:37.360023 29253 solver.cpp:237] Iteration 27280, loss = 0.00137528
I0302 12:27:37.360054 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00137528 (* 1 = 0.00137528 loss)
I0302 12:27:37.360062 29253 sgd_solver.cpp:106] Iteration 27280, lr = 0.0001
I0302 12:28:06.214946 29253 solver.cpp:237] Iteration 27300, loss = 0.00160745
I0302 12:28:06.214978 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00160745 (* 1 = 0.00160745 loss)
I0302 12:28:06.214987 29253 sgd_solver.cpp:106] Iteration 27300, lr = 0.0001
I0302 12:28:35.179242 29253 solver.cpp:237] Iteration 27320, loss = 0.00217379
I0302 12:28:35.179273 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00217379 (* 1 = 0.00217379 loss)
I0302 12:28:35.179283 29253 sgd_solver.cpp:106] Iteration 27320, lr = 0.0001
I0302 12:29:04.213034 29253 solver.cpp:237] Iteration 27340, loss = 0.00182919
I0302 12:29:04.213065 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00182919 (* 1 = 0.00182919 loss)
I0302 12:29:04.213075 29253 sgd_solver.cpp:106] Iteration 27340, lr = 0.0001
I0302 12:29:33.081928 29253 solver.cpp:237] Iteration 27360, loss = 0.00181868
I0302 12:29:33.081959 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00181869 (* 1 = 0.00181869 loss)
I0302 12:29:33.081969 29253 sgd_solver.cpp:106] Iteration 27360, lr = 0.0001
I0302 12:30:01.935107 29253 solver.cpp:237] Iteration 27380, loss = 0.00233144
I0302 12:30:01.935140 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00233144 (* 1 = 0.00233144 loss)
I0302 12:30:01.935148 29253 sgd_solver.cpp:106] Iteration 27380, lr = 0.0001
I0302 12:30:30.816974 29253 solver.cpp:237] Iteration 27400, loss = 0.00152033
I0302 12:30:30.817006 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00152033 (* 1 = 0.00152033 loss)
I0302 12:30:30.817016 29253 sgd_solver.cpp:106] Iteration 27400, lr = 0.0001
I0302 12:30:59.650115 29253 solver.cpp:237] Iteration 27420, loss = 0.00159925
I0302 12:30:59.650146 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00159926 (* 1 = 0.00159926 loss)
I0302 12:30:59.650156 29253 sgd_solver.cpp:106] Iteration 27420, lr = 0.0001
I0302 12:31:28.494657 29253 solver.cpp:237] Iteration 27440, loss = 0.00179283
I0302 12:31:28.494686 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00179283 (* 1 = 0.00179283 loss)
I0302 12:31:28.494695 29253 sgd_solver.cpp:106] Iteration 27440, lr = 0.0001
I0302 12:31:57.441205 29253 solver.cpp:237] Iteration 27460, loss = 0.00177934
I0302 12:31:57.441236 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00177934 (* 1 = 0.00177934 loss)
I0302 12:31:57.441246 29253 sgd_solver.cpp:106] Iteration 27460, lr = 0.0001
I0302 12:32:26.370982 29253 solver.cpp:237] Iteration 27480, loss = 0.00185035
I0302 12:32:26.371014 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00185036 (* 1 = 0.00185036 loss)
I0302 12:32:26.371022 29253 sgd_solver.cpp:106] Iteration 27480, lr = 0.0001
I0302 12:32:55.448979 29253 solver.cpp:237] Iteration 27500, loss = 0.00149566
I0302 12:32:55.449012 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00149566 (* 1 = 0.00149566 loss)
I0302 12:32:55.449021 29253 sgd_solver.cpp:106] Iteration 27500, lr = 0.0001
I0302 12:33:23.886890 29253 solver.cpp:237] Iteration 27520, loss = 0.00155106
I0302 12:33:23.886922 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00155106 (* 1 = 0.00155106 loss)
I0302 12:33:23.886930 29253 sgd_solver.cpp:106] Iteration 27520, lr = 0.0001
I0302 12:33:52.772156 29253 solver.cpp:237] Iteration 27540, loss = 0.00163158
I0302 12:33:52.772187 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00163158 (* 1 = 0.00163158 loss)
I0302 12:33:52.772195 29253 sgd_solver.cpp:106] Iteration 27540, lr = 0.0001
I0302 12:34:21.488193 29253 solver.cpp:237] Iteration 27560, loss = 0.00127056
I0302 12:34:21.488222 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00127056 (* 1 = 0.00127056 loss)
I0302 12:34:21.488231 29253 sgd_solver.cpp:106] Iteration 27560, lr = 0.0001
I0302 12:34:50.825820 29253 solver.cpp:237] Iteration 27580, loss = 0.0017652
I0302 12:34:50.825855 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0017652 (* 1 = 0.0017652 loss)
I0302 12:34:50.825862 29253 sgd_solver.cpp:106] Iteration 27580, lr = 0.0001
I0302 12:35:19.432047 29253 solver.cpp:237] Iteration 27600, loss = 0.00165635
I0302 12:35:19.432078 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00165635 (* 1 = 0.00165635 loss)
I0302 12:35:19.432087 29253 sgd_solver.cpp:106] Iteration 27600, lr = 0.0001
I0302 12:35:48.243057 29253 solver.cpp:237] Iteration 27620, loss = 0.00167887
I0302 12:35:48.243084 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00167887 (* 1 = 0.00167887 loss)
I0302 12:35:48.243093 29253 sgd_solver.cpp:106] Iteration 27620, lr = 0.0001
I0302 12:36:17.214774 29253 solver.cpp:237] Iteration 27640, loss = 0.00173094
I0302 12:36:17.214808 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00173095 (* 1 = 0.00173095 loss)
I0302 12:36:17.214817 29253 sgd_solver.cpp:106] Iteration 27640, lr = 0.0001
I0302 12:36:45.992105 29253 solver.cpp:237] Iteration 27660, loss = 0.00173949
I0302 12:36:45.992137 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00173949 (* 1 = 0.00173949 loss)
I0302 12:36:45.992146 29253 sgd_solver.cpp:106] Iteration 27660, lr = 0.0001
I0302 12:37:14.909333 29253 solver.cpp:237] Iteration 27680, loss = 0.0014952
I0302 12:37:14.909364 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00149521 (* 1 = 0.00149521 loss)
I0302 12:37:14.909373 29253 sgd_solver.cpp:106] Iteration 27680, lr = 0.0001
I0302 12:37:43.750439 29253 solver.cpp:237] Iteration 27700, loss = 0.00167704
I0302 12:37:43.750469 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00167704 (* 1 = 0.00167704 loss)
I0302 12:37:43.750478 29253 sgd_solver.cpp:106] Iteration 27700, lr = 0.0001
I0302 12:38:12.767743 29253 solver.cpp:237] Iteration 27720, loss = 0.0016293
I0302 12:38:12.767774 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0016293 (* 1 = 0.0016293 loss)
I0302 12:38:12.767784 29253 sgd_solver.cpp:106] Iteration 27720, lr = 0.0001
I0302 12:38:41.681318 29253 solver.cpp:237] Iteration 27740, loss = 0.00139973
I0302 12:38:41.681349 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00139974 (* 1 = 0.00139974 loss)
I0302 12:38:41.681359 29253 sgd_solver.cpp:106] Iteration 27740, lr = 0.0001
I0302 12:39:10.629802 29253 solver.cpp:237] Iteration 27760, loss = 0.00174972
I0302 12:39:10.629834 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00174972 (* 1 = 0.00174972 loss)
I0302 12:39:10.629842 29253 sgd_solver.cpp:106] Iteration 27760, lr = 0.0001
I0302 12:39:39.384028 29253 solver.cpp:237] Iteration 27780, loss = 0.00148208
I0302 12:39:39.384062 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00148208 (* 1 = 0.00148208 loss)
I0302 12:39:39.384070 29253 sgd_solver.cpp:106] Iteration 27780, lr = 0.0001
I0302 12:40:08.521359 29253 solver.cpp:237] Iteration 27800, loss = 0.00143036
I0302 12:40:08.521391 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00143037 (* 1 = 0.00143037 loss)
I0302 12:40:08.521400 29253 sgd_solver.cpp:106] Iteration 27800, lr = 0.0001
I0302 12:40:37.554538 29253 solver.cpp:237] Iteration 27820, loss = 0.00151076
I0302 12:40:37.554570 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00151076 (* 1 = 0.00151076 loss)
I0302 12:40:37.554579 29253 sgd_solver.cpp:106] Iteration 27820, lr = 0.0001
I0302 12:41:06.438977 29253 solver.cpp:237] Iteration 27840, loss = 0.00159307
I0302 12:41:06.439009 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00159307 (* 1 = 0.00159307 loss)
I0302 12:41:06.439018 29253 sgd_solver.cpp:106] Iteration 27840, lr = 0.0001
I0302 12:41:35.359529 29253 solver.cpp:237] Iteration 27860, loss = 0.00217
I0302 12:41:35.359561 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00217 (* 1 = 0.00217 loss)
I0302 12:41:35.359570 29253 sgd_solver.cpp:106] Iteration 27860, lr = 0.0001
I0302 12:42:04.358667 29253 solver.cpp:237] Iteration 27880, loss = 0.0014595
I0302 12:42:04.358700 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0014595 (* 1 = 0.0014595 loss)
I0302 12:42:04.358710 29253 sgd_solver.cpp:106] Iteration 27880, lr = 0.0001
I0302 12:42:33.104917 29253 solver.cpp:237] Iteration 27900, loss = 0.00138401
I0302 12:42:33.104949 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00138402 (* 1 = 0.00138402 loss)
I0302 12:42:33.104959 29253 sgd_solver.cpp:106] Iteration 27900, lr = 0.0001
I0302 12:43:02.136968 29253 solver.cpp:237] Iteration 27920, loss = 0.00182519
I0302 12:43:02.137001 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00182519 (* 1 = 0.00182519 loss)
I0302 12:43:02.137009 29253 sgd_solver.cpp:106] Iteration 27920, lr = 0.0001
I0302 12:43:30.879176 29253 solver.cpp:237] Iteration 27940, loss = 0.00158895
I0302 12:43:30.879205 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00158895 (* 1 = 0.00158895 loss)
I0302 12:43:30.879215 29253 sgd_solver.cpp:106] Iteration 27940, lr = 0.0001
I0302 12:43:59.795474 29253 solver.cpp:237] Iteration 27960, loss = 0.00130326
I0302 12:43:59.795506 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00130326 (* 1 = 0.00130326 loss)
I0302 12:43:59.795514 29253 sgd_solver.cpp:106] Iteration 27960, lr = 0.0001
I0302 12:44:28.970083 29253 solver.cpp:237] Iteration 27980, loss = 0.00154855
I0302 12:44:28.970116 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00154855 (* 1 = 0.00154855 loss)
I0302 12:44:28.970125 29253 sgd_solver.cpp:106] Iteration 27980, lr = 0.0001
I0302 12:44:57.881312 29253 solver.cpp:237] Iteration 28000, loss = 0.00169206
I0302 12:44:57.881345 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00169206 (* 1 = 0.00169206 loss)
I0302 12:44:57.881353 29253 sgd_solver.cpp:106] Iteration 28000, lr = 0.0001
I0302 12:45:12.157768 29253 blocking_queue.cpp:50] Data layer prefetch queue empty
I0302 12:45:26.594895 29253 solver.cpp:237] Iteration 28020, loss = 0.0016274
I0302 12:45:26.594928 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00162741 (* 1 = 0.00162741 loss)
I0302 12:45:26.594935 29253 sgd_solver.cpp:106] Iteration 28020, lr = 0.0001
I0302 12:45:55.577014 29253 solver.cpp:237] Iteration 28040, loss = 0.00150844
I0302 12:45:55.577045 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00150844 (* 1 = 0.00150844 loss)
I0302 12:45:55.577054 29253 sgd_solver.cpp:106] Iteration 28040, lr = 0.0001
I0302 12:46:24.799728 29253 solver.cpp:237] Iteration 28060, loss = 0.00213745
I0302 12:46:24.799760 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00213746 (* 1 = 0.00213746 loss)
I0302 12:46:24.799768 29253 sgd_solver.cpp:106] Iteration 28060, lr = 0.0001
I0302 12:46:53.820374 29253 solver.cpp:237] Iteration 28080, loss = 0.00244638
I0302 12:46:53.820405 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00244638 (* 1 = 0.00244638 loss)
I0302 12:46:53.820415 29253 sgd_solver.cpp:106] Iteration 28080, lr = 0.0001
I0302 12:47:22.501658 29253 solver.cpp:237] Iteration 28100, loss = 0.00180923
I0302 12:47:22.501690 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00180923 (* 1 = 0.00180923 loss)
I0302 12:47:22.501699 29253 sgd_solver.cpp:106] Iteration 28100, lr = 0.0001
I0302 12:47:51.484537 29253 solver.cpp:237] Iteration 28120, loss = 0.00143221
I0302 12:47:51.484568 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00143221 (* 1 = 0.00143221 loss)
I0302 12:47:51.484577 29253 sgd_solver.cpp:106] Iteration 28120, lr = 0.0001
I0302 12:48:20.426192 29253 solver.cpp:237] Iteration 28140, loss = 0.00142557
I0302 12:48:20.426223 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00142557 (* 1 = 0.00142557 loss)
I0302 12:48:20.426231 29253 sgd_solver.cpp:106] Iteration 28140, lr = 0.0001
I0302 12:48:49.150713 29253 solver.cpp:237] Iteration 28160, loss = 0.00136227
I0302 12:48:49.150744 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00136227 (* 1 = 0.00136227 loss)
I0302 12:48:49.150753 29253 sgd_solver.cpp:106] Iteration 28160, lr = 0.0001
I0302 12:49:18.319396 29253 solver.cpp:237] Iteration 28180, loss = 0.00158424
I0302 12:49:18.319428 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00158424 (* 1 = 0.00158424 loss)
I0302 12:49:18.319437 29253 sgd_solver.cpp:106] Iteration 28180, lr = 0.0001
I0302 12:49:46.965034 29253 solver.cpp:237] Iteration 28200, loss = 0.0016902
I0302 12:49:46.965065 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0016902 (* 1 = 0.0016902 loss)
I0302 12:49:46.965075 29253 sgd_solver.cpp:106] Iteration 28200, lr = 0.0001
I0302 12:50:16.101495 29253 solver.cpp:237] Iteration 28220, loss = 0.00135538
I0302 12:50:16.101529 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00135538 (* 1 = 0.00135538 loss)
I0302 12:50:16.101538 29253 sgd_solver.cpp:106] Iteration 28220, lr = 0.0001
I0302 12:50:44.953982 29253 solver.cpp:237] Iteration 28240, loss = 0.00162544
I0302 12:50:44.954015 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00162545 (* 1 = 0.00162545 loss)
I0302 12:50:44.954025 29253 sgd_solver.cpp:106] Iteration 28240, lr = 0.0001
I0302 12:51:13.889546 29253 solver.cpp:237] Iteration 28260, loss = 0.00176678
I0302 12:51:13.889578 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00176678 (* 1 = 0.00176678 loss)
I0302 12:51:13.889587 29253 sgd_solver.cpp:106] Iteration 28260, lr = 0.0001
I0302 12:51:42.609030 29253 solver.cpp:237] Iteration 28280, loss = 0.00206016
I0302 12:51:42.609061 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00206016 (* 1 = 0.00206016 loss)
I0302 12:51:42.609069 29253 sgd_solver.cpp:106] Iteration 28280, lr = 0.0001
I0302 12:52:11.479928 29253 solver.cpp:237] Iteration 28300, loss = 0.0015711
I0302 12:52:11.479959 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00157111 (* 1 = 0.00157111 loss)
I0302 12:52:11.479967 29253 sgd_solver.cpp:106] Iteration 28300, lr = 0.0001
I0302 12:52:40.387398 29253 solver.cpp:237] Iteration 28320, loss = 0.00145707
I0302 12:52:40.387430 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00145707 (* 1 = 0.00145707 loss)
I0302 12:52:40.387439 29253 sgd_solver.cpp:106] Iteration 28320, lr = 0.0001
I0302 12:53:09.390705 29253 solver.cpp:237] Iteration 28340, loss = 0.00163603
I0302 12:53:09.390738 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00163603 (* 1 = 0.00163603 loss)
I0302 12:53:09.390746 29253 sgd_solver.cpp:106] Iteration 28340, lr = 0.0001
I0302 12:53:38.275091 29253 solver.cpp:237] Iteration 28360, loss = 0.00144775
I0302 12:53:38.275122 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00144775 (* 1 = 0.00144775 loss)
I0302 12:53:38.275130 29253 sgd_solver.cpp:106] Iteration 28360, lr = 0.0001
I0302 12:54:07.193950 29253 solver.cpp:237] Iteration 28380, loss = 0.0017847
I0302 12:54:07.193981 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00178471 (* 1 = 0.00178471 loss)
I0302 12:54:07.193990 29253 sgd_solver.cpp:106] Iteration 28380, lr = 0.0001
I0302 12:54:36.233716 29253 solver.cpp:237] Iteration 28400, loss = 0.00185752
I0302 12:54:36.233749 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00185753 (* 1 = 0.00185753 loss)
I0302 12:54:36.233758 29253 sgd_solver.cpp:106] Iteration 28400, lr = 0.0001
I0302 12:55:05.213805 29253 solver.cpp:237] Iteration 28420, loss = 0.00159883
I0302 12:55:05.213836 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00159883 (* 1 = 0.00159883 loss)
I0302 12:55:05.213845 29253 sgd_solver.cpp:106] Iteration 28420, lr = 0.0001
I0302 12:55:33.869837 29253 solver.cpp:237] Iteration 28440, loss = 0.00148243
I0302 12:55:33.869868 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00148244 (* 1 = 0.00148244 loss)
I0302 12:55:33.869877 29253 sgd_solver.cpp:106] Iteration 28440, lr = 0.0001
I0302 12:56:02.953333 29253 solver.cpp:237] Iteration 28460, loss = 0.00163074
I0302 12:56:02.953364 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00163074 (* 1 = 0.00163074 loss)
I0302 12:56:02.953373 29253 sgd_solver.cpp:106] Iteration 28460, lr = 0.0001
I0302 12:56:31.754048 29253 solver.cpp:237] Iteration 28480, loss = 0.00173888
I0302 12:56:31.754081 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00173889 (* 1 = 0.00173889 loss)
I0302 12:56:31.754091 29253 sgd_solver.cpp:106] Iteration 28480, lr = 0.0001
I0302 12:57:00.712213 29253 solver.cpp:237] Iteration 28500, loss = 0.00158466
I0302 12:57:00.712246 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00158466 (* 1 = 0.00158466 loss)
I0302 12:57:00.712255 29253 sgd_solver.cpp:106] Iteration 28500, lr = 0.0001
I0302 12:57:29.510756 29253 solver.cpp:237] Iteration 28520, loss = 0.00135223
I0302 12:57:29.510787 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00135223 (* 1 = 0.00135223 loss)
I0302 12:57:29.510797 29253 sgd_solver.cpp:106] Iteration 28520, lr = 0.0001
I0302 12:57:58.577751 29253 solver.cpp:237] Iteration 28540, loss = 0.0014853
I0302 12:57:58.577782 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00148531 (* 1 = 0.00148531 loss)
I0302 12:57:58.577791 29253 sgd_solver.cpp:106] Iteration 28540, lr = 0.0001
I0302 12:58:27.503792 29253 solver.cpp:237] Iteration 28560, loss = 0.00157138
I0302 12:58:27.503823 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00157138 (* 1 = 0.00157138 loss)
I0302 12:58:27.503831 29253 sgd_solver.cpp:106] Iteration 28560, lr = 0.0001
I0302 12:58:56.276199 29253 solver.cpp:237] Iteration 28580, loss = 0.00157931
I0302 12:58:56.276231 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00157931 (* 1 = 0.00157931 loss)
I0302 12:58:56.276239 29253 sgd_solver.cpp:106] Iteration 28580, lr = 0.0001
I0302 12:59:25.131445 29253 solver.cpp:237] Iteration 28600, loss = 0.00148591
I0302 12:59:25.131477 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00148591 (* 1 = 0.00148591 loss)
I0302 12:59:25.131486 29253 sgd_solver.cpp:106] Iteration 28600, lr = 0.0001
I0302 12:59:54.137536 29253 solver.cpp:237] Iteration 28620, loss = 0.0019517
I0302 12:59:54.137567 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00195171 (* 1 = 0.00195171 loss)
I0302 12:59:54.137576 29253 sgd_solver.cpp:106] Iteration 28620, lr = 0.0001
I0302 13:00:22.975020 29253 solver.cpp:237] Iteration 28640, loss = 0.00148223
I0302 13:00:22.975052 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00148224 (* 1 = 0.00148224 loss)
I0302 13:00:22.975061 29253 sgd_solver.cpp:106] Iteration 28640, lr = 0.0001
I0302 13:00:51.750221 29253 solver.cpp:237] Iteration 28660, loss = 0.0014244
I0302 13:00:51.750252 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0014244 (* 1 = 0.0014244 loss)
I0302 13:00:51.750260 29253 sgd_solver.cpp:106] Iteration 28660, lr = 0.0001
I0302 13:01:20.692497 29253 solver.cpp:237] Iteration 28680, loss = 0.00165411
I0302 13:01:20.692529 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00165412 (* 1 = 0.00165412 loss)
I0302 13:01:20.692538 29253 sgd_solver.cpp:106] Iteration 28680, lr = 0.0001
I0302 13:01:49.543839 29253 solver.cpp:237] Iteration 28700, loss = 0.00202372
I0302 13:01:49.543871 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00202372 (* 1 = 0.00202372 loss)
I0302 13:01:49.543879 29253 sgd_solver.cpp:106] Iteration 28700, lr = 0.0001
I0302 13:02:18.545853 29253 solver.cpp:237] Iteration 28720, loss = 0.00206248
I0302 13:02:18.545886 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00206249 (* 1 = 0.00206249 loss)
I0302 13:02:18.545895 29253 sgd_solver.cpp:106] Iteration 28720, lr = 0.0001
I0302 13:02:47.331058 29253 solver.cpp:237] Iteration 28740, loss = 0.00138779
I0302 13:02:47.331089 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0013878 (* 1 = 0.0013878 loss)
I0302 13:02:47.331097 29253 sgd_solver.cpp:106] Iteration 28740, lr = 0.0001
I0302 13:03:16.337766 29253 solver.cpp:237] Iteration 28760, loss = 0.00155444
I0302 13:03:16.337798 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00155444 (* 1 = 0.00155444 loss)
I0302 13:03:16.337807 29253 sgd_solver.cpp:106] Iteration 28760, lr = 0.0001
I0302 13:03:45.241677 29253 solver.cpp:237] Iteration 28780, loss = 0.0012638
I0302 13:03:45.241710 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00126381 (* 1 = 0.00126381 loss)
I0302 13:03:45.241719 29253 sgd_solver.cpp:106] Iteration 28780, lr = 0.0001
I0302 13:04:14.263051 29253 solver.cpp:237] Iteration 28800, loss = 0.00182621
I0302 13:04:14.263082 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00182622 (* 1 = 0.00182622 loss)
I0302 13:04:14.263090 29253 sgd_solver.cpp:106] Iteration 28800, lr = 0.0001
I0302 13:04:43.042388 29253 solver.cpp:237] Iteration 28820, loss = 0.00173086
I0302 13:04:43.042420 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00173086 (* 1 = 0.00173086 loss)
I0302 13:04:43.042429 29253 sgd_solver.cpp:106] Iteration 28820, lr = 0.0001
I0302 13:05:11.982756 29253 solver.cpp:237] Iteration 28840, loss = 0.00143803
I0302 13:05:11.982789 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00143803 (* 1 = 0.00143803 loss)
I0302 13:05:11.982797 29253 sgd_solver.cpp:106] Iteration 28840, lr = 0.0001
I0302 13:05:40.999083 29253 solver.cpp:237] Iteration 28860, loss = 0.00151354
I0302 13:05:40.999114 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00151354 (* 1 = 0.00151354 loss)
I0302 13:05:40.999124 29253 sgd_solver.cpp:106] Iteration 28860, lr = 0.0001
I0302 13:06:09.856773 29253 solver.cpp:237] Iteration 28880, loss = 0.00171398
I0302 13:06:09.856806 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00171398 (* 1 = 0.00171398 loss)
I0302 13:06:09.856813 29253 sgd_solver.cpp:106] Iteration 28880, lr = 0.0001
I0302 13:06:38.772078 29253 solver.cpp:237] Iteration 28900, loss = 0.00158691
I0302 13:06:38.772109 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00158691 (* 1 = 0.00158691 loss)
I0302 13:06:38.772119 29253 sgd_solver.cpp:106] Iteration 28900, lr = 0.0001
I0302 13:07:07.475121 29253 solver.cpp:237] Iteration 28920, loss = 0.00178737
I0302 13:07:07.475152 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00178737 (* 1 = 0.00178737 loss)
I0302 13:07:07.475159 29253 sgd_solver.cpp:106] Iteration 28920, lr = 0.0001
I0302 13:07:36.451367 29253 solver.cpp:237] Iteration 28940, loss = 0.00198578
I0302 13:07:36.451398 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00198578 (* 1 = 0.00198578 loss)
I0302 13:07:36.451407 29253 sgd_solver.cpp:106] Iteration 28940, lr = 0.0001
I0302 13:08:05.533232 29253 solver.cpp:237] Iteration 28960, loss = 0.00147238
I0302 13:08:05.533264 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00147238 (* 1 = 0.00147238 loss)
I0302 13:08:05.533272 29253 sgd_solver.cpp:106] Iteration 28960, lr = 0.0001
I0302 13:08:34.265939 29253 solver.cpp:237] Iteration 28980, loss = 0.00197618
I0302 13:08:34.265972 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00197618 (* 1 = 0.00197618 loss)
I0302 13:08:34.265981 29253 sgd_solver.cpp:106] Iteration 28980, lr = 0.0001
I0302 13:09:03.041388 29253 solver.cpp:237] Iteration 29000, loss = 0.00166359
I0302 13:09:03.041419 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00166359 (* 1 = 0.00166359 loss)
I0302 13:09:03.041427 29253 sgd_solver.cpp:106] Iteration 29000, lr = 0.0001
I0302 13:09:17.371922 29253 blocking_queue.cpp:50] Data layer prefetch queue empty
I0302 13:09:31.908663 29253 solver.cpp:237] Iteration 29020, loss = 0.00199778
I0302 13:09:31.908695 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00199779 (* 1 = 0.00199779 loss)
I0302 13:09:31.908704 29253 sgd_solver.cpp:106] Iteration 29020, lr = 0.0001
I0302 13:10:00.674338 29253 solver.cpp:237] Iteration 29040, loss = 0.0016999
I0302 13:10:00.674371 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0016999 (* 1 = 0.0016999 loss)
I0302 13:10:00.674379 29253 sgd_solver.cpp:106] Iteration 29040, lr = 0.0001
I0302 13:10:29.477129 29253 solver.cpp:237] Iteration 29060, loss = 0.00154906
I0302 13:10:29.477160 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00154906 (* 1 = 0.00154906 loss)
I0302 13:10:29.477169 29253 sgd_solver.cpp:106] Iteration 29060, lr = 0.0001
I0302 13:10:58.347312 29253 solver.cpp:237] Iteration 29080, loss = 0.00160857
I0302 13:10:58.347345 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00160857 (* 1 = 0.00160857 loss)
I0302 13:10:58.347353 29253 sgd_solver.cpp:106] Iteration 29080, lr = 0.0001
I0302 13:11:27.160537 29253 solver.cpp:237] Iteration 29100, loss = 0.00192398
I0302 13:11:27.160570 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00192399 (* 1 = 0.00192399 loss)
I0302 13:11:27.160579 29253 sgd_solver.cpp:106] Iteration 29100, lr = 0.0001
I0302 13:11:56.184965 29253 solver.cpp:237] Iteration 29120, loss = 0.00208427
I0302 13:11:56.184996 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00208428 (* 1 = 0.00208428 loss)
I0302 13:11:56.185005 29253 sgd_solver.cpp:106] Iteration 29120, lr = 0.0001
I0302 13:12:24.792964 29253 solver.cpp:237] Iteration 29140, loss = 0.00193797
I0302 13:12:24.792996 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00193797 (* 1 = 0.00193797 loss)
I0302 13:12:24.793005 29253 sgd_solver.cpp:106] Iteration 29140, lr = 0.0001
I0302 13:12:53.876721 29253 solver.cpp:237] Iteration 29160, loss = 0.00184533
I0302 13:12:53.876754 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00184533 (* 1 = 0.00184533 loss)
I0302 13:12:53.876763 29253 sgd_solver.cpp:106] Iteration 29160, lr = 0.0001
I0302 13:13:22.892680 29253 solver.cpp:237] Iteration 29180, loss = 0.00174538
I0302 13:13:22.892712 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00174539 (* 1 = 0.00174539 loss)
I0302 13:13:22.892720 29253 sgd_solver.cpp:106] Iteration 29180, lr = 0.0001
I0302 13:13:51.713860 29253 solver.cpp:237] Iteration 29200, loss = 0.00166759
I0302 13:13:51.713891 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0016676 (* 1 = 0.0016676 loss)
I0302 13:13:51.713901 29253 sgd_solver.cpp:106] Iteration 29200, lr = 0.0001
I0302 13:14:20.553643 29253 solver.cpp:237] Iteration 29220, loss = 0.00150928
I0302 13:14:20.553676 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00150928 (* 1 = 0.00150928 loss)
I0302 13:14:20.553685 29253 sgd_solver.cpp:106] Iteration 29220, lr = 0.0001
I0302 13:14:49.529892 29253 solver.cpp:237] Iteration 29240, loss = 0.00161235
I0302 13:14:49.529925 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00161235 (* 1 = 0.00161235 loss)
I0302 13:14:49.529934 29253 sgd_solver.cpp:106] Iteration 29240, lr = 0.0001
I0302 13:15:18.391304 29253 solver.cpp:237] Iteration 29260, loss = 0.00147191
I0302 13:15:18.391335 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00147192 (* 1 = 0.00147192 loss)
I0302 13:15:18.391345 29253 sgd_solver.cpp:106] Iteration 29260, lr = 0.0001
I0302 13:15:47.332096 29253 solver.cpp:237] Iteration 29280, loss = 0.0017183
I0302 13:15:47.332129 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0017183 (* 1 = 0.0017183 loss)
I0302 13:15:47.332137 29253 sgd_solver.cpp:106] Iteration 29280, lr = 0.0001
I0302 13:16:16.230357 29253 solver.cpp:237] Iteration 29300, loss = 0.00152543
I0302 13:16:16.230389 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00152543 (* 1 = 0.00152543 loss)
I0302 13:16:16.230398 29253 sgd_solver.cpp:106] Iteration 29300, lr = 0.0001
I0302 13:16:45.127521 29253 solver.cpp:237] Iteration 29320, loss = 0.00122217
I0302 13:16:45.127554 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00122218 (* 1 = 0.00122218 loss)
I0302 13:16:45.127563 29253 sgd_solver.cpp:106] Iteration 29320, lr = 0.0001
I0302 13:17:14.077596 29253 solver.cpp:237] Iteration 29340, loss = 0.00175757
I0302 13:17:14.077628 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00175757 (* 1 = 0.00175757 loss)
I0302 13:17:14.077637 29253 sgd_solver.cpp:106] Iteration 29340, lr = 0.0001
I0302 13:17:42.830219 29253 solver.cpp:237] Iteration 29360, loss = 0.00142887
I0302 13:17:42.830252 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00142887 (* 1 = 0.00142887 loss)
I0302 13:17:42.830261 29253 sgd_solver.cpp:106] Iteration 29360, lr = 0.0001
I0302 13:18:11.828174 29253 solver.cpp:237] Iteration 29380, loss = 0.00152268
I0302 13:18:11.828207 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00152268 (* 1 = 0.00152268 loss)
I0302 13:18:11.828217 29253 sgd_solver.cpp:106] Iteration 29380, lr = 0.0001
I0302 13:18:40.710185 29253 solver.cpp:237] Iteration 29400, loss = 0.00147134
I0302 13:18:40.710216 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00147134 (* 1 = 0.00147134 loss)
I0302 13:18:40.710225 29253 sgd_solver.cpp:106] Iteration 29400, lr = 0.0001
I0302 13:19:09.733501 29253 solver.cpp:237] Iteration 29420, loss = 0.001534
I0302 13:19:09.733535 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00153401 (* 1 = 0.00153401 loss)
I0302 13:19:09.733543 29253 sgd_solver.cpp:106] Iteration 29420, lr = 0.0001
I0302 13:19:38.219527 29253 solver.cpp:237] Iteration 29440, loss = 0.00135905
I0302 13:19:38.219559 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00135906 (* 1 = 0.00135906 loss)
I0302 13:19:38.219568 29253 sgd_solver.cpp:106] Iteration 29440, lr = 0.0001
I0302 13:20:07.143501 29253 solver.cpp:237] Iteration 29460, loss = 0.00133044
I0302 13:20:07.143532 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00133045 (* 1 = 0.00133045 loss)
I0302 13:20:07.143542 29253 sgd_solver.cpp:106] Iteration 29460, lr = 0.0001
I0302 13:20:36.114897 29253 solver.cpp:237] Iteration 29480, loss = 0.00144899
I0302 13:20:36.114930 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00144899 (* 1 = 0.00144899 loss)
I0302 13:20:36.114940 29253 sgd_solver.cpp:106] Iteration 29480, lr = 0.0001
I0302 13:21:04.841398 29253 solver.cpp:237] Iteration 29500, loss = 0.00227575
I0302 13:21:04.841431 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00227576 (* 1 = 0.00227576 loss)
I0302 13:21:04.841440 29253 sgd_solver.cpp:106] Iteration 29500, lr = 0.0001
I0302 13:21:33.819597 29253 solver.cpp:237] Iteration 29520, loss = 0.00149774
I0302 13:21:33.819629 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00149774 (* 1 = 0.00149774 loss)
I0302 13:21:33.819638 29253 sgd_solver.cpp:106] Iteration 29520, lr = 0.0001
I0302 13:22:02.780170 29253 solver.cpp:237] Iteration 29540, loss = 0.00180189
I0302 13:22:02.780202 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00180189 (* 1 = 0.00180189 loss)
I0302 13:22:02.780211 29253 sgd_solver.cpp:106] Iteration 29540, lr = 0.0001
I0302 13:22:31.617493 29253 solver.cpp:237] Iteration 29560, loss = 0.00145768
I0302 13:22:31.617527 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00145768 (* 1 = 0.00145768 loss)
I0302 13:22:31.617535 29253 sgd_solver.cpp:106] Iteration 29560, lr = 0.0001
I0302 13:23:00.451907 29253 solver.cpp:237] Iteration 29580, loss = 0.00151965
I0302 13:23:00.451938 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00151966 (* 1 = 0.00151966 loss)
I0302 13:23:00.451948 29253 sgd_solver.cpp:106] Iteration 29580, lr = 0.0001
I0302 13:23:29.273497 29253 solver.cpp:237] Iteration 29600, loss = 0.00253898
I0302 13:23:29.273530 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00253898 (* 1 = 0.00253898 loss)
I0302 13:23:29.273540 29253 sgd_solver.cpp:106] Iteration 29600, lr = 0.0001
I0302 13:23:58.157892 29253 solver.cpp:237] Iteration 29620, loss = 0.00188351
I0302 13:23:58.157927 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00188352 (* 1 = 0.00188352 loss)
I0302 13:23:58.157935 29253 sgd_solver.cpp:106] Iteration 29620, lr = 0.0001
I0302 13:24:27.056892 29253 solver.cpp:237] Iteration 29640, loss = 0.0015173
I0302 13:24:27.056926 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00151731 (* 1 = 0.00151731 loss)
I0302 13:24:27.056934 29253 sgd_solver.cpp:106] Iteration 29640, lr = 0.0001
I0302 13:24:55.794631 29253 solver.cpp:237] Iteration 29660, loss = 0.00104407
I0302 13:24:55.794664 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00104407 (* 1 = 0.00104407 loss)
I0302 13:24:55.794673 29253 sgd_solver.cpp:106] Iteration 29660, lr = 0.0001
I0302 13:25:24.609444 29253 solver.cpp:237] Iteration 29680, loss = 0.00158932
I0302 13:25:24.609479 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00158932 (* 1 = 0.00158932 loss)
I0302 13:25:24.609488 29253 sgd_solver.cpp:106] Iteration 29680, lr = 0.0001
I0302 13:25:53.342720 29253 solver.cpp:237] Iteration 29700, loss = 0.00141743
I0302 13:25:53.342752 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00141744 (* 1 = 0.00141744 loss)
I0302 13:25:53.342761 29253 sgd_solver.cpp:106] Iteration 29700, lr = 0.0001
I0302 13:26:22.218724 29253 solver.cpp:237] Iteration 29720, loss = 0.00150686
I0302 13:26:22.218755 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00150686 (* 1 = 0.00150686 loss)
I0302 13:26:22.218763 29253 sgd_solver.cpp:106] Iteration 29720, lr = 0.0001
I0302 13:26:51.287168 29253 solver.cpp:237] Iteration 29740, loss = 0.00154536
I0302 13:26:51.287201 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00154536 (* 1 = 0.00154536 loss)
I0302 13:26:51.287210 29253 sgd_solver.cpp:106] Iteration 29740, lr = 0.0001
I0302 13:27:20.037557 29253 solver.cpp:237] Iteration 29760, loss = 0.00156447
I0302 13:27:20.037588 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00156447 (* 1 = 0.00156447 loss)
I0302 13:27:20.037597 29253 sgd_solver.cpp:106] Iteration 29760, lr = 0.0001
I0302 13:27:49.056162 29253 solver.cpp:237] Iteration 29780, loss = 0.00154462
I0302 13:27:49.056192 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00154462 (* 1 = 0.00154462 loss)
I0302 13:27:49.056201 29253 sgd_solver.cpp:106] Iteration 29780, lr = 0.0001
I0302 13:28:17.889403 29253 solver.cpp:237] Iteration 29800, loss = 0.0016707
I0302 13:28:17.889438 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0016707 (* 1 = 0.0016707 loss)
I0302 13:28:17.889448 29253 sgd_solver.cpp:106] Iteration 29800, lr = 0.0001
I0302 13:28:46.810541 29253 solver.cpp:237] Iteration 29820, loss = 0.00144294
I0302 13:28:46.810573 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00144295 (* 1 = 0.00144295 loss)
I0302 13:28:46.810581 29253 sgd_solver.cpp:106] Iteration 29820, lr = 0.0001
I0302 13:29:15.677881 29253 solver.cpp:237] Iteration 29840, loss = 0.00170041
I0302 13:29:15.677913 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00170041 (* 1 = 0.00170041 loss)
I0302 13:29:15.677922 29253 sgd_solver.cpp:106] Iteration 29840, lr = 0.0001
I0302 13:29:44.851706 29253 solver.cpp:237] Iteration 29860, loss = 0.0017736
I0302 13:29:44.851738 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0017736 (* 1 = 0.0017736 loss)
I0302 13:29:44.851747 29253 sgd_solver.cpp:106] Iteration 29860, lr = 0.0001
I0302 13:30:13.681200 29253 solver.cpp:237] Iteration 29880, loss = 0.0019811
I0302 13:30:13.681231 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0019811 (* 1 = 0.0019811 loss)
I0302 13:30:13.681238 29253 sgd_solver.cpp:106] Iteration 29880, lr = 0.0001
I0302 13:30:42.417866 29253 solver.cpp:237] Iteration 29900, loss = 0.00142888
I0302 13:30:42.417898 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00142888 (* 1 = 0.00142888 loss)
I0302 13:30:42.417907 29253 sgd_solver.cpp:106] Iteration 29900, lr = 0.0001
I0302 13:31:11.400641 29253 solver.cpp:237] Iteration 29920, loss = 0.00149936
I0302 13:31:11.400672 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00149936 (* 1 = 0.00149936 loss)
I0302 13:31:11.400681 29253 sgd_solver.cpp:106] Iteration 29920, lr = 0.0001
I0302 13:31:40.339392 29253 solver.cpp:237] Iteration 29940, loss = 0.00165186
I0302 13:31:40.339426 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00165186 (* 1 = 0.00165186 loss)
I0302 13:31:40.339434 29253 sgd_solver.cpp:106] Iteration 29940, lr = 0.0001
I0302 13:32:09.244683 29253 solver.cpp:237] Iteration 29960, loss = 0.001485
I0302 13:32:09.244716 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.001485 (* 1 = 0.001485 loss)
I0302 13:32:09.244725 29253 sgd_solver.cpp:106] Iteration 29960, lr = 0.0001
I0302 13:32:37.972064 29253 solver.cpp:237] Iteration 29980, loss = 0.00152759
I0302 13:32:37.972096 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0015276 (* 1 = 0.0015276 loss)
I0302 13:32:37.972105 29253 sgd_solver.cpp:106] Iteration 29980, lr = 0.0001
I0302 13:33:05.238860 29253 solver.cpp:459] Snapshotting to binary proto file /nfs.yoda/xiaolonw/fast_rcnn/models_sunrgbd/pre_cls_1fc_scratch/model__iter_30000.caffemodel
I0302 13:33:05.405599 29253 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /nfs.yoda/xiaolonw/fast_rcnn/models_sunrgbd/pre_cls_1fc_scratch/model__iter_30000.solverstate
I0302 13:33:06.679749 29253 solver.cpp:237] Iteration 30000, loss = 0.00155896
I0302 13:33:06.679779 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00155896 (* 1 = 0.00155896 loss)
I0302 13:33:06.679788 29253 sgd_solver.cpp:106] Iteration 30000, lr = 1e-05
I0302 13:33:21.148082 29253 blocking_queue.cpp:50] Data layer prefetch queue empty
I0302 13:33:35.634992 29253 solver.cpp:237] Iteration 30020, loss = 0.00176177
I0302 13:33:35.635025 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00176178 (* 1 = 0.00176178 loss)
I0302 13:33:35.635035 29253 sgd_solver.cpp:106] Iteration 30020, lr = 1e-05
I0302 13:34:04.744413 29253 solver.cpp:237] Iteration 30040, loss = 0.00126286
I0302 13:34:04.744446 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00126286 (* 1 = 0.00126286 loss)
I0302 13:34:04.744454 29253 sgd_solver.cpp:106] Iteration 30040, lr = 1e-05
I0302 13:34:33.794906 29253 solver.cpp:237] Iteration 30060, loss = 0.00165098
I0302 13:34:33.794937 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00165098 (* 1 = 0.00165098 loss)
I0302 13:34:33.794946 29253 sgd_solver.cpp:106] Iteration 30060, lr = 1e-05
I0302 13:35:02.576117 29253 solver.cpp:237] Iteration 30080, loss = 0.00185106
I0302 13:35:02.576148 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00185106 (* 1 = 0.00185106 loss)
I0302 13:35:02.576158 29253 sgd_solver.cpp:106] Iteration 30080, lr = 1e-05
I0302 13:35:31.723927 29253 solver.cpp:237] Iteration 30100, loss = 0.00156241
I0302 13:35:31.723958 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00156242 (* 1 = 0.00156242 loss)
I0302 13:35:31.723968 29253 sgd_solver.cpp:106] Iteration 30100, lr = 1e-05
I0302 13:36:00.614421 29253 solver.cpp:237] Iteration 30120, loss = 0.00150648
I0302 13:36:00.614452 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00150648 (* 1 = 0.00150648 loss)
I0302 13:36:00.614461 29253 sgd_solver.cpp:106] Iteration 30120, lr = 1e-05
I0302 13:36:29.480741 29253 solver.cpp:237] Iteration 30140, loss = 0.0014234
I0302 13:36:29.480772 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0014234 (* 1 = 0.0014234 loss)
I0302 13:36:29.480782 29253 sgd_solver.cpp:106] Iteration 30140, lr = 1e-05
I0302 13:36:58.321786 29253 solver.cpp:237] Iteration 30160, loss = 0.00138084
I0302 13:36:58.321818 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00138084 (* 1 = 0.00138084 loss)
I0302 13:36:58.321827 29253 sgd_solver.cpp:106] Iteration 30160, lr = 1e-05
I0302 13:37:26.980753 29253 solver.cpp:237] Iteration 30180, loss = 0.00151877
I0302 13:37:26.980783 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00151877 (* 1 = 0.00151877 loss)
I0302 13:37:26.980792 29253 sgd_solver.cpp:106] Iteration 30180, lr = 1e-05
I0302 13:37:55.856021 29253 solver.cpp:237] Iteration 30200, loss = 0.00122701
I0302 13:37:55.856053 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00122701 (* 1 = 0.00122701 loss)
I0302 13:37:55.856063 29253 sgd_solver.cpp:106] Iteration 30200, lr = 1e-05
I0302 13:38:24.711151 29253 solver.cpp:237] Iteration 30220, loss = 0.00152797
I0302 13:38:24.711182 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00152797 (* 1 = 0.00152797 loss)
I0302 13:38:24.711191 29253 sgd_solver.cpp:106] Iteration 30220, lr = 1e-05
I0302 13:38:53.727731 29253 solver.cpp:237] Iteration 30240, loss = 0.00174314
I0302 13:38:53.727764 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00174315 (* 1 = 0.00174315 loss)
I0302 13:38:53.727773 29253 sgd_solver.cpp:106] Iteration 30240, lr = 1e-05
I0302 13:39:22.681200 29253 solver.cpp:237] Iteration 30260, loss = 0.00147748
I0302 13:39:22.681231 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00147748 (* 1 = 0.00147748 loss)
I0302 13:39:22.681239 29253 sgd_solver.cpp:106] Iteration 30260, lr = 1e-05
I0302 13:39:51.537871 29253 solver.cpp:237] Iteration 30280, loss = 0.00162081
I0302 13:39:51.537904 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00162081 (* 1 = 0.00162081 loss)
I0302 13:39:51.537912 29253 sgd_solver.cpp:106] Iteration 30280, lr = 1e-05
I0302 13:40:20.533720 29253 solver.cpp:237] Iteration 30300, loss = 0.00145927
I0302 13:40:20.533751 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00145928 (* 1 = 0.00145928 loss)
I0302 13:40:20.533761 29253 sgd_solver.cpp:106] Iteration 30300, lr = 1e-05
I0302 13:40:49.151456 29253 solver.cpp:237] Iteration 30320, loss = 0.00167457
I0302 13:40:49.151489 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00167457 (* 1 = 0.00167457 loss)
I0302 13:40:49.151497 29253 sgd_solver.cpp:106] Iteration 30320, lr = 1e-05
I0302 13:41:18.215250 29253 solver.cpp:237] Iteration 30340, loss = 0.00148052
I0302 13:41:18.215281 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00148052 (* 1 = 0.00148052 loss)
I0302 13:41:18.215291 29253 sgd_solver.cpp:106] Iteration 30340, lr = 1e-05
I0302 13:41:47.193333 29253 solver.cpp:237] Iteration 30360, loss = 0.00217336
I0302 13:41:47.193364 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00217336 (* 1 = 0.00217336 loss)
I0302 13:41:47.193374 29253 sgd_solver.cpp:106] Iteration 30360, lr = 1e-05
I0302 13:42:16.028085 29253 solver.cpp:237] Iteration 30380, loss = 0.0021252
I0302 13:42:16.028117 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0021252 (* 1 = 0.0021252 loss)
I0302 13:42:16.028126 29253 sgd_solver.cpp:106] Iteration 30380, lr = 1e-05
I0302 13:42:45.012476 29253 solver.cpp:237] Iteration 30400, loss = 0.00173189
I0302 13:42:45.012508 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0017319 (* 1 = 0.0017319 loss)
I0302 13:42:45.012517 29253 sgd_solver.cpp:106] Iteration 30400, lr = 1e-05
I0302 13:43:13.873220 29253 solver.cpp:237] Iteration 30420, loss = 0.00131722
I0302 13:43:13.873251 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00131722 (* 1 = 0.00131722 loss)
I0302 13:43:13.873261 29253 sgd_solver.cpp:106] Iteration 30420, lr = 1e-05
I0302 13:43:42.775861 29253 solver.cpp:237] Iteration 30440, loss = 0.00154952
I0302 13:43:42.775893 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00154952 (* 1 = 0.00154952 loss)
I0302 13:43:42.775902 29253 sgd_solver.cpp:106] Iteration 30440, lr = 1e-05
I0302 13:44:11.526751 29253 solver.cpp:237] Iteration 30460, loss = 0.00172409
I0302 13:44:11.526783 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00172409 (* 1 = 0.00172409 loss)
I0302 13:44:11.526793 29253 sgd_solver.cpp:106] Iteration 30460, lr = 1e-05
I0302 13:44:40.468003 29253 solver.cpp:237] Iteration 30480, loss = 0.00203232
I0302 13:44:40.468034 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00203232 (* 1 = 0.00203232 loss)
I0302 13:44:40.468044 29253 sgd_solver.cpp:106] Iteration 30480, lr = 1e-05
I0302 13:45:09.537623 29253 solver.cpp:237] Iteration 30500, loss = 0.00153058
I0302 13:45:09.537655 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00153058 (* 1 = 0.00153058 loss)
I0302 13:45:09.537664 29253 sgd_solver.cpp:106] Iteration 30500, lr = 1e-05
I0302 13:45:38.275976 29253 solver.cpp:237] Iteration 30520, loss = 0.00156937
I0302 13:45:38.276010 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00156937 (* 1 = 0.00156937 loss)
I0302 13:45:38.276021 29253 sgd_solver.cpp:106] Iteration 30520, lr = 1e-05
I0302 13:46:07.290873 29253 solver.cpp:237] Iteration 30540, loss = 0.00174021
I0302 13:46:07.290904 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00174021 (* 1 = 0.00174021 loss)
I0302 13:46:07.290913 29253 sgd_solver.cpp:106] Iteration 30540, lr = 1e-05
I0302 13:46:36.259037 29253 solver.cpp:237] Iteration 30560, loss = 0.00165798
I0302 13:46:36.259069 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00165798 (* 1 = 0.00165798 loss)
I0302 13:46:36.259078 29253 sgd_solver.cpp:106] Iteration 30560, lr = 1e-05
I0302 13:47:05.047468 29253 solver.cpp:237] Iteration 30580, loss = 0.00194879
I0302 13:47:05.047500 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0019488 (* 1 = 0.0019488 loss)
I0302 13:47:05.047509 29253 sgd_solver.cpp:106] Iteration 30580, lr = 1e-05
I0302 13:47:33.966480 29253 solver.cpp:237] Iteration 30600, loss = 0.00180012
I0302 13:47:33.966512 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00180013 (* 1 = 0.00180013 loss)
I0302 13:47:33.966521 29253 sgd_solver.cpp:106] Iteration 30600, lr = 1e-05
I0302 13:48:02.959246 29253 solver.cpp:237] Iteration 30620, loss = 0.00186559
I0302 13:48:02.959276 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0018656 (* 1 = 0.0018656 loss)
I0302 13:48:02.959285 29253 sgd_solver.cpp:106] Iteration 30620, lr = 1e-05
I0302 13:48:31.740969 29253 solver.cpp:237] Iteration 30640, loss = 0.00131694
I0302 13:48:31.741000 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00131695 (* 1 = 0.00131695 loss)
I0302 13:48:31.741008 29253 sgd_solver.cpp:106] Iteration 30640, lr = 1e-05
I0302 13:49:00.656311 29253 solver.cpp:237] Iteration 30660, loss = 0.00133018
I0302 13:49:00.656342 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00133019 (* 1 = 0.00133019 loss)
I0302 13:49:00.656352 29253 sgd_solver.cpp:106] Iteration 30660, lr = 1e-05
I0302 13:49:29.560839 29253 solver.cpp:237] Iteration 30680, loss = 0.00261673
I0302 13:49:29.560873 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00261673 (* 1 = 0.00261673 loss)
I0302 13:49:29.560881 29253 sgd_solver.cpp:106] Iteration 30680, lr = 1e-05
I0302 13:49:58.462843 29253 solver.cpp:237] Iteration 30700, loss = 0.00180028
I0302 13:49:58.462874 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00180029 (* 1 = 0.00180029 loss)
I0302 13:49:58.462883 29253 sgd_solver.cpp:106] Iteration 30700, lr = 1e-05
I0302 13:50:27.316228 29253 solver.cpp:237] Iteration 30720, loss = 0.00163383
I0302 13:50:27.316262 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00163383 (* 1 = 0.00163383 loss)
I0302 13:50:27.316270 29253 sgd_solver.cpp:106] Iteration 30720, lr = 1e-05
I0302 13:50:56.402683 29253 solver.cpp:237] Iteration 30740, loss = 0.00180805
I0302 13:50:56.402714 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00180805 (* 1 = 0.00180805 loss)
I0302 13:50:56.402724 29253 sgd_solver.cpp:106] Iteration 30740, lr = 1e-05
I0302 13:51:25.338502 29253 solver.cpp:237] Iteration 30760, loss = 0.00162635
I0302 13:51:25.338534 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00162635 (* 1 = 0.00162635 loss)
I0302 13:51:25.338543 29253 sgd_solver.cpp:106] Iteration 30760, lr = 1e-05
I0302 13:51:54.301758 29253 solver.cpp:237] Iteration 30780, loss = 0.00229731
I0302 13:51:54.301789 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00229732 (* 1 = 0.00229732 loss)
I0302 13:51:54.301798 29253 sgd_solver.cpp:106] Iteration 30780, lr = 1e-05
I0302 13:52:23.035006 29253 solver.cpp:237] Iteration 30800, loss = 0.00195355
I0302 13:52:23.035037 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00195356 (* 1 = 0.00195356 loss)
I0302 13:52:23.035045 29253 sgd_solver.cpp:106] Iteration 30800, lr = 1e-05
I0302 13:52:52.044554 29253 solver.cpp:237] Iteration 30820, loss = 0.00155812
I0302 13:52:52.044586 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00155812 (* 1 = 0.00155812 loss)
I0302 13:52:52.044595 29253 sgd_solver.cpp:106] Iteration 30820, lr = 1e-05
I0302 13:53:20.678779 29253 solver.cpp:237] Iteration 30840, loss = 0.00158031
I0302 13:53:20.678812 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00158031 (* 1 = 0.00158031 loss)
I0302 13:53:20.678822 29253 sgd_solver.cpp:106] Iteration 30840, lr = 1e-05
I0302 13:53:49.469979 29253 solver.cpp:237] Iteration 30860, loss = 0.00181257
I0302 13:53:49.470008 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00181257 (* 1 = 0.00181257 loss)
I0302 13:53:49.470017 29253 sgd_solver.cpp:106] Iteration 30860, lr = 1e-05
I0302 13:54:18.456812 29253 solver.cpp:237] Iteration 30880, loss = 0.00138087
I0302 13:54:18.456843 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00138088 (* 1 = 0.00138088 loss)
I0302 13:54:18.456852 29253 sgd_solver.cpp:106] Iteration 30880, lr = 1e-05
I0302 13:54:47.300938 29253 solver.cpp:237] Iteration 30900, loss = 0.00139378
I0302 13:54:47.300971 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00139378 (* 1 = 0.00139378 loss)
I0302 13:54:47.300979 29253 sgd_solver.cpp:106] Iteration 30900, lr = 1e-05
I0302 13:55:16.227990 29253 solver.cpp:237] Iteration 30920, loss = 0.00217663
I0302 13:55:16.228024 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00217663 (* 1 = 0.00217663 loss)
I0302 13:55:16.228032 29253 sgd_solver.cpp:106] Iteration 30920, lr = 1e-05
I0302 13:55:45.041329 29253 solver.cpp:237] Iteration 30940, loss = 0.00172515
I0302 13:55:45.041362 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00172515 (* 1 = 0.00172515 loss)
I0302 13:55:45.041370 29253 sgd_solver.cpp:106] Iteration 30940, lr = 1e-05
I0302 13:56:13.838578 29253 solver.cpp:237] Iteration 30960, loss = 0.00139398
I0302 13:56:13.838610 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00139398 (* 1 = 0.00139398 loss)
I0302 13:56:13.838619 29253 sgd_solver.cpp:106] Iteration 30960, lr = 1e-05
I0302 13:56:42.752425 29253 solver.cpp:237] Iteration 30980, loss = 0.00178209
I0302 13:56:42.752456 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0017821 (* 1 = 0.0017821 loss)
I0302 13:56:42.752465 29253 sgd_solver.cpp:106] Iteration 30980, lr = 1e-05
I0302 13:57:11.894608 29253 solver.cpp:237] Iteration 31000, loss = 0.0015247
I0302 13:57:11.894640 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0015247 (* 1 = 0.0015247 loss)
I0302 13:57:11.894649 29253 sgd_solver.cpp:106] Iteration 31000, lr = 1e-05
I0302 13:57:26.324599 29253 blocking_queue.cpp:50] Data layer prefetch queue empty
I0302 13:57:40.786764 29253 solver.cpp:237] Iteration 31020, loss = 0.00172224
I0302 13:57:40.786799 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00172224 (* 1 = 0.00172224 loss)
I0302 13:57:40.786808 29253 sgd_solver.cpp:106] Iteration 31020, lr = 1e-05
I0302 13:58:09.585175 29253 solver.cpp:237] Iteration 31040, loss = 0.00203658
I0302 13:58:09.585206 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00203658 (* 1 = 0.00203658 loss)
I0302 13:58:09.585216 29253 sgd_solver.cpp:106] Iteration 31040, lr = 1e-05
I0302 13:58:38.637189 29253 solver.cpp:237] Iteration 31060, loss = 0.00160129
I0302 13:58:38.637220 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00160129 (* 1 = 0.00160129 loss)
I0302 13:58:38.637229 29253 sgd_solver.cpp:106] Iteration 31060, lr = 1e-05
I0302 13:59:07.512871 29253 solver.cpp:237] Iteration 31080, loss = 0.00146366
I0302 13:59:07.512902 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00146367 (* 1 = 0.00146367 loss)
I0302 13:59:07.512912 29253 sgd_solver.cpp:106] Iteration 31080, lr = 1e-05
I0302 13:59:36.497985 29253 solver.cpp:237] Iteration 31100, loss = 0.0017605
I0302 13:59:36.498018 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0017605 (* 1 = 0.0017605 loss)
I0302 13:59:36.498026 29253 sgd_solver.cpp:106] Iteration 31100, lr = 1e-05
I0302 14:00:05.319100 29253 solver.cpp:237] Iteration 31120, loss = 0.0031298
I0302 14:00:05.319133 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00312981 (* 1 = 0.00312981 loss)
I0302 14:00:05.319141 29253 sgd_solver.cpp:106] Iteration 31120, lr = 1e-05
I0302 14:00:34.304430 29253 solver.cpp:237] Iteration 31140, loss = 0.00159288
I0302 14:00:34.304461 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00159288 (* 1 = 0.00159288 loss)
I0302 14:00:34.304471 29253 sgd_solver.cpp:106] Iteration 31140, lr = 1e-05
I0302 14:01:03.358817 29253 solver.cpp:237] Iteration 31160, loss = 0.00160262
I0302 14:01:03.358849 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00160263 (* 1 = 0.00160263 loss)
I0302 14:01:03.358857 29253 sgd_solver.cpp:106] Iteration 31160, lr = 1e-05
I0302 14:01:32.146819 29253 solver.cpp:237] Iteration 31180, loss = 0.00183898
I0302 14:01:32.146852 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00183898 (* 1 = 0.00183898 loss)
I0302 14:01:32.146862 29253 sgd_solver.cpp:106] Iteration 31180, lr = 1e-05
I0302 14:02:01.034225 29253 solver.cpp:237] Iteration 31200, loss = 0.0014701
I0302 14:02:01.034255 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00147011 (* 1 = 0.00147011 loss)
I0302 14:02:01.034265 29253 sgd_solver.cpp:106] Iteration 31200, lr = 1e-05
I0302 14:02:30.179132 29253 solver.cpp:237] Iteration 31220, loss = 0.00161981
I0302 14:02:30.179164 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00161981 (* 1 = 0.00161981 loss)
I0302 14:02:30.179173 29253 sgd_solver.cpp:106] Iteration 31220, lr = 1e-05
I0302 14:02:58.874528 29253 solver.cpp:237] Iteration 31240, loss = 0.00146463
I0302 14:02:58.874560 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00146463 (* 1 = 0.00146463 loss)
I0302 14:02:58.874569 29253 sgd_solver.cpp:106] Iteration 31240, lr = 1e-05
I0302 14:03:27.948479 29253 solver.cpp:237] Iteration 31260, loss = 0.00161889
I0302 14:03:27.948511 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00161889 (* 1 = 0.00161889 loss)
I0302 14:03:27.948520 29253 sgd_solver.cpp:106] Iteration 31260, lr = 1e-05
I0302 14:03:56.664898 29253 solver.cpp:237] Iteration 31280, loss = 0.00149725
I0302 14:03:56.664930 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00149725 (* 1 = 0.00149725 loss)
I0302 14:03:56.664939 29253 sgd_solver.cpp:106] Iteration 31280, lr = 1e-05
I0302 14:04:25.734361 29253 solver.cpp:237] Iteration 31300, loss = 0.00142754
I0302 14:04:25.734392 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00142755 (* 1 = 0.00142755 loss)
I0302 14:04:25.734401 29253 sgd_solver.cpp:106] Iteration 31300, lr = 1e-05
I0302 14:04:54.486817 29253 solver.cpp:237] Iteration 31320, loss = 0.00141368
I0302 14:04:54.486848 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00141368 (* 1 = 0.00141368 loss)
I0302 14:04:54.486858 29253 sgd_solver.cpp:106] Iteration 31320, lr = 1e-05
I0302 14:05:23.405527 29253 solver.cpp:237] Iteration 31340, loss = 0.00142427
I0302 14:05:23.405560 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00142427 (* 1 = 0.00142427 loss)
I0302 14:05:23.405568 29253 sgd_solver.cpp:106] Iteration 31340, lr = 1e-05
I0302 14:05:52.350203 29253 solver.cpp:237] Iteration 31360, loss = 0.00154669
I0302 14:05:52.350234 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00154669 (* 1 = 0.00154669 loss)
I0302 14:05:52.350241 29253 sgd_solver.cpp:106] Iteration 31360, lr = 1e-05
I0302 14:06:21.362666 29253 solver.cpp:237] Iteration 31380, loss = 0.00191159
I0302 14:06:21.362699 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00191159 (* 1 = 0.00191159 loss)
I0302 14:06:21.362707 29253 sgd_solver.cpp:106] Iteration 31380, lr = 1e-05
I0302 14:06:50.251117 29253 solver.cpp:237] Iteration 31400, loss = 0.00165115
I0302 14:06:50.251150 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00165115 (* 1 = 0.00165115 loss)
I0302 14:06:50.251159 29253 sgd_solver.cpp:106] Iteration 31400, lr = 1e-05
I0302 14:07:19.044019 29253 solver.cpp:237] Iteration 31420, loss = 0.00139219
I0302 14:07:19.044051 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00139219 (* 1 = 0.00139219 loss)
I0302 14:07:19.044060 29253 sgd_solver.cpp:106] Iteration 31420, lr = 1e-05
I0302 14:07:48.188453 29253 solver.cpp:237] Iteration 31440, loss = 0.00151141
I0302 14:07:48.188485 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00151141 (* 1 = 0.00151141 loss)
I0302 14:07:48.188494 29253 sgd_solver.cpp:106] Iteration 31440, lr = 1e-05
I0302 14:08:16.962373 29253 solver.cpp:237] Iteration 31460, loss = 0.00152367
I0302 14:08:16.962407 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00152367 (* 1 = 0.00152367 loss)
I0302 14:08:16.962417 29253 sgd_solver.cpp:106] Iteration 31460, lr = 1e-05
I0302 14:08:45.892109 29253 solver.cpp:237] Iteration 31480, loss = 0.00180713
I0302 14:08:45.892143 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00180714 (* 1 = 0.00180714 loss)
I0302 14:08:45.892151 29253 sgd_solver.cpp:106] Iteration 31480, lr = 1e-05
I0302 14:09:14.629586 29253 solver.cpp:237] Iteration 31500, loss = 0.00185029
I0302 14:09:14.629617 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00185029 (* 1 = 0.00185029 loss)
I0302 14:09:14.629627 29253 sgd_solver.cpp:106] Iteration 31500, lr = 1e-05
I0302 14:09:43.668081 29253 solver.cpp:237] Iteration 31520, loss = 0.00167242
I0302 14:09:43.668112 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00167242 (* 1 = 0.00167242 loss)
I0302 14:09:43.668120 29253 sgd_solver.cpp:106] Iteration 31520, lr = 1e-05
I0302 14:10:12.628178 29253 solver.cpp:237] Iteration 31540, loss = 0.00156311
I0302 14:10:12.628211 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00156311 (* 1 = 0.00156311 loss)
I0302 14:10:12.628219 29253 sgd_solver.cpp:106] Iteration 31540, lr = 1e-05
I0302 14:10:41.615809 29253 solver.cpp:237] Iteration 31560, loss = 0.00166021
I0302 14:10:41.615841 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00166022 (* 1 = 0.00166022 loss)
I0302 14:10:41.615850 29253 sgd_solver.cpp:106] Iteration 31560, lr = 1e-05
I0302 14:11:10.406968 29253 solver.cpp:237] Iteration 31580, loss = 0.00165262
I0302 14:11:10.406999 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00165262 (* 1 = 0.00165262 loss)
I0302 14:11:10.407008 29253 sgd_solver.cpp:106] Iteration 31580, lr = 1e-05
I0302 14:11:39.306670 29253 solver.cpp:237] Iteration 31600, loss = 0.00166706
I0302 14:11:39.306702 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00166706 (* 1 = 0.00166706 loss)
I0302 14:11:39.306711 29253 sgd_solver.cpp:106] Iteration 31600, lr = 1e-05
I0302 14:12:08.023053 29253 solver.cpp:237] Iteration 31620, loss = 0.00162046
I0302 14:12:08.023085 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00162046 (* 1 = 0.00162046 loss)
I0302 14:12:08.023094 29253 sgd_solver.cpp:106] Iteration 31620, lr = 1e-05
I0302 14:12:36.869915 29253 solver.cpp:237] Iteration 31640, loss = 0.00233033
I0302 14:12:36.869948 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00233033 (* 1 = 0.00233033 loss)
I0302 14:12:36.869958 29253 sgd_solver.cpp:106] Iteration 31640, lr = 1e-05
I0302 14:13:05.709084 29253 solver.cpp:237] Iteration 31660, loss = 0.00159674
I0302 14:13:05.709116 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00159675 (* 1 = 0.00159675 loss)
I0302 14:13:05.709125 29253 sgd_solver.cpp:106] Iteration 31660, lr = 1e-05
I0302 14:13:34.772364 29253 solver.cpp:237] Iteration 31680, loss = 0.00172589
I0302 14:13:34.772397 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00172589 (* 1 = 0.00172589 loss)
I0302 14:13:34.772405 29253 sgd_solver.cpp:106] Iteration 31680, lr = 1e-05
I0302 14:14:03.878166 29253 solver.cpp:237] Iteration 31700, loss = 0.00168176
I0302 14:14:03.878199 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00168177 (* 1 = 0.00168177 loss)
I0302 14:14:03.878208 29253 sgd_solver.cpp:106] Iteration 31700, lr = 1e-05
I0302 14:14:32.400514 29253 solver.cpp:237] Iteration 31720, loss = 0.00195898
I0302 14:14:32.400547 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00195899 (* 1 = 0.00195899 loss)
I0302 14:14:32.400557 29253 sgd_solver.cpp:106] Iteration 31720, lr = 1e-05
I0302 14:15:01.530742 29253 solver.cpp:237] Iteration 31740, loss = 0.00129683
I0302 14:15:01.530773 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00129684 (* 1 = 0.00129684 loss)
I0302 14:15:01.530782 29253 sgd_solver.cpp:106] Iteration 31740, lr = 1e-05
I0302 14:15:30.498821 29253 solver.cpp:237] Iteration 31760, loss = 0.00160978
I0302 14:15:30.498853 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00160978 (* 1 = 0.00160978 loss)
I0302 14:15:30.498862 29253 sgd_solver.cpp:106] Iteration 31760, lr = 1e-05
I0302 14:15:59.429920 29253 solver.cpp:237] Iteration 31780, loss = 0.00157923
I0302 14:15:59.429952 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00157924 (* 1 = 0.00157924 loss)
I0302 14:15:59.429961 29253 sgd_solver.cpp:106] Iteration 31780, lr = 1e-05
I0302 14:16:28.428217 29253 solver.cpp:237] Iteration 31800, loss = 0.00201045
I0302 14:16:28.428248 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00201046 (* 1 = 0.00201046 loss)
I0302 14:16:28.428257 29253 sgd_solver.cpp:106] Iteration 31800, lr = 1e-05
I0302 14:16:57.316639 29253 solver.cpp:237] Iteration 31820, loss = 0.00138615
I0302 14:16:57.316671 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00138615 (* 1 = 0.00138615 loss)
I0302 14:16:57.316680 29253 sgd_solver.cpp:106] Iteration 31820, lr = 1e-05
I0302 14:17:26.018134 29253 solver.cpp:237] Iteration 31840, loss = 0.00151902
I0302 14:17:26.018167 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00151902 (* 1 = 0.00151902 loss)
I0302 14:17:26.018177 29253 sgd_solver.cpp:106] Iteration 31840, lr = 1e-05
I0302 14:17:54.993863 29253 solver.cpp:237] Iteration 31860, loss = 0.00174207
I0302 14:17:54.993896 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00174207 (* 1 = 0.00174207 loss)
I0302 14:17:54.993904 29253 sgd_solver.cpp:106] Iteration 31860, lr = 1e-05
I0302 14:18:23.842332 29253 solver.cpp:237] Iteration 31880, loss = 0.00169375
I0302 14:18:23.842362 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00169376 (* 1 = 0.00169376 loss)
I0302 14:18:23.842371 29253 sgd_solver.cpp:106] Iteration 31880, lr = 1e-05
I0302 14:18:52.761971 29253 solver.cpp:237] Iteration 31900, loss = 0.001573
I0302 14:18:52.762003 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.001573 (* 1 = 0.001573 loss)
I0302 14:18:52.762012 29253 sgd_solver.cpp:106] Iteration 31900, lr = 1e-05
I0302 14:19:21.630743 29253 solver.cpp:237] Iteration 31920, loss = 0.00173376
I0302 14:19:21.630774 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00173376 (* 1 = 0.00173376 loss)
I0302 14:19:21.630782 29253 sgd_solver.cpp:106] Iteration 31920, lr = 1e-05
I0302 14:19:50.736544 29253 solver.cpp:237] Iteration 31940, loss = 0.00191825
I0302 14:19:50.736575 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00191825 (* 1 = 0.00191825 loss)
I0302 14:19:50.736584 29253 sgd_solver.cpp:106] Iteration 31940, lr = 1e-05
I0302 14:20:19.563954 29253 solver.cpp:237] Iteration 31960, loss = 0.00168277
I0302 14:20:19.563984 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00168277 (* 1 = 0.00168277 loss)
I0302 14:20:19.563994 29253 sgd_solver.cpp:106] Iteration 31960, lr = 1e-05
I0302 14:20:48.586400 29253 solver.cpp:237] Iteration 31980, loss = 0.0012027
I0302 14:20:48.586432 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00120271 (* 1 = 0.00120271 loss)
I0302 14:20:48.586441 29253 sgd_solver.cpp:106] Iteration 31980, lr = 1e-05
I0302 14:21:17.487700 29253 solver.cpp:237] Iteration 32000, loss = 0.00138768
I0302 14:21:17.487733 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00138768 (* 1 = 0.00138768 loss)
I0302 14:21:17.487741 29253 sgd_solver.cpp:106] Iteration 32000, lr = 1e-05
I0302 14:21:31.870026 29253 blocking_queue.cpp:50] Data layer prefetch queue empty
I0302 14:21:46.409045 29253 solver.cpp:237] Iteration 32020, loss = 0.00162549
I0302 14:21:46.409080 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00162549 (* 1 = 0.00162549 loss)
I0302 14:21:46.409088 29253 sgd_solver.cpp:106] Iteration 32020, lr = 1e-05
I0302 14:22:15.228255 29253 solver.cpp:237] Iteration 32040, loss = 0.00153934
I0302 14:22:15.228286 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00153934 (* 1 = 0.00153934 loss)
I0302 14:22:15.228296 29253 sgd_solver.cpp:106] Iteration 32040, lr = 1e-05
I0302 14:22:44.101768 29253 solver.cpp:237] Iteration 32060, loss = 0.00153009
I0302 14:22:44.101800 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0015301 (* 1 = 0.0015301 loss)
I0302 14:22:44.101809 29253 sgd_solver.cpp:106] Iteration 32060, lr = 1e-05
I0302 14:23:13.194448 29253 solver.cpp:237] Iteration 32080, loss = 0.00150681
I0302 14:23:13.194481 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00150681 (* 1 = 0.00150681 loss)
I0302 14:23:13.194490 29253 sgd_solver.cpp:106] Iteration 32080, lr = 1e-05
I0302 14:23:41.974555 29253 solver.cpp:237] Iteration 32100, loss = 0.00142757
I0302 14:23:41.974586 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00142757 (* 1 = 0.00142757 loss)
I0302 14:23:41.974594 29253 sgd_solver.cpp:106] Iteration 32100, lr = 1e-05
I0302 14:24:11.038794 29253 solver.cpp:237] Iteration 32120, loss = 0.00189086
I0302 14:24:11.038825 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00189086 (* 1 = 0.00189086 loss)
I0302 14:24:11.038835 29253 sgd_solver.cpp:106] Iteration 32120, lr = 1e-05
I0302 14:24:40.089540 29253 solver.cpp:237] Iteration 32140, loss = 0.00184997
I0302 14:24:40.089572 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00184998 (* 1 = 0.00184998 loss)
I0302 14:24:40.089581 29253 sgd_solver.cpp:106] Iteration 32140, lr = 1e-05
I0302 14:25:09.047415 29253 solver.cpp:237] Iteration 32160, loss = 0.00159776
I0302 14:25:09.047447 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00159776 (* 1 = 0.00159776 loss)
I0302 14:25:09.047456 29253 sgd_solver.cpp:106] Iteration 32160, lr = 1e-05
I0302 14:25:37.881813 29253 solver.cpp:237] Iteration 32180, loss = 0.0020745
I0302 14:25:37.881846 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0020745 (* 1 = 0.0020745 loss)
I0302 14:25:37.881855 29253 sgd_solver.cpp:106] Iteration 32180, lr = 1e-05
I0302 14:26:06.950736 29253 solver.cpp:237] Iteration 32200, loss = 0.0015257
I0302 14:26:06.950772 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0015257 (* 1 = 0.0015257 loss)
I0302 14:26:06.950780 29253 sgd_solver.cpp:106] Iteration 32200, lr = 1e-05
I0302 14:26:35.826038 29253 solver.cpp:237] Iteration 32220, loss = 0.00219795
I0302 14:26:35.826071 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00219796 (* 1 = 0.00219796 loss)
I0302 14:26:35.826079 29253 sgd_solver.cpp:106] Iteration 32220, lr = 1e-05
I0302 14:27:04.990988 29253 solver.cpp:237] Iteration 32240, loss = 0.00143376
I0302 14:27:04.991019 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00143376 (* 1 = 0.00143376 loss)
I0302 14:27:04.991027 29253 sgd_solver.cpp:106] Iteration 32240, lr = 1e-05
I0302 14:27:33.899812 29253 solver.cpp:237] Iteration 32260, loss = 0.00144061
I0302 14:27:33.899843 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00144061 (* 1 = 0.00144061 loss)
I0302 14:27:33.899852 29253 sgd_solver.cpp:106] Iteration 32260, lr = 1e-05
I0302 14:28:02.626243 29253 solver.cpp:237] Iteration 32280, loss = 0.00150998
I0302 14:28:02.626274 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00150999 (* 1 = 0.00150999 loss)
I0302 14:28:02.626283 29253 sgd_solver.cpp:106] Iteration 32280, lr = 1e-05
I0302 14:28:31.476534 29253 solver.cpp:237] Iteration 32300, loss = 0.0014956
I0302 14:28:31.476567 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0014956 (* 1 = 0.0014956 loss)
I0302 14:28:31.476586 29253 sgd_solver.cpp:106] Iteration 32300, lr = 1e-05
I0302 14:29:00.543999 29253 solver.cpp:237] Iteration 32320, loss = 0.00169373
I0302 14:29:00.544031 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00169373 (* 1 = 0.00169373 loss)
I0302 14:29:00.544040 29253 sgd_solver.cpp:106] Iteration 32320, lr = 1e-05
I0302 14:29:29.458792 29253 solver.cpp:237] Iteration 32340, loss = 0.00127203
I0302 14:29:29.458823 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00127204 (* 1 = 0.00127204 loss)
I0302 14:29:29.458832 29253 sgd_solver.cpp:106] Iteration 32340, lr = 1e-05
I0302 14:29:58.465801 29253 solver.cpp:237] Iteration 32360, loss = 0.00234923
I0302 14:29:58.465831 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00234923 (* 1 = 0.00234923 loss)
I0302 14:29:58.465839 29253 sgd_solver.cpp:106] Iteration 32360, lr = 1e-05
I0302 14:30:27.139287 29253 solver.cpp:237] Iteration 32380, loss = 0.00143209
I0302 14:30:27.139319 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0014321 (* 1 = 0.0014321 loss)
I0302 14:30:27.139328 29253 sgd_solver.cpp:106] Iteration 32380, lr = 1e-05
I0302 14:30:56.190462 29253 solver.cpp:237] Iteration 32400, loss = 0.00145777
I0302 14:30:56.190495 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00145778 (* 1 = 0.00145778 loss)
I0302 14:30:56.190503 29253 sgd_solver.cpp:106] Iteration 32400, lr = 1e-05
I0302 14:31:25.140233 29253 solver.cpp:237] Iteration 32420, loss = 0.00126542
I0302 14:31:25.140264 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00126543 (* 1 = 0.00126543 loss)
I0302 14:31:25.140275 29253 sgd_solver.cpp:106] Iteration 32420, lr = 1e-05
I0302 14:31:53.981417 29253 solver.cpp:237] Iteration 32440, loss = 0.00192166
I0302 14:31:53.981449 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00192166 (* 1 = 0.00192166 loss)
I0302 14:31:53.981458 29253 sgd_solver.cpp:106] Iteration 32440, lr = 1e-05
I0302 14:32:23.019812 29253 solver.cpp:237] Iteration 32460, loss = 0.00197071
I0302 14:32:23.019843 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00197072 (* 1 = 0.00197072 loss)
I0302 14:32:23.019852 29253 sgd_solver.cpp:106] Iteration 32460, lr = 1e-05
I0302 14:32:51.945246 29253 solver.cpp:237] Iteration 32480, loss = 0.00152764
I0302 14:32:51.945278 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00152764 (* 1 = 0.00152764 loss)
I0302 14:32:51.945287 29253 sgd_solver.cpp:106] Iteration 32480, lr = 1e-05
I0302 14:33:20.900102 29253 solver.cpp:237] Iteration 32500, loss = 0.0016696
I0302 14:33:20.900132 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0016696 (* 1 = 0.0016696 loss)
I0302 14:33:20.900142 29253 sgd_solver.cpp:106] Iteration 32500, lr = 1e-05
I0302 14:33:49.736477 29253 solver.cpp:237] Iteration 32520, loss = 0.00166166
I0302 14:33:49.736510 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00166167 (* 1 = 0.00166167 loss)
I0302 14:33:49.736520 29253 sgd_solver.cpp:106] Iteration 32520, lr = 1e-05
I0302 14:34:18.696784 29253 solver.cpp:237] Iteration 32540, loss = 0.0016933
I0302 14:34:18.696815 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00169331 (* 1 = 0.00169331 loss)
I0302 14:34:18.696823 29253 sgd_solver.cpp:106] Iteration 32540, lr = 1e-05
I0302 14:34:47.485191 29253 solver.cpp:237] Iteration 32560, loss = 0.00176997
I0302 14:34:47.485224 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00176997 (* 1 = 0.00176997 loss)
I0302 14:34:47.485232 29253 sgd_solver.cpp:106] Iteration 32560, lr = 1e-05
I0302 14:35:16.422490 29253 solver.cpp:237] Iteration 32580, loss = 0.001482
I0302 14:35:16.422523 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00148201 (* 1 = 0.00148201 loss)
I0302 14:35:16.422533 29253 sgd_solver.cpp:106] Iteration 32580, lr = 1e-05
I0302 14:35:45.490663 29253 solver.cpp:237] Iteration 32600, loss = 0.00158556
I0302 14:35:45.490694 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00158557 (* 1 = 0.00158557 loss)
I0302 14:35:45.490702 29253 sgd_solver.cpp:106] Iteration 32600, lr = 1e-05
I0302 14:36:14.412740 29253 solver.cpp:237] Iteration 32620, loss = 0.00166482
I0302 14:36:14.412772 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00166482 (* 1 = 0.00166482 loss)
I0302 14:36:14.412781 29253 sgd_solver.cpp:106] Iteration 32620, lr = 1e-05
I0302 14:36:43.153144 29253 solver.cpp:237] Iteration 32640, loss = 0.00159076
I0302 14:36:43.153175 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00159077 (* 1 = 0.00159077 loss)
I0302 14:36:43.153184 29253 sgd_solver.cpp:106] Iteration 32640, lr = 1e-05
I0302 14:37:12.073302 29253 solver.cpp:237] Iteration 32660, loss = 0.00176981
I0302 14:37:12.073333 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00176982 (* 1 = 0.00176982 loss)
I0302 14:37:12.073341 29253 sgd_solver.cpp:106] Iteration 32660, lr = 1e-05
I0302 14:37:40.941349 29253 solver.cpp:237] Iteration 32680, loss = 0.00144658
I0302 14:37:40.941383 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00144658 (* 1 = 0.00144658 loss)
I0302 14:37:40.941393 29253 sgd_solver.cpp:106] Iteration 32680, lr = 1e-05
I0302 14:38:10.090833 29253 solver.cpp:237] Iteration 32700, loss = 0.00183132
I0302 14:38:10.090864 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00183132 (* 1 = 0.00183132 loss)
I0302 14:38:10.090873 29253 sgd_solver.cpp:106] Iteration 32700, lr = 1e-05
I0302 14:38:38.965922 29253 solver.cpp:237] Iteration 32720, loss = 0.00164477
I0302 14:38:38.965955 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00164478 (* 1 = 0.00164478 loss)
I0302 14:38:38.965963 29253 sgd_solver.cpp:106] Iteration 32720, lr = 1e-05
I0302 14:39:07.750236 29253 solver.cpp:237] Iteration 32740, loss = 0.00140129
I0302 14:39:07.750267 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00140129 (* 1 = 0.00140129 loss)
I0302 14:39:07.750275 29253 sgd_solver.cpp:106] Iteration 32740, lr = 1e-05
I0302 14:39:36.624686 29253 solver.cpp:237] Iteration 32760, loss = 0.00181802
I0302 14:39:36.624717 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00181802 (* 1 = 0.00181802 loss)
I0302 14:39:36.624725 29253 sgd_solver.cpp:106] Iteration 32760, lr = 1e-05
I0302 14:40:05.389632 29253 solver.cpp:237] Iteration 32780, loss = 0.00143221
I0302 14:40:05.389662 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00143221 (* 1 = 0.00143221 loss)
I0302 14:40:05.389670 29253 sgd_solver.cpp:106] Iteration 32780, lr = 1e-05
I0302 14:40:34.630822 29253 solver.cpp:237] Iteration 32800, loss = 0.00162901
I0302 14:40:34.630854 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00162901 (* 1 = 0.00162901 loss)
I0302 14:40:34.630864 29253 sgd_solver.cpp:106] Iteration 32800, lr = 1e-05
I0302 14:41:03.713910 29253 solver.cpp:237] Iteration 32820, loss = 0.00180964
I0302 14:41:03.713942 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00180964 (* 1 = 0.00180964 loss)
I0302 14:41:03.713951 29253 sgd_solver.cpp:106] Iteration 32820, lr = 1e-05
I0302 14:41:32.585571 29253 solver.cpp:237] Iteration 32840, loss = 0.00134701
I0302 14:41:32.585602 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00134701 (* 1 = 0.00134701 loss)
I0302 14:41:32.585611 29253 sgd_solver.cpp:106] Iteration 32840, lr = 1e-05
I0302 14:42:01.494483 29253 solver.cpp:237] Iteration 32860, loss = 0.00135549
I0302 14:42:01.494515 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00135549 (* 1 = 0.00135549 loss)
I0302 14:42:01.494524 29253 sgd_solver.cpp:106] Iteration 32860, lr = 1e-05
I0302 14:42:30.410979 29253 solver.cpp:237] Iteration 32880, loss = 0.00159721
I0302 14:42:30.411012 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00159722 (* 1 = 0.00159722 loss)
I0302 14:42:30.411021 29253 sgd_solver.cpp:106] Iteration 32880, lr = 1e-05
I0302 14:42:59.559278 29253 solver.cpp:237] Iteration 32900, loss = 0.00142024
I0302 14:42:59.559310 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00142025 (* 1 = 0.00142025 loss)
I0302 14:42:59.559319 29253 sgd_solver.cpp:106] Iteration 32900, lr = 1e-05
I0302 14:43:28.399597 29253 solver.cpp:237] Iteration 32920, loss = 0.00159237
I0302 14:43:28.399629 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00159238 (* 1 = 0.00159238 loss)
I0302 14:43:28.399638 29253 sgd_solver.cpp:106] Iteration 32920, lr = 1e-05
I0302 14:43:57.416858 29253 solver.cpp:237] Iteration 32940, loss = 0.00186626
I0302 14:43:57.416894 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00186626 (* 1 = 0.00186626 loss)
I0302 14:43:57.416904 29253 sgd_solver.cpp:106] Iteration 32940, lr = 1e-05
I0302 14:44:26.274392 29253 solver.cpp:237] Iteration 32960, loss = 0.00164245
I0302 14:44:26.274425 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00164246 (* 1 = 0.00164246 loss)
I0302 14:44:26.274435 29253 sgd_solver.cpp:106] Iteration 32960, lr = 1e-05
I0302 14:44:55.519505 29253 solver.cpp:237] Iteration 32980, loss = 0.00173067
I0302 14:44:55.519539 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00173067 (* 1 = 0.00173067 loss)
I0302 14:44:55.519551 29253 sgd_solver.cpp:106] Iteration 32980, lr = 1e-05
I0302 14:45:24.637936 29253 solver.cpp:237] Iteration 33000, loss = 0.00143416
I0302 14:45:24.637970 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00143416 (* 1 = 0.00143416 loss)
I0302 14:45:24.637979 29253 sgd_solver.cpp:106] Iteration 33000, lr = 1e-05
I0302 14:45:39.117770 29253 blocking_queue.cpp:50] Data layer prefetch queue empty
I0302 14:45:53.706964 29253 solver.cpp:237] Iteration 33020, loss = 0.00124439
I0302 14:45:53.706995 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00124439 (* 1 = 0.00124439 loss)
I0302 14:45:53.707005 29253 sgd_solver.cpp:106] Iteration 33020, lr = 1e-05
I0302 14:46:22.321655 29253 solver.cpp:237] Iteration 33040, loss = 0.00161894
I0302 14:46:22.321688 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00161895 (* 1 = 0.00161895 loss)
I0302 14:46:22.321697 29253 sgd_solver.cpp:106] Iteration 33040, lr = 1e-05
I0302 14:46:51.227998 29253 solver.cpp:237] Iteration 33060, loss = 0.00154992
I0302 14:46:51.228031 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00154992 (* 1 = 0.00154992 loss)
I0302 14:46:51.228040 29253 sgd_solver.cpp:106] Iteration 33060, lr = 1e-05
I0302 14:47:20.285830 29253 solver.cpp:237] Iteration 33080, loss = 0.00139549
I0302 14:47:20.285863 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00139549 (* 1 = 0.00139549 loss)
I0302 14:47:20.285872 29253 sgd_solver.cpp:106] Iteration 33080, lr = 1e-05
I0302 14:47:49.094977 29253 solver.cpp:237] Iteration 33100, loss = 0.00167082
I0302 14:47:49.095011 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00167083 (* 1 = 0.00167083 loss)
I0302 14:47:49.095021 29253 sgd_solver.cpp:106] Iteration 33100, lr = 1e-05
I0302 14:48:18.222218 29253 solver.cpp:237] Iteration 33120, loss = 0.00155515
I0302 14:48:18.222249 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00155516 (* 1 = 0.00155516 loss)
I0302 14:48:18.222259 29253 sgd_solver.cpp:106] Iteration 33120, lr = 1e-05
I0302 14:48:47.186255 29253 solver.cpp:237] Iteration 33140, loss = 0.00187709
I0302 14:48:47.186288 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00187709 (* 1 = 0.00187709 loss)
I0302 14:48:47.186298 29253 sgd_solver.cpp:106] Iteration 33140, lr = 1e-05
I0302 14:49:16.030297 29253 solver.cpp:237] Iteration 33160, loss = 0.00134018
I0302 14:49:16.030330 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00134018 (* 1 = 0.00134018 loss)
I0302 14:49:16.030340 29253 sgd_solver.cpp:106] Iteration 33160, lr = 1e-05
I0302 14:49:45.224664 29253 solver.cpp:237] Iteration 33180, loss = 0.00161097
I0302 14:49:45.224695 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00161097 (* 1 = 0.00161097 loss)
I0302 14:49:45.224704 29253 sgd_solver.cpp:106] Iteration 33180, lr = 1e-05
I0302 14:50:14.309238 29253 solver.cpp:237] Iteration 33200, loss = 0.00196984
I0302 14:50:14.309269 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00196984 (* 1 = 0.00196984 loss)
I0302 14:50:14.309278 29253 sgd_solver.cpp:106] Iteration 33200, lr = 1e-05
I0302 14:50:43.283143 29253 solver.cpp:237] Iteration 33220, loss = 0.00157464
I0302 14:50:43.283175 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00157465 (* 1 = 0.00157465 loss)
I0302 14:50:43.283185 29253 sgd_solver.cpp:106] Iteration 33220, lr = 1e-05
I0302 14:51:12.515300 29253 solver.cpp:237] Iteration 33240, loss = 0.00163147
I0302 14:51:12.515331 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00163148 (* 1 = 0.00163148 loss)
I0302 14:51:12.515339 29253 sgd_solver.cpp:106] Iteration 33240, lr = 1e-05
I0302 14:51:41.259289 29253 solver.cpp:237] Iteration 33260, loss = 0.00155144
I0302 14:51:41.259321 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00155145 (* 1 = 0.00155145 loss)
I0302 14:51:41.259331 29253 sgd_solver.cpp:106] Iteration 33260, lr = 1e-05
I0302 14:52:10.118484 29253 solver.cpp:237] Iteration 33280, loss = 0.00134424
I0302 14:52:10.118515 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00134425 (* 1 = 0.00134425 loss)
I0302 14:52:10.118525 29253 sgd_solver.cpp:106] Iteration 33280, lr = 1e-05
I0302 14:52:39.226402 29253 solver.cpp:237] Iteration 33300, loss = 0.00140358
I0302 14:52:39.226436 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00140359 (* 1 = 0.00140359 loss)
I0302 14:52:39.226445 29253 sgd_solver.cpp:106] Iteration 33300, lr = 1e-05
I0302 14:53:08.273382 29253 solver.cpp:237] Iteration 33320, loss = 0.00141457
I0302 14:53:08.273416 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00141457 (* 1 = 0.00141457 loss)
I0302 14:53:08.273424 29253 sgd_solver.cpp:106] Iteration 33320, lr = 1e-05
I0302 14:53:37.415630 29253 solver.cpp:237] Iteration 33340, loss = 0.00166601
I0302 14:53:37.415663 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00166601 (* 1 = 0.00166601 loss)
I0302 14:53:37.415673 29253 sgd_solver.cpp:106] Iteration 33340, lr = 1e-05
I0302 14:54:06.038861 29253 solver.cpp:237] Iteration 33360, loss = 0.00152948
I0302 14:54:06.038894 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00152948 (* 1 = 0.00152948 loss)
I0302 14:54:06.038904 29253 sgd_solver.cpp:106] Iteration 33360, lr = 1e-05
I0302 14:54:35.226584 29253 solver.cpp:237] Iteration 33380, loss = 0.0016781
I0302 14:54:35.226618 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0016781 (* 1 = 0.0016781 loss)
I0302 14:54:35.226629 29253 sgd_solver.cpp:106] Iteration 33380, lr = 1e-05
I0302 14:55:04.084713 29253 solver.cpp:237] Iteration 33400, loss = 0.00154739
I0302 14:55:04.084745 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00154739 (* 1 = 0.00154739 loss)
I0302 14:55:04.084754 29253 sgd_solver.cpp:106] Iteration 33400, lr = 1e-05
I0302 14:55:32.966186 29253 solver.cpp:237] Iteration 33420, loss = 0.00145402
I0302 14:55:32.966217 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00145402 (* 1 = 0.00145402 loss)
I0302 14:55:32.966226 29253 sgd_solver.cpp:106] Iteration 33420, lr = 1e-05
I0302 14:56:02.145530 29253 solver.cpp:237] Iteration 33440, loss = 0.00150049
I0302 14:56:02.145565 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00150049 (* 1 = 0.00150049 loss)
I0302 14:56:02.145573 29253 sgd_solver.cpp:106] Iteration 33440, lr = 1e-05
I0302 14:56:31.269636 29253 solver.cpp:237] Iteration 33460, loss = 0.00184588
I0302 14:56:31.269668 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00184588 (* 1 = 0.00184588 loss)
I0302 14:56:31.269685 29253 sgd_solver.cpp:106] Iteration 33460, lr = 1e-05
I0302 14:57:00.284742 29253 solver.cpp:237] Iteration 33480, loss = 0.00151369
I0302 14:57:00.284775 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00151369 (* 1 = 0.00151369 loss)
I0302 14:57:00.284783 29253 sgd_solver.cpp:106] Iteration 33480, lr = 1e-05
I0302 14:57:29.326661 29253 solver.cpp:237] Iteration 33500, loss = 0.00149928
I0302 14:57:29.326695 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00149928 (* 1 = 0.00149928 loss)
I0302 14:57:29.326705 29253 sgd_solver.cpp:106] Iteration 33500, lr = 1e-05
I0302 14:57:58.318632 29253 solver.cpp:237] Iteration 33520, loss = 0.00146828
I0302 14:57:58.318665 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00146828 (* 1 = 0.00146828 loss)
I0302 14:57:58.318675 29253 sgd_solver.cpp:106] Iteration 33520, lr = 1e-05
I0302 14:58:27.201073 29253 solver.cpp:237] Iteration 33540, loss = 0.00166303
I0302 14:58:27.201105 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00166303 (* 1 = 0.00166303 loss)
I0302 14:58:27.201114 29253 sgd_solver.cpp:106] Iteration 33540, lr = 1e-05
I0302 14:58:56.364605 29253 solver.cpp:237] Iteration 33560, loss = 0.00147724
I0302 14:58:56.364639 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00147724 (* 1 = 0.00147724 loss)
I0302 14:58:56.364648 29253 sgd_solver.cpp:106] Iteration 33560, lr = 1e-05
I0302 14:59:25.417415 29253 solver.cpp:237] Iteration 33580, loss = 0.00167041
I0302 14:59:25.417448 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00167042 (* 1 = 0.00167042 loss)
I0302 14:59:25.417457 29253 sgd_solver.cpp:106] Iteration 33580, lr = 1e-05
I0302 14:59:54.599304 29253 solver.cpp:237] Iteration 33600, loss = 0.0018788
I0302 14:59:54.599336 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00187881 (* 1 = 0.00187881 loss)
I0302 14:59:54.599346 29253 sgd_solver.cpp:106] Iteration 33600, lr = 1e-05
I0302 15:00:23.382794 29253 solver.cpp:237] Iteration 33620, loss = 0.00123512
I0302 15:00:23.382827 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00123512 (* 1 = 0.00123512 loss)
I0302 15:00:23.382838 29253 sgd_solver.cpp:106] Iteration 33620, lr = 1e-05
I0302 15:00:52.259853 29253 solver.cpp:237] Iteration 33640, loss = 0.0017734
I0302 15:00:52.259886 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0017734 (* 1 = 0.0017734 loss)
I0302 15:00:52.259896 29253 sgd_solver.cpp:106] Iteration 33640, lr = 1e-05
I0302 15:01:21.392885 29253 solver.cpp:237] Iteration 33660, loss = 0.00146615
I0302 15:01:21.392920 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00146616 (* 1 = 0.00146616 loss)
I0302 15:01:21.392928 29253 sgd_solver.cpp:106] Iteration 33660, lr = 1e-05
I0302 15:01:50.231086 29253 solver.cpp:237] Iteration 33680, loss = 0.0015304
I0302 15:01:50.231117 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00153041 (* 1 = 0.00153041 loss)
I0302 15:01:50.231127 29253 sgd_solver.cpp:106] Iteration 33680, lr = 1e-05
I0302 15:02:19.289425 29253 solver.cpp:237] Iteration 33700, loss = 0.00187828
I0302 15:02:19.289458 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00187829 (* 1 = 0.00187829 loss)
I0302 15:02:19.289466 29253 sgd_solver.cpp:106] Iteration 33700, lr = 1e-05
I0302 15:02:48.365406 29253 solver.cpp:237] Iteration 33720, loss = 0.00153434
I0302 15:02:48.365440 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00153434 (* 1 = 0.00153434 loss)
I0302 15:02:48.365450 29253 sgd_solver.cpp:106] Iteration 33720, lr = 1e-05
I0302 15:03:17.460758 29253 solver.cpp:237] Iteration 33740, loss = 0.00155584
I0302 15:03:17.460790 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00155585 (* 1 = 0.00155585 loss)
I0302 15:03:17.460799 29253 sgd_solver.cpp:106] Iteration 33740, lr = 1e-05
I0302 15:03:46.565994 29253 solver.cpp:237] Iteration 33760, loss = 0.00157457
I0302 15:03:46.566026 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00157457 (* 1 = 0.00157457 loss)
I0302 15:03:46.566035 29253 sgd_solver.cpp:106] Iteration 33760, lr = 1e-05
I0302 15:04:15.653872 29253 solver.cpp:237] Iteration 33780, loss = 0.00183916
I0302 15:04:15.653904 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00183916 (* 1 = 0.00183916 loss)
I0302 15:04:15.653913 29253 sgd_solver.cpp:106] Iteration 33780, lr = 1e-05
I0302 15:04:44.214085 29253 solver.cpp:237] Iteration 33800, loss = 0.00173103
I0302 15:04:44.214118 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00173103 (* 1 = 0.00173103 loss)
I0302 15:04:44.214128 29253 sgd_solver.cpp:106] Iteration 33800, lr = 1e-05
I0302 15:05:13.263780 29253 solver.cpp:237] Iteration 33820, loss = 0.00179642
I0302 15:05:13.263813 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00179642 (* 1 = 0.00179642 loss)
I0302 15:05:13.263821 29253 sgd_solver.cpp:106] Iteration 33820, lr = 1e-05
I0302 15:05:42.196915 29253 solver.cpp:237] Iteration 33840, loss = 0.00172763
I0302 15:05:42.196949 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00172763 (* 1 = 0.00172763 loss)
I0302 15:05:42.196959 29253 sgd_solver.cpp:106] Iteration 33840, lr = 1e-05
I0302 15:06:11.105849 29253 solver.cpp:237] Iteration 33860, loss = 0.00185401
I0302 15:06:11.105881 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00185401 (* 1 = 0.00185401 loss)
I0302 15:06:11.105890 29253 sgd_solver.cpp:106] Iteration 33860, lr = 1e-05
I0302 15:06:40.053061 29253 solver.cpp:237] Iteration 33880, loss = 0.00139235
I0302 15:06:40.053094 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00139235 (* 1 = 0.00139235 loss)
I0302 15:06:40.053103 29253 sgd_solver.cpp:106] Iteration 33880, lr = 1e-05
I0302 15:07:08.894984 29253 solver.cpp:237] Iteration 33900, loss = 0.00147043
I0302 15:07:08.895017 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00147043 (* 1 = 0.00147043 loss)
I0302 15:07:08.895026 29253 sgd_solver.cpp:106] Iteration 33900, lr = 1e-05
I0302 15:07:37.923231 29253 solver.cpp:237] Iteration 33920, loss = 0.00172956
I0302 15:07:37.923264 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00172956 (* 1 = 0.00172956 loss)
I0302 15:07:37.923274 29253 sgd_solver.cpp:106] Iteration 33920, lr = 1e-05
I0302 15:08:06.774027 29253 solver.cpp:237] Iteration 33940, loss = 0.0013938
I0302 15:08:06.774060 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0013938 (* 1 = 0.0013938 loss)
I0302 15:08:06.774070 29253 sgd_solver.cpp:106] Iteration 33940, lr = 1e-05
I0302 15:08:35.924473 29253 solver.cpp:237] Iteration 33960, loss = 0.00149607
I0302 15:08:35.924504 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00149607 (* 1 = 0.00149607 loss)
I0302 15:08:35.924513 29253 sgd_solver.cpp:106] Iteration 33960, lr = 1e-05
I0302 15:09:04.726614 29253 solver.cpp:237] Iteration 33980, loss = 0.00144037
I0302 15:09:04.726644 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00144038 (* 1 = 0.00144038 loss)
I0302 15:09:04.726654 29253 sgd_solver.cpp:106] Iteration 33980, lr = 1e-05
I0302 15:09:33.992643 29253 solver.cpp:237] Iteration 34000, loss = 0.00149758
I0302 15:09:33.992681 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00149759 (* 1 = 0.00149759 loss)
I0302 15:09:33.992691 29253 sgd_solver.cpp:106] Iteration 34000, lr = 1e-05
I0302 15:09:48.348534 29253 blocking_queue.cpp:50] Data layer prefetch queue empty
I0302 15:10:02.856185 29253 solver.cpp:237] Iteration 34020, loss = 0.00139246
I0302 15:10:02.856219 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00139246 (* 1 = 0.00139246 loss)
I0302 15:10:02.856227 29253 sgd_solver.cpp:106] Iteration 34020, lr = 1e-05
I0302 15:10:31.759366 29253 solver.cpp:237] Iteration 34040, loss = 0.00146005
I0302 15:10:31.759397 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00146005 (* 1 = 0.00146005 loss)
I0302 15:10:31.759407 29253 sgd_solver.cpp:106] Iteration 34040, lr = 1e-05
I0302 15:11:00.753089 29253 solver.cpp:237] Iteration 34060, loss = 0.00129835
I0302 15:11:00.753123 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00129835 (* 1 = 0.00129835 loss)
I0302 15:11:00.753132 29253 sgd_solver.cpp:106] Iteration 34060, lr = 1e-05
I0302 15:11:29.448405 29253 solver.cpp:237] Iteration 34080, loss = 0.00133737
I0302 15:11:29.448438 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00133737 (* 1 = 0.00133737 loss)
I0302 15:11:29.448447 29253 sgd_solver.cpp:106] Iteration 34080, lr = 1e-05
I0302 15:11:58.551748 29253 solver.cpp:237] Iteration 34100, loss = 0.00148658
I0302 15:11:58.551779 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00148658 (* 1 = 0.00148658 loss)
I0302 15:11:58.551789 29253 sgd_solver.cpp:106] Iteration 34100, lr = 1e-05
I0302 15:12:27.358078 29253 solver.cpp:237] Iteration 34120, loss = 0.00165129
I0302 15:12:27.358109 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0016513 (* 1 = 0.0016513 loss)
I0302 15:12:27.358119 29253 sgd_solver.cpp:106] Iteration 34120, lr = 1e-05
I0302 15:12:56.365665 29253 solver.cpp:237] Iteration 34140, loss = 0.00174934
I0302 15:12:56.365699 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00174935 (* 1 = 0.00174935 loss)
I0302 15:12:56.365707 29253 sgd_solver.cpp:106] Iteration 34140, lr = 1e-05
I0302 15:13:25.436942 29253 solver.cpp:237] Iteration 34160, loss = 0.00142771
I0302 15:13:25.436976 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00142771 (* 1 = 0.00142771 loss)
I0302 15:13:25.436986 29253 sgd_solver.cpp:106] Iteration 34160, lr = 1e-05
I0302 15:13:54.395267 29253 solver.cpp:237] Iteration 34180, loss = 0.00191641
I0302 15:13:54.395300 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00191642 (* 1 = 0.00191642 loss)
I0302 15:13:54.395309 29253 sgd_solver.cpp:106] Iteration 34180, lr = 1e-05
I0302 15:14:23.359545 29253 solver.cpp:237] Iteration 34200, loss = 0.00179624
I0302 15:14:23.359580 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00179624 (* 1 = 0.00179624 loss)
I0302 15:14:23.359589 29253 sgd_solver.cpp:106] Iteration 34200, lr = 1e-05
I0302 15:14:52.523260 29253 solver.cpp:237] Iteration 34220, loss = 0.00168731
I0302 15:14:52.523293 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00168731 (* 1 = 0.00168731 loss)
I0302 15:14:52.523303 29253 sgd_solver.cpp:106] Iteration 34220, lr = 1e-05
I0302 15:15:21.456719 29253 solver.cpp:237] Iteration 34240, loss = 0.00146006
I0302 15:15:21.456750 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00146006 (* 1 = 0.00146006 loss)
I0302 15:15:21.456759 29253 sgd_solver.cpp:106] Iteration 34240, lr = 1e-05
I0302 15:15:50.465248 29253 solver.cpp:237] Iteration 34260, loss = 0.00163875
I0302 15:15:50.465281 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00163876 (* 1 = 0.00163876 loss)
I0302 15:15:50.465289 29253 sgd_solver.cpp:106] Iteration 34260, lr = 1e-05
I0302 15:16:19.429158 29253 solver.cpp:237] Iteration 34280, loss = 0.00169685
I0302 15:16:19.429191 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00169685 (* 1 = 0.00169685 loss)
I0302 15:16:19.429200 29253 sgd_solver.cpp:106] Iteration 34280, lr = 1e-05
I0302 15:16:48.435196 29253 solver.cpp:237] Iteration 34300, loss = 0.00148563
I0302 15:16:48.435230 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00148563 (* 1 = 0.00148563 loss)
I0302 15:16:48.435240 29253 sgd_solver.cpp:106] Iteration 34300, lr = 1e-05
I0302 15:17:17.286603 29253 solver.cpp:237] Iteration 34320, loss = 0.00160308
I0302 15:17:17.286639 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00160308 (* 1 = 0.00160308 loss)
I0302 15:17:17.286648 29253 sgd_solver.cpp:106] Iteration 34320, lr = 1e-05
I0302 15:17:46.257730 29253 solver.cpp:237] Iteration 34340, loss = 0.00163199
I0302 15:17:46.257763 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00163199 (* 1 = 0.00163199 loss)
I0302 15:17:46.257772 29253 sgd_solver.cpp:106] Iteration 34340, lr = 1e-05
I0302 15:18:15.037466 29253 solver.cpp:237] Iteration 34360, loss = 0.0016066
I0302 15:18:15.037498 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0016066 (* 1 = 0.0016066 loss)
I0302 15:18:15.037508 29253 sgd_solver.cpp:106] Iteration 34360, lr = 1e-05
I0302 15:18:44.076215 29253 solver.cpp:237] Iteration 34380, loss = 0.00167682
I0302 15:18:44.076246 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00167682 (* 1 = 0.00167682 loss)
I0302 15:18:44.076256 29253 sgd_solver.cpp:106] Iteration 34380, lr = 1e-05
I0302 15:19:13.079675 29253 solver.cpp:237] Iteration 34400, loss = 0.00142241
I0302 15:19:13.079710 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00142241 (* 1 = 0.00142241 loss)
I0302 15:19:13.079718 29253 sgd_solver.cpp:106] Iteration 34400, lr = 1e-05
I0302 15:19:42.309761 29253 solver.cpp:237] Iteration 34420, loss = 0.00160525
I0302 15:19:42.309792 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00160525 (* 1 = 0.00160525 loss)
I0302 15:19:42.309800 29253 sgd_solver.cpp:106] Iteration 34420, lr = 1e-05
I0302 15:20:11.096882 29253 solver.cpp:237] Iteration 34440, loss = 0.00145405
I0302 15:20:11.096916 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00145405 (* 1 = 0.00145405 loss)
I0302 15:20:11.096926 29253 sgd_solver.cpp:106] Iteration 34440, lr = 1e-05
I0302 15:20:40.036005 29253 solver.cpp:237] Iteration 34460, loss = 0.00201593
I0302 15:20:40.036037 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00201593 (* 1 = 0.00201593 loss)
I0302 15:20:40.036047 29253 sgd_solver.cpp:106] Iteration 34460, lr = 1e-05
I0302 15:21:08.992861 29253 solver.cpp:237] Iteration 34480, loss = 0.00158987
I0302 15:21:08.992894 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00158987 (* 1 = 0.00158987 loss)
I0302 15:21:08.992903 29253 sgd_solver.cpp:106] Iteration 34480, lr = 1e-05
I0302 15:21:38.016851 29253 solver.cpp:237] Iteration 34500, loss = 0.00153335
I0302 15:21:38.016883 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00153335 (* 1 = 0.00153335 loss)
I0302 15:21:38.016893 29253 sgd_solver.cpp:106] Iteration 34500, lr = 1e-05
I0302 15:22:06.901093 29253 solver.cpp:237] Iteration 34520, loss = 0.00133933
I0302 15:22:06.901125 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00133934 (* 1 = 0.00133934 loss)
I0302 15:22:06.901134 29253 sgd_solver.cpp:106] Iteration 34520, lr = 1e-05
I0302 15:22:35.801908 29253 solver.cpp:237] Iteration 34540, loss = 0.00172636
I0302 15:22:35.801937 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00172636 (* 1 = 0.00172636 loss)
I0302 15:22:35.801946 29253 sgd_solver.cpp:106] Iteration 34540, lr = 1e-05
I0302 15:23:04.780050 29253 solver.cpp:237] Iteration 34560, loss = 0.00157716
I0302 15:23:04.780081 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00157716 (* 1 = 0.00157716 loss)
I0302 15:23:04.780089 29253 sgd_solver.cpp:106] Iteration 34560, lr = 1e-05
I0302 15:23:33.952648 29253 solver.cpp:237] Iteration 34580, loss = 0.00172032
I0302 15:23:33.952679 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00172032 (* 1 = 0.00172032 loss)
I0302 15:23:33.952688 29253 sgd_solver.cpp:106] Iteration 34580, lr = 1e-05
I0302 15:24:02.851300 29253 solver.cpp:237] Iteration 34600, loss = 0.00178238
I0302 15:24:02.851332 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00178238 (* 1 = 0.00178238 loss)
I0302 15:24:02.851341 29253 sgd_solver.cpp:106] Iteration 34600, lr = 1e-05
I0302 15:24:31.668882 29253 solver.cpp:237] Iteration 34620, loss = 0.0013784
I0302 15:24:31.668915 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0013784 (* 1 = 0.0013784 loss)
I0302 15:24:31.668923 29253 sgd_solver.cpp:106] Iteration 34620, lr = 1e-05
I0302 15:25:00.710306 29253 solver.cpp:237] Iteration 34640, loss = 0.00205709
I0302 15:25:00.710340 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00205709 (* 1 = 0.00205709 loss)
I0302 15:25:00.710348 29253 sgd_solver.cpp:106] Iteration 34640, lr = 1e-05
I0302 15:25:29.996707 29253 solver.cpp:237] Iteration 34660, loss = 0.0014676
I0302 15:25:29.996739 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.0014676 (* 1 = 0.0014676 loss)
I0302 15:25:29.996749 29253 sgd_solver.cpp:106] Iteration 34660, lr = 1e-05
I0302 15:25:59.072110 29253 solver.cpp:237] Iteration 34680, loss = 0.00188106
I0302 15:25:59.072144 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00188106 (* 1 = 0.00188106 loss)
I0302 15:25:59.072154 29253 sgd_solver.cpp:106] Iteration 34680, lr = 1e-05
I0302 15:26:27.950772 29253 solver.cpp:237] Iteration 34700, loss = 0.00142222
I0302 15:26:27.950805 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00142222 (* 1 = 0.00142222 loss)
I0302 15:26:27.950815 29253 sgd_solver.cpp:106] Iteration 34700, lr = 1e-05
I0302 15:26:56.798802 29253 solver.cpp:237] Iteration 34720, loss = 0.00164931
I0302 15:26:56.798835 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00164931 (* 1 = 0.00164931 loss)
I0302 15:26:56.798845 29253 sgd_solver.cpp:106] Iteration 34720, lr = 1e-05
I0302 15:27:25.960685 29253 solver.cpp:237] Iteration 34740, loss = 0.00132795
I0302 15:27:25.960716 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00132796 (* 1 = 0.00132796 loss)
I0302 15:27:25.960726 29253 sgd_solver.cpp:106] Iteration 34740, lr = 1e-05
I0302 15:27:54.828096 29253 solver.cpp:237] Iteration 34760, loss = 0.00144826
I0302 15:27:54.828130 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00144827 (* 1 = 0.00144827 loss)
I0302 15:27:54.828140 29253 sgd_solver.cpp:106] Iteration 34760, lr = 1e-05
I0302 15:28:23.862799 29253 solver.cpp:237] Iteration 34780, loss = 0.00155118
I0302 15:28:23.862831 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00155119 (* 1 = 0.00155119 loss)
I0302 15:28:23.862840 29253 sgd_solver.cpp:106] Iteration 34780, lr = 1e-05
I0302 15:28:52.868479 29253 solver.cpp:237] Iteration 34800, loss = 0.00146019
I0302 15:28:52.868512 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00146019 (* 1 = 0.00146019 loss)
I0302 15:28:52.868521 29253 sgd_solver.cpp:106] Iteration 34800, lr = 1e-05
I0302 15:29:21.784904 29253 solver.cpp:237] Iteration 34820, loss = 0.00176831
I0302 15:29:21.784934 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00176832 (* 1 = 0.00176832 loss)
I0302 15:29:21.784943 29253 sgd_solver.cpp:106] Iteration 34820, lr = 1e-05
I0302 15:29:50.786202 29253 solver.cpp:237] Iteration 34840, loss = 0.00171766
I0302 15:29:50.786236 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00171766 (* 1 = 0.00171766 loss)
I0302 15:29:50.786244 29253 sgd_solver.cpp:106] Iteration 34840, lr = 1e-05
I0302 15:30:19.762960 29253 solver.cpp:237] Iteration 34860, loss = 0.00167266
I0302 15:30:19.763000 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00167267 (* 1 = 0.00167267 loss)
I0302 15:30:19.763010 29253 sgd_solver.cpp:106] Iteration 34860, lr = 1e-05
I0302 15:30:48.669893 29253 solver.cpp:237] Iteration 34880, loss = 0.00169066
I0302 15:30:48.669924 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00169067 (* 1 = 0.00169067 loss)
I0302 15:30:48.669934 29253 sgd_solver.cpp:106] Iteration 34880, lr = 1e-05
I0302 15:31:17.445377 29253 solver.cpp:237] Iteration 34900, loss = 0.00134672
I0302 15:31:17.445411 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00134673 (* 1 = 0.00134673 loss)
I0302 15:31:17.445421 29253 sgd_solver.cpp:106] Iteration 34900, lr = 1e-05
I0302 15:31:46.526513 29253 solver.cpp:237] Iteration 34920, loss = 0.00170232
I0302 15:31:46.526546 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00170232 (* 1 = 0.00170232 loss)
I0302 15:31:46.526556 29253 sgd_solver.cpp:106] Iteration 34920, lr = 1e-05
I0302 15:32:15.657488 29253 solver.cpp:237] Iteration 34940, loss = 0.00142706
I0302 15:32:15.657518 29253 solver.cpp:253]     Train net output #0: loss_cls = 0.00142706 (* 1 = 0.00142706 loss)
I0302 15:32:15.657527 29253 sgd_solver.cpp:106] Iteration 34940, lr = 1e-05
