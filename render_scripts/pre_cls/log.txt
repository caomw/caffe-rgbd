Vendor:  Continuum Analytics, Inc.
Package: mkl
Message: trial mode expires in 11 days
Vendor:  Continuum Analytics, Inc.
Package: mkl
Message: trial mode expires in 11 days
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0301 21:47:53.027148  9663 solver.cpp:48] Initializing solver from parameters: 
base_lr: 0.01
display: 20
max_iter: 100000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 10000
snapshot: 5000
snapshot_prefix: "/nfs.yoda/xiaolonw/fast_rcnn/models_sunrgbd/pre_cls/model_"
solver_mode: GPU
net: "train.prototxt"
I0301 21:47:53.037103  9663 solver.cpp:91] Creating training net from net file: train.prototxt
I0301 21:47:53.039108  9663 net.cpp:49] Initializing net from parameters: 
name: "sungrbd"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: false
    crop_size: 128
    mean_value: 1
  }
  image_data_param {
    source: "/nfs/hn38/users/xiaolonw/sunrgbd/SUNRGBDtoolbox/trainlist2.txt"
    batch_size: 100
    shuffle: true
    new_height: 128
    new_width: 128
    root_folder: "/scratch/xiaolonw/sunrgbd/data/"
  }
}
layer {
  name: "da_conv1"
  type: "Convolution"
  bottom: "data"
  top: "da_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "da_conv1"
  top: "bn1"
}
layer {
  name: "da_relu1"
  type: "ReLU"
  bottom: "bn1"
  top: "bn1"
  relu_param {
    negative_slope: 0.2
  }
}
layer {
  name: "da_conv2"
  type: "Convolution"
  bottom: "bn1"
  top: "da_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 2
    kernel_size: 5
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "da_conv2"
  top: "bn2"
}
layer {
  name: "da_relu2"
  type: "ReLU"
  bottom: "bn2"
  top: "bn2"
  relu_param {
    negative_slope: 0.2
  }
}
layer {
  name: "da_conv3"
  type: "Convolution"
  bottom: "bn2"
  top: "da_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "da_conv3"
  top: "bn3"
}
layer {
  name: "da_relu3"
  type: "ReLU"
  bottom: "bn3"
  top: "bn3"
  relu_param {
    negative_slope: 0.2
  }
}
layer {
  name: "da_conv4"
  type: "Convolution"
  bottom: "bn3"
  top: "da_conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "da_conv4"
  top: "bn4"
}
layer {
  name: "da_relu4"
  type: "ReLU"
  bottom: "bn4"
  top: "bn4"
  relu_param {
    negative_slope: 0.2
  }
}
layer {
  name: "da_conv5"
  type: "Convolution"
  bottom: "bn4"
  top: "da_conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn5"
  type: "BatchNorm"
  bottom: "da_conv5"
  top: "bn5"
}
layer {
  name: "da_relu5"
  type: "ReLU"
  bottom: "bn5"
  top: "bn5"
  relu_param {
    negative_slope: 0.2
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "bn5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn6_2"
  type: "BatchNorm"
  bottom: "fc6"
  top: "bn6_2"
}
layer {
  name: "da_relu6"
  type: "ReLU"
  bottom: "bn6_2"
  top: "bn6_2"
}
layer {
  name: "da_drop6"
  type: "Dropout"
  bottom: "bn6_2"
  top: "bn6_2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "bn6_2"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc7"
  top: "bn7"
}
layer {
  name: "da_relu7"
  type: "ReLU"
  bottom: "bn7"
  top: "bn7"
}
layer {
  name: "da_drop7"
  type: "Dropout"
  bottom: "bn7"
  top: "bn7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "cls_score"
  type: "InnerProduct"
  bottom: "bn7"
  top: "cls_score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 19
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss_cls"
  type: "SoftmaxWithLoss"
  bottom: "cls_score"
  bottom: "label"
  top: "loss_cls"
}
I0301 21:47:53.039227  9663 layer_factory.hpp:77] Creating layer data
I0301 21:47:53.039249  9663 net.cpp:106] Creating Layer data
I0301 21:47:53.039255  9663 net.cpp:411] data -> data
I0301 21:47:53.039273  9663 net.cpp:411] data -> label
I0301 21:47:53.039870  9663 image_data_layer.cpp:38] Opening file /nfs/hn38/users/xiaolonw/sunrgbd/SUNRGBDtoolbox/trainlist2.txt
I0301 21:47:53.046538  9663 image_data_layer.cpp:51] Shuffling data
I0301 21:47:53.047688  9663 image_data_layer.cpp:56] A total of 4845 images.
I0301 21:47:53.088943  9663 image_data_layer.cpp:84] output data size: 100,6,128,128
I0301 21:47:53.156421  9663 net.cpp:150] Setting up data
I0301 21:47:53.156487  9663 net.cpp:157] Top shape: 100 6 128 128 (9830400)
I0301 21:47:53.156497  9663 net.cpp:157] Top shape: 100 (100)
I0301 21:47:53.156500  9663 net.cpp:165] Memory required for data: 39322000
I0301 21:47:53.156508  9663 layer_factory.hpp:77] Creating layer da_conv1
I0301 21:47:53.156528  9663 net.cpp:106] Creating Layer da_conv1
I0301 21:47:53.156534  9663 net.cpp:454] da_conv1 <- data
I0301 21:47:53.156543  9663 net.cpp:411] da_conv1 -> da_conv1
I0301 21:47:53.158524  9663 net.cpp:150] Setting up da_conv1
I0301 21:47:53.158540  9663 net.cpp:157] Top shape: 100 64 64 64 (26214400)
I0301 21:47:53.158542  9663 net.cpp:165] Memory required for data: 144179600
I0301 21:47:53.158556  9663 layer_factory.hpp:77] Creating layer bn1
I0301 21:47:53.158566  9663 net.cpp:106] Creating Layer bn1
I0301 21:47:53.158570  9663 net.cpp:454] bn1 <- da_conv1
I0301 21:47:53.158579  9663 net.cpp:411] bn1 -> bn1
I0301 21:47:53.158926  9663 net.cpp:150] Setting up bn1
I0301 21:47:53.158936  9663 net.cpp:157] Top shape: 100 64 64 64 (26214400)
I0301 21:47:53.158939  9663 net.cpp:165] Memory required for data: 249037200
I0301 21:47:53.158951  9663 layer_factory.hpp:77] Creating layer da_relu1
I0301 21:47:53.158959  9663 net.cpp:106] Creating Layer da_relu1
I0301 21:47:53.158965  9663 net.cpp:454] da_relu1 <- bn1
I0301 21:47:53.158970  9663 net.cpp:397] da_relu1 -> bn1 (in-place)
I0301 21:47:53.158983  9663 net.cpp:150] Setting up da_relu1
I0301 21:47:53.158989  9663 net.cpp:157] Top shape: 100 64 64 64 (26214400)
I0301 21:47:53.158993  9663 net.cpp:165] Memory required for data: 353894800
I0301 21:47:53.158995  9663 layer_factory.hpp:77] Creating layer da_conv2
I0301 21:47:53.159003  9663 net.cpp:106] Creating Layer da_conv2
I0301 21:47:53.159008  9663 net.cpp:454] da_conv2 <- bn1
I0301 21:47:53.159015  9663 net.cpp:411] da_conv2 -> da_conv2
I0301 21:47:53.163712  9663 net.cpp:150] Setting up da_conv2
I0301 21:47:53.163725  9663 net.cpp:157] Top shape: 100 128 32 32 (13107200)
I0301 21:47:53.163728  9663 net.cpp:165] Memory required for data: 406323600
I0301 21:47:53.163736  9663 layer_factory.hpp:77] Creating layer bn2
I0301 21:47:53.163743  9663 net.cpp:106] Creating Layer bn2
I0301 21:47:53.163745  9663 net.cpp:454] bn2 <- da_conv2
I0301 21:47:53.163750  9663 net.cpp:411] bn2 -> bn2
I0301 21:47:53.167898  9663 net.cpp:150] Setting up bn2
I0301 21:47:53.167914  9663 net.cpp:157] Top shape: 100 128 32 32 (13107200)
I0301 21:47:53.167918  9663 net.cpp:165] Memory required for data: 458752400
I0301 21:47:53.167932  9663 layer_factory.hpp:77] Creating layer da_relu2
I0301 21:47:53.167942  9663 net.cpp:106] Creating Layer da_relu2
I0301 21:47:53.167946  9663 net.cpp:454] da_relu2 <- bn2
I0301 21:47:53.167953  9663 net.cpp:397] da_relu2 -> bn2 (in-place)
I0301 21:47:53.167963  9663 net.cpp:150] Setting up da_relu2
I0301 21:47:53.167968  9663 net.cpp:157] Top shape: 100 128 32 32 (13107200)
I0301 21:47:53.167971  9663 net.cpp:165] Memory required for data: 511181200
I0301 21:47:53.167974  9663 layer_factory.hpp:77] Creating layer da_conv3
I0301 21:47:53.167984  9663 net.cpp:106] Creating Layer da_conv3
I0301 21:47:53.167987  9663 net.cpp:454] da_conv3 <- bn2
I0301 21:47:53.167994  9663 net.cpp:411] da_conv3 -> da_conv3
I0301 21:47:53.173598  9663 net.cpp:150] Setting up da_conv3
I0301 21:47:53.173611  9663 net.cpp:157] Top shape: 100 256 16 16 (6553600)
I0301 21:47:53.173615  9663 net.cpp:165] Memory required for data: 537395600
I0301 21:47:53.173622  9663 layer_factory.hpp:77] Creating layer bn3
I0301 21:47:53.173629  9663 net.cpp:106] Creating Layer bn3
I0301 21:47:53.173634  9663 net.cpp:454] bn3 <- da_conv3
I0301 21:47:53.173638  9663 net.cpp:411] bn3 -> bn3
I0301 21:47:53.173936  9663 net.cpp:150] Setting up bn3
I0301 21:47:53.173945  9663 net.cpp:157] Top shape: 100 256 16 16 (6553600)
I0301 21:47:53.173949  9663 net.cpp:165] Memory required for data: 563610000
I0301 21:47:53.173957  9663 layer_factory.hpp:77] Creating layer da_relu3
I0301 21:47:53.173964  9663 net.cpp:106] Creating Layer da_relu3
I0301 21:47:53.173969  9663 net.cpp:454] da_relu3 <- bn3
I0301 21:47:53.173976  9663 net.cpp:397] da_relu3 -> bn3 (in-place)
I0301 21:47:53.173984  9663 net.cpp:150] Setting up da_relu3
I0301 21:47:53.173988  9663 net.cpp:157] Top shape: 100 256 16 16 (6553600)
I0301 21:47:53.173992  9663 net.cpp:165] Memory required for data: 589824400
I0301 21:47:53.173995  9663 layer_factory.hpp:77] Creating layer da_conv4
I0301 21:47:53.174005  9663 net.cpp:106] Creating Layer da_conv4
I0301 21:47:53.174008  9663 net.cpp:454] da_conv4 <- bn3
I0301 21:47:53.174013  9663 net.cpp:411] da_conv4 -> da_conv4
I0301 21:47:53.194408  9663 net.cpp:150] Setting up da_conv4
I0301 21:47:53.194422  9663 net.cpp:157] Top shape: 100 512 8 8 (3276800)
I0301 21:47:53.194427  9663 net.cpp:165] Memory required for data: 602931600
I0301 21:47:53.194437  9663 layer_factory.hpp:77] Creating layer bn4
I0301 21:47:53.194445  9663 net.cpp:106] Creating Layer bn4
I0301 21:47:53.194448  9663 net.cpp:454] bn4 <- da_conv4
I0301 21:47:53.194454  9663 net.cpp:411] bn4 -> bn4
I0301 21:47:53.194777  9663 net.cpp:150] Setting up bn4
I0301 21:47:53.194785  9663 net.cpp:157] Top shape: 100 512 8 8 (3276800)
I0301 21:47:53.194788  9663 net.cpp:165] Memory required for data: 616038800
I0301 21:47:53.194797  9663 layer_factory.hpp:77] Creating layer da_relu4
I0301 21:47:53.194803  9663 net.cpp:106] Creating Layer da_relu4
I0301 21:47:53.194808  9663 net.cpp:454] da_relu4 <- bn4
I0301 21:47:53.194813  9663 net.cpp:397] da_relu4 -> bn4 (in-place)
I0301 21:47:53.194820  9663 net.cpp:150] Setting up da_relu4
I0301 21:47:53.194825  9663 net.cpp:157] Top shape: 100 512 8 8 (3276800)
I0301 21:47:53.194828  9663 net.cpp:165] Memory required for data: 629146000
I0301 21:47:53.194830  9663 layer_factory.hpp:77] Creating layer da_conv5
I0301 21:47:53.194840  9663 net.cpp:106] Creating Layer da_conv5
I0301 21:47:53.194844  9663 net.cpp:454] da_conv5 <- bn4
I0301 21:47:53.194850  9663 net.cpp:411] da_conv5 -> da_conv5
I0301 21:47:53.205303  9663 net.cpp:150] Setting up da_conv5
I0301 21:47:53.205317  9663 net.cpp:157] Top shape: 100 128 8 8 (819200)
I0301 21:47:53.205319  9663 net.cpp:165] Memory required for data: 632422800
I0301 21:47:53.205327  9663 layer_factory.hpp:77] Creating layer bn5
I0301 21:47:53.205334  9663 net.cpp:106] Creating Layer bn5
I0301 21:47:53.205338  9663 net.cpp:454] bn5 <- da_conv5
I0301 21:47:53.205343  9663 net.cpp:411] bn5 -> bn5
I0301 21:47:53.205665  9663 net.cpp:150] Setting up bn5
I0301 21:47:53.205673  9663 net.cpp:157] Top shape: 100 128 8 8 (819200)
I0301 21:47:53.205677  9663 net.cpp:165] Memory required for data: 635699600
I0301 21:47:53.205684  9663 layer_factory.hpp:77] Creating layer da_relu5
I0301 21:47:53.205690  9663 net.cpp:106] Creating Layer da_relu5
I0301 21:47:53.205693  9663 net.cpp:454] da_relu5 <- bn5
I0301 21:47:53.205699  9663 net.cpp:397] da_relu5 -> bn5 (in-place)
I0301 21:47:53.205708  9663 net.cpp:150] Setting up da_relu5
I0301 21:47:53.205711  9663 net.cpp:157] Top shape: 100 128 8 8 (819200)
I0301 21:47:53.205714  9663 net.cpp:165] Memory required for data: 638976400
I0301 21:47:53.205718  9663 layer_factory.hpp:77] Creating layer pool5
I0301 21:47:53.205725  9663 net.cpp:106] Creating Layer pool5
I0301 21:47:53.205729  9663 net.cpp:454] pool5 <- bn5
I0301 21:47:53.205734  9663 net.cpp:411] pool5 -> pool5
I0301 21:47:53.205796  9663 net.cpp:150] Setting up pool5
I0301 21:47:53.205802  9663 net.cpp:157] Top shape: 100 128 4 4 (204800)
I0301 21:47:53.205806  9663 net.cpp:165] Memory required for data: 639795600
I0301 21:47:53.205809  9663 layer_factory.hpp:77] Creating layer fc6
I0301 21:47:53.205821  9663 net.cpp:106] Creating Layer fc6
I0301 21:47:53.205826  9663 net.cpp:454] fc6 <- pool5
I0301 21:47:53.205832  9663 net.cpp:411] fc6 -> fc6
I0301 21:47:53.347692  9663 net.cpp:150] Setting up fc6
I0301 21:47:53.347712  9663 net.cpp:157] Top shape: 100 4096 (409600)
I0301 21:47:53.347717  9663 net.cpp:165] Memory required for data: 641434000
I0301 21:47:53.347726  9663 layer_factory.hpp:77] Creating layer bn6_2
I0301 21:47:53.347738  9663 net.cpp:106] Creating Layer bn6_2
I0301 21:47:53.347741  9663 net.cpp:454] bn6_2 <- fc6
I0301 21:47:53.347749  9663 net.cpp:411] bn6_2 -> bn6_2
I0301 21:47:53.348078  9663 net.cpp:150] Setting up bn6_2
I0301 21:47:53.348085  9663 net.cpp:157] Top shape: 100 4096 (409600)
I0301 21:47:53.348088  9663 net.cpp:165] Memory required for data: 643072400
I0301 21:47:53.348096  9663 layer_factory.hpp:77] Creating layer da_relu6
I0301 21:47:53.348103  9663 net.cpp:106] Creating Layer da_relu6
I0301 21:47:53.348106  9663 net.cpp:454] da_relu6 <- bn6_2
I0301 21:47:53.348114  9663 net.cpp:397] da_relu6 -> bn6_2 (in-place)
I0301 21:47:53.348121  9663 net.cpp:150] Setting up da_relu6
I0301 21:47:53.348127  9663 net.cpp:157] Top shape: 100 4096 (409600)
I0301 21:47:53.348130  9663 net.cpp:165] Memory required for data: 644710800
I0301 21:47:53.348134  9663 layer_factory.hpp:77] Creating layer da_drop6
I0301 21:47:53.348140  9663 net.cpp:106] Creating Layer da_drop6
I0301 21:47:53.348143  9663 net.cpp:454] da_drop6 <- bn6_2
I0301 21:47:53.348150  9663 net.cpp:397] da_drop6 -> bn6_2 (in-place)
I0301 21:47:53.348184  9663 net.cpp:150] Setting up da_drop6
I0301 21:47:53.348191  9663 net.cpp:157] Top shape: 100 4096 (409600)
I0301 21:47:53.348194  9663 net.cpp:165] Memory required for data: 646349200
I0301 21:47:53.348196  9663 layer_factory.hpp:77] Creating layer fc7
I0301 21:47:53.348204  9663 net.cpp:106] Creating Layer fc7
I0301 21:47:53.348208  9663 net.cpp:454] fc7 <- bn6_2
I0301 21:47:53.348214  9663 net.cpp:411] fc7 -> fc7
I0301 21:47:53.631420  9663 net.cpp:150] Setting up fc7
I0301 21:47:53.631441  9663 net.cpp:157] Top shape: 100 4096 (409600)
I0301 21:47:53.631445  9663 net.cpp:165] Memory required for data: 647987600
I0301 21:47:53.631455  9663 layer_factory.hpp:77] Creating layer bn7
I0301 21:47:53.631467  9663 net.cpp:106] Creating Layer bn7
I0301 21:47:53.631472  9663 net.cpp:454] bn7 <- fc7
I0301 21:47:53.631480  9663 net.cpp:411] bn7 -> bn7
I0301 21:47:53.631832  9663 net.cpp:150] Setting up bn7
I0301 21:47:53.631841  9663 net.cpp:157] Top shape: 100 4096 (409600)
I0301 21:47:53.631844  9663 net.cpp:165] Memory required for data: 649626000
I0301 21:47:53.631861  9663 layer_factory.hpp:77] Creating layer da_relu7
I0301 21:47:53.631868  9663 net.cpp:106] Creating Layer da_relu7
I0301 21:47:53.631872  9663 net.cpp:454] da_relu7 <- bn7
I0301 21:47:53.631877  9663 net.cpp:397] da_relu7 -> bn7 (in-place)
I0301 21:47:53.631885  9663 net.cpp:150] Setting up da_relu7
I0301 21:47:53.631889  9663 net.cpp:157] Top shape: 100 4096 (409600)
I0301 21:47:53.631892  9663 net.cpp:165] Memory required for data: 651264400
I0301 21:47:53.631896  9663 layer_factory.hpp:77] Creating layer da_drop7
I0301 21:47:53.631901  9663 net.cpp:106] Creating Layer da_drop7
I0301 21:47:53.631906  9663 net.cpp:454] da_drop7 <- bn7
I0301 21:47:53.631911  9663 net.cpp:397] da_drop7 -> bn7 (in-place)
I0301 21:47:53.631947  9663 net.cpp:150] Setting up da_drop7
I0301 21:47:53.631953  9663 net.cpp:157] Top shape: 100 4096 (409600)
I0301 21:47:53.631956  9663 net.cpp:165] Memory required for data: 652902800
I0301 21:47:53.631959  9663 layer_factory.hpp:77] Creating layer cls_score
I0301 21:47:53.631969  9663 net.cpp:106] Creating Layer cls_score
I0301 21:47:53.631973  9663 net.cpp:454] cls_score <- bn7
I0301 21:47:53.631978  9663 net.cpp:411] cls_score -> cls_score
I0301 21:47:53.634034  9663 net.cpp:150] Setting up cls_score
I0301 21:47:53.634047  9663 net.cpp:157] Top shape: 100 19 (1900)
I0301 21:47:53.634050  9663 net.cpp:165] Memory required for data: 652910400
I0301 21:47:53.634057  9663 layer_factory.hpp:77] Creating layer loss_cls
I0301 21:47:53.634065  9663 net.cpp:106] Creating Layer loss_cls
I0301 21:47:53.634069  9663 net.cpp:454] loss_cls <- cls_score
I0301 21:47:53.634073  9663 net.cpp:454] loss_cls <- label
I0301 21:47:53.634078  9663 net.cpp:411] loss_cls -> loss_cls
I0301 21:47:53.634093  9663 layer_factory.hpp:77] Creating layer loss_cls
I0301 21:47:53.634239  9663 net.cpp:150] Setting up loss_cls
I0301 21:47:53.634246  9663 net.cpp:157] Top shape: (1)
I0301 21:47:53.634250  9663 net.cpp:160]     with loss weight 1
I0301 21:47:53.634259  9663 net.cpp:165] Memory required for data: 652910404
I0301 21:47:53.634263  9663 net.cpp:226] loss_cls needs backward computation.
I0301 21:47:53.634268  9663 net.cpp:226] cls_score needs backward computation.
I0301 21:47:53.634271  9663 net.cpp:226] da_drop7 needs backward computation.
I0301 21:47:53.634274  9663 net.cpp:226] da_relu7 needs backward computation.
I0301 21:47:53.634276  9663 net.cpp:226] bn7 needs backward computation.
I0301 21:47:53.634279  9663 net.cpp:226] fc7 needs backward computation.
I0301 21:47:53.634284  9663 net.cpp:226] da_drop6 needs backward computation.
I0301 21:47:53.634286  9663 net.cpp:226] da_relu6 needs backward computation.
I0301 21:47:53.634290  9663 net.cpp:226] bn6_2 needs backward computation.
I0301 21:47:53.634294  9663 net.cpp:226] fc6 needs backward computation.
I0301 21:47:53.634297  9663 net.cpp:226] pool5 needs backward computation.
I0301 21:47:53.634300  9663 net.cpp:226] da_relu5 needs backward computation.
I0301 21:47:53.634305  9663 net.cpp:226] bn5 needs backward computation.
I0301 21:47:53.634307  9663 net.cpp:226] da_conv5 needs backward computation.
I0301 21:47:53.634311  9663 net.cpp:226] da_relu4 needs backward computation.
I0301 21:47:53.634315  9663 net.cpp:226] bn4 needs backward computation.
I0301 21:47:53.634318  9663 net.cpp:226] da_conv4 needs backward computation.
I0301 21:47:53.634321  9663 net.cpp:226] da_relu3 needs backward computation.
I0301 21:47:53.634325  9663 net.cpp:226] bn3 needs backward computation.
I0301 21:47:53.634328  9663 net.cpp:226] da_conv3 needs backward computation.
I0301 21:47:53.634331  9663 net.cpp:226] da_relu2 needs backward computation.
I0301 21:47:53.634335  9663 net.cpp:226] bn2 needs backward computation.
I0301 21:47:53.634337  9663 net.cpp:226] da_conv2 needs backward computation.
I0301 21:47:53.634341  9663 net.cpp:226] da_relu1 needs backward computation.
I0301 21:47:53.634343  9663 net.cpp:226] bn1 needs backward computation.
I0301 21:47:53.634347  9663 net.cpp:226] da_conv1 needs backward computation.
I0301 21:47:53.634351  9663 net.cpp:228] data does not need backward computation.
I0301 21:47:53.634356  9663 net.cpp:270] This network produces output loss_cls
I0301 21:47:53.634380  9663 net.cpp:283] Network initialization done.
I0301 21:47:53.634459  9663 solver.cpp:60] Solver scaffolding done.
I0301 21:47:54.637480  9663 net.cpp:816] Ignoring source layer da_roi_pool5
I0301 21:47:54.637504  9663 net.cpp:816] Ignoring source layer da_fc6
I0301 21:47:54.637522  9663 net.cpp:816] Ignoring source layer da_fc7
I0301 21:47:54.637537  9663 net.cpp:816] Ignoring source layer bn7_da_drop7_0_split
I0301 21:47:54.637540  9663 net.cpp:816] Ignoring source layer da_cls_score
I0301 21:47:54.637542  9663 net.cpp:816] Ignoring source layer da_bbox_pred
I0301 21:47:54.637544  9663 net.cpp:816] Ignoring source layer da_loss_cls
I0301 21:47:54.637547  9663 net.cpp:816] Ignoring source layer da_loss_bbox
I0301 21:47:54.651432  9663 blocking_queue.cpp:50] Data layer prefetch queue empty
I0301 21:47:55.852459  9663 solver.cpp:237] Iteration 0, loss = 2.96455
I0301 21:47:55.852491  9663 solver.cpp:253]     Train net output #0: loss_cls = 2.96455 (* 1 = 2.96455 loss)
I0301 21:47:55.852504  9663 sgd_solver.cpp:106] Iteration 0, lr = 0.01
I0301 21:48:31.627071  9663 solver.cpp:237] Iteration 20, loss = 2.35479
I0301 21:48:31.627121  9663 solver.cpp:253]     Train net output #0: loss_cls = 2.35479 (* 1 = 2.35479 loss)
I0301 21:48:31.627138  9663 sgd_solver.cpp:106] Iteration 20, lr = 0.01
I0301 21:49:04.726003  9663 solver.cpp:237] Iteration 40, loss = 2.67903
I0301 21:49:04.726033  9663 solver.cpp:253]     Train net output #0: loss_cls = 2.67903 (* 1 = 2.67903 loss)
I0301 21:49:04.726042  9663 sgd_solver.cpp:106] Iteration 40, lr = 0.01
I0301 21:49:39.940237  9663 solver.cpp:237] Iteration 60, loss = 2.37625
I0301 21:49:39.940299  9663 solver.cpp:253]     Train net output #0: loss_cls = 2.37625 (* 1 = 2.37625 loss)
I0301 21:49:39.940313  9663 sgd_solver.cpp:106] Iteration 60, lr = 0.01
I0301 21:50:31.773386  9663 solver.cpp:237] Iteration 80, loss = 2.21105
I0301 21:50:31.773430  9663 solver.cpp:253]     Train net output #0: loss_cls = 2.21105 (* 1 = 2.21105 loss)
I0301 21:50:31.773445  9663 sgd_solver.cpp:106] Iteration 80, lr = 0.01
I0301 21:51:16.113775  9663 solver.cpp:237] Iteration 100, loss = 1.83185
I0301 21:51:16.113836  9663 solver.cpp:253]     Train net output #0: loss_cls = 1.83185 (* 1 = 1.83185 loss)
I0301 21:51:16.113852  9663 sgd_solver.cpp:106] Iteration 100, lr = 0.01
I0301 21:52:00.603674  9663 solver.cpp:237] Iteration 120, loss = 1.46741
I0301 21:52:00.603734  9663 solver.cpp:253]     Train net output #0: loss_cls = 1.46741 (* 1 = 1.46741 loss)
I0301 21:52:00.603754  9663 sgd_solver.cpp:106] Iteration 120, lr = 0.01
I0301 21:52:46.182821  9663 solver.cpp:237] Iteration 140, loss = 1.55271
I0301 21:52:46.182867  9663 solver.cpp:253]     Train net output #0: loss_cls = 1.55271 (* 1 = 1.55271 loss)
I0301 21:52:46.182878  9663 sgd_solver.cpp:106] Iteration 140, lr = 0.01
I0301 21:53:29.705191  9663 solver.cpp:237] Iteration 160, loss = 1.69438
I0301 21:53:29.705291  9663 solver.cpp:253]     Train net output #0: loss_cls = 1.69438 (* 1 = 1.69438 loss)
I0301 21:53:29.705325  9663 sgd_solver.cpp:106] Iteration 160, lr = 0.01
I0301 21:54:14.668144  9663 solver.cpp:237] Iteration 180, loss = 1.60879
I0301 21:54:14.668201  9663 solver.cpp:253]     Train net output #0: loss_cls = 1.60879 (* 1 = 1.60879 loss)
I0301 21:54:14.668217  9663 sgd_solver.cpp:106] Iteration 180, lr = 0.01
I0301 21:54:58.689162  9663 solver.cpp:237] Iteration 200, loss = 0.970903
I0301 21:54:58.689209  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.970903 (* 1 = 0.970903 loss)
I0301 21:54:58.689227  9663 sgd_solver.cpp:106] Iteration 200, lr = 0.01
I0301 21:55:43.928199  9663 solver.cpp:237] Iteration 220, loss = 1.02218
I0301 21:55:43.928236  9663 solver.cpp:253]     Train net output #0: loss_cls = 1.02218 (* 1 = 1.02218 loss)
I0301 21:55:43.928252  9663 sgd_solver.cpp:106] Iteration 220, lr = 0.01
I0301 21:56:29.332762  9663 solver.cpp:237] Iteration 240, loss = 1.27205
I0301 21:56:29.332819  9663 solver.cpp:253]     Train net output #0: loss_cls = 1.27205 (* 1 = 1.27205 loss)
I0301 21:56:29.332841  9663 sgd_solver.cpp:106] Iteration 240, lr = 0.01
I0301 21:57:13.389706  9663 solver.cpp:237] Iteration 260, loss = 0.856561
I0301 21:57:13.389755  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.856561 (* 1 = 0.856561 loss)
I0301 21:57:13.389763  9663 sgd_solver.cpp:106] Iteration 260, lr = 0.01
I0301 21:57:57.927000  9663 solver.cpp:237] Iteration 280, loss = 0.81616
I0301 21:57:57.927062  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.81616 (* 1 = 0.81616 loss)
I0301 21:57:57.927084  9663 sgd_solver.cpp:106] Iteration 280, lr = 0.01
I0301 21:58:41.659163  9663 solver.cpp:237] Iteration 300, loss = 0.561704
I0301 21:58:41.659235  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.561704 (* 1 = 0.561704 loss)
I0301 21:58:41.659247  9663 sgd_solver.cpp:106] Iteration 300, lr = 0.01
I0301 21:59:25.887245  9663 solver.cpp:237] Iteration 320, loss = 0.640143
I0301 21:59:25.887300  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.640143 (* 1 = 0.640143 loss)
I0301 21:59:25.887312  9663 sgd_solver.cpp:106] Iteration 320, lr = 0.01
I0301 22:00:10.160462  9663 solver.cpp:237] Iteration 340, loss = 0.451188
I0301 22:00:10.160511  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.451188 (* 1 = 0.451188 loss)
I0301 22:00:10.160521  9663 sgd_solver.cpp:106] Iteration 340, lr = 0.01
I0301 22:00:53.268815  9663 solver.cpp:237] Iteration 360, loss = 0.226146
I0301 22:00:53.268846  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.226146 (* 1 = 0.226146 loss)
I0301 22:00:53.268856  9663 sgd_solver.cpp:106] Iteration 360, lr = 0.01
I0301 22:01:35.302830  9663 solver.cpp:237] Iteration 380, loss = 0.703473
I0301 22:01:35.302870  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.703473 (* 1 = 0.703473 loss)
I0301 22:01:35.302880  9663 sgd_solver.cpp:106] Iteration 380, lr = 0.01
I0301 22:02:14.633530  9663 solver.cpp:237] Iteration 400, loss = 0.487711
I0301 22:02:14.633595  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.487711 (* 1 = 0.487711 loss)
I0301 22:02:14.633616  9663 sgd_solver.cpp:106] Iteration 400, lr = 0.01
I0301 22:02:53.954252  9663 solver.cpp:237] Iteration 420, loss = 0.381282
I0301 22:02:53.954301  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.381282 (* 1 = 0.381282 loss)
I0301 22:02:53.954316  9663 sgd_solver.cpp:106] Iteration 420, lr = 0.01
I0301 22:03:34.847791  9663 solver.cpp:237] Iteration 440, loss = 0.246366
I0301 22:03:34.847826  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.246366 (* 1 = 0.246366 loss)
I0301 22:03:34.847837  9663 sgd_solver.cpp:106] Iteration 440, lr = 0.01
I0301 22:04:13.708935  9663 solver.cpp:237] Iteration 460, loss = 0.190487
I0301 22:04:13.708983  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.190487 (* 1 = 0.190487 loss)
I0301 22:04:13.708995  9663 sgd_solver.cpp:106] Iteration 460, lr = 0.01
I0301 22:04:52.570339  9663 solver.cpp:237] Iteration 480, loss = 0.166167
I0301 22:04:52.570377  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.166167 (* 1 = 0.166167 loss)
I0301 22:04:52.570386  9663 sgd_solver.cpp:106] Iteration 480, lr = 0.01
I0301 22:05:21.894124  9663 solver.cpp:237] Iteration 500, loss = 0.104363
I0301 22:05:21.894155  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.104363 (* 1 = 0.104363 loss)
I0301 22:05:21.894163  9663 sgd_solver.cpp:106] Iteration 500, lr = 0.01
I0301 22:05:50.600615  9663 solver.cpp:237] Iteration 520, loss = 0.347236
I0301 22:05:50.600648  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.347236 (* 1 = 0.347236 loss)
I0301 22:05:50.600657  9663 sgd_solver.cpp:106] Iteration 520, lr = 0.01
I0301 22:06:19.753453  9663 solver.cpp:237] Iteration 540, loss = 0.152047
I0301 22:06:19.753482  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.152047 (* 1 = 0.152047 loss)
I0301 22:06:19.753491  9663 sgd_solver.cpp:106] Iteration 540, lr = 0.01
I0301 22:06:48.567901  9663 solver.cpp:237] Iteration 560, loss = 0.258926
I0301 22:06:48.567931  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.258926 (* 1 = 0.258926 loss)
I0301 22:06:48.567940  9663 sgd_solver.cpp:106] Iteration 560, lr = 0.01
I0301 22:07:17.012840  9663 solver.cpp:237] Iteration 580, loss = 0.166991
I0301 22:07:17.012869  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.166991 (* 1 = 0.166991 loss)
I0301 22:07:17.012878  9663 sgd_solver.cpp:106] Iteration 580, lr = 0.01
I0301 22:07:46.407876  9663 solver.cpp:237] Iteration 600, loss = 0.0806793
I0301 22:07:46.407910  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.0806793 (* 1 = 0.0806793 loss)
I0301 22:07:46.407919  9663 sgd_solver.cpp:106] Iteration 600, lr = 0.01
I0301 22:08:20.473932  9663 solver.cpp:237] Iteration 620, loss = 0.186281
I0301 22:08:20.473961  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.186281 (* 1 = 0.186281 loss)
I0301 22:08:20.473970  9663 sgd_solver.cpp:106] Iteration 620, lr = 0.01
I0301 22:08:52.710014  9663 solver.cpp:237] Iteration 640, loss = 0.115153
I0301 22:08:52.710049  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.115153 (* 1 = 0.115153 loss)
I0301 22:08:52.710059  9663 sgd_solver.cpp:106] Iteration 640, lr = 0.01
I0301 22:09:25.217936  9663 solver.cpp:237] Iteration 660, loss = 0.113379
I0301 22:09:25.217964  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.11338 (* 1 = 0.11338 loss)
I0301 22:09:25.217973  9663 sgd_solver.cpp:106] Iteration 660, lr = 0.01
I0301 22:09:58.012145  9663 solver.cpp:237] Iteration 680, loss = 0.0785808
I0301 22:09:58.012176  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.0785808 (* 1 = 0.0785808 loss)
I0301 22:09:58.012186  9663 sgd_solver.cpp:106] Iteration 680, lr = 0.01
I0301 22:10:31.123358  9663 solver.cpp:237] Iteration 700, loss = 0.0779111
I0301 22:10:31.123394  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.0779112 (* 1 = 0.0779112 loss)
I0301 22:10:31.123404  9663 sgd_solver.cpp:106] Iteration 700, lr = 0.01
I0301 22:11:04.039299  9663 solver.cpp:237] Iteration 720, loss = 0.115524
I0301 22:11:04.039330  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.115524 (* 1 = 0.115524 loss)
I0301 22:11:04.039338  9663 sgd_solver.cpp:106] Iteration 720, lr = 0.01
I0301 22:11:36.262272  9663 solver.cpp:237] Iteration 740, loss = 0.0599725
I0301 22:11:36.262306  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.0599725 (* 1 = 0.0599725 loss)
I0301 22:11:36.262317  9663 sgd_solver.cpp:106] Iteration 740, lr = 0.01
I0301 22:12:08.763875  9663 solver.cpp:237] Iteration 760, loss = 0.0338461
I0301 22:12:08.763911  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.0338461 (* 1 = 0.0338461 loss)
I0301 22:12:08.763926  9663 sgd_solver.cpp:106] Iteration 760, lr = 0.01
I0301 22:12:40.312927  9663 solver.cpp:237] Iteration 780, loss = 0.154876
I0301 22:12:40.312959  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.154876 (* 1 = 0.154876 loss)
I0301 22:12:40.312968  9663 sgd_solver.cpp:106] Iteration 780, lr = 0.01
I0301 22:13:12.815755  9663 solver.cpp:237] Iteration 800, loss = 0.0407309
I0301 22:13:12.815786  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.040731 (* 1 = 0.040731 loss)
I0301 22:13:12.815794  9663 sgd_solver.cpp:106] Iteration 800, lr = 0.01
I0301 22:13:44.935001  9663 solver.cpp:237] Iteration 820, loss = 0.0265625
I0301 22:13:44.935034  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.0265625 (* 1 = 0.0265625 loss)
I0301 22:13:44.935044  9663 sgd_solver.cpp:106] Iteration 820, lr = 0.01
I0301 22:14:17.115875  9663 solver.cpp:237] Iteration 840, loss = 0.0384799
I0301 22:14:17.115906  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.0384799 (* 1 = 0.0384799 loss)
I0301 22:14:17.115913  9663 sgd_solver.cpp:106] Iteration 840, lr = 0.01
I0301 22:14:49.597738  9663 solver.cpp:237] Iteration 860, loss = 0.0414257
I0301 22:14:49.597771  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.0414258 (* 1 = 0.0414258 loss)
I0301 22:14:49.597779  9663 sgd_solver.cpp:106] Iteration 860, lr = 0.01
I0301 22:15:21.591470  9663 solver.cpp:237] Iteration 880, loss = 0.0593415
I0301 22:15:21.591505  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.0593416 (* 1 = 0.0593416 loss)
I0301 22:15:21.591514  9663 sgd_solver.cpp:106] Iteration 880, lr = 0.01
I0301 22:15:54.708683  9663 solver.cpp:237] Iteration 900, loss = 0.033083
I0301 22:15:54.708715  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.033083 (* 1 = 0.033083 loss)
I0301 22:15:54.708724  9663 sgd_solver.cpp:106] Iteration 900, lr = 0.01
I0301 22:16:26.731154  9663 solver.cpp:237] Iteration 920, loss = 0.0443132
I0301 22:16:26.731186  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.0443132 (* 1 = 0.0443132 loss)
I0301 22:16:26.731195  9663 sgd_solver.cpp:106] Iteration 920, lr = 0.01
I0301 22:16:58.821497  9663 solver.cpp:237] Iteration 940, loss = 0.00608114
I0301 22:16:58.821528  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00608118 (* 1 = 0.00608118 loss)
I0301 22:16:58.821537  9663 sgd_solver.cpp:106] Iteration 940, lr = 0.01
I0301 22:17:31.361500  9663 solver.cpp:237] Iteration 960, loss = 0.0736683
I0301 22:17:31.361546  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.0736683 (* 1 = 0.0736683 loss)
I0301 22:17:31.361567  9663 sgd_solver.cpp:106] Iteration 960, lr = 0.01
I0301 22:18:04.014852  9663 solver.cpp:237] Iteration 980, loss = 0.0438353
I0301 22:18:04.014883  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.0438354 (* 1 = 0.0438354 loss)
I0301 22:18:04.014891  9663 sgd_solver.cpp:106] Iteration 980, lr = 0.01
I0301 22:18:34.884629  9663 blocking_queue.cpp:50] Data layer prefetch queue empty
I0301 22:18:36.469480  9663 solver.cpp:237] Iteration 1000, loss = 0.0526553
I0301 22:18:36.469530  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.0526553 (* 1 = 0.0526553 loss)
I0301 22:18:36.469543  9663 sgd_solver.cpp:106] Iteration 1000, lr = 0.01
I0301 22:19:08.214617  9663 solver.cpp:237] Iteration 1020, loss = 0.0189454
I0301 22:19:08.214648  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.0189455 (* 1 = 0.0189455 loss)
I0301 22:19:08.214656  9663 sgd_solver.cpp:106] Iteration 1020, lr = 0.01
I0301 22:19:40.185400  9663 solver.cpp:237] Iteration 1040, loss = 0.0439749
I0301 22:19:40.185431  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.0439749 (* 1 = 0.0439749 loss)
I0301 22:19:40.185441  9663 sgd_solver.cpp:106] Iteration 1040, lr = 0.01
I0301 22:20:12.906996  9663 solver.cpp:237] Iteration 1060, loss = 0.137596
I0301 22:20:12.907042  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.137596 (* 1 = 0.137596 loss)
I0301 22:20:12.907055  9663 sgd_solver.cpp:106] Iteration 1060, lr = 0.01
I0301 22:20:44.449604  9663 solver.cpp:237] Iteration 1080, loss = 0.0927357
I0301 22:20:44.449635  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.0927357 (* 1 = 0.0927357 loss)
I0301 22:20:44.449645  9663 sgd_solver.cpp:106] Iteration 1080, lr = 0.01
I0301 22:21:17.287626  9663 solver.cpp:237] Iteration 1100, loss = 0.0536196
I0301 22:21:17.287657  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.0536196 (* 1 = 0.0536196 loss)
I0301 22:21:17.287665  9663 sgd_solver.cpp:106] Iteration 1100, lr = 0.01
I0301 22:21:49.507103  9663 solver.cpp:237] Iteration 1120, loss = 0.0238894
I0301 22:21:49.507139  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.0238894 (* 1 = 0.0238894 loss)
I0301 22:21:49.507149  9663 sgd_solver.cpp:106] Iteration 1120, lr = 0.01
I0301 22:22:22.037557  9663 solver.cpp:237] Iteration 1140, loss = 0.0202552
I0301 22:22:22.037607  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.0202553 (* 1 = 0.0202553 loss)
I0301 22:22:22.037622  9663 sgd_solver.cpp:106] Iteration 1140, lr = 0.01
I0301 22:23:09.544201  9663 solver.cpp:237] Iteration 1160, loss = 0.0199309
I0301 22:23:09.544235  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.0199309 (* 1 = 0.0199309 loss)
I0301 22:23:09.544245  9663 sgd_solver.cpp:106] Iteration 1160, lr = 0.01
I0301 22:23:46.864394  9663 solver.cpp:237] Iteration 1180, loss = 0.00502498
I0301 22:23:46.864428  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00502501 (* 1 = 0.00502501 loss)
I0301 22:23:46.864437  9663 sgd_solver.cpp:106] Iteration 1180, lr = 0.01
I0301 22:24:26.639149  9663 solver.cpp:237] Iteration 1200, loss = 0.0122173
I0301 22:24:26.639179  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.0122173 (* 1 = 0.0122173 loss)
I0301 22:24:26.639188  9663 sgd_solver.cpp:106] Iteration 1200, lr = 0.01
I0301 22:25:03.543316  9663 solver.cpp:237] Iteration 1220, loss = 0.00701224
I0301 22:25:03.543359  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00701226 (* 1 = 0.00701226 loss)
I0301 22:25:03.543370  9663 sgd_solver.cpp:106] Iteration 1220, lr = 0.01
I0301 22:25:41.628525  9663 solver.cpp:237] Iteration 1240, loss = 0.0322393
I0301 22:25:41.628554  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.0322394 (* 1 = 0.0322394 loss)
I0301 22:25:41.628563  9663 sgd_solver.cpp:106] Iteration 1240, lr = 0.01
I0301 22:26:19.363512  9663 solver.cpp:237] Iteration 1260, loss = 0.00271751
I0301 22:26:19.363560  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00271752 (* 1 = 0.00271752 loss)
I0301 22:26:19.363571  9663 sgd_solver.cpp:106] Iteration 1260, lr = 0.01
I0301 22:26:58.443552  9663 solver.cpp:237] Iteration 1280, loss = 0.0339785
I0301 22:26:58.443637  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.0339785 (* 1 = 0.0339785 loss)
I0301 22:26:58.443660  9663 sgd_solver.cpp:106] Iteration 1280, lr = 0.01
I0301 22:27:35.269462  9663 solver.cpp:237] Iteration 1300, loss = 0.00802338
I0301 22:27:35.269498  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00802341 (* 1 = 0.00802341 loss)
I0301 22:27:35.269510  9663 sgd_solver.cpp:106] Iteration 1300, lr = 0.01
I0301 22:28:13.649143  9663 solver.cpp:237] Iteration 1320, loss = 0.0451976
I0301 22:28:13.649199  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.0451976 (* 1 = 0.0451976 loss)
I0301 22:28:13.649215  9663 sgd_solver.cpp:106] Iteration 1320, lr = 0.01
I0301 22:28:52.389293  9663 solver.cpp:237] Iteration 1340, loss = 0.00536836
I0301 22:28:52.389327  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00536839 (* 1 = 0.00536839 loss)
I0301 22:28:52.389334  9663 sgd_solver.cpp:106] Iteration 1340, lr = 0.01
I0301 22:29:30.277104  9663 solver.cpp:237] Iteration 1360, loss = 0.0387921
I0301 22:29:30.277134  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.0387921 (* 1 = 0.0387921 loss)
I0301 22:29:30.277143  9663 sgd_solver.cpp:106] Iteration 1360, lr = 0.01
I0301 22:30:07.708081  9663 solver.cpp:237] Iteration 1380, loss = 0.0293724
I0301 22:30:07.708112  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.0293725 (* 1 = 0.0293725 loss)
I0301 22:30:07.708119  9663 sgd_solver.cpp:106] Iteration 1380, lr = 0.01
I0301 22:30:45.349964  9663 solver.cpp:237] Iteration 1400, loss = 0.00405129
I0301 22:30:45.349995  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00405133 (* 1 = 0.00405133 loss)
I0301 22:30:45.350004  9663 sgd_solver.cpp:106] Iteration 1400, lr = 0.01
I0301 22:31:22.889019  9663 solver.cpp:237] Iteration 1420, loss = 0.0422424
I0301 22:31:22.889050  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.0422424 (* 1 = 0.0422424 loss)
I0301 22:31:22.889060  9663 sgd_solver.cpp:106] Iteration 1420, lr = 0.01
I0301 22:32:00.815958  9663 solver.cpp:237] Iteration 1440, loss = 0.0014606
I0301 22:32:00.815990  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00146064 (* 1 = 0.00146064 loss)
I0301 22:32:00.815999  9663 sgd_solver.cpp:106] Iteration 1440, lr = 0.01
I0301 22:32:38.883460  9663 solver.cpp:237] Iteration 1460, loss = 0.00850812
I0301 22:32:38.883491  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00850816 (* 1 = 0.00850816 loss)
I0301 22:32:38.883501  9663 sgd_solver.cpp:106] Iteration 1460, lr = 0.01
I0301 22:33:17.379390  9663 solver.cpp:237] Iteration 1480, loss = 0.0329398
I0301 22:33:17.379422  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.0329398 (* 1 = 0.0329398 loss)
I0301 22:33:17.379431  9663 sgd_solver.cpp:106] Iteration 1480, lr = 0.01
I0301 22:33:55.878458  9663 solver.cpp:237] Iteration 1500, loss = 0.00730377
I0301 22:33:55.878511  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00730381 (* 1 = 0.00730381 loss)
I0301 22:33:55.878525  9663 sgd_solver.cpp:106] Iteration 1500, lr = 0.01
I0301 22:34:34.206776  9663 solver.cpp:237] Iteration 1520, loss = 0.0101712
I0301 22:34:34.206822  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.0101712 (* 1 = 0.0101712 loss)
I0301 22:34:34.206835  9663 sgd_solver.cpp:106] Iteration 1520, lr = 0.01
I0301 22:35:13.324589  9663 solver.cpp:237] Iteration 1540, loss = 0.0024345
I0301 22:35:13.324631  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00243455 (* 1 = 0.00243455 loss)
I0301 22:35:13.324640  9663 sgd_solver.cpp:106] Iteration 1540, lr = 0.01
I0301 22:35:51.882464  9663 solver.cpp:237] Iteration 1560, loss = 0.00533107
I0301 22:35:51.882505  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00533112 (* 1 = 0.00533112 loss)
I0301 22:35:51.882516  9663 sgd_solver.cpp:106] Iteration 1560, lr = 0.01
I0301 22:36:30.779924  9663 solver.cpp:237] Iteration 1580, loss = 0.0150176
I0301 22:36:30.779969  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.0150177 (* 1 = 0.0150177 loss)
I0301 22:36:30.779983  9663 sgd_solver.cpp:106] Iteration 1580, lr = 0.01
I0301 22:37:08.443117  9663 solver.cpp:237] Iteration 1600, loss = 0.00122168
I0301 22:37:08.443150  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00122173 (* 1 = 0.00122173 loss)
I0301 22:37:08.443158  9663 sgd_solver.cpp:106] Iteration 1600, lr = 0.01
I0301 22:37:46.206042  9663 solver.cpp:237] Iteration 1620, loss = 0.0177301
I0301 22:37:46.206078  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.0177301 (* 1 = 0.0177301 loss)
I0301 22:37:46.206085  9663 sgd_solver.cpp:106] Iteration 1620, lr = 0.01
I0301 22:38:24.610891  9663 solver.cpp:237] Iteration 1640, loss = 0.0108426
I0301 22:38:24.610923  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.0108426 (* 1 = 0.0108426 loss)
I0301 22:38:24.610931  9663 sgd_solver.cpp:106] Iteration 1640, lr = 0.01
I0301 22:39:03.066813  9663 solver.cpp:237] Iteration 1660, loss = 0.0011438
I0301 22:39:03.066846  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00114385 (* 1 = 0.00114385 loss)
I0301 22:39:03.066854  9663 sgd_solver.cpp:106] Iteration 1660, lr = 0.01
I0301 22:39:41.409849  9663 solver.cpp:237] Iteration 1680, loss = 0.0154643
I0301 22:39:41.409878  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.0154644 (* 1 = 0.0154644 loss)
I0301 22:39:41.409886  9663 sgd_solver.cpp:106] Iteration 1680, lr = 0.01
I0301 22:40:19.897840  9663 solver.cpp:237] Iteration 1700, loss = 0.0117182
I0301 22:40:19.897881  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.0117183 (* 1 = 0.0117183 loss)
I0301 22:40:19.897896  9663 sgd_solver.cpp:106] Iteration 1700, lr = 0.01
I0301 22:40:58.641142  9663 solver.cpp:237] Iteration 1720, loss = 0.00163726
I0301 22:40:58.641175  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00163731 (* 1 = 0.00163731 loss)
I0301 22:40:58.641182  9663 sgd_solver.cpp:106] Iteration 1720, lr = 0.01
I0301 22:41:37.405841  9663 solver.cpp:237] Iteration 1740, loss = 0.0389118
I0301 22:41:37.405889  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.0389118 (* 1 = 0.0389118 loss)
I0301 22:41:37.405899  9663 sgd_solver.cpp:106] Iteration 1740, lr = 0.01
I0301 22:42:14.381786  9663 solver.cpp:237] Iteration 1760, loss = 0.00471193
I0301 22:42:14.381832  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00471199 (* 1 = 0.00471199 loss)
I0301 22:42:14.381849  9663 sgd_solver.cpp:106] Iteration 1760, lr = 0.01
I0301 22:42:53.504077  9663 solver.cpp:237] Iteration 1780, loss = 0.00855316
I0301 22:42:53.504113  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00855322 (* 1 = 0.00855322 loss)
I0301 22:42:53.504122  9663 sgd_solver.cpp:106] Iteration 1780, lr = 0.01
I0301 22:43:32.054517  9663 solver.cpp:237] Iteration 1800, loss = 0.0172796
I0301 22:43:32.054571  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.0172796 (* 1 = 0.0172796 loss)
I0301 22:43:32.054587  9663 sgd_solver.cpp:106] Iteration 1800, lr = 0.01
I0301 22:44:10.036794  9663 solver.cpp:237] Iteration 1820, loss = 0.0802462
I0301 22:44:10.036828  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.0802463 (* 1 = 0.0802463 loss)
I0301 22:44:10.036840  9663 sgd_solver.cpp:106] Iteration 1820, lr = 0.01
I0301 22:44:46.728926  9663 solver.cpp:237] Iteration 1840, loss = 0.00246384
I0301 22:44:46.728962  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00246391 (* 1 = 0.00246391 loss)
I0301 22:44:46.728979  9663 sgd_solver.cpp:106] Iteration 1840, lr = 0.01
I0301 22:45:22.686664  9663 solver.cpp:237] Iteration 1860, loss = 0.0736411
I0301 22:45:22.686764  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.0736412 (* 1 = 0.0736412 loss)
I0301 22:45:22.686787  9663 sgd_solver.cpp:106] Iteration 1860, lr = 0.01
I0301 22:45:59.124577  9663 solver.cpp:237] Iteration 1880, loss = 0.0132069
I0301 22:45:59.124656  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.013207 (* 1 = 0.013207 loss)
I0301 22:45:59.124675  9663 sgd_solver.cpp:106] Iteration 1880, lr = 0.01
I0301 22:46:36.456941  9663 solver.cpp:237] Iteration 1900, loss = 0.044425
I0301 22:46:36.456979  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.0444251 (* 1 = 0.0444251 loss)
I0301 22:46:36.456990  9663 sgd_solver.cpp:106] Iteration 1900, lr = 0.01
I0301 22:47:13.809286  9663 solver.cpp:237] Iteration 1920, loss = 0.00154725
I0301 22:47:13.809339  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00154731 (* 1 = 0.00154731 loss)
I0301 22:47:13.809357  9663 sgd_solver.cpp:106] Iteration 1920, lr = 0.01
I0301 22:47:52.005079  9663 solver.cpp:237] Iteration 1940, loss = 0.00497891
I0301 22:47:52.005120  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00497898 (* 1 = 0.00497898 loss)
I0301 22:47:52.005131  9663 sgd_solver.cpp:106] Iteration 1940, lr = 0.01
I0301 22:48:28.515310  9663 solver.cpp:237] Iteration 1960, loss = 0.00303338
I0301 22:48:28.515339  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00303345 (* 1 = 0.00303345 loss)
I0301 22:48:28.515347  9663 sgd_solver.cpp:106] Iteration 1960, lr = 0.01
I0301 22:49:05.306865  9663 solver.cpp:237] Iteration 1980, loss = 0.0474367
I0301 22:49:05.306913  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.0474367 (* 1 = 0.0474367 loss)
I0301 22:49:05.306923  9663 sgd_solver.cpp:106] Iteration 1980, lr = 0.01
I0301 22:49:40.432828  9663 blocking_queue.cpp:50] Data layer prefetch queue empty
I0301 22:49:41.917603  9663 solver.cpp:237] Iteration 2000, loss = 0.00153417
I0301 22:49:41.917631  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00153424 (* 1 = 0.00153424 loss)
I0301 22:49:41.917639  9663 sgd_solver.cpp:106] Iteration 2000, lr = 0.01
I0301 22:50:19.066858  9663 solver.cpp:237] Iteration 2020, loss = 0.0119263
I0301 22:50:19.066898  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.0119263 (* 1 = 0.0119263 loss)
I0301 22:50:19.066912  9663 sgd_solver.cpp:106] Iteration 2020, lr = 0.01
I0301 22:50:56.385448  9663 solver.cpp:237] Iteration 2040, loss = 0.0323955
I0301 22:50:56.385480  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.0323956 (* 1 = 0.0323956 loss)
I0301 22:50:56.385489  9663 sgd_solver.cpp:106] Iteration 2040, lr = 0.01
I0301 22:51:35.636005  9663 solver.cpp:237] Iteration 2060, loss = 0.00718377
I0301 22:51:35.636070  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00718383 (* 1 = 0.00718383 loss)
I0301 22:51:35.636097  9663 sgd_solver.cpp:106] Iteration 2060, lr = 0.01
I0301 22:52:17.870533  9663 solver.cpp:237] Iteration 2080, loss = 0.00565079
I0301 22:52:17.870662  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00565085 (* 1 = 0.00565085 loss)
I0301 22:52:17.870714  9663 sgd_solver.cpp:106] Iteration 2080, lr = 0.01
I0301 22:53:00.216053  9663 solver.cpp:237] Iteration 2100, loss = 0.00780988
I0301 22:53:00.216087  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00780994 (* 1 = 0.00780994 loss)
I0301 22:53:00.216096  9663 sgd_solver.cpp:106] Iteration 2100, lr = 0.01
I0301 22:53:42.452489  9663 solver.cpp:237] Iteration 2120, loss = 0.0244847
I0301 22:53:42.452534  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.0244848 (* 1 = 0.0244848 loss)
I0301 22:53:42.452549  9663 sgd_solver.cpp:106] Iteration 2120, lr = 0.01
I0301 22:54:24.752571  9663 solver.cpp:237] Iteration 2140, loss = 0.000725986
I0301 22:54:24.752636  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000726048 (* 1 = 0.000726048 loss)
I0301 22:54:24.752671  9663 sgd_solver.cpp:106] Iteration 2140, lr = 0.01
I0301 22:55:07.476022  9663 solver.cpp:237] Iteration 2160, loss = 0.000872768
I0301 22:55:07.476052  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000872828 (* 1 = 0.000872828 loss)
I0301 22:55:07.476060  9663 sgd_solver.cpp:106] Iteration 2160, lr = 0.01
I0301 22:55:47.841842  9663 solver.cpp:237] Iteration 2180, loss = 0.0318346
I0301 22:55:47.841934  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.0318346 (* 1 = 0.0318346 loss)
I0301 22:55:47.841972  9663 sgd_solver.cpp:106] Iteration 2180, lr = 0.01
I0301 22:56:31.129228  9663 solver.cpp:237] Iteration 2200, loss = 0.008797
I0301 22:56:31.129307  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00879706 (* 1 = 0.00879706 loss)
I0301 22:56:31.129323  9663 sgd_solver.cpp:106] Iteration 2200, lr = 0.01
I0301 22:57:12.875461  9663 solver.cpp:237] Iteration 2220, loss = 0.0544974
I0301 22:57:12.875558  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.0544975 (* 1 = 0.0544975 loss)
I0301 22:57:12.875593  9663 sgd_solver.cpp:106] Iteration 2220, lr = 0.01
I0301 22:57:55.892438  9663 solver.cpp:237] Iteration 2240, loss = 0.00192976
I0301 22:57:55.892475  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00192981 (* 1 = 0.00192981 loss)
I0301 22:57:55.892484  9663 sgd_solver.cpp:106] Iteration 2240, lr = 0.01
I0301 22:58:39.951587  9663 solver.cpp:237] Iteration 2260, loss = 0.000934118
I0301 22:58:39.951625  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000934174 (* 1 = 0.000934174 loss)
I0301 22:58:39.951634  9663 sgd_solver.cpp:106] Iteration 2260, lr = 0.01
I0301 22:59:20.699275  9663 solver.cpp:237] Iteration 2280, loss = 0.000197379
I0301 22:59:20.699308  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000197431 (* 1 = 0.000197431 loss)
I0301 22:59:20.699318  9663 sgd_solver.cpp:106] Iteration 2280, lr = 0.01
I0301 23:00:00.854339  9663 solver.cpp:237] Iteration 2300, loss = 0.00243984
I0301 23:00:00.854394  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00243989 (* 1 = 0.00243989 loss)
I0301 23:00:00.854405  9663 sgd_solver.cpp:106] Iteration 2300, lr = 0.01
I0301 23:00:44.583359  9663 solver.cpp:237] Iteration 2320, loss = 0.00463238
I0301 23:00:44.583443  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00463244 (* 1 = 0.00463244 loss)
I0301 23:00:44.583472  9663 sgd_solver.cpp:106] Iteration 2320, lr = 0.01
I0301 23:01:29.672184  9663 solver.cpp:237] Iteration 2340, loss = 0.00105714
I0301 23:01:29.672220  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00105719 (* 1 = 0.00105719 loss)
I0301 23:01:29.672230  9663 sgd_solver.cpp:106] Iteration 2340, lr = 0.01
I0301 23:02:15.056644  9663 solver.cpp:237] Iteration 2360, loss = 0.00262194
I0301 23:02:15.056680  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.002622 (* 1 = 0.002622 loss)
I0301 23:02:15.056690  9663 sgd_solver.cpp:106] Iteration 2360, lr = 0.01
I0301 23:02:57.193934  9663 solver.cpp:237] Iteration 2380, loss = 0.000131865
I0301 23:02:57.193966  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000131917 (* 1 = 0.000131917 loss)
I0301 23:02:57.193976  9663 sgd_solver.cpp:106] Iteration 2380, lr = 0.01
I0301 23:03:41.959564  9663 solver.cpp:237] Iteration 2400, loss = 0.000693119
I0301 23:03:41.959599  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000693168 (* 1 = 0.000693168 loss)
I0301 23:03:41.959609  9663 sgd_solver.cpp:106] Iteration 2400, lr = 0.01
I0301 23:04:24.530372  9663 solver.cpp:237] Iteration 2420, loss = 0.000788935
I0301 23:04:24.530403  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000788988 (* 1 = 0.000788988 loss)
I0301 23:04:24.530412  9663 sgd_solver.cpp:106] Iteration 2420, lr = 0.01
I0301 23:05:07.067618  9663 solver.cpp:237] Iteration 2440, loss = 0.00107127
I0301 23:05:07.067656  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00107132 (* 1 = 0.00107132 loss)
I0301 23:05:07.067668  9663 sgd_solver.cpp:106] Iteration 2440, lr = 0.01
I0301 23:05:45.993794  9663 solver.cpp:237] Iteration 2460, loss = 0.019107
I0301 23:05:45.993865  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.019107 (* 1 = 0.019107 loss)
I0301 23:05:45.993878  9663 sgd_solver.cpp:106] Iteration 2460, lr = 0.01
I0301 23:06:24.764864  9663 solver.cpp:237] Iteration 2480, loss = 0.00831877
I0301 23:06:24.764900  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00831882 (* 1 = 0.00831882 loss)
I0301 23:06:24.764912  9663 sgd_solver.cpp:106] Iteration 2480, lr = 0.01
I0301 23:07:01.492712  9663 solver.cpp:237] Iteration 2500, loss = 0.00110045
I0301 23:07:01.492748  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00110051 (* 1 = 0.00110051 loss)
I0301 23:07:01.492761  9663 sgd_solver.cpp:106] Iteration 2500, lr = 0.01
I0301 23:07:37.636514  9663 solver.cpp:237] Iteration 2520, loss = 0.016271
I0301 23:07:37.636554  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.0162711 (* 1 = 0.0162711 loss)
I0301 23:07:37.636564  9663 sgd_solver.cpp:106] Iteration 2520, lr = 0.01
I0301 23:08:08.618787  9663 solver.cpp:237] Iteration 2540, loss = 0.00443375
I0301 23:08:08.618823  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.0044338 (* 1 = 0.0044338 loss)
I0301 23:08:08.618832  9663 sgd_solver.cpp:106] Iteration 2540, lr = 0.01
I0301 23:08:39.194507  9663 solver.cpp:237] Iteration 2560, loss = 0.00638158
I0301 23:08:39.194545  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00638162 (* 1 = 0.00638162 loss)
I0301 23:08:39.194555  9663 sgd_solver.cpp:106] Iteration 2560, lr = 0.01
I0301 23:09:08.752276  9663 solver.cpp:237] Iteration 2580, loss = 0.0013882
I0301 23:09:08.752310  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00138825 (* 1 = 0.00138825 loss)
I0301 23:09:08.752320  9663 sgd_solver.cpp:106] Iteration 2580, lr = 0.01
I0301 23:09:39.878767  9663 solver.cpp:237] Iteration 2600, loss = 0.00104994
I0301 23:09:39.878800  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00104998 (* 1 = 0.00104998 loss)
I0301 23:09:39.878809  9663 sgd_solver.cpp:106] Iteration 2600, lr = 0.01
I0301 23:10:10.307549  9663 solver.cpp:237] Iteration 2620, loss = 0.0275213
I0301 23:10:10.307618  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.0275214 (* 1 = 0.0275214 loss)
I0301 23:10:10.307633  9663 sgd_solver.cpp:106] Iteration 2620, lr = 0.01
I0301 23:10:42.916641  9663 solver.cpp:237] Iteration 2640, loss = 0.0145003
I0301 23:10:42.916681  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.0145004 (* 1 = 0.0145004 loss)
I0301 23:10:42.916689  9663 sgd_solver.cpp:106] Iteration 2640, lr = 0.01
I0301 23:11:14.773371  9663 solver.cpp:237] Iteration 2660, loss = 0.00142583
I0301 23:11:14.773409  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00142588 (* 1 = 0.00142588 loss)
I0301 23:11:14.773418  9663 sgd_solver.cpp:106] Iteration 2660, lr = 0.01
I0301 23:11:44.886561  9663 solver.cpp:237] Iteration 2680, loss = 0.00871427
I0301 23:11:44.886596  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00871431 (* 1 = 0.00871431 loss)
I0301 23:11:44.886606  9663 sgd_solver.cpp:106] Iteration 2680, lr = 0.01
I0301 23:12:15.969779  9663 solver.cpp:237] Iteration 2700, loss = 0.0122842
I0301 23:12:15.969813  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.0122842 (* 1 = 0.0122842 loss)
I0301 23:12:15.969823  9663 sgd_solver.cpp:106] Iteration 2700, lr = 0.01
I0301 23:12:47.611932  9663 solver.cpp:237] Iteration 2720, loss = 0.000190622
I0301 23:12:47.611968  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000190667 (* 1 = 0.000190667 loss)
I0301 23:12:47.611977  9663 sgd_solver.cpp:106] Iteration 2720, lr = 0.01
I0301 23:13:17.686470  9663 solver.cpp:237] Iteration 2740, loss = 0.00282421
I0301 23:13:17.686501  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00282425 (* 1 = 0.00282425 loss)
I0301 23:13:17.686511  9663 sgd_solver.cpp:106] Iteration 2740, lr = 0.01
I0301 23:13:47.937775  9663 solver.cpp:237] Iteration 2760, loss = 0.00634094
I0301 23:13:47.937808  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00634098 (* 1 = 0.00634098 loss)
I0301 23:13:47.937818  9663 sgd_solver.cpp:106] Iteration 2760, lr = 0.01
I0301 23:14:18.574436  9663 solver.cpp:237] Iteration 2780, loss = 0.000356135
I0301 23:14:18.574481  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000356175 (* 1 = 0.000356175 loss)
I0301 23:14:18.574492  9663 sgd_solver.cpp:106] Iteration 2780, lr = 0.01
I0301 23:14:53.072963  9663 solver.cpp:237] Iteration 2800, loss = 0.00138289
I0301 23:14:53.072999  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00138293 (* 1 = 0.00138293 loss)
I0301 23:14:53.073007  9663 sgd_solver.cpp:106] Iteration 2800, lr = 0.01
I0301 23:15:24.533643  9663 solver.cpp:237] Iteration 2820, loss = 0.000540787
I0301 23:15:24.533685  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000540826 (* 1 = 0.000540826 loss)
I0301 23:15:24.533697  9663 sgd_solver.cpp:106] Iteration 2820, lr = 0.01
I0301 23:15:55.495892  9663 solver.cpp:237] Iteration 2840, loss = 0.000273656
I0301 23:15:55.495929  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000273695 (* 1 = 0.000273695 loss)
I0301 23:15:55.495939  9663 sgd_solver.cpp:106] Iteration 2840, lr = 0.01
I0301 23:16:28.464727  9663 solver.cpp:237] Iteration 2860, loss = 0.00597591
I0301 23:16:28.464768  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00597595 (* 1 = 0.00597595 loss)
I0301 23:16:28.464782  9663 sgd_solver.cpp:106] Iteration 2860, lr = 0.01
I0301 23:17:00.905771  9663 solver.cpp:237] Iteration 2880, loss = 0.00360351
I0301 23:17:00.905802  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00360355 (* 1 = 0.00360355 loss)
I0301 23:17:00.905812  9663 sgd_solver.cpp:106] Iteration 2880, lr = 0.01
I0301 23:17:29.805994  9663 solver.cpp:237] Iteration 2900, loss = 0.00429686
I0301 23:17:29.806028  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.0042969 (* 1 = 0.0042969 loss)
I0301 23:17:29.806037  9663 sgd_solver.cpp:106] Iteration 2900, lr = 0.01
I0301 23:17:58.875551  9663 solver.cpp:237] Iteration 2920, loss = 0.00426828
I0301 23:17:58.875586  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00426832 (* 1 = 0.00426832 loss)
I0301 23:17:58.875594  9663 sgd_solver.cpp:106] Iteration 2920, lr = 0.01
I0301 23:18:27.301904  9663 solver.cpp:237] Iteration 2940, loss = 0.000650288
I0301 23:18:27.301937  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000650323 (* 1 = 0.000650323 loss)
I0301 23:18:27.301946  9663 sgd_solver.cpp:106] Iteration 2940, lr = 0.01
I0301 23:18:56.243866  9663 solver.cpp:237] Iteration 2960, loss = 0.000214634
I0301 23:18:56.243901  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00021467 (* 1 = 0.00021467 loss)
I0301 23:18:56.243911  9663 sgd_solver.cpp:106] Iteration 2960, lr = 0.01
I0301 23:19:25.394381  9663 solver.cpp:237] Iteration 2980, loss = 0.00023017
I0301 23:19:25.394418  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000230208 (* 1 = 0.000230208 loss)
I0301 23:19:25.394426  9663 sgd_solver.cpp:106] Iteration 2980, lr = 0.01
I0301 23:19:52.676720  9663 blocking_queue.cpp:50] Data layer prefetch queue empty
I0301 23:19:54.159750  9663 solver.cpp:237] Iteration 3000, loss = 0.00127478
I0301 23:19:54.159782  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00127482 (* 1 = 0.00127482 loss)
I0301 23:19:54.159791  9663 sgd_solver.cpp:106] Iteration 3000, lr = 0.01
I0301 23:20:23.397749  9663 solver.cpp:237] Iteration 3020, loss = 0.0013744
I0301 23:20:23.397790  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00137444 (* 1 = 0.00137444 loss)
I0301 23:20:23.397800  9663 sgd_solver.cpp:106] Iteration 3020, lr = 0.01
I0301 23:20:52.480134  9663 solver.cpp:237] Iteration 3040, loss = 0.00426128
I0301 23:20:52.480165  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00426132 (* 1 = 0.00426132 loss)
I0301 23:20:52.480175  9663 sgd_solver.cpp:106] Iteration 3040, lr = 0.01
I0301 23:21:21.439550  9663 solver.cpp:237] Iteration 3060, loss = 0.000363439
I0301 23:21:21.439584  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000363481 (* 1 = 0.000363481 loss)
I0301 23:21:21.439592  9663 sgd_solver.cpp:106] Iteration 3060, lr = 0.01
I0301 23:21:50.166296  9663 solver.cpp:237] Iteration 3080, loss = 0.000125252
I0301 23:21:50.166329  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000125293 (* 1 = 0.000125293 loss)
I0301 23:21:50.166339  9663 sgd_solver.cpp:106] Iteration 3080, lr = 0.01
I0301 23:22:19.320605  9663 solver.cpp:237] Iteration 3100, loss = 0.0116246
I0301 23:22:19.320636  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.0116246 (* 1 = 0.0116246 loss)
I0301 23:22:19.320647  9663 sgd_solver.cpp:106] Iteration 3100, lr = 0.01
I0301 23:22:47.958384  9663 solver.cpp:237] Iteration 3120, loss = 0.000542586
I0301 23:22:47.958420  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000542627 (* 1 = 0.000542627 loss)
I0301 23:22:47.958431  9663 sgd_solver.cpp:106] Iteration 3120, lr = 0.01
I0301 23:23:16.944742  9663 solver.cpp:237] Iteration 3140, loss = 0.00288937
I0301 23:23:16.944777  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00288941 (* 1 = 0.00288941 loss)
I0301 23:23:16.944785  9663 sgd_solver.cpp:106] Iteration 3140, lr = 0.01
I0301 23:23:45.966789  9663 solver.cpp:237] Iteration 3160, loss = 0.00946904
I0301 23:23:45.966822  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00946908 (* 1 = 0.00946908 loss)
I0301 23:23:45.966832  9663 sgd_solver.cpp:106] Iteration 3160, lr = 0.01
I0301 23:24:15.257179  9663 solver.cpp:237] Iteration 3180, loss = 0.00046392
I0301 23:24:15.257211  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000463961 (* 1 = 0.000463961 loss)
I0301 23:24:15.257220  9663 sgd_solver.cpp:106] Iteration 3180, lr = 0.01
I0301 23:24:44.422852  9663 solver.cpp:237] Iteration 3200, loss = 0.000877806
I0301 23:24:44.422884  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000877847 (* 1 = 0.000877847 loss)
I0301 23:24:44.422894  9663 sgd_solver.cpp:106] Iteration 3200, lr = 0.01
I0301 23:25:13.399186  9663 solver.cpp:237] Iteration 3220, loss = 0.003738
I0301 23:25:13.399217  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00373804 (* 1 = 0.00373804 loss)
I0301 23:25:13.399226  9663 sgd_solver.cpp:106] Iteration 3220, lr = 0.01
I0301 23:25:42.343732  9663 solver.cpp:237] Iteration 3240, loss = 0.000421819
I0301 23:25:42.343765  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000421861 (* 1 = 0.000421861 loss)
I0301 23:25:42.343775  9663 sgd_solver.cpp:106] Iteration 3240, lr = 0.01
I0301 23:26:11.321502  9663 solver.cpp:237] Iteration 3260, loss = 0.000607566
I0301 23:26:11.321537  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000607607 (* 1 = 0.000607607 loss)
I0301 23:26:11.321545  9663 sgd_solver.cpp:106] Iteration 3260, lr = 0.01
I0301 23:26:40.110766  9663 solver.cpp:237] Iteration 3280, loss = 0.000381192
I0301 23:26:40.110797  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000381234 (* 1 = 0.000381234 loss)
I0301 23:26:40.110807  9663 sgd_solver.cpp:106] Iteration 3280, lr = 0.01
I0301 23:27:09.057857  9663 solver.cpp:237] Iteration 3300, loss = 0.000124502
I0301 23:27:09.057888  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000124544 (* 1 = 0.000124544 loss)
I0301 23:27:09.057896  9663 sgd_solver.cpp:106] Iteration 3300, lr = 0.01
I0301 23:27:38.158349  9663 solver.cpp:237] Iteration 3320, loss = 0.0053773
I0301 23:27:38.158381  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00537735 (* 1 = 0.00537735 loss)
I0301 23:27:38.158390  9663 sgd_solver.cpp:106] Iteration 3320, lr = 0.01
I0301 23:28:06.617657  9663 solver.cpp:237] Iteration 3340, loss = 0.000230062
I0301 23:28:06.617692  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000230103 (* 1 = 0.000230103 loss)
I0301 23:28:06.617702  9663 sgd_solver.cpp:106] Iteration 3340, lr = 0.01
I0301 23:28:35.973502  9663 solver.cpp:237] Iteration 3360, loss = 0.000167036
I0301 23:28:35.973536  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000167078 (* 1 = 0.000167078 loss)
I0301 23:28:35.973544  9663 sgd_solver.cpp:106] Iteration 3360, lr = 0.01
I0301 23:29:04.599740  9663 solver.cpp:237] Iteration 3380, loss = 0.000253668
I0301 23:29:04.599774  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00025371 (* 1 = 0.00025371 loss)
I0301 23:29:04.599784  9663 sgd_solver.cpp:106] Iteration 3380, lr = 0.01
I0301 23:29:33.400877  9663 solver.cpp:237] Iteration 3400, loss = 0.00144054
I0301 23:29:33.400910  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00144058 (* 1 = 0.00144058 loss)
I0301 23:29:33.400918  9663 sgd_solver.cpp:106] Iteration 3400, lr = 0.01
I0301 23:30:02.560880  9663 solver.cpp:237] Iteration 3420, loss = 0.00139253
I0301 23:30:02.560912  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00139258 (* 1 = 0.00139258 loss)
I0301 23:30:02.560920  9663 sgd_solver.cpp:106] Iteration 3420, lr = 0.01
I0301 23:30:31.814384  9663 solver.cpp:237] Iteration 3440, loss = 0.00486553
I0301 23:30:31.814416  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00486557 (* 1 = 0.00486557 loss)
I0301 23:30:31.814430  9663 sgd_solver.cpp:106] Iteration 3440, lr = 0.01
I0301 23:31:00.717844  9663 solver.cpp:237] Iteration 3460, loss = 0.000713025
I0301 23:31:00.717870  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000713067 (* 1 = 0.000713067 loss)
I0301 23:31:00.717878  9663 sgd_solver.cpp:106] Iteration 3460, lr = 0.01
I0301 23:31:29.764725  9663 solver.cpp:237] Iteration 3480, loss = 0.00025399
I0301 23:31:29.764758  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000254033 (* 1 = 0.000254033 loss)
I0301 23:31:29.764767  9663 sgd_solver.cpp:106] Iteration 3480, lr = 0.01
I0301 23:31:58.661957  9663 solver.cpp:237] Iteration 3500, loss = 0.000338576
I0301 23:31:58.661991  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000338619 (* 1 = 0.000338619 loss)
I0301 23:31:58.661999  9663 sgd_solver.cpp:106] Iteration 3500, lr = 0.01
I0301 23:32:27.590538  9663 solver.cpp:237] Iteration 3520, loss = 0.000277098
I0301 23:32:27.590569  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000277141 (* 1 = 0.000277141 loss)
I0301 23:32:27.590581  9663 sgd_solver.cpp:106] Iteration 3520, lr = 0.01
I0301 23:32:56.610635  9663 solver.cpp:237] Iteration 3540, loss = 0.0272445
I0301 23:32:56.610666  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.0272446 (* 1 = 0.0272446 loss)
I0301 23:32:56.610676  9663 sgd_solver.cpp:106] Iteration 3540, lr = 0.01
I0301 23:33:25.569730  9663 solver.cpp:237] Iteration 3560, loss = 0.000196537
I0301 23:33:25.569763  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00019658 (* 1 = 0.00019658 loss)
I0301 23:33:25.569772  9663 sgd_solver.cpp:106] Iteration 3560, lr = 0.01
I0301 23:33:54.550565  9663 solver.cpp:237] Iteration 3580, loss = 0.00453096
I0301 23:33:54.550598  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.004531 (* 1 = 0.004531 loss)
I0301 23:33:54.550607  9663 sgd_solver.cpp:106] Iteration 3580, lr = 0.01
I0301 23:34:23.471408  9663 solver.cpp:237] Iteration 3600, loss = 0.000860164
I0301 23:34:23.471444  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000860208 (* 1 = 0.000860208 loss)
I0301 23:34:23.471453  9663 sgd_solver.cpp:106] Iteration 3600, lr = 0.01
I0301 23:34:52.262675  9663 solver.cpp:237] Iteration 3620, loss = 0.00257917
I0301 23:34:52.262707  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00257922 (* 1 = 0.00257922 loss)
I0301 23:34:52.262717  9663 sgd_solver.cpp:106] Iteration 3620, lr = 0.01
I0301 23:35:21.105654  9663 solver.cpp:237] Iteration 3640, loss = 0.000395886
I0301 23:35:21.105689  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00039593 (* 1 = 0.00039593 loss)
I0301 23:35:21.105697  9663 sgd_solver.cpp:106] Iteration 3640, lr = 0.01
I0301 23:35:49.689916  9663 solver.cpp:237] Iteration 3660, loss = 0.00139958
I0301 23:35:49.689949  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00139963 (* 1 = 0.00139963 loss)
I0301 23:35:49.689957  9663 sgd_solver.cpp:106] Iteration 3660, lr = 0.01
I0301 23:36:19.105219  9663 solver.cpp:237] Iteration 3680, loss = 0.00511608
I0301 23:36:19.105252  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00511612 (* 1 = 0.00511612 loss)
I0301 23:36:19.105262  9663 sgd_solver.cpp:106] Iteration 3680, lr = 0.01
I0301 23:36:48.128787  9663 solver.cpp:237] Iteration 3700, loss = 0.0037241
I0301 23:36:48.128821  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00372414 (* 1 = 0.00372414 loss)
I0301 23:36:48.128830  9663 sgd_solver.cpp:106] Iteration 3700, lr = 0.01
I0301 23:37:17.307947  9663 solver.cpp:237] Iteration 3720, loss = 0.00131704
I0301 23:37:17.307981  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00131709 (* 1 = 0.00131709 loss)
I0301 23:37:17.307989  9663 sgd_solver.cpp:106] Iteration 3720, lr = 0.01
I0301 23:37:46.187440  9663 solver.cpp:237] Iteration 3740, loss = 0.00163783
I0301 23:37:46.187474  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00163787 (* 1 = 0.00163787 loss)
I0301 23:37:46.187481  9663 sgd_solver.cpp:106] Iteration 3740, lr = 0.01
I0301 23:38:14.503167  9663 solver.cpp:237] Iteration 3760, loss = 0.00366866
I0301 23:38:14.503198  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00366871 (* 1 = 0.00366871 loss)
I0301 23:38:14.503208  9663 sgd_solver.cpp:106] Iteration 3760, lr = 0.01
I0301 23:38:43.222501  9663 solver.cpp:237] Iteration 3780, loss = 0.000651747
I0301 23:38:43.222538  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00065179 (* 1 = 0.00065179 loss)
I0301 23:38:43.222548  9663 sgd_solver.cpp:106] Iteration 3780, lr = 0.01
I0301 23:39:12.331704  9663 solver.cpp:237] Iteration 3800, loss = 0.000249095
I0301 23:39:12.331737  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00024914 (* 1 = 0.00024914 loss)
I0301 23:39:12.331746  9663 sgd_solver.cpp:106] Iteration 3800, lr = 0.01
I0301 23:39:41.145865  9663 solver.cpp:237] Iteration 3820, loss = 0.00261303
I0301 23:39:41.145898  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00261307 (* 1 = 0.00261307 loss)
I0301 23:39:41.145907  9663 sgd_solver.cpp:106] Iteration 3820, lr = 0.01
I0301 23:40:10.081656  9663 solver.cpp:237] Iteration 3840, loss = 0.00065075
I0301 23:40:10.081688  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000650795 (* 1 = 0.000650795 loss)
I0301 23:40:10.081697  9663 sgd_solver.cpp:106] Iteration 3840, lr = 0.01
I0301 23:40:38.634872  9663 solver.cpp:237] Iteration 3860, loss = 0.00130238
I0301 23:40:38.634903  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00130242 (* 1 = 0.00130242 loss)
I0301 23:40:38.634912  9663 sgd_solver.cpp:106] Iteration 3860, lr = 0.01
I0301 23:41:07.603391  9663 solver.cpp:237] Iteration 3880, loss = 0.000634712
I0301 23:41:07.603422  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000634757 (* 1 = 0.000634757 loss)
I0301 23:41:07.603435  9663 sgd_solver.cpp:106] Iteration 3880, lr = 0.01
I0301 23:41:36.432449  9663 solver.cpp:237] Iteration 3900, loss = 0.000131787
I0301 23:41:36.432482  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000131832 (* 1 = 0.000131832 loss)
I0301 23:41:36.432492  9663 sgd_solver.cpp:106] Iteration 3900, lr = 0.01
I0301 23:42:05.529278  9663 solver.cpp:237] Iteration 3920, loss = 8.83844e-05
I0301 23:42:05.529315  9663 solver.cpp:253]     Train net output #0: loss_cls = 8.84293e-05 (* 1 = 8.84293e-05 loss)
I0301 23:42:05.529325  9663 sgd_solver.cpp:106] Iteration 3920, lr = 0.01
I0301 23:42:34.455013  9663 solver.cpp:237] Iteration 3940, loss = 0.000444931
I0301 23:42:34.455044  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000444976 (* 1 = 0.000444976 loss)
I0301 23:42:34.455054  9663 sgd_solver.cpp:106] Iteration 3940, lr = 0.01
I0301 23:43:03.578487  9663 solver.cpp:237] Iteration 3960, loss = 0.0109231
I0301 23:43:03.578522  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.0109231 (* 1 = 0.0109231 loss)
I0301 23:43:03.578532  9663 sgd_solver.cpp:106] Iteration 3960, lr = 0.01
I0301 23:43:32.773280  9663 solver.cpp:237] Iteration 3980, loss = 5.53667e-05
I0301 23:43:32.773314  9663 solver.cpp:253]     Train net output #0: loss_cls = 5.54133e-05 (* 1 = 5.54133e-05 loss)
I0301 23:43:32.773324  9663 sgd_solver.cpp:106] Iteration 3980, lr = 0.01
I0301 23:44:00.633738  9663 blocking_queue.cpp:50] Data layer prefetch queue empty
I0301 23:44:02.063014  9663 solver.cpp:237] Iteration 4000, loss = 0.000178881
I0301 23:44:02.063046  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000178928 (* 1 = 0.000178928 loss)
I0301 23:44:02.063056  9663 sgd_solver.cpp:106] Iteration 4000, lr = 0.01
I0301 23:44:30.525692  9663 solver.cpp:237] Iteration 4020, loss = 0.000758666
I0301 23:44:30.525724  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000758713 (* 1 = 0.000758713 loss)
I0301 23:44:30.525732  9663 sgd_solver.cpp:106] Iteration 4020, lr = 0.01
I0301 23:44:59.129138  9663 solver.cpp:237] Iteration 4040, loss = 0.000272211
I0301 23:44:59.129171  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000272257 (* 1 = 0.000272257 loss)
I0301 23:44:59.129180  9663 sgd_solver.cpp:106] Iteration 4040, lr = 0.01
I0301 23:45:28.219177  9663 solver.cpp:237] Iteration 4060, loss = 6.23236e-05
I0301 23:45:28.219215  9663 solver.cpp:253]     Train net output #0: loss_cls = 6.23699e-05 (* 1 = 6.23699e-05 loss)
I0301 23:45:28.219225  9663 sgd_solver.cpp:106] Iteration 4060, lr = 0.01
I0301 23:45:57.308279  9663 solver.cpp:237] Iteration 4080, loss = 0.000108648
I0301 23:45:57.308315  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000108695 (* 1 = 0.000108695 loss)
I0301 23:45:57.308326  9663 sgd_solver.cpp:106] Iteration 4080, lr = 0.01
I0301 23:46:26.327044  9663 solver.cpp:237] Iteration 4100, loss = 0.00024881
I0301 23:46:26.327078  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000248857 (* 1 = 0.000248857 loss)
I0301 23:46:26.327087  9663 sgd_solver.cpp:106] Iteration 4100, lr = 0.01
I0301 23:46:55.362243  9663 solver.cpp:237] Iteration 4120, loss = 0.000262569
I0301 23:46:55.362272  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000262616 (* 1 = 0.000262616 loss)
I0301 23:46:55.362282  9663 sgd_solver.cpp:106] Iteration 4120, lr = 0.01
I0301 23:47:24.027721  9663 solver.cpp:237] Iteration 4140, loss = 0.000233527
I0301 23:47:24.027753  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000233575 (* 1 = 0.000233575 loss)
I0301 23:47:24.027762  9663 sgd_solver.cpp:106] Iteration 4140, lr = 0.01
I0301 23:47:52.937850  9663 solver.cpp:237] Iteration 4160, loss = 0.000598973
I0301 23:47:52.937885  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00059902 (* 1 = 0.00059902 loss)
I0301 23:47:52.937894  9663 sgd_solver.cpp:106] Iteration 4160, lr = 0.01
I0301 23:48:21.799603  9663 solver.cpp:237] Iteration 4180, loss = 0.000599227
I0301 23:48:21.799635  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000599274 (* 1 = 0.000599274 loss)
I0301 23:48:21.799644  9663 sgd_solver.cpp:106] Iteration 4180, lr = 0.01
I0301 23:48:51.053784  9663 solver.cpp:237] Iteration 4200, loss = 0.00148261
I0301 23:48:51.053818  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00148265 (* 1 = 0.00148265 loss)
I0301 23:48:51.053828  9663 sgd_solver.cpp:106] Iteration 4200, lr = 0.01
I0301 23:49:20.196580  9663 solver.cpp:237] Iteration 4220, loss = 0.000262016
I0301 23:49:20.196611  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000262063 (* 1 = 0.000262063 loss)
I0301 23:49:20.196620  9663 sgd_solver.cpp:106] Iteration 4220, lr = 0.01
I0301 23:49:48.919522  9663 solver.cpp:237] Iteration 4240, loss = 0.000259881
I0301 23:49:48.919553  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000259929 (* 1 = 0.000259929 loss)
I0301 23:49:48.919561  9663 sgd_solver.cpp:106] Iteration 4240, lr = 0.01
I0301 23:50:17.362294  9663 solver.cpp:237] Iteration 4260, loss = 0.000281814
I0301 23:50:17.362328  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000281861 (* 1 = 0.000281861 loss)
I0301 23:50:17.362336  9663 sgd_solver.cpp:106] Iteration 4260, lr = 0.01
I0301 23:50:46.143224  9663 solver.cpp:237] Iteration 4280, loss = 0.000280564
I0301 23:50:46.143259  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000280612 (* 1 = 0.000280612 loss)
I0301 23:50:46.143268  9663 sgd_solver.cpp:106] Iteration 4280, lr = 0.01
I0301 23:51:15.299669  9663 solver.cpp:237] Iteration 4300, loss = 7.69596e-05
I0301 23:51:15.299701  9663 solver.cpp:253]     Train net output #0: loss_cls = 7.70072e-05 (* 1 = 7.70072e-05 loss)
I0301 23:51:15.299710  9663 sgd_solver.cpp:106] Iteration 4300, lr = 0.01
I0301 23:51:44.167572  9663 solver.cpp:237] Iteration 4320, loss = 0.000116235
I0301 23:51:44.167611  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000116282 (* 1 = 0.000116282 loss)
I0301 23:51:44.167621  9663 sgd_solver.cpp:106] Iteration 4320, lr = 0.01
I0301 23:52:16.596843  9663 solver.cpp:237] Iteration 4340, loss = 0.00012234
I0301 23:52:16.596890  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000122388 (* 1 = 0.000122388 loss)
I0301 23:52:16.596907  9663 sgd_solver.cpp:106] Iteration 4340, lr = 0.01
I0301 23:52:47.207043  9663 solver.cpp:237] Iteration 4360, loss = 8.74712e-05
I0301 23:52:47.207077  9663 solver.cpp:253]     Train net output #0: loss_cls = 8.75186e-05 (* 1 = 8.75186e-05 loss)
I0301 23:52:47.207085  9663 sgd_solver.cpp:106] Iteration 4360, lr = 0.01
I0301 23:53:16.192639  9663 solver.cpp:237] Iteration 4380, loss = 7.75709e-05
I0301 23:53:16.192675  9663 solver.cpp:253]     Train net output #0: loss_cls = 7.76182e-05 (* 1 = 7.76182e-05 loss)
I0301 23:53:16.192684  9663 sgd_solver.cpp:106] Iteration 4380, lr = 0.01
I0301 23:53:45.042349  9663 solver.cpp:237] Iteration 4400, loss = 0.000144053
I0301 23:53:45.042381  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000144101 (* 1 = 0.000144101 loss)
I0301 23:53:45.042389  9663 sgd_solver.cpp:106] Iteration 4400, lr = 0.01
I0301 23:54:13.503926  9663 solver.cpp:237] Iteration 4420, loss = 5.67669e-05
I0301 23:54:13.503959  9663 solver.cpp:253]     Train net output #0: loss_cls = 5.68146e-05 (* 1 = 5.68146e-05 loss)
I0301 23:54:13.503968  9663 sgd_solver.cpp:106] Iteration 4420, lr = 0.01
I0301 23:54:42.457561  9663 solver.cpp:237] Iteration 4440, loss = 0.00105655
I0301 23:54:42.457597  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.0010566 (* 1 = 0.0010566 loss)
I0301 23:54:42.457607  9663 sgd_solver.cpp:106] Iteration 4440, lr = 0.01
I0301 23:55:11.519621  9663 solver.cpp:237] Iteration 4460, loss = 6.34356e-05
I0301 23:55:11.519655  9663 solver.cpp:253]     Train net output #0: loss_cls = 6.34832e-05 (* 1 = 6.34832e-05 loss)
I0301 23:55:11.519665  9663 sgd_solver.cpp:106] Iteration 4460, lr = 0.01
I0301 23:55:40.626972  9663 solver.cpp:237] Iteration 4480, loss = 0.00120343
I0301 23:55:40.627009  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00120348 (* 1 = 0.00120348 loss)
I0301 23:55:40.627019  9663 sgd_solver.cpp:106] Iteration 4480, lr = 0.01
I0301 23:56:09.575945  9663 solver.cpp:237] Iteration 4500, loss = 0.000257948
I0301 23:56:09.575978  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000257996 (* 1 = 0.000257996 loss)
I0301 23:56:09.575987  9663 sgd_solver.cpp:106] Iteration 4500, lr = 0.01
I0301 23:56:37.960391  9663 solver.cpp:237] Iteration 4520, loss = 5.81959e-05
I0301 23:56:37.960429  9663 solver.cpp:253]     Train net output #0: loss_cls = 5.82436e-05 (* 1 = 5.82436e-05 loss)
I0301 23:56:37.960439  9663 sgd_solver.cpp:106] Iteration 4520, lr = 0.01
I0301 23:57:07.937396  9663 solver.cpp:237] Iteration 4540, loss = 0.00242139
I0301 23:57:07.937427  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00242144 (* 1 = 0.00242144 loss)
I0301 23:57:07.937436  9663 sgd_solver.cpp:106] Iteration 4540, lr = 0.01
I0301 23:57:36.323513  9663 solver.cpp:237] Iteration 4560, loss = 4.00977e-05
I0301 23:57:36.323544  9663 solver.cpp:253]     Train net output #0: loss_cls = 4.01457e-05 (* 1 = 4.01457e-05 loss)
I0301 23:57:36.323554  9663 sgd_solver.cpp:106] Iteration 4560, lr = 0.01
I0301 23:58:05.557811  9663 solver.cpp:237] Iteration 4580, loss = 0.000146119
I0301 23:58:05.557843  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000146167 (* 1 = 0.000146167 loss)
I0301 23:58:05.557852  9663 sgd_solver.cpp:106] Iteration 4580, lr = 0.01
I0301 23:58:34.502194  9663 solver.cpp:237] Iteration 4600, loss = 0.000176088
I0301 23:58:34.502233  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000176136 (* 1 = 0.000176136 loss)
I0301 23:58:34.502241  9663 sgd_solver.cpp:106] Iteration 4600, lr = 0.01
I0301 23:59:03.797736  9663 solver.cpp:237] Iteration 4620, loss = 4.37691e-05
I0301 23:59:03.797768  9663 solver.cpp:253]     Train net output #0: loss_cls = 4.38171e-05 (* 1 = 4.38171e-05 loss)
I0301 23:59:03.797778  9663 sgd_solver.cpp:106] Iteration 4620, lr = 0.01
I0301 23:59:32.850818  9663 solver.cpp:237] Iteration 4640, loss = 0.000228539
I0301 23:59:32.850849  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000228587 (* 1 = 0.000228587 loss)
I0301 23:59:32.850858  9663 sgd_solver.cpp:106] Iteration 4640, lr = 0.01
I0302 00:00:02.074055  9663 solver.cpp:237] Iteration 4660, loss = 5.74797e-05
I0302 00:00:02.074089  9663 solver.cpp:253]     Train net output #0: loss_cls = 5.75277e-05 (* 1 = 5.75277e-05 loss)
I0302 00:00:02.074097  9663 sgd_solver.cpp:106] Iteration 4660, lr = 0.01
I0302 00:00:30.826586  9663 solver.cpp:237] Iteration 4680, loss = 9.33699e-05
I0302 00:00:30.826616  9663 solver.cpp:253]     Train net output #0: loss_cls = 9.34178e-05 (* 1 = 9.34178e-05 loss)
I0302 00:00:30.826623  9663 sgd_solver.cpp:106] Iteration 4680, lr = 0.01
I0302 00:00:59.517892  9663 solver.cpp:237] Iteration 4700, loss = 0.000616774
I0302 00:00:59.517925  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000616822 (* 1 = 0.000616822 loss)
I0302 00:00:59.517935  9663 sgd_solver.cpp:106] Iteration 4700, lr = 0.01
I0302 00:01:28.349539  9663 solver.cpp:237] Iteration 4720, loss = 0.000557442
I0302 00:01:28.349575  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00055749 (* 1 = 0.00055749 loss)
I0302 00:01:28.349586  9663 sgd_solver.cpp:106] Iteration 4720, lr = 0.01
I0302 00:01:57.482870  9663 solver.cpp:237] Iteration 4740, loss = 0.000521685
I0302 00:01:57.482911  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000521733 (* 1 = 0.000521733 loss)
I0302 00:01:57.482921  9663 sgd_solver.cpp:106] Iteration 4740, lr = 0.01
I0302 00:02:26.011008  9663 solver.cpp:237] Iteration 4760, loss = 6.91834e-05
I0302 00:02:26.011044  9663 solver.cpp:253]     Train net output #0: loss_cls = 6.92312e-05 (* 1 = 6.92312e-05 loss)
I0302 00:02:26.011052  9663 sgd_solver.cpp:106] Iteration 4760, lr = 0.01
I0302 00:02:54.767915  9663 solver.cpp:237] Iteration 4780, loss = 0.000156811
I0302 00:02:54.767946  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000156858 (* 1 = 0.000156858 loss)
I0302 00:02:54.767956  9663 sgd_solver.cpp:106] Iteration 4780, lr = 0.01
I0302 00:03:23.658429  9663 solver.cpp:237] Iteration 4800, loss = 0.000235118
I0302 00:03:23.658463  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000235164 (* 1 = 0.000235164 loss)
I0302 00:03:23.658471  9663 sgd_solver.cpp:106] Iteration 4800, lr = 0.01
I0302 00:03:52.304060  9663 solver.cpp:237] Iteration 4820, loss = 0.000499644
I0302 00:03:52.304095  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000499691 (* 1 = 0.000499691 loss)
I0302 00:03:52.304103  9663 sgd_solver.cpp:106] Iteration 4820, lr = 0.01
I0302 00:04:21.669111  9663 solver.cpp:237] Iteration 4840, loss = 9.82505e-05
I0302 00:04:21.669144  9663 solver.cpp:253]     Train net output #0: loss_cls = 9.82971e-05 (* 1 = 9.82971e-05 loss)
I0302 00:04:21.669154  9663 sgd_solver.cpp:106] Iteration 4840, lr = 0.01
I0302 00:04:51.279201  9663 solver.cpp:237] Iteration 4860, loss = 0.000304405
I0302 00:04:51.279232  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000304452 (* 1 = 0.000304452 loss)
I0302 00:04:51.279240  9663 sgd_solver.cpp:106] Iteration 4860, lr = 0.01
I0302 00:05:21.514180  9663 solver.cpp:237] Iteration 4880, loss = 0.00174707
I0302 00:05:21.514302  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00174712 (* 1 = 0.00174712 loss)
I0302 00:05:21.514343  9663 sgd_solver.cpp:106] Iteration 4880, lr = 0.01
I0302 00:05:57.871969  9663 solver.cpp:237] Iteration 4900, loss = 6.7328e-05
I0302 00:05:57.872072  9663 solver.cpp:253]     Train net output #0: loss_cls = 6.73748e-05 (* 1 = 6.73748e-05 loss)
I0302 00:05:57.872109  9663 sgd_solver.cpp:106] Iteration 4900, lr = 0.01
I0302 00:06:35.881309  9663 solver.cpp:237] Iteration 4920, loss = 7.39854e-05
I0302 00:06:35.881407  9663 solver.cpp:253]     Train net output #0: loss_cls = 7.40322e-05 (* 1 = 7.40322e-05 loss)
I0302 00:06:35.881438  9663 sgd_solver.cpp:106] Iteration 4920, lr = 0.01
I0302 00:07:09.685792  9663 solver.cpp:237] Iteration 4940, loss = 7.97306e-05
I0302 00:07:09.685837  9663 solver.cpp:253]     Train net output #0: loss_cls = 7.97777e-05 (* 1 = 7.97777e-05 loss)
I0302 00:07:09.685854  9663 sgd_solver.cpp:106] Iteration 4940, lr = 0.01
I0302 00:07:41.523880  9663 solver.cpp:237] Iteration 4960, loss = 5.22362e-05
I0302 00:07:41.523913  9663 solver.cpp:253]     Train net output #0: loss_cls = 5.22834e-05 (* 1 = 5.22834e-05 loss)
I0302 00:07:41.523922  9663 sgd_solver.cpp:106] Iteration 4960, lr = 0.01
I0302 00:08:10.652168  9663 solver.cpp:237] Iteration 4980, loss = 0.000130431
I0302 00:08:10.652199  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000130479 (* 1 = 0.000130479 loss)
I0302 00:08:10.652209  9663 sgd_solver.cpp:106] Iteration 4980, lr = 0.01
I0302 00:08:38.960254  9663 solver.cpp:459] Snapshotting to binary proto file /nfs.yoda/xiaolonw/fast_rcnn/models_sunrgbd/pre_cls/model__iter_5000.caffemodel
I0302 00:08:41.250815  9663 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /nfs.yoda/xiaolonw/fast_rcnn/models_sunrgbd/pre_cls/model__iter_5000.solverstate
I0302 00:08:43.013979  9663 solver.cpp:237] Iteration 5000, loss = 0.000155768
I0302 00:08:43.014013  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000155815 (* 1 = 0.000155815 loss)
I0302 00:08:43.014021  9663 sgd_solver.cpp:106] Iteration 5000, lr = 0.01
I0302 00:08:48.305840  9663 blocking_queue.cpp:50] Data layer prefetch queue empty
I0302 00:09:09.427780  9663 solver.cpp:237] Iteration 5020, loss = 0.00398995
I0302 00:09:09.427814  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00399 (* 1 = 0.00399 loss)
I0302 00:09:09.427824  9663 sgd_solver.cpp:106] Iteration 5020, lr = 0.01
I0302 00:09:38.705014  9663 solver.cpp:237] Iteration 5040, loss = 0.000732835
I0302 00:09:38.705049  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000732883 (* 1 = 0.000732883 loss)
I0302 00:09:38.705060  9663 sgd_solver.cpp:106] Iteration 5040, lr = 0.01
I0302 00:10:07.464882  9663 solver.cpp:237] Iteration 5060, loss = 9.06387e-05
I0302 00:10:07.464915  9663 solver.cpp:253]     Train net output #0: loss_cls = 9.06869e-05 (* 1 = 9.06869e-05 loss)
I0302 00:10:07.464925  9663 sgd_solver.cpp:106] Iteration 5060, lr = 0.01
I0302 00:10:36.419497  9663 solver.cpp:237] Iteration 5080, loss = 4.51159e-05
I0302 00:10:36.419528  9663 solver.cpp:253]     Train net output #0: loss_cls = 4.51641e-05 (* 1 = 4.51641e-05 loss)
I0302 00:10:36.419538  9663 sgd_solver.cpp:106] Iteration 5080, lr = 0.01
I0302 00:11:05.521394  9663 solver.cpp:237] Iteration 5100, loss = 0.000108452
I0302 00:11:05.521423  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.0001085 (* 1 = 0.0001085 loss)
I0302 00:11:05.521431  9663 sgd_solver.cpp:106] Iteration 5100, lr = 0.01
I0302 00:11:34.651979  9663 solver.cpp:237] Iteration 5120, loss = 0.000110613
I0302 00:11:34.652010  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000110662 (* 1 = 0.000110662 loss)
I0302 00:11:34.652019  9663 sgd_solver.cpp:106] Iteration 5120, lr = 0.01
I0302 00:12:04.200120  9663 solver.cpp:237] Iteration 5140, loss = 0.00019841
I0302 00:12:04.200152  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000198458 (* 1 = 0.000198458 loss)
I0302 00:12:04.200161  9663 sgd_solver.cpp:106] Iteration 5140, lr = 0.01
I0302 00:12:33.065490  9663 solver.cpp:237] Iteration 5160, loss = 0.000116025
I0302 00:12:33.065523  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000116072 (* 1 = 0.000116072 loss)
I0302 00:12:33.065536  9663 sgd_solver.cpp:106] Iteration 5160, lr = 0.01
I0302 00:13:02.356156  9663 solver.cpp:237] Iteration 5180, loss = 0.000186266
I0302 00:13:02.356189  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000186314 (* 1 = 0.000186314 loss)
I0302 00:13:02.356199  9663 sgd_solver.cpp:106] Iteration 5180, lr = 0.01
I0302 00:13:31.331202  9663 solver.cpp:237] Iteration 5200, loss = 0.00108736
I0302 00:13:31.331235  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.0010874 (* 1 = 0.0010874 loss)
I0302 00:13:31.331244  9663 sgd_solver.cpp:106] Iteration 5200, lr = 0.01
I0302 00:14:00.673843  9663 solver.cpp:237] Iteration 5220, loss = 4.28927e-05
I0302 00:14:00.673877  9663 solver.cpp:253]     Train net output #0: loss_cls = 4.29408e-05 (* 1 = 4.29408e-05 loss)
I0302 00:14:00.673887  9663 sgd_solver.cpp:106] Iteration 5220, lr = 0.01
I0302 00:14:29.686991  9663 solver.cpp:237] Iteration 5240, loss = 5.06718e-05
I0302 00:14:29.687024  9663 solver.cpp:253]     Train net output #0: loss_cls = 5.07199e-05 (* 1 = 5.07199e-05 loss)
I0302 00:14:29.687033  9663 sgd_solver.cpp:106] Iteration 5240, lr = 0.01
I0302 00:14:59.200947  9663 solver.cpp:237] Iteration 5260, loss = 9.52488e-05
I0302 00:14:59.200983  9663 solver.cpp:253]     Train net output #0: loss_cls = 9.5297e-05 (* 1 = 9.5297e-05 loss)
I0302 00:14:59.200991  9663 sgd_solver.cpp:106] Iteration 5260, lr = 0.01
I0302 00:15:28.116251  9663 solver.cpp:237] Iteration 5280, loss = 0.000201699
I0302 00:15:28.116283  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000201747 (* 1 = 0.000201747 loss)
I0302 00:15:28.116292  9663 sgd_solver.cpp:106] Iteration 5280, lr = 0.01
I0302 00:15:57.142343  9663 solver.cpp:237] Iteration 5300, loss = 9.17075e-05
I0302 00:15:57.142377  9663 solver.cpp:253]     Train net output #0: loss_cls = 9.17556e-05 (* 1 = 9.17556e-05 loss)
I0302 00:15:57.142386  9663 sgd_solver.cpp:106] Iteration 5300, lr = 0.01
I0302 00:16:26.628753  9663 solver.cpp:237] Iteration 5320, loss = 0.000270705
I0302 00:16:26.628787  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000270753 (* 1 = 0.000270753 loss)
I0302 00:16:26.628795  9663 sgd_solver.cpp:106] Iteration 5320, lr = 0.01
I0302 00:16:55.879124  9663 solver.cpp:237] Iteration 5340, loss = 6.05189e-05
I0302 00:16:55.879155  9663 solver.cpp:253]     Train net output #0: loss_cls = 6.05671e-05 (* 1 = 6.05671e-05 loss)
I0302 00:16:55.879164  9663 sgd_solver.cpp:106] Iteration 5340, lr = 0.01
I0302 00:17:24.771185  9663 solver.cpp:237] Iteration 5360, loss = 9.05305e-05
I0302 00:17:24.771219  9663 solver.cpp:253]     Train net output #0: loss_cls = 9.05787e-05 (* 1 = 9.05787e-05 loss)
I0302 00:17:24.771227  9663 sgd_solver.cpp:106] Iteration 5360, lr = 0.01
I0302 00:17:54.166419  9663 solver.cpp:237] Iteration 5380, loss = 4.51196e-05
I0302 00:17:54.166445  9663 solver.cpp:253]     Train net output #0: loss_cls = 4.51677e-05 (* 1 = 4.51677e-05 loss)
I0302 00:17:54.166455  9663 sgd_solver.cpp:106] Iteration 5380, lr = 0.01
I0302 00:18:23.744088  9663 solver.cpp:237] Iteration 5400, loss = 0.000867931
I0302 00:18:23.744120  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00086798 (* 1 = 0.00086798 loss)
I0302 00:18:23.744130  9663 sgd_solver.cpp:106] Iteration 5400, lr = 0.01
I0302 00:18:52.905938  9663 solver.cpp:237] Iteration 5420, loss = 0.000237439
I0302 00:18:52.905971  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000237487 (* 1 = 0.000237487 loss)
I0302 00:18:52.905979  9663 sgd_solver.cpp:106] Iteration 5420, lr = 0.01
I0302 00:19:22.129765  9663 solver.cpp:237] Iteration 5440, loss = 0.000460042
I0302 00:19:22.129798  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00046009 (* 1 = 0.00046009 loss)
I0302 00:19:22.129808  9663 sgd_solver.cpp:106] Iteration 5440, lr = 0.01
I0302 00:19:51.180676  9663 solver.cpp:237] Iteration 5460, loss = 3.81321e-05
I0302 00:19:51.180706  9663 solver.cpp:253]     Train net output #0: loss_cls = 3.81802e-05 (* 1 = 3.81802e-05 loss)
I0302 00:19:51.180716  9663 sgd_solver.cpp:106] Iteration 5460, lr = 0.01
I0302 00:20:20.176957  9663 solver.cpp:237] Iteration 5480, loss = 0.000157462
I0302 00:20:20.176987  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00015751 (* 1 = 0.00015751 loss)
I0302 00:20:20.176996  9663 sgd_solver.cpp:106] Iteration 5480, lr = 0.01
I0302 00:20:49.820294  9663 solver.cpp:237] Iteration 5500, loss = 6.736e-05
I0302 00:20:49.820327  9663 solver.cpp:253]     Train net output #0: loss_cls = 6.74082e-05 (* 1 = 6.74082e-05 loss)
I0302 00:20:49.820336  9663 sgd_solver.cpp:106] Iteration 5500, lr = 0.01
I0302 00:21:20.215513  9663 solver.cpp:237] Iteration 5520, loss = 3.20444e-05
I0302 00:21:20.215546  9663 solver.cpp:253]     Train net output #0: loss_cls = 3.20926e-05 (* 1 = 3.20926e-05 loss)
I0302 00:21:20.215555  9663 sgd_solver.cpp:106] Iteration 5520, lr = 0.01
I0302 00:21:49.312880  9663 solver.cpp:237] Iteration 5540, loss = 8.13781e-05
I0302 00:21:49.312911  9663 solver.cpp:253]     Train net output #0: loss_cls = 8.14263e-05 (* 1 = 8.14263e-05 loss)
I0302 00:21:49.312921  9663 sgd_solver.cpp:106] Iteration 5540, lr = 0.01
I0302 00:22:19.136907  9663 solver.cpp:237] Iteration 5560, loss = 4.15851e-05
I0302 00:22:19.136943  9663 solver.cpp:253]     Train net output #0: loss_cls = 4.16333e-05 (* 1 = 4.16333e-05 loss)
I0302 00:22:19.136953  9663 sgd_solver.cpp:106] Iteration 5560, lr = 0.01
I0302 00:22:48.425633  9663 solver.cpp:237] Iteration 5580, loss = 0.000143249
I0302 00:22:48.425667  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000143297 (* 1 = 0.000143297 loss)
I0302 00:22:48.425675  9663 sgd_solver.cpp:106] Iteration 5580, lr = 0.01
I0302 00:23:17.408746  9663 solver.cpp:237] Iteration 5600, loss = 4.09044e-05
I0302 00:23:17.408779  9663 solver.cpp:253]     Train net output #0: loss_cls = 4.09526e-05 (* 1 = 4.09526e-05 loss)
I0302 00:23:17.408789  9663 sgd_solver.cpp:106] Iteration 5600, lr = 0.01
I0302 00:23:46.284525  9663 solver.cpp:237] Iteration 5620, loss = 0.000497339
I0302 00:23:46.284556  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000497387 (* 1 = 0.000497387 loss)
I0302 00:23:46.284566  9663 sgd_solver.cpp:106] Iteration 5620, lr = 0.01
I0302 00:24:15.622328  9663 solver.cpp:237] Iteration 5640, loss = 0.000136711
I0302 00:24:15.622360  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00013676 (* 1 = 0.00013676 loss)
I0302 00:24:15.622370  9663 sgd_solver.cpp:106] Iteration 5640, lr = 0.01
I0302 00:24:45.614413  9663 solver.cpp:237] Iteration 5660, loss = 9.92946e-05
I0302 00:24:45.614444  9663 solver.cpp:253]     Train net output #0: loss_cls = 9.93428e-05 (* 1 = 9.93428e-05 loss)
I0302 00:24:45.614454  9663 sgd_solver.cpp:106] Iteration 5660, lr = 0.01
I0302 00:25:14.154570  9663 solver.cpp:237] Iteration 5680, loss = 5.32467e-05
I0302 00:25:14.154602  9663 solver.cpp:253]     Train net output #0: loss_cls = 5.32949e-05 (* 1 = 5.32949e-05 loss)
I0302 00:25:14.154610  9663 sgd_solver.cpp:106] Iteration 5680, lr = 0.01
I0302 00:25:43.066169  9663 solver.cpp:237] Iteration 5700, loss = 9.36091e-05
I0302 00:25:43.066200  9663 solver.cpp:253]     Train net output #0: loss_cls = 9.36572e-05 (* 1 = 9.36572e-05 loss)
I0302 00:25:43.066208  9663 sgd_solver.cpp:106] Iteration 5700, lr = 0.01
I0302 00:26:12.102952  9663 solver.cpp:237] Iteration 5720, loss = 0.000156989
I0302 00:26:12.102985  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000157038 (* 1 = 0.000157038 loss)
I0302 00:26:12.102993  9663 sgd_solver.cpp:106] Iteration 5720, lr = 0.01
I0302 00:26:41.451721  9663 solver.cpp:237] Iteration 5740, loss = 0.000173956
I0302 00:26:41.451753  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000174005 (* 1 = 0.000174005 loss)
I0302 00:26:41.451762  9663 sgd_solver.cpp:106] Iteration 5740, lr = 0.01
I0302 00:27:10.225145  9663 solver.cpp:237] Iteration 5760, loss = 3.4849e-05
I0302 00:27:10.225179  9663 solver.cpp:253]     Train net output #0: loss_cls = 3.48978e-05 (* 1 = 3.48978e-05 loss)
I0302 00:27:10.225189  9663 sgd_solver.cpp:106] Iteration 5760, lr = 0.01
I0302 00:27:39.080293  9663 solver.cpp:237] Iteration 5780, loss = 8.35667e-05
I0302 00:27:39.080327  9663 solver.cpp:253]     Train net output #0: loss_cls = 8.36154e-05 (* 1 = 8.36154e-05 loss)
I0302 00:27:39.080335  9663 sgd_solver.cpp:106] Iteration 5780, lr = 0.01
I0302 00:28:08.005336  9663 solver.cpp:237] Iteration 5800, loss = 0.000314844
I0302 00:28:08.005370  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000314892 (* 1 = 0.000314892 loss)
I0302 00:28:08.005383  9663 sgd_solver.cpp:106] Iteration 5800, lr = 0.01
I0302 00:28:36.758887  9663 solver.cpp:237] Iteration 5820, loss = 0.000327785
I0302 00:28:36.758918  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000327833 (* 1 = 0.000327833 loss)
I0302 00:28:36.758926  9663 sgd_solver.cpp:106] Iteration 5820, lr = 0.01
I0302 00:29:05.679328  9663 solver.cpp:237] Iteration 5840, loss = 6.64823e-05
I0302 00:29:05.679360  9663 solver.cpp:253]     Train net output #0: loss_cls = 6.65306e-05 (* 1 = 6.65306e-05 loss)
I0302 00:29:05.679369  9663 sgd_solver.cpp:106] Iteration 5840, lr = 0.01
I0302 00:29:34.595839  9663 solver.cpp:237] Iteration 5860, loss = 7.2688e-05
I0302 00:29:34.595872  9663 solver.cpp:253]     Train net output #0: loss_cls = 7.27361e-05 (* 1 = 7.27361e-05 loss)
I0302 00:29:34.595881  9663 sgd_solver.cpp:106] Iteration 5860, lr = 0.01
I0302 00:30:03.754271  9663 solver.cpp:237] Iteration 5880, loss = 4.52213e-05
I0302 00:30:03.754305  9663 solver.cpp:253]     Train net output #0: loss_cls = 4.52694e-05 (* 1 = 4.52694e-05 loss)
I0302 00:30:03.754314  9663 sgd_solver.cpp:106] Iteration 5880, lr = 0.01
I0302 00:30:32.751004  9663 solver.cpp:237] Iteration 5900, loss = 0.000265401
I0302 00:30:32.751039  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000265449 (* 1 = 0.000265449 loss)
I0302 00:30:32.751049  9663 sgd_solver.cpp:106] Iteration 5900, lr = 0.01
I0302 00:31:01.747956  9663 solver.cpp:237] Iteration 5920, loss = 3.9324e-05
I0302 00:31:01.747988  9663 solver.cpp:253]     Train net output #0: loss_cls = 3.93718e-05 (* 1 = 3.93718e-05 loss)
I0302 00:31:01.747997  9663 sgd_solver.cpp:106] Iteration 5920, lr = 0.01
I0302 00:31:30.713562  9663 solver.cpp:237] Iteration 5940, loss = 3.16251e-05
I0302 00:31:30.713593  9663 solver.cpp:253]     Train net output #0: loss_cls = 3.1673e-05 (* 1 = 3.1673e-05 loss)
I0302 00:31:30.713603  9663 sgd_solver.cpp:106] Iteration 5940, lr = 0.01
I0302 00:31:59.613168  9663 solver.cpp:237] Iteration 5960, loss = 0.00108821
I0302 00:31:59.613199  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00108826 (* 1 = 0.00108826 loss)
I0302 00:31:59.613209  9663 sgd_solver.cpp:106] Iteration 5960, lr = 0.01
I0302 00:32:28.337018  9663 solver.cpp:237] Iteration 5980, loss = 0.00016987
I0302 00:32:28.337054  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000169918 (* 1 = 0.000169918 loss)
I0302 00:32:28.337062  9663 sgd_solver.cpp:106] Iteration 5980, lr = 0.01
I0302 00:32:57.285220  9663 solver.cpp:237] Iteration 6000, loss = 3.70647e-05
I0302 00:32:57.285254  9663 solver.cpp:253]     Train net output #0: loss_cls = 3.71125e-05 (* 1 = 3.71125e-05 loss)
I0302 00:32:57.285262  9663 sgd_solver.cpp:106] Iteration 6000, lr = 0.01
I0302 00:33:04.621207  9663 blocking_queue.cpp:50] Data layer prefetch queue empty
I0302 00:33:26.723646  9663 solver.cpp:237] Iteration 6020, loss = 0.00011575
I0302 00:33:26.723678  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000115798 (* 1 = 0.000115798 loss)
I0302 00:33:26.723687  9663 sgd_solver.cpp:106] Iteration 6020, lr = 0.01
I0302 00:33:56.316975  9663 solver.cpp:237] Iteration 6040, loss = 9.81327e-05
I0302 00:33:56.317008  9663 solver.cpp:253]     Train net output #0: loss_cls = 9.81807e-05 (* 1 = 9.81807e-05 loss)
I0302 00:33:56.317018  9663 sgd_solver.cpp:106] Iteration 6040, lr = 0.01
I0302 00:34:25.256847  9663 solver.cpp:237] Iteration 6060, loss = 9.37528e-05
I0302 00:34:25.256881  9663 solver.cpp:253]     Train net output #0: loss_cls = 9.38006e-05 (* 1 = 9.38006e-05 loss)
I0302 00:34:25.256891  9663 sgd_solver.cpp:106] Iteration 6060, lr = 0.01
I0302 00:34:54.316834  9663 solver.cpp:237] Iteration 6080, loss = 0.000240852
I0302 00:34:54.316866  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000240901 (* 1 = 0.000240901 loss)
I0302 00:34:54.316875  9663 sgd_solver.cpp:106] Iteration 6080, lr = 0.01
I0302 00:35:23.507364  9663 solver.cpp:237] Iteration 6100, loss = 4.8097e-05
I0302 00:35:23.507397  9663 solver.cpp:253]     Train net output #0: loss_cls = 4.81457e-05 (* 1 = 4.81457e-05 loss)
I0302 00:35:23.507407  9663 sgd_solver.cpp:106] Iteration 6100, lr = 0.01
I0302 00:35:52.337798  9663 solver.cpp:237] Iteration 6120, loss = 9.56733e-05
I0302 00:35:52.337833  9663 solver.cpp:253]     Train net output #0: loss_cls = 9.57219e-05 (* 1 = 9.57219e-05 loss)
I0302 00:35:52.337843  9663 sgd_solver.cpp:106] Iteration 6120, lr = 0.01
I0302 00:36:21.101608  9663 solver.cpp:237] Iteration 6140, loss = 0.000172069
I0302 00:36:21.101644  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000172118 (* 1 = 0.000172118 loss)
I0302 00:36:21.101654  9663 sgd_solver.cpp:106] Iteration 6140, lr = 0.01
I0302 00:36:49.870679  9663 solver.cpp:237] Iteration 6160, loss = 3.26816e-05
I0302 00:36:49.870712  9663 solver.cpp:253]     Train net output #0: loss_cls = 3.27309e-05 (* 1 = 3.27309e-05 loss)
I0302 00:36:49.870721  9663 sgd_solver.cpp:106] Iteration 6160, lr = 0.01
I0302 00:37:18.862417  9663 solver.cpp:237] Iteration 6180, loss = 0.000264588
I0302 00:37:18.862452  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000264637 (* 1 = 0.000264637 loss)
I0302 00:37:18.862462  9663 sgd_solver.cpp:106] Iteration 6180, lr = 0.01
I0302 00:37:47.935868  9663 solver.cpp:237] Iteration 6200, loss = 5.13527e-05
I0302 00:37:47.935899  9663 solver.cpp:253]     Train net output #0: loss_cls = 5.1402e-05 (* 1 = 5.1402e-05 loss)
I0302 00:37:47.935907  9663 sgd_solver.cpp:106] Iteration 6200, lr = 0.01
I0302 00:38:16.784027  9663 solver.cpp:237] Iteration 6220, loss = 0.000110217
I0302 00:38:16.784060  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000110266 (* 1 = 0.000110266 loss)
I0302 00:38:16.784068  9663 sgd_solver.cpp:106] Iteration 6220, lr = 0.01
I0302 00:38:46.062387  9663 solver.cpp:237] Iteration 6240, loss = 5.24019e-05
I0302 00:38:46.062419  9663 solver.cpp:253]     Train net output #0: loss_cls = 5.24511e-05 (* 1 = 5.24511e-05 loss)
I0302 00:38:46.062433  9663 sgd_solver.cpp:106] Iteration 6240, lr = 0.01
I0302 00:39:14.892343  9663 solver.cpp:237] Iteration 6260, loss = 7.24596e-05
I0302 00:39:14.892377  9663 solver.cpp:253]     Train net output #0: loss_cls = 7.25089e-05 (* 1 = 7.25089e-05 loss)
I0302 00:39:14.892387  9663 sgd_solver.cpp:106] Iteration 6260, lr = 0.01
I0302 00:39:43.872366  9663 solver.cpp:237] Iteration 6280, loss = 4.17977e-05
I0302 00:39:43.872400  9663 solver.cpp:253]     Train net output #0: loss_cls = 4.18469e-05 (* 1 = 4.18469e-05 loss)
I0302 00:39:43.872411  9663 sgd_solver.cpp:106] Iteration 6280, lr = 0.01
I0302 00:40:12.791095  9663 solver.cpp:237] Iteration 6300, loss = 7.34777e-05
I0302 00:40:12.791126  9663 solver.cpp:253]     Train net output #0: loss_cls = 7.3527e-05 (* 1 = 7.3527e-05 loss)
I0302 00:40:12.791134  9663 sgd_solver.cpp:106] Iteration 6300, lr = 0.01
I0302 00:40:41.510584  9663 solver.cpp:237] Iteration 6320, loss = 0.000260028
I0302 00:40:41.510615  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000260077 (* 1 = 0.000260077 loss)
I0302 00:40:41.510624  9663 sgd_solver.cpp:106] Iteration 6320, lr = 0.01
I0302 00:41:10.553182  9663 solver.cpp:237] Iteration 6340, loss = 5.25916e-05
I0302 00:41:10.553216  9663 solver.cpp:253]     Train net output #0: loss_cls = 5.26408e-05 (* 1 = 5.26408e-05 loss)
I0302 00:41:10.553225  9663 sgd_solver.cpp:106] Iteration 6340, lr = 0.01
I0302 00:41:39.122383  9663 solver.cpp:237] Iteration 6360, loss = 0.000131442
I0302 00:41:39.122414  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000131492 (* 1 = 0.000131492 loss)
I0302 00:41:39.122424  9663 sgd_solver.cpp:106] Iteration 6360, lr = 0.01
I0302 00:42:07.957563  9663 solver.cpp:237] Iteration 6380, loss = 0.00014234
I0302 00:42:07.957597  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00014239 (* 1 = 0.00014239 loss)
I0302 00:42:07.957607  9663 sgd_solver.cpp:106] Iteration 6380, lr = 0.01
I0302 00:42:36.916245  9663 solver.cpp:237] Iteration 6400, loss = 0.00023512
I0302 00:42:36.916278  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00023517 (* 1 = 0.00023517 loss)
I0302 00:42:36.916287  9663 sgd_solver.cpp:106] Iteration 6400, lr = 0.01
I0302 00:43:05.807983  9663 solver.cpp:237] Iteration 6420, loss = 0.000177053
I0302 00:43:05.808015  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000177103 (* 1 = 0.000177103 loss)
I0302 00:43:05.808024  9663 sgd_solver.cpp:106] Iteration 6420, lr = 0.01
I0302 00:43:34.793579  9663 solver.cpp:237] Iteration 6440, loss = 0.00029193
I0302 00:43:34.793612  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00029198 (* 1 = 0.00029198 loss)
I0302 00:43:34.793622  9663 sgd_solver.cpp:106] Iteration 6440, lr = 0.01
I0302 00:44:03.615751  9663 solver.cpp:237] Iteration 6460, loss = 0.00195282
I0302 00:44:03.615783  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00195287 (* 1 = 0.00195287 loss)
I0302 00:44:03.615792  9663 sgd_solver.cpp:106] Iteration 6460, lr = 0.01
I0302 00:44:32.655061  9663 solver.cpp:237] Iteration 6480, loss = 4.35959e-05
I0302 00:44:32.655092  9663 solver.cpp:253]     Train net output #0: loss_cls = 4.36465e-05 (* 1 = 4.36465e-05 loss)
I0302 00:44:32.655102  9663 sgd_solver.cpp:106] Iteration 6480, lr = 0.01
I0302 00:45:01.567257  9663 solver.cpp:237] Iteration 6500, loss = 9.68684e-05
I0302 00:45:01.567291  9663 solver.cpp:253]     Train net output #0: loss_cls = 9.69191e-05 (* 1 = 9.69191e-05 loss)
I0302 00:45:01.567299  9663 sgd_solver.cpp:106] Iteration 6500, lr = 0.01
I0302 00:45:30.524595  9663 solver.cpp:237] Iteration 6520, loss = 0.00191109
I0302 00:45:30.524627  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00191114 (* 1 = 0.00191114 loss)
I0302 00:45:30.524636  9663 sgd_solver.cpp:106] Iteration 6520, lr = 0.01
I0302 00:45:59.321081  9663 solver.cpp:237] Iteration 6540, loss = 0.000241036
I0302 00:45:59.321115  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000241087 (* 1 = 0.000241087 loss)
I0302 00:45:59.321123  9663 sgd_solver.cpp:106] Iteration 6540, lr = 0.01
I0302 00:46:28.284508  9663 solver.cpp:237] Iteration 6560, loss = 0.000210786
I0302 00:46:28.284543  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000210837 (* 1 = 0.000210837 loss)
I0302 00:46:28.284554  9663 sgd_solver.cpp:106] Iteration 6560, lr = 0.01
I0302 00:46:57.480170  9663 solver.cpp:237] Iteration 6580, loss = 0.000487245
I0302 00:46:57.480201  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000487296 (* 1 = 0.000487296 loss)
I0302 00:46:57.480211  9663 sgd_solver.cpp:106] Iteration 6580, lr = 0.01
I0302 00:47:26.370003  9663 solver.cpp:237] Iteration 6600, loss = 0.000126155
I0302 00:47:26.370035  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000126207 (* 1 = 0.000126207 loss)
I0302 00:47:26.370044  9663 sgd_solver.cpp:106] Iteration 6600, lr = 0.01
I0302 00:47:55.390822  9663 solver.cpp:237] Iteration 6620, loss = 0.000202159
I0302 00:47:55.390856  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00020221 (* 1 = 0.00020221 loss)
I0302 00:47:55.390864  9663 sgd_solver.cpp:106] Iteration 6620, lr = 0.01
I0302 00:48:24.554455  9663 solver.cpp:237] Iteration 6640, loss = 9.77346e-05
I0302 00:48:24.554488  9663 solver.cpp:253]     Train net output #0: loss_cls = 9.77859e-05 (* 1 = 9.77859e-05 loss)
I0302 00:48:24.554497  9663 sgd_solver.cpp:106] Iteration 6640, lr = 0.01
I0302 00:48:53.497715  9663 solver.cpp:237] Iteration 6660, loss = 0.000407729
I0302 00:48:53.497750  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00040778 (* 1 = 0.00040778 loss)
I0302 00:48:53.497761  9663 sgd_solver.cpp:106] Iteration 6660, lr = 0.01
I0302 00:49:22.341917  9663 solver.cpp:237] Iteration 6680, loss = 0.000231363
I0302 00:49:22.341950  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000231414 (* 1 = 0.000231414 loss)
I0302 00:49:22.341959  9663 sgd_solver.cpp:106] Iteration 6680, lr = 0.01
I0302 00:49:51.457779  9663 solver.cpp:237] Iteration 6700, loss = 0.000162701
I0302 00:49:51.457813  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000162752 (* 1 = 0.000162752 loss)
I0302 00:49:51.457823  9663 sgd_solver.cpp:106] Iteration 6700, lr = 0.01
I0302 00:50:20.543552  9663 solver.cpp:237] Iteration 6720, loss = 0.000111562
I0302 00:50:20.543584  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000111613 (* 1 = 0.000111613 loss)
I0302 00:50:20.543593  9663 sgd_solver.cpp:106] Iteration 6720, lr = 0.01
I0302 00:50:49.389734  9663 solver.cpp:237] Iteration 6740, loss = 0.000187216
I0302 00:50:49.389768  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000187268 (* 1 = 0.000187268 loss)
I0302 00:50:49.389777  9663 sgd_solver.cpp:106] Iteration 6740, lr = 0.01
I0302 00:51:18.336436  9663 solver.cpp:237] Iteration 6760, loss = 4.93008e-05
I0302 00:51:18.336469  9663 solver.cpp:253]     Train net output #0: loss_cls = 4.9352e-05 (* 1 = 4.9352e-05 loss)
I0302 00:51:18.336482  9663 sgd_solver.cpp:106] Iteration 6760, lr = 0.01
I0302 00:51:47.526633  9663 solver.cpp:237] Iteration 6780, loss = 0.000186002
I0302 00:51:47.526666  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000186053 (* 1 = 0.000186053 loss)
I0302 00:51:47.526675  9663 sgd_solver.cpp:106] Iteration 6780, lr = 0.01
I0302 00:52:16.293154  9663 solver.cpp:237] Iteration 6800, loss = 0.00043128
I0302 00:52:16.293186  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000431331 (* 1 = 0.000431331 loss)
I0302 00:52:16.293195  9663 sgd_solver.cpp:106] Iteration 6800, lr = 0.01
I0302 00:52:45.107933  9663 solver.cpp:237] Iteration 6820, loss = 0.000139103
I0302 00:52:45.107967  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000139155 (* 1 = 0.000139155 loss)
I0302 00:52:45.107977  9663 sgd_solver.cpp:106] Iteration 6820, lr = 0.01
I0302 00:53:13.952584  9663 solver.cpp:237] Iteration 6840, loss = 0.000310014
I0302 00:53:13.952617  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000310065 (* 1 = 0.000310065 loss)
I0302 00:53:13.952626  9663 sgd_solver.cpp:106] Iteration 6840, lr = 0.01
I0302 00:53:42.975714  9663 solver.cpp:237] Iteration 6860, loss = 2.18119e-05
I0302 00:53:42.975747  9663 solver.cpp:253]     Train net output #0: loss_cls = 2.18632e-05 (* 1 = 2.18632e-05 loss)
I0302 00:53:42.975757  9663 sgd_solver.cpp:106] Iteration 6860, lr = 0.01
I0302 00:54:11.908689  9663 solver.cpp:237] Iteration 6880, loss = 0.000160576
I0302 00:54:11.908723  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000160627 (* 1 = 0.000160627 loss)
I0302 00:54:11.908733  9663 sgd_solver.cpp:106] Iteration 6880, lr = 0.01
I0302 00:54:40.775715  9663 solver.cpp:237] Iteration 6900, loss = 4.01448e-05
I0302 00:54:40.775748  9663 solver.cpp:253]     Train net output #0: loss_cls = 4.01961e-05 (* 1 = 4.01961e-05 loss)
I0302 00:54:40.775758  9663 sgd_solver.cpp:106] Iteration 6900, lr = 0.01
I0302 00:55:09.623126  9663 solver.cpp:237] Iteration 6920, loss = 0.000229013
I0302 00:55:09.623158  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000229065 (* 1 = 0.000229065 loss)
I0302 00:55:09.623168  9663 sgd_solver.cpp:106] Iteration 6920, lr = 0.01
I0302 00:55:38.429154  9663 solver.cpp:237] Iteration 6940, loss = 3.13851e-05
I0302 00:55:38.429188  9663 solver.cpp:253]     Train net output #0: loss_cls = 3.14365e-05 (* 1 = 3.14365e-05 loss)
I0302 00:55:38.429198  9663 sgd_solver.cpp:106] Iteration 6940, lr = 0.01
I0302 00:56:07.543004  9663 solver.cpp:237] Iteration 6960, loss = 4.54495e-05
I0302 00:56:07.543035  9663 solver.cpp:253]     Train net output #0: loss_cls = 4.55008e-05 (* 1 = 4.55008e-05 loss)
I0302 00:56:07.543043  9663 sgd_solver.cpp:106] Iteration 6960, lr = 0.01
I0302 00:56:36.498941  9663 solver.cpp:237] Iteration 6980, loss = 0.000395452
I0302 00:56:36.498972  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000395503 (* 1 = 0.000395503 loss)
I0302 00:56:36.498982  9663 sgd_solver.cpp:106] Iteration 6980, lr = 0.01
I0302 00:57:05.375469  9663 solver.cpp:237] Iteration 7000, loss = 0.000466136
I0302 00:57:05.375500  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000466187 (* 1 = 0.000466187 loss)
I0302 00:57:05.375509  9663 sgd_solver.cpp:106] Iteration 7000, lr = 0.01
I0302 00:57:12.578877  9663 blocking_queue.cpp:50] Data layer prefetch queue empty
I0302 00:57:34.189328  9663 solver.cpp:237] Iteration 7020, loss = 8.95775e-05
I0302 00:57:34.189365  9663 solver.cpp:253]     Train net output #0: loss_cls = 8.96288e-05 (* 1 = 8.96288e-05 loss)
I0302 00:57:34.189375  9663 sgd_solver.cpp:106] Iteration 7020, lr = 0.01
I0302 00:58:03.241665  9663 solver.cpp:237] Iteration 7040, loss = 0.000247021
I0302 00:58:03.241698  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000247073 (* 1 = 0.000247073 loss)
I0302 00:58:03.241708  9663 sgd_solver.cpp:106] Iteration 7040, lr = 0.01
I0302 00:58:32.084107  9663 solver.cpp:237] Iteration 7060, loss = 9.70191e-05
I0302 00:58:32.084141  9663 solver.cpp:253]     Train net output #0: loss_cls = 9.70707e-05 (* 1 = 9.70707e-05 loss)
I0302 00:58:32.084149  9663 sgd_solver.cpp:106] Iteration 7060, lr = 0.01
I0302 00:59:01.174785  9663 solver.cpp:237] Iteration 7080, loss = 4.25015e-05
I0302 00:59:01.174818  9663 solver.cpp:253]     Train net output #0: loss_cls = 4.25529e-05 (* 1 = 4.25529e-05 loss)
I0302 00:59:01.174828  9663 sgd_solver.cpp:106] Iteration 7080, lr = 0.01
I0302 00:59:30.074596  9663 solver.cpp:237] Iteration 7100, loss = 7.38551e-05
I0302 00:59:30.074630  9663 solver.cpp:253]     Train net output #0: loss_cls = 7.39065e-05 (* 1 = 7.39065e-05 loss)
I0302 00:59:30.074640  9663 sgd_solver.cpp:106] Iteration 7100, lr = 0.01
I0302 00:59:59.052559  9663 solver.cpp:237] Iteration 7120, loss = 3.09927e-05
I0302 00:59:59.052592  9663 solver.cpp:253]     Train net output #0: loss_cls = 3.1044e-05 (* 1 = 3.1044e-05 loss)
I0302 00:59:59.052603  9663 sgd_solver.cpp:106] Iteration 7120, lr = 0.01
I0302 01:00:27.979943  9663 solver.cpp:237] Iteration 7140, loss = 0.000321021
I0302 01:00:27.979975  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000321072 (* 1 = 0.000321072 loss)
I0302 01:00:27.979984  9663 sgd_solver.cpp:106] Iteration 7140, lr = 0.01
I0302 01:00:57.025717  9663 solver.cpp:237] Iteration 7160, loss = 5.19355e-05
I0302 01:00:57.025749  9663 solver.cpp:253]     Train net output #0: loss_cls = 5.19868e-05 (* 1 = 5.19868e-05 loss)
I0302 01:00:57.025758  9663 sgd_solver.cpp:106] Iteration 7160, lr = 0.01
I0302 01:01:25.910519  9663 solver.cpp:237] Iteration 7180, loss = 0.000498547
I0302 01:01:25.910555  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000498598 (* 1 = 0.000498598 loss)
I0302 01:01:25.910564  9663 sgd_solver.cpp:106] Iteration 7180, lr = 0.01
I0302 01:01:54.963788  9663 solver.cpp:237] Iteration 7200, loss = 7.13196e-05
I0302 01:01:54.963821  9663 solver.cpp:253]     Train net output #0: loss_cls = 7.13707e-05 (* 1 = 7.13707e-05 loss)
I0302 01:01:54.963830  9663 sgd_solver.cpp:106] Iteration 7200, lr = 0.01
I0302 01:02:23.775638  9663 solver.cpp:237] Iteration 7220, loss = 6.64685e-05
I0302 01:02:23.775671  9663 solver.cpp:253]     Train net output #0: loss_cls = 6.65198e-05 (* 1 = 6.65198e-05 loss)
I0302 01:02:23.775679  9663 sgd_solver.cpp:106] Iteration 7220, lr = 0.01
I0302 01:02:52.835453  9663 solver.cpp:237] Iteration 7240, loss = 5.23798e-05
I0302 01:02:52.835484  9663 solver.cpp:253]     Train net output #0: loss_cls = 5.24309e-05 (* 1 = 5.24309e-05 loss)
I0302 01:02:52.835494  9663 sgd_solver.cpp:106] Iteration 7240, lr = 0.01
I0302 01:03:21.684396  9663 solver.cpp:237] Iteration 7260, loss = 9.5322e-05
I0302 01:03:21.684430  9663 solver.cpp:253]     Train net output #0: loss_cls = 9.53731e-05 (* 1 = 9.53731e-05 loss)
I0302 01:03:21.684439  9663 sgd_solver.cpp:106] Iteration 7260, lr = 0.01
I0302 01:03:50.754139  9663 solver.cpp:237] Iteration 7280, loss = 0.000110864
I0302 01:03:50.754170  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000110915 (* 1 = 0.000110915 loss)
I0302 01:03:50.754179  9663 sgd_solver.cpp:106] Iteration 7280, lr = 0.01
I0302 01:04:19.683318  9663 solver.cpp:237] Iteration 7300, loss = 7.60661e-05
I0302 01:04:19.683351  9663 solver.cpp:253]     Train net output #0: loss_cls = 7.6117e-05 (* 1 = 7.6117e-05 loss)
I0302 01:04:19.683360  9663 sgd_solver.cpp:106] Iteration 7300, lr = 0.01
I0302 01:04:48.423146  9663 solver.cpp:237] Iteration 7320, loss = 5.05605e-05
I0302 01:04:48.423182  9663 solver.cpp:253]     Train net output #0: loss_cls = 5.06114e-05 (* 1 = 5.06114e-05 loss)
I0302 01:04:48.423192  9663 sgd_solver.cpp:106] Iteration 7320, lr = 0.01
I0302 01:05:17.185991  9663 solver.cpp:237] Iteration 7340, loss = 3.71489e-05
I0302 01:05:17.186022  9663 solver.cpp:253]     Train net output #0: loss_cls = 3.71998e-05 (* 1 = 3.71998e-05 loss)
I0302 01:05:17.186031  9663 sgd_solver.cpp:106] Iteration 7340, lr = 0.01
I0302 01:05:46.229997  9663 solver.cpp:237] Iteration 7360, loss = 3.16634e-05
I0302 01:05:46.230028  9663 solver.cpp:253]     Train net output #0: loss_cls = 3.17146e-05 (* 1 = 3.17146e-05 loss)
I0302 01:05:46.230037  9663 sgd_solver.cpp:106] Iteration 7360, lr = 0.01
I0302 01:06:15.169847  9663 solver.cpp:237] Iteration 7380, loss = 0.000215465
I0302 01:06:15.169879  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000215516 (* 1 = 0.000215516 loss)
I0302 01:06:15.169888  9663 sgd_solver.cpp:106] Iteration 7380, lr = 0.01
I0302 01:06:43.528784  9663 solver.cpp:237] Iteration 7400, loss = 0.000596301
I0302 01:06:43.528822  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000596352 (* 1 = 0.000596352 loss)
I0302 01:06:43.528832  9663 sgd_solver.cpp:106] Iteration 7400, lr = 0.01
I0302 01:07:12.667515  9663 solver.cpp:237] Iteration 7420, loss = 7.60107e-05
I0302 01:07:12.667548  9663 solver.cpp:253]     Train net output #0: loss_cls = 7.60617e-05 (* 1 = 7.60617e-05 loss)
I0302 01:07:12.667558  9663 sgd_solver.cpp:106] Iteration 7420, lr = 0.01
I0302 01:07:42.038991  9663 solver.cpp:237] Iteration 7440, loss = 0.000277434
I0302 01:07:42.039022  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000277485 (* 1 = 0.000277485 loss)
I0302 01:07:42.039031  9663 sgd_solver.cpp:106] Iteration 7440, lr = 0.01
I0302 01:08:10.867576  9663 solver.cpp:237] Iteration 7460, loss = 0.000365185
I0302 01:08:10.867606  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000365236 (* 1 = 0.000365236 loss)
I0302 01:08:10.867616  9663 sgd_solver.cpp:106] Iteration 7460, lr = 0.01
I0302 01:08:39.435744  9663 solver.cpp:237] Iteration 7480, loss = 0.000141591
I0302 01:08:39.435773  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000141642 (* 1 = 0.000141642 loss)
I0302 01:08:39.435782  9663 sgd_solver.cpp:106] Iteration 7480, lr = 0.01
I0302 01:09:08.557018  9663 solver.cpp:237] Iteration 7500, loss = 0.000517469
I0302 01:09:08.557049  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00051752 (* 1 = 0.00051752 loss)
I0302 01:09:08.557057  9663 sgd_solver.cpp:106] Iteration 7500, lr = 0.01
I0302 01:09:37.414290  9663 solver.cpp:237] Iteration 7520, loss = 5.71475e-05
I0302 01:09:37.414322  9663 solver.cpp:253]     Train net output #0: loss_cls = 5.71988e-05 (* 1 = 5.71988e-05 loss)
I0302 01:09:37.414331  9663 sgd_solver.cpp:106] Iteration 7520, lr = 0.01
I0302 01:10:06.124307  9663 solver.cpp:237] Iteration 7540, loss = 0.000234425
I0302 01:10:06.124341  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000234476 (* 1 = 0.000234476 loss)
I0302 01:10:06.124349  9663 sgd_solver.cpp:106] Iteration 7540, lr = 0.01
I0302 01:10:35.252152  9663 solver.cpp:237] Iteration 7560, loss = 0.00255477
I0302 01:10:35.252184  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00255482 (* 1 = 0.00255482 loss)
I0302 01:10:35.252194  9663 sgd_solver.cpp:106] Iteration 7560, lr = 0.01
I0302 01:11:03.978297  9663 solver.cpp:237] Iteration 7580, loss = 6.81879e-05
I0302 01:11:03.978328  9663 solver.cpp:253]     Train net output #0: loss_cls = 6.82392e-05 (* 1 = 6.82392e-05 loss)
I0302 01:11:03.978338  9663 sgd_solver.cpp:106] Iteration 7580, lr = 0.01
I0302 01:11:32.600946  9663 solver.cpp:237] Iteration 7600, loss = 7.06765e-05
I0302 01:11:32.600977  9663 solver.cpp:253]     Train net output #0: loss_cls = 7.07278e-05 (* 1 = 7.07278e-05 loss)
I0302 01:11:32.600986  9663 sgd_solver.cpp:106] Iteration 7600, lr = 0.01
I0302 01:12:01.326689  9663 solver.cpp:237] Iteration 7620, loss = 9.30895e-05
I0302 01:12:01.326719  9663 solver.cpp:253]     Train net output #0: loss_cls = 9.31408e-05 (* 1 = 9.31408e-05 loss)
I0302 01:12:01.326731  9663 sgd_solver.cpp:106] Iteration 7620, lr = 0.01
I0302 01:12:30.267910  9663 solver.cpp:237] Iteration 7640, loss = 9.19008e-05
I0302 01:12:30.267941  9663 solver.cpp:253]     Train net output #0: loss_cls = 9.19521e-05 (* 1 = 9.19521e-05 loss)
I0302 01:12:30.267949  9663 sgd_solver.cpp:106] Iteration 7640, lr = 0.01
I0302 01:12:59.477120  9663 solver.cpp:237] Iteration 7660, loss = 8.50365e-05
I0302 01:12:59.477150  9663 solver.cpp:253]     Train net output #0: loss_cls = 8.50878e-05 (* 1 = 8.50878e-05 loss)
I0302 01:12:59.477159  9663 sgd_solver.cpp:106] Iteration 7660, lr = 0.01
I0302 01:13:28.639488  9663 solver.cpp:237] Iteration 7680, loss = 0.000174214
I0302 01:13:28.639518  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000174266 (* 1 = 0.000174266 loss)
I0302 01:13:28.639526  9663 sgd_solver.cpp:106] Iteration 7680, lr = 0.01
I0302 01:13:57.509228  9663 solver.cpp:237] Iteration 7700, loss = 0.000230474
I0302 01:13:57.509259  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000230525 (* 1 = 0.000230525 loss)
I0302 01:13:57.509268  9663 sgd_solver.cpp:106] Iteration 7700, lr = 0.01
I0302 01:14:25.991652  9663 solver.cpp:237] Iteration 7720, loss = 0.00012054
I0302 01:14:25.991683  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000120591 (* 1 = 0.000120591 loss)
I0302 01:14:25.991691  9663 sgd_solver.cpp:106] Iteration 7720, lr = 0.01
I0302 01:14:55.094734  9663 solver.cpp:237] Iteration 7740, loss = 3.56651e-05
I0302 01:14:55.094764  9663 solver.cpp:253]     Train net output #0: loss_cls = 3.57164e-05 (* 1 = 3.57164e-05 loss)
I0302 01:14:55.094774  9663 sgd_solver.cpp:106] Iteration 7740, lr = 0.01
I0302 01:15:24.153056  9663 solver.cpp:237] Iteration 7760, loss = 0.000470911
I0302 01:15:24.153087  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000470962 (* 1 = 0.000470962 loss)
I0302 01:15:24.153095  9663 sgd_solver.cpp:106] Iteration 7760, lr = 0.01
I0302 01:15:52.805881  9663 solver.cpp:237] Iteration 7780, loss = 0.000204062
I0302 01:15:52.805912  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000204113 (* 1 = 0.000204113 loss)
I0302 01:15:52.805920  9663 sgd_solver.cpp:106] Iteration 7780, lr = 0.01
I0302 01:16:21.924469  9663 solver.cpp:237] Iteration 7800, loss = 0.000207694
I0302 01:16:21.924500  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000207745 (* 1 = 0.000207745 loss)
I0302 01:16:21.924510  9663 sgd_solver.cpp:106] Iteration 7800, lr = 0.01
I0302 01:16:50.651252  9663 solver.cpp:237] Iteration 7820, loss = 0.00019142
I0302 01:16:50.651284  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000191472 (* 1 = 0.000191472 loss)
I0302 01:16:50.651293  9663 sgd_solver.cpp:106] Iteration 7820, lr = 0.01
I0302 01:17:19.649999  9663 solver.cpp:237] Iteration 7840, loss = 7.33385e-05
I0302 01:17:19.650030  9663 solver.cpp:253]     Train net output #0: loss_cls = 7.33898e-05 (* 1 = 7.33898e-05 loss)
I0302 01:17:19.650039  9663 sgd_solver.cpp:106] Iteration 7840, lr = 0.01
I0302 01:17:47.963798  9663 solver.cpp:237] Iteration 7860, loss = 0.000137984
I0302 01:17:47.963829  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000138035 (* 1 = 0.000138035 loss)
I0302 01:17:47.963837  9663 sgd_solver.cpp:106] Iteration 7860, lr = 0.01
I0302 01:18:16.832041  9663 solver.cpp:237] Iteration 7880, loss = 0.000399388
I0302 01:18:16.832072  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00039944 (* 1 = 0.00039944 loss)
I0302 01:18:16.832082  9663 sgd_solver.cpp:106] Iteration 7880, lr = 0.01
I0302 01:18:45.802206  9663 solver.cpp:237] Iteration 7900, loss = 0.000564365
I0302 01:18:45.802237  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000564416 (* 1 = 0.000564416 loss)
I0302 01:18:45.802247  9663 sgd_solver.cpp:106] Iteration 7900, lr = 0.01
I0302 01:19:14.494083  9663 solver.cpp:237] Iteration 7920, loss = 8.85617e-05
I0302 01:19:14.494113  9663 solver.cpp:253]     Train net output #0: loss_cls = 8.86129e-05 (* 1 = 8.86129e-05 loss)
I0302 01:19:14.494122  9663 sgd_solver.cpp:106] Iteration 7920, lr = 0.01
I0302 01:19:43.570526  9663 solver.cpp:237] Iteration 7940, loss = 5.47532e-05
I0302 01:19:43.570556  9663 solver.cpp:253]     Train net output #0: loss_cls = 5.48044e-05 (* 1 = 5.48044e-05 loss)
I0302 01:19:43.570565  9663 sgd_solver.cpp:106] Iteration 7940, lr = 0.01
I0302 01:20:12.599139  9663 solver.cpp:237] Iteration 7960, loss = 0.000130287
I0302 01:20:12.599171  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000130338 (* 1 = 0.000130338 loss)
I0302 01:20:12.599179  9663 sgd_solver.cpp:106] Iteration 7960, lr = 0.01
I0302 01:20:41.574666  9663 solver.cpp:237] Iteration 7980, loss = 8.04359e-05
I0302 01:20:41.574699  9663 solver.cpp:253]     Train net output #0: loss_cls = 8.0487e-05 (* 1 = 8.0487e-05 loss)
I0302 01:20:41.574708  9663 sgd_solver.cpp:106] Iteration 7980, lr = 0.01
I0302 01:21:10.501857  9663 solver.cpp:237] Iteration 8000, loss = 0.000246335
I0302 01:21:10.501888  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000246386 (* 1 = 0.000246386 loss)
I0302 01:21:10.501898  9663 sgd_solver.cpp:106] Iteration 8000, lr = 0.01
I0302 01:21:17.789628  9663 blocking_queue.cpp:50] Data layer prefetch queue empty
I0302 01:21:39.348459  9663 solver.cpp:237] Iteration 8020, loss = 6.93025e-05
I0302 01:21:39.348489  9663 solver.cpp:253]     Train net output #0: loss_cls = 6.93537e-05 (* 1 = 6.93537e-05 loss)
I0302 01:21:39.348498  9663 sgd_solver.cpp:106] Iteration 8020, lr = 0.01
I0302 01:22:08.348660  9663 solver.cpp:237] Iteration 8040, loss = 0.000290275
I0302 01:22:08.348690  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000290326 (* 1 = 0.000290326 loss)
I0302 01:22:08.348700  9663 sgd_solver.cpp:106] Iteration 8040, lr = 0.01
I0302 01:22:36.731156  9663 solver.cpp:237] Iteration 8060, loss = 0.000138969
I0302 01:22:36.731200  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00013902 (* 1 = 0.00013902 loss)
I0302 01:22:36.731210  9663 sgd_solver.cpp:106] Iteration 8060, lr = 0.01
I0302 01:23:05.406527  9663 solver.cpp:237] Iteration 8080, loss = 6.34881e-05
I0302 01:23:05.406559  9663 solver.cpp:253]     Train net output #0: loss_cls = 6.35393e-05 (* 1 = 6.35393e-05 loss)
I0302 01:23:05.406569  9663 sgd_solver.cpp:106] Iteration 8080, lr = 0.01
I0302 01:23:34.530907  9663 solver.cpp:237] Iteration 8100, loss = 9.1749e-05
I0302 01:23:34.530939  9663 solver.cpp:253]     Train net output #0: loss_cls = 9.18002e-05 (* 1 = 9.18002e-05 loss)
I0302 01:23:34.530948  9663 sgd_solver.cpp:106] Iteration 8100, lr = 0.01
I0302 01:24:03.305238  9663 solver.cpp:237] Iteration 8120, loss = 0.000247102
I0302 01:24:03.305266  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000247153 (* 1 = 0.000247153 loss)
I0302 01:24:03.305275  9663 sgd_solver.cpp:106] Iteration 8120, lr = 0.01
I0302 01:24:32.278007  9663 solver.cpp:237] Iteration 8140, loss = 3.95055e-05
I0302 01:24:32.278038  9663 solver.cpp:253]     Train net output #0: loss_cls = 3.95566e-05 (* 1 = 3.95566e-05 loss)
I0302 01:24:32.278048  9663 sgd_solver.cpp:106] Iteration 8140, lr = 0.01
I0302 01:25:01.184244  9663 solver.cpp:237] Iteration 8160, loss = 0.00016462
I0302 01:25:01.184275  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000164671 (* 1 = 0.000164671 loss)
I0302 01:25:01.184284  9663 sgd_solver.cpp:106] Iteration 8160, lr = 0.01
I0302 01:25:30.061424  9663 solver.cpp:237] Iteration 8180, loss = 6.92116e-05
I0302 01:25:30.061455  9663 solver.cpp:253]     Train net output #0: loss_cls = 6.92626e-05 (* 1 = 6.92626e-05 loss)
I0302 01:25:30.061465  9663 sgd_solver.cpp:106] Iteration 8180, lr = 0.01
I0302 01:25:58.812170  9663 solver.cpp:237] Iteration 8200, loss = 0.000285116
I0302 01:25:58.812201  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000285167 (* 1 = 0.000285167 loss)
I0302 01:25:58.812209  9663 sgd_solver.cpp:106] Iteration 8200, lr = 0.01
I0302 01:26:27.676334  9663 solver.cpp:237] Iteration 8220, loss = 0.000150433
I0302 01:26:27.676365  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000150484 (* 1 = 0.000150484 loss)
I0302 01:26:27.676374  9663 sgd_solver.cpp:106] Iteration 8220, lr = 0.01
I0302 01:26:56.424991  9663 solver.cpp:237] Iteration 8240, loss = 7.37568e-05
I0302 01:26:56.425022  9663 solver.cpp:253]     Train net output #0: loss_cls = 7.38079e-05 (* 1 = 7.38079e-05 loss)
I0302 01:26:56.425030  9663 sgd_solver.cpp:106] Iteration 8240, lr = 0.01
I0302 01:27:25.457468  9663 solver.cpp:237] Iteration 8260, loss = 0.000105284
I0302 01:27:25.457496  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000105335 (* 1 = 0.000105335 loss)
I0302 01:27:25.457504  9663 sgd_solver.cpp:106] Iteration 8260, lr = 0.01
I0302 01:27:54.063768  9663 solver.cpp:237] Iteration 8280, loss = 0.000159341
I0302 01:27:54.063798  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000159392 (* 1 = 0.000159392 loss)
I0302 01:27:54.063807  9663 sgd_solver.cpp:106] Iteration 8280, lr = 0.01
I0302 01:28:23.020478  9663 solver.cpp:237] Iteration 8300, loss = 0.00159196
I0302 01:28:23.020508  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.00159201 (* 1 = 0.00159201 loss)
I0302 01:28:23.020516  9663 sgd_solver.cpp:106] Iteration 8300, lr = 0.01
I0302 01:28:51.881117  9663 solver.cpp:237] Iteration 8320, loss = 8.69621e-05
I0302 01:28:51.881148  9663 solver.cpp:253]     Train net output #0: loss_cls = 8.70132e-05 (* 1 = 8.70132e-05 loss)
I0302 01:28:51.881157  9663 sgd_solver.cpp:106] Iteration 8320, lr = 0.01
I0302 01:29:20.807216  9663 solver.cpp:237] Iteration 8340, loss = 4.11863e-05
I0302 01:29:20.807245  9663 solver.cpp:253]     Train net output #0: loss_cls = 4.12372e-05 (* 1 = 4.12372e-05 loss)
I0302 01:29:20.807255  9663 sgd_solver.cpp:106] Iteration 8340, lr = 0.01
I0302 01:29:49.564602  9663 solver.cpp:237] Iteration 8360, loss = 0.000163287
I0302 01:29:49.564636  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000163338 (* 1 = 0.000163338 loss)
I0302 01:29:49.564645  9663 sgd_solver.cpp:106] Iteration 8360, lr = 0.01
I0302 01:30:18.488325  9663 solver.cpp:237] Iteration 8380, loss = 2.53961e-05
I0302 01:30:18.488358  9663 solver.cpp:253]     Train net output #0: loss_cls = 2.5447e-05 (* 1 = 2.5447e-05 loss)
I0302 01:30:18.488366  9663 sgd_solver.cpp:106] Iteration 8380, lr = 0.01
I0302 01:30:47.332792  9663 solver.cpp:237] Iteration 8400, loss = 0.000374611
I0302 01:30:47.332824  9663 solver.cpp:253]     Train net output #0: loss_cls = 0.000374662 (* 1 = 0.000374662 loss)
I0302 01:30:47.332833  9663 sgd_solver.cpp:106] Iteration 8400, lr = 0.01
I0302 01:31:16.292917  9663 solver.cpp:237] Iteration 8420, loss = 2.85917e-05
I0302 01:31:16.292948  9663 solver.cpp:253]     Train net output #0: loss_cls = 2.86425e-05 (* 1 = 2.86425e-05 loss)
I0302 01:31:16.292956  9663 sgd_solver.cpp:106] Iteration 8420, lr = 0.01
